
@book{noauthor_nonparametric_2006,
	series = {Springer {Series} in {Statistics}},
	title = {Nonparametric {Functional} {Data} {Analysis}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-0-387-30369-7},
	url = {http://link.springer.com/10.1007/0-387-36620-2},
	language = {en},
	urldate = {2025-01-15},
	publisher = {Springer New York},
	year = {2006},
	doi = {10.1007/0-387-36620-2},
	keywords = {Parametric statistics, Pattern Recognition, calculus, data analysis, econometrics, modeling, nonparametric methods, statistical method, statistics},
}

@incollection{ferraty_functional_2006,
	address = {New York, NY},
	title = {Some {Functional} {Datasets} and {Associated} {Statistical} {Problematics}},
	isbn = {978-0-387-36620-3},
	url = {https://doi.org/10.1007/0-387-36620-2_2},
	language = {en},
	urldate = {2025-01-15},
	booktitle = {Nonparametric {Functional} {Data} {Analysis}: {Theory} and {Practice}},
	publisher = {Springer},
	editor = {Ferraty, Frédéric and Vieu, Philippe},
	year = {2006},
	doi = {10.1007/0-387-36620-2_2},
	pages = {11--20},
}

@incollection{rumelhart_learning_1986,
	address = {Cambridge, MA, USA},
	title = {Learning internal representations by error propagation},
	isbn = {978-0-262-68053-0},
	urldate = {2025-01-14},
	booktitle = {Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations},
	publisher = {MIT Press},
	author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
	month = jan,
	year = {1986},
	pages = {318--362},
}

@misc{mcinnes_umap_2020,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	doi = {10.48550/arXiv.1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	urldate = {2025-01-14},
	publisher = {arXiv},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = sep,
	year = {2020},
	note = {arXiv:1802.03426 [stat]},
	keywords = {Computer Science - Computational Geometry, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hotelling_analysis_1933,
	title = {Analysis of a complex of statistical variables into principal components},
	volume = {24},
	issn = {1939-2176},
	doi = {10.1037/h0071325},
	abstract = {The problem is stated in detail, a method of analysis is derived and its geometrical meaning shown, methods of solution are illustrated and certain derivative problems are discussed. (To be concluded in October issue.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Journal of Educational Psychology},
	author = {Hotelling, H.},
	year = {1933},
	note = {Place: US
Publisher: Warwick \& York},
	keywords = {Statistical Analysis, Statistical Variables},
	pages = {417--441},
}

@article{collins_evaluation_2024,
	title = {Evaluation of clinical prediction models (part 1): from development to external validation},
	volume = {384},
	issn = {0959-8138},
	shorttitle = {Evaluation of clinical prediction models (part 1)},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10772854/},
	doi = {10.1136/bmj-2023-074819},
	abstract = {Evaluating the performance of a clinical prediction model is crucial to establish its predictive accuracy in the populations and settings intended for use. In this article, the first in a three part series, Collins and colleagues describe the importance of a meaningful evaluation using internal, internal-external, and external validation, as well as exploring heterogeneity, fairness, and generalisability in model performance.},
	urldate = {2025-01-02},
	journal = {The BMJ},
	author = {Collins, Gary S and Dhiman, Paula and Ma, Jie and Schlussel, Michael M and Archer, Lucinda and Van Calster, Ben and Harrell, Frank E and Martin, Glen P and Moons, Karel G M and van Smeden, Maarten and Sperrin, Matthew and Bullock, Garrett S and Riley, Richard D},
	month = jan,
	year = {2024},
	pmid = {38191193},
	pmcid = {PMC10772854},
	pages = {e074819},
}

@article{diana_cross-validation_2002,
	title = {Cross-validation methods in principal component analysis: {A} comparison},
	volume = {11},
	issn = {1613-981X},
	shorttitle = {Cross-validation methods in principal component analysis},
	url = {https://doi.org/10.1007/BF02511446},
	doi = {10.1007/BF02511446},
	abstract = {In principal component analysis (PCA), it is crucial to know how many principal components (PCs) should be retained in order to account for most of the data variability. A class of “objective” rules for finding this quantity is the class of cross-validation (CV) methods. In this work we compare three CV techniques showing how the performance of these methods depends on the covariance matrix structure. Finally we propose a rule for the choice of the “best” CV method and give an application to real data.},
	language = {en},
	number = {1},
	urldate = {2025-01-02},
	journal = {Statistical Methods and Applications},
	author = {Diana, Giancarlo and Tommasi, Chiara},
	month = feb,
	year = {2002},
	keywords = {Principal component analysis, cross-validation methods},
	pages = {71--82},
}

@article{yang_quantile_2020,
	title = {Quantile {Function} on {Scalar} {Regression} {Analysis} for {Distributional} {Data}},
	volume = {115},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2019.1609969},
	doi = {10.1080/01621459.2019.1609969},
	abstract = {Radiomics involves the study of tumor images to identify quantitative markers explaining cancer heterogeneity. The predominant approach is to extract hundreds to thousands of image features, including histogram features comprised of summaries of the marginal distribution of pixel intensities, which leads to multiple testing problems and can miss out on insights not contained in the selected features. In this paper, we present methods to model the entire marginal distribution of pixel intensities via the quantile function as functional data, regressed on a set of demographic, clinical, and genetic predictors to investigate their effects of imaging-based cancer heterogeneity. We call this approach quantile functional regression, regressing subject-specific marginal distributions across repeated measurements on a set of covariates, allowing us to assess which covariates are associated with the distribution in a global sense, as well as to identify distributional features characterizing these differences, including mean, variance, skewness, heavy-tailedness, and various upper and lower quantiles. To account for smoothness in the quantile functions, account for intrafunctional correlation, and gain statistical power, we introduce custom basis functions we call quantlets that are sparse, regularized, near-lossless, and empirically defined, adapting to the features of a given dataset and containing a Gaussian subspace so non-Gaussianness can be assessed. We fit this model using a Bayesian framework that uses nonlinear shrinkage of quantlet coefficients to regularize the functional regression coefficients and provides fully Bayesian inference after fitting a Markov chain Monte Carlo. We demonstrate the benefit of the basis space modeling through simulation studies, and apply the method to Magnetic resonance imaging (MRI)-based radiomic dataset from Glioblastoma Multiforme to relate imaging-based quantile functions to various demographic, clinical, and genetic predictors, finding specific differences in tumor pixel intensity distribution between males and females and between tumors with and without DDIT3 mutations. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
	number = {529},
	urldate = {2024-12-30},
	journal = {Journal of the American Statistical Association},
	author = {Yang, Hojin and Baladandayuthapani, Veerabhadran and Rao, Arvind U.K. and Morris, Jeffrey S.},
	month = jan,
	year = {2020},
	pmid = {32981991},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/01621459.2019.1609969},
	keywords = {Basis functions, Bayesian modeling, Functional regression, Imaging genetics, Markov chain Monte Carlo, Probability density function},
	pages = {90--106},
}

@article{bergmeir_note_2018,
	title = {A note on the validity of cross-validation for evaluating autoregressive time series prediction},
	volume = {120},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947317302384},
	doi = {10.1016/j.csda.2017.11.003},
	abstract = {One of the most widely used standard procedures for model evaluation in classification and regression is K-fold cross-validation (CV). However, when it comes to time series forecasting, because of the inherent serial correlation and potential non-stationarity of the data, its application is not straightforward and often replaced by practitioners in favour of an out-of-sample (OOS) evaluation. It is shown that for purely autoregressive models, the use of standard K-fold CV is possible provided the models considered have uncorrelated errors. Such a setup occurs, for example, when the models nest a more appropriate model. This is very common when Machine Learning methods are used for prediction, and where CV can control for overfitting the data. Theoretical insights supporting these arguments are presented, along with a simulation study and a real-world example. It is shown empirically that K-fold CV performs favourably compared to both OOS evaluation and other time-series-specific techniques such as non-dependent cross-validation.},
	urldate = {2024-12-30},
	journal = {Computational Statistics \& Data Analysis},
	author = {Bergmeir, Christoph and Hyndman, Rob J. and Koo, Bonsoo},
	month = apr,
	year = {2018},
	keywords = {Autoregression, Cross-validation, Time series},
	pages = {70--83},
}

@misc{hornung_evaluating_2023,
	title = {Evaluating machine learning models in non-standard settings: {An} overview and new findings},
	shorttitle = {Evaluating machine learning models in non-standard settings},
	url = {http://arxiv.org/abs/2310.15108},
	doi = {10.48550/arXiv.2310.15108},
	abstract = {Estimating the generalization error (GE) of machine learning models is fundamental, with resampling methods being the most common approach. However, in non-standard settings, particularly those where observations are not independently and identically distributed, resampling using simple random data divisions may lead to biased GE estimates. This paper strives to present well-grounded guidelines for GE estimation in various such non-standard settings: clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. Our overview combines well-established methodologies with other existing methods that, to our knowledge, have not been frequently considered in these particular settings. A unifying principle among these techniques is that the test data used in each iteration of the resampling procedure should reflect the new observations to which the model will be applied, while the training data should be representative of the entire data set used to obtain the final model. Beyond providing an overview, we address literature gaps by conducting simulation studies. These studies assess the necessity of using GE-estimation methods tailored to the respective setting. Our findings corroborate the concern that standard resampling methods often yield biased GE estimates in non-standard settings, underscoring the importance of tailored GE estimation.},
	urldate = {2024-12-30},
	publisher = {arXiv},
	author = {Hornung, Roman and Nalenz, Malte and Schneider, Lennart and Bender, Andreas and Bothmann, Ludwig and Bischl, Bernd and Augustin, Thomas and Boulesteix, Anne-Laure},
	month = oct,
	year = {2023},
	note = {arXiv:2310.15108 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
}

@article{roberts_cross-validation_2017,
	title = {Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure},
	volume = {40},
	copyright = {© 2016 The Authors},
	issn = {1600-0587},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ecog.02881},
	doi = {10.1111/ecog.02881},
	abstract = {Ecological data often show temporal, spatial, hierarchical (random effects), or phylogenetic structure. Modern statistical approaches are increasingly accounting for such dependencies. However, when performing cross-validation, these structures are regularly ignored, resulting in serious underestimation of predictive error. One cause for the poor performance of uncorrected (random) cross-validation, noted often by modellers, are dependence structures in the data that persist as dependence structures in model residuals, violating the assumption of independence. Even more concerning, because often overlooked, is that structured data also provides ample opportunity for overfitting with non-causal predictors. This problem can persist even if remedies such as autoregressive models, generalized least squares, or mixed models are used. Block cross-validation, where data are split strategically rather than randomly, can address these issues. However, the blocking strategy must be carefully considered. Blocking in space, time, random effects or phylogenetic distance, while accounting for dependencies in the data, may also unwittingly induce extrapolations by restricting the ranges or combinations of predictor variables available for model training, thus overestimating interpolation errors. On the other hand, deliberate blocking in predictor space may also improve error estimates when extrapolation is the modelling goal. Here, we review the ecological literature on non-random and blocked cross-validation approaches. We also provide a series of simulations and case studies, in which we show that, for all instances tested, block cross-validation is nearly universally more appropriate than random cross-validation if the goal is predicting to new data or predictor space, or for selecting causal predictors. We recommend that block cross-validation be used wherever dependence structures exist in a dataset, even if no correlation structure is visible in the fitted model residuals, or if the fitted models account for such correlations.},
	language = {en},
	number = {8},
	urldate = {2024-12-30},
	journal = {Ecography},
	author = {Roberts, David R. and Bahn, Volker and Ciuti, Simone and Boyce, Mark S. and Elith, Jane and Guillera-Arroita, Gurutzeta and Hauenstein, Severin and Lahoz-Monfort, José J. and Schröder, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Hartig, Florian and Dormann, Carsten F.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecog.02881},
	pages = {913--929},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2024-12-18},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@book{winter_biomechanics_1990,
	title = {Biomechanics and {Motor} {Control} of {Human} {Movement}},
	isbn = {978-0-471-50908-0},
	url = {https://books.google.com/books?id=Hc9qAAAAMAAJ},
	publisher = {Wiley},
	author = {Winter, D.A.},
	year = {1990},
	lccn = {lc89070467},
}

@misc{desai_connectivity_2023,
	title = {Connectivity {Regression}},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.11.14.567081v1},
	doi = {10.1101/2023.11.14.567081},
	abstract = {Assessing how brain functional connectivity networks vary across individuals promises to uncover important scientific questions such as patterns of healthy brain aging through the lifespan or dysconnectivity associated with disease. In this article we introduce a general regression framework, Connectivity Regression (ConnReg), for regressing subject-specific functional connectivity networks on covariates while accounting for within-network inter-edge dependence. ConnReg utilizes a multivariate generalization of Fisher’s transformation to project network objects into an alternative space where Gaussian assumptions are justified and positive semidefinite constraints are automatically satisfied. Penalized multivariate regression is fit in the transformed space to simultaneously induce sparsity in regression coefficients and in covariance elements, which capture within network inter-edge dependence. We use permutation tests to perform multiplicity-adjusted inference to identify covariates associated with connectivity, and stability selection scores to identify network edges that vary with selected covariates. Simulation studies validate the inferential properties of our proposed method and demonstrate how estimating and accounting for within-network inter-edge dependence leads to more efficient estimation, more powerful inference, and more accurate selection of covariate-dependent network edges. We apply ConnReg to the Human Connectome Project Young Adult study, revealing insights into how connectivity varies with language processing covariates and structural brain features.},
	language = {en},
	urldate = {2024-10-17},
	publisher = {bioRxiv},
	author = {Desai, Neel and Baladandayuthapani, Veera and Shinohara, Russell T. and Morris, Jeffrey S.},
	month = nov,
	year = {2023},
	note = {Pages: 2023.11.14.567081
Section: New Results},
}

@book{daubechies_ten_1992,
	address = {Philadelphia, Pa},
	edition = {1st edition},
	title = {Ten {Lectures} on {Wavelets}},
	isbn = {978-0-89871-274-2},
	abstract = {This monograph contains 10 lectures presented by Dr. Daubechies as the principal speaker at the 1990 CBMS-NSF Conference on Wavelets and Applications. Wavelets are a mathematical development that many experts think may revolutionize the world of information storage and retrieval. They are a fairly simple mathematical tool now being applied to the compression of data, such as fingerprints, weather satellite photographs, and medical x-rays - that were previously thought to be impossible to condense without losing crucial details. The opening chapter provides an overview of the main problems presented in the book. Following chapters discuss the theoretical and practical aspects of wavelet theory, including wavelet transforms, orthonormal bases of wavelets, and characterization of functional spaces by means of wavelets. The last chapter presents several topics under active research, as multidimensional wavelets, wavelet packet bases, and a construction of wavelets tailored to decompose functions defined in a finite interval.},
	language = {English},
	publisher = {SIAM: Society for Industrial and Applied Mathematics},
	author = {Daubechies, Ingrid},
	month = jun,
	year = {1992},
}

@misc{whitcher_waveslim_2024,
	title = {waveslim: {Basic} {Wavelet} {Routines} for {One}-, {Two}-, and {Three}-{Dimensional} {Signal} {Processing}},
	copyright = {BSD\_3\_clause + file LICENSE},
	shorttitle = {waveslim},
	url = {https://cran.r-project.org/web/packages/waveslim/index.html},
	abstract = {Basic wavelet routines for time series (1D), image (2D) and array (3D) analysis. The code provided here is based on wavelet methodology developed in Percival and Walden (2000); Gencay, Selcuk and Whitcher (2001); the dual-tree complex wavelet transform (DTCWT) from Kingsbury (1999, 2001) as implemented by Selesnick; and Hilbert wavelet pairs (Selesnick 2001, 2002). All figures in chapters 4-7 of GSW (2001) are reproducible using this package and R code available at the book website(s) below.},
	urldate = {2024-10-17},
	author = {Whitcher, Brandon},
	month = jun,
	year = {2024},
	keywords = {Finance, TimeSeries},
}

@misc{kalinowski_keras_2024,
	title = {keras: {R} {Interface} to '{Keras}'},
	copyright = {MIT + file LICENSE},
	shorttitle = {keras},
	url = {https://cran.r-project.org/web/packages/keras/index.html},
	abstract = {Interface to 'Keras' {\textless}https://keras.io{\textgreater}, a high-level neural networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation, supports both convolution based networks and recurrent networks (as well as combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.},
	urldate = {2024-10-17},
	author = {Kalinowski, Tomasz and Falbel, Daniel and Allaire, J. J. and Chollet, François and RStudio and Google and Tang  [ctb, Yuan and cph and Bijl, Wouter Van Der and Studer, Martin and Keydana, Sigrid},
	month = apr,
	year = {2024},
	keywords = {HighPerformanceComputing, ModelDeployment},
}

@article{lecun_mnist_1998,
	title = {The {MNIST} database of handwritten digits},
	url = {https://cir.nii.ac.jp/crid/1571417126193283840},
	urldate = {2024-10-17},
	journal = {http://yann. lecun. com/exdb/mnist/},
	author = {LeCun, Yann},
	year = {1998},
}

@article{lecun_mnist_nodate,
	title = {{THE} {MNIST} {DATABASE} of handwritten digits},
	url = {https://cir.nii.ac.jp/crid/1571417126193283840},
	urldate = {2024-10-17},
	journal = {http://yann.lecun.com/exdb/mnist/},
	author = {LECUN, Y.},
}

@article{morris_pinnacle_2008,
	title = {Pinnacle: a fast, automatic and accurate method for detecting and quantifying protein spots in 2-dimensional gel electrophoresis data},
	volume = {24},
	issn = {1367-4803},
	shorttitle = {Pinnacle},
	url = {https://doi.org/10.1093/bioinformatics/btm590},
	doi = {10.1093/bioinformatics/btm590},
	abstract = {Motivation: One of the key limitations for proteomic studies using 2-dimensional gel electrophoresis (2DE) is the lack of rapid, robust and reproducible methods for detecting, matching and quantifying protein spots. The most commonly used approaches involve first detecting spots and drawing spot boundaries on individual gels, then matching spots across gels and finally quantifying each spot by calculating normalized spot volumes. This approach is time consuming, error-prone and frequently requires extensive manual editing, which can unintentionally introduce bias into the results.Results: We introduce a new method for spot detection and quantification called Pinnacle that is automatic, quick, sensitive and specific and yields spot quantifications that are reliable and precise. This method incorporates a spot definition that is based on simple, straightforward criteria rather than complex arbitrary definitions, and results in no missing data. Using dilution series for validation, we demonstrate Pinnacle outperformed two well-established 2DE analysis packages, proving to be more accurate and yielding smaller coefficiant of variations (CVs). More accurate quantifications may lead to increased power for detecting differentially expressed spots, an idea supported by the results of our group comparison experiment. Our fast, automatic analysis method makes it feasible to conduct very large 2DE-based proteomic studies that are adequately powered to find important protein expression differences.Availability: Matlab code to implement Pinnacle is available from the authors upon request for non-commercial use.Contact:  jefmorris@mdanderson.orgSupplementary information: Supplementary data are available at Bioinformatics online.},
	number = {4},
	urldate = {2024-10-17},
	journal = {Bioinformatics},
	author = {Morris, Jeffrey S. and Clark, Brittan N. and Gutstein, Howard B.},
	month = feb,
	year = {2008},
	pages = {529--536},
}

@article{morris_statistical_2012,
	title = {Statistical methods for proteomic biomarker discovery based on feature extraction or functional modeling approaches},
	volume = {5},
	issn = {19387989, 19387997},
	url = {https://link.intlpress.com/JDetail/1806634544960876546},
	doi = {10.4310/SII.2012.v5.n1.a11},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Statistics and Its Interface},
	author = {Morris, Jeffrey S.},
	year = {2012},
	pages = {117--135},
}

@misc{chang_shiny_2021,
	title = {shiny: {Web} {Application} {Framework} for {R}},
	copyright = {GPL-3 {\textbar} file LICENSE},
	shorttitle = {shiny},
	url = {https://CRAN.R-project.org/package=shiny},
	abstract = {Makes it incredibly easy to build interactive web applications with R. Automatic "reactive" binding between inputs and outputs and extensive prebuilt widgets make it possible to build beautiful, responsive, and powerful applications with minimal effort.},
	urldate = {2021-02-08},
	author = {Chang, Winston and Cheng, Joe and Allaire, J. J. and Sievert, Carson and Schloerke, Barret and Xie, Yihui and Allen, Jeff and McPherson, Jonathan and Dipert, Alan and Borges, Barbara},
	month = jan,
	year = {2021},
	keywords = {TeachingStatistics, WebTechnologies},
}

@article{fazio_age-related_2014,
	title = {Age-related changes in human peripapillary scleral strain},
	volume = {13},
	issn = {1617-7940},
	url = {https://doi.org/10.1007/s10237-013-0517-9},
	doi = {10.1007/s10237-013-0517-9},
	abstract = {To test the hypothesis that mechanical strain in the posterior human sclera is altered with age, 20 pairs of normal eyes from human donors aged 20 to 90 years old were inflation tested within 48-h postmortem. The intact posterior scleral shells were pressurized from 5 to 45 mmHg, while the full-field three-dimensional displacements of the scleral surface were measured using laser speckle interferometry. The full strain tensor of the outer scleral surface was calculated directly from the displacement field. Mean maximum principal (tensile) strain was computed for eight circumferential sectors (\$\$45{\textasciicircum}\{{\textbackslash}circ \}\$\$wide) within the peripapillary and mid-peripheral regions surrounding the optic nerve head (ONH). To estimate the age-related changes in scleral strain, results were fit using a functional mixed effects model that accounts for intradonor variability and spatial autocorrelation. Mechanical tensile strain in the peripapillary sclera is significantly higher than the strain in the sclera farther away from the ONH. Overall, strains in the peripapillary sclera decrease significantly with age. Sectorially, peripapillary scleral tensile strains in the nasal sectors are significantly higher than the temporal sectors at younger ages, but the sectorial strain pattern reverses with age, and the temporal sectors exhibited the highest tensile strains in the elderly. Overall, peripapillary scleral structural stiffness increases significantly with age. The sectorial pattern of peripapillary scleral strain reverses with age, which may predispose adjacent regions of the lamina cribrosa to biomechanical insult. The pattern and age-related changes in sectorial peripapillary scleral strain closely match those seen in disk hemorrhages and neuroretinal rim area measurement change rates reported in previous studies of normal human subjects.},
	language = {en},
	number = {3},
	urldate = {2024-10-17},
	journal = {Biomechanics and Modeling in Mechanobiology},
	author = {Fazio, Massimo A. and Grytz, Rafael and Morris, Jeffrey S. and Bruno, Luigi and Gardiner, Stuart K. and Girkin, Christopher A. and Downs, J. Crawford},
	month = jun,
	year = {2014},
	keywords = {Electronic speckle interferometry, Glaucoma, Optic nerve head biomechanics, Sclera biomechanics},
	pages = {551--563},
}

@incollection{srivastava_functional_2016,
	address = {New York, NY},
	title = {Functional {Data} and {Elastic} {Registration}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_4},
	abstract = {Functional data analysis (FDA) is a branch of statistics where one observes, models, and analyzes quantities that are functions on certain intervals. This kind of data naturally arises in nearly every branch of science, ranging from engineering to geology, biology, medicine, and chemistry.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_4},
	keywords = {Functional Data Analysis (FDA), Functional Principal Component Analysis (FPCA), Inverse Exponential Map, Random Warping, Warping Function},
	pages = {73--123},
}

@incollection{srivastava_shapes_2016,
	address = {New York, NY},
	title = {Shapes of {Planar} {Closed} {Curves}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_6},
	abstract = {In this chapter we are interested in analyzing shapes of planar curves that are closed. A closed curve is a curve that starts and ends at the same point. If differentiability is needed (for example, in the case of the angle function representation), then we will require the derivative at the initial point of the curve to agree with the derivative at the ending point. However, if only absolute continuity is required (for example, in the case of the square-root velocity representation), then it will be enough to assume the curve starts and ends at the same point.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_6},
	keywords = {Angle Function, Close Curve, Finding Geodesics, Geodesic Path, Shooting Method},
	pages = {167--231},
}

@incollection{srivastava_shapes_2016-1,
	address = {New York, NY},
	title = {Shapes of {Planar} {Curves}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_5},
	abstract = {In this chapter we introduce a framework for analyzing shapes of curves that lie in a two-dimensional plane. Using the mathematical tools introduced in the previous Chaps. 3and 4 and Appendices A and A.2, we will develop approaches for comparing, deforming, and statistical modeling of shapes of curves.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_5},
	keywords = {Angle Function, Elastic Metal, Plane Curves, Pre-shape Space, Square-root Velocity Function (SRVF)},
	pages = {125--165},
}

@incollection{srivastava_statistical_2016,
	address = {New York, NY},
	title = {Statistical {Modeling} of {Planar} {Shapes}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_9},
	abstract = {As emphasized in the introduction chapter (Sect. 1.3), one of the main goals in this textbook is to develop statistical models of shapes of curves.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_9},
	keywords = {Closed Curf, Geodesic Distance, Planar Curf, Point Cloud, Tangent Space},
	pages = {305--347},
}

@incollection{srivastava_background_2016,
	address = {New York, NY},
	title = {Background: {Relevant} {Tools} from {Geometry}},
	isbn = {978-1-4939-4020-2},
	shorttitle = {Background},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_3},
	abstract = {Shape spaces are typically nonlinear spaces where the rules of vector-space calculus do not apply directly. Instead, one uses tools from algebra, geometry, and functional analysis to develop frameworks for optimization and statistics in shape spaces. In this chapter, we provide a brief introduction of fundamental tools and techniques from algebra, differential geometry and functional analysis that are basic to shape analysis. This topic includes definitions and examples of groups, differentiable manifolds and actions of groups on manifolds. For understanding differentiable geometry of shape manifolds, we introduce the concepts of tangent spaces, Riemannian structures, geodesics, and exponential maps. An important development in shape analysis of curves has been the involvement of functional analysis. The representations of continuous curves involve functions on real lines or planes, and we will summarize basic concepts from functional analysis. In particular, we will establish the notions of Hilbert spaces, submanifolds, …},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_3},
	keywords = {Geodesic Path, Parallel Transport, Riemannian Structure, Shape Space, Standard Euclidean Metric},
	pages = {39--72},
}

@incollection{srivastava_statistical_2016-1,
	address = {New York, NY},
	title = {Statistical {Modeling} on {Nonlinear} {Manifolds}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_7},
	abstract = {It has been emphasized frequently in the earlier chapters that the representation spaces of our interest are both nonlinear and infinite dimensional.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_7},
	keywords = {Extrinsic Analysis, Extrinsic Means, Inverse Exponential Map, Karcher Mean, Warping Function},
	pages = {233--267},
}

@incollection{srivastava_shapes_2016-2,
	address = {New York, NY},
	title = {Shapes of {Curves} in {Higher} {Dimensions}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_10},
	abstract = {So far in this text we have considered only planar curves. Although the shapes of planar curves are quite important, especially for recognizing objects in images, the shapes of curves in higher-dimensional spaces also have an important role to play.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_10},
	keywords = {Auxiliary Function, Closed Curf, Geodesic Distance, Medial Axis, Shape Analysis},
	pages = {349--384},
}

@incollection{srivastava_statistical_2016-2,
	address = {New York, NY},
	title = {Statistical {Modeling} of {Functional} {Data}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_8},
	abstract = {In this chapter we will look at the problem of developing statistical models that capture the essential modes of variability in a given functional dataset.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_8},
	keywords = {Amplitude Component, Functional Data, Mean Square Error, Phase Component, Warping Function},
	pages = {269--303},
}

@incollection{srivastava_motivation_2016,
	address = {New York, NY},
	title = {Motivation for {Function} and {Shape} {Analysis}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_1},
	abstract = {This textbook is dedicated to the study of functional data analysis and shape analysis of curves in Euclidean spaces. In the first item, one develops tools for statistical analysis of real-valued functional data on fixed intervals. While function data analysis is a broad topic area, worthy of a textbook in itself, we will focus heavily on a specific aspect that deals with alignment or registration of functional data. In the second item, one studies shapes formed by curves in 2D, 3D, and higher dimensions, with a goal of performing statistical inferences. Since these curves are also functions, albeit vector valued, and the issue of registration is of prime importance in their shape analysis, we will cover these topics under a broad umbrella of elastic functional and shape data analysis!},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_1},
	keywords = {Fiber Tract, Functional Data Analysis, Point Cloud, Shape Analysis, Shape Space},
	pages = {1--19},
}

@book{srivastava_functional_2016-1,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional and {Shape} {Data} {Analysis}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-4939-4018-9 978-1-4939-4020-2},
	url = {http://link.springer.com/10.1007/978-1-4939-4020-2},
	urldate = {2024-10-17},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2},
	keywords = {Riemannian methods, curves, function data analysis, geodesic, mathematical representations, shape analysis, square-root representations, vector-space-based statistical analyses},
}

@incollection{srivastava_related_2016,
	address = {New York, NY},
	title = {Related {Topics} in {Shape} {Analysis} of {Curves}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_11},
	abstract = {Previously we have developed theory and computational solutions for shape analysis associated with curves in Euclidean spaces. We end this textbook by presenting some related topics that fall outside the main framework. These miscellaneous topics do not fit an organized theme but are bunched together in this chapter for convenience. They include: (1) Investigate the use of shape in conjunction with other features, such as scale, pose, and position, to characterize curves. (2) Extend the group of shape-invariant transformations, from the similarity group to the affine group, in the case of planar closed curves. While most shape analysis works consider similarity transformations (rigid motions and global scales) as the main shape-preserving transformations, some applications, including imaging, may require us to nullify affine distortions of curves. (3) Develop techniques for analyzing trajectories on nonlinear Riemannian manifolds. While we have studied only the Euclidean curves so far, there is also a strong need for analyzing curves on other, perhaps nonlinear, domains. One may not use the word shape for characterizing the desired properties of these curves, but this analysis should be invariant at least to parameterizations of these trajectories.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_11},
	keywords = {Geodesic Distance, Global Section, Quotient Space, Riemannian Manifold, Shape Analysis},
	pages = {385--416},
}

@incollection{srivastava_previous_2016,
	address = {New York, NY},
	title = {Previous {Techniques} in {Shape} {Analysis}},
	isbn = {978-1-4939-4020-2},
	url = {https://doi.org/10.1007/978-1-4939-4020-2_2},
	abstract = {A recent search on Google using the query: shape analysis results returned more than 24 million hits, approximately 5 million for statistical shape analysis and 71 million for functional data analysis! Of course, not all of them are relevant to our use of this phrase, but a large fraction of them partly or completely share the same goals as this textbook. This shows the scope and involvement of these topics in all areas of science and engineering and indeed life in general. This also makes it difficult for us to provide a complete picture of the previous efforts in shape analysis. We choose to focus on those works where statistical tools, based on precise mathematical representations, have been used to address shape-related issues.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Functional and {Shape} {Data} {Analysis}},
	publisher = {Springer},
	author = {Srivastava, Anuj and Klassen, Eric P.},
	editor = {Srivastava, Anuj and Klassen, Eric P.},
	year = {2016},
	doi = {10.1007/978-1-4939-4020-2_2},
	keywords = {Iterative Close Point, Optimal Rotation, Shape Analysis, Transformation Variable},
	pages = {21--37},
}

@article{petersen_functional_2016,
	title = {Functional {Data} {Analysis} for {Density} {Functions} by {Transformation} to a {Hilbert} {Space}},
	volume = {44},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/43818904},
	abstract = {Functional data that are nonnegative and have a constrained integral can be considered as samples of one-dimensional density functions. Such data are ubiquitous. Due to the inherent constraints, densities do not live in a vector space and, therefore, commonly used Hubert space based methods of functional data analysis are not applicable. To address this problem, we introduce a transformation approach, mapping probability densities to a Hubert space of functions through a continuous and invertible map. Basic methods of functional data analysis, such as the construction of functional modes of variation, functional regression or classification, are then implemented by using representations of the densities in this linear space. Representations of the densities themselves are obtained by applying the inverse map from the linear functional space to the density space. Transformations of interest include log quantile density and log hazard transformations, among others. Rates of convergence are derived for the representations that are obtained for a general class of transformations under certain structural properties. If the subjectspecific densities need to be estimated from data, these rates correspond to the optimal rates of convergence for density estimation. The proposed methods are illustrated through simulations and applications in brain imaging.},
	number = {1},
	urldate = {2024-10-17},
	journal = {The Annals of Statistics},
	author = {Petersen, Alexander and Müller, Hans-Georg},
	year = {2016},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {183--218},
}

@article{wang_object_2007,
	title = {Object oriented data analysis: {Sets} of trees},
	volume = {35},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Object oriented data analysis},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-35/issue-5/Object-oriented-data-analysis-Sets-of-trees/10.1214/009053607000000217.full},
	doi = {10.1214/009053607000000217},
	abstract = {Object oriented data analysis is the statistical analysis of populations of complex objects. In the special case of functional data analysis, these data objects are curves, where standard Euclidean approaches, such as principal component analysis, have been very successful. Recent developments in medical image analysis motivate the statistical analysis of populations of more complex data objects which are elements of mildly non-Euclidean spaces, such as Lie groups and symmetric spaces, or of strongly non-Euclidean spaces, such as spaces of tree-structured data objects. These new contexts for object oriented data analysis create several potentially large new interfaces between mathematics and statistics. This point is illustrated through the careful development of a novel mathematical framework for statistical analysis of populations of tree-structured objects.},
	number = {5},
	urldate = {2024-10-17},
	journal = {The Annals of Statistics},
	author = {Wang, Haonan and Marron, J. S.},
	month = oct,
	year = {2007},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G99, 62H99, Functional data analysis, Object oriented data analysis, Principal Component Analysis, nonlinear data space, population of tree-structured objects},
	pages = {1849--1873},
}

@book{noauthor_functional_nodate,
	title = {Functional and {Shape} {Data} {Analysis}},
	url = {https://link.springer.com/book/10.1007/978-1-4939-4020-2},
	language = {en},
	urldate = {2024-10-17},
}

@book{marron_object_2021,
	address = {New York},
	title = {Object {Oriented} {Data} {Analysis}},
	isbn = {978-1-351-18967-5},
	abstract = {Object Oriented Data Analysis is a framework that facilitates inter-disciplinary research through new terminology for discussing the often many possible approaches to the analysis of complex data. Such data are naturally arising in a wide variety of areas. This book aims to provide ways of thinking that enable the making of sensible choices.
The main points are illustrated with many real data examples, based on the authors' personal experiences, which have motivated the invention of a wide array of analytic methods.
While the mathematics go far beyond the usual in statistics (including differential geometry and even topology), the book is aimed at accessibility by graduate students. There is deliberate focus on ideas over mathematical formulas.},
	publisher = {Chapman and Hall/CRC},
	author = {Marron, J. S. and Dryden, Ian L.},
	month = nov,
	year = {2021},
	doi = {10.1201/9781351189675},
}

@misc{noauthor_object_nodate,
	title = {Object {Oriented} {Data} {Analysis}},
	url = {https://www.routledge.com/Object-Oriented-Data-Analysis/Marron-Dryden/p/book/9781032114804},
	abstract = {Object Oriented Data Analysis is a framework that facilitates inter-disciplinary research through new terminology for discussing the often many possible approaches to the analysis of complex data. Such data are naturally arising in a wide variety of areas. This book aims to provide ways of thinking that enable the making of sensible choices.
The main points are illustrated with many real data examples, based on the authors' personal experiences, which have motivated the invention of a wide array},
	language = {en},
	urldate = {2024-10-17},
	journal = {Routledge \& CRC Press},
}

@article{mokbel_visualizing_2013,
	series = {Advances in artificial neural networks, machine learning, and computational intelligence},
	title = {Visualizing the quality of dimensionality reduction},
	volume = {112},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231213002439},
	doi = {10.1016/j.neucom.2012.11.046},
	abstract = {The growing number of dimensionality reduction methods available for data visualization has recently inspired the development of formal measures to evaluate the resulting low-dimensional representation independently from the methods' inherent criteria. Many evaluation measures can be summarized based on the co-ranking matrix. In this work, we analyze the characteristics of the co-ranking framework, focusing on interpretability and controllability in evaluation scenarios where a fine-grained assessment of a given visualization is desired. We extend the framework in two ways: (i) we propose how to link the evaluation to point-wise quality measures which can be used directly to augment the evaluated visualization and highlight erroneous regions; (ii) we improve the parameterization of the quality measure to offer more direct control over the evaluation's focus, and thus help the user to investigate more specific characteristics of the visualization.},
	urldate = {2024-10-17},
	journal = {Neurocomputing},
	author = {Mokbel, Bassam and Lueks, Wouter and Gisbrecht, Andrej and Hammer, Barbara},
	month = jul,
	year = {2013},
	keywords = {Co-ranking matrix, Data visualization, Nonlinear dimensionality reduction, Quality assessment},
	pages = {109--123},
}

@article{winham_r_2011,
	title = {An {R} package implementation of multifactor dimensionality reduction},
	volume = {4},
	issn = {1756-0381},
	url = {https://doi.org/10.1186/1756-0381-4-24},
	doi = {10.1186/1756-0381-4-24},
	abstract = {A breadth of high-dimensional data is now available with unprecedented numbers of genetic markers and data-mining approaches to variable selection are increasingly being utilized to uncover associations, including potential gene-gene and gene-environment interactions. One of the most commonly used data-mining methods for case-control data is Multifactor Dimensionality Reduction (MDR), which has displayed success in both simulations and real data applications. Additional software applications in alternative programming languages can improve the availability and usefulness of the method for a broader range of users.},
	number = {1},
	urldate = {2024-10-17},
	journal = {BioData Mining},
	author = {Winham, Stacey J. and Motsinger-Reif, Alison A.},
	month = aug,
	year = {2011},
	keywords = {Alternative Implementation, Balance Accuracy, Multifactor Dimensionality Reduction, Multifactor Dimensionality Reduction Method, Prediction Accuracy},
	pages = {24},
}

@inproceedings{cavallo_visual_2018,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '18},
	title = {A {Visual} {Interaction} {Framework} for {Dimensionality} {Reduction} {Based} {Data} {Exploration}},
	isbn = {978-1-4503-5621-3},
	url = {https://dl.acm.org/doi/10.1145/3170427.3186508},
	doi = {10.1145/3170427.3186508},
	abstract = {Dimensionality reduction is a common method for analyzing and visualizing high-dimensional data. However, reasoning dynamically about the results of a dimensionality reduction is difficult. Dimensionality-reduction algorithms use complex optimizations to reduce the number of dimensions of a dataset, but these new dimensions often lack a clear relation to the initial data dimensions, thus making them difficult to interpret. Here we propose a visual interaction framework to improve dimensionality-reduction based exploratory data analysis. We introduce two interaction techniques, forward projection and backward projection, for dynamically reasoning about dimensionally reduced data. We also contribute two visualization techniques, prolines and feasibility maps, to facilitate the effective use of the proposed interactions. We apply our framework to PCA and autoencoder-based dimensionality reductions. Through data-exploration examples, we demonstrate how our visual interactions can improve the use of dimensionality reduction in exploratory data analysis.},
	urldate = {2024-10-16},
	booktitle = {Extended {Abstracts} of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cavallo, Marco and Demiralp, Çagatay},
	month = apr,
	year = {2018},
	pages = {1--4},
}

@misc{noauthor_visual_nodate,
	title = {A {Visual} {Interaction} {Framework} for {Dimensionality} {Reduction} {Based} {Data} {Exploration} {\textbar} {Extended} {Abstracts} of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3170427.3186508},
	urldate = {2024-10-17},
}

@article{zubova_dimensionality_2018,
	title = {Dimensionality {Reduction} {Methods}: {The} {Comparison} {Of} {Speed} {And} {Accuracy}},
	volume = {47},
	copyright = {Copyright (c)},
	issn = {2335-884X},
	shorttitle = {Dimensionality {Reduction} {Methods}},
	url = {https://itc.ktu.lt/index.php/ITC/article/view/18813},
	doi = {10.5755/j01.itc.47.1.18813},
	abstract = {This research focuses on big data visualization that is based on dimensionality reduction methods. We propose a multi-level method for data clustering and visualization. Whole data mining process is divided into separate steps. For each step particular dimensionality reduction and visualization method is applied considering to data volume and type.  The selection of methods is based on their speed and accuracy. Therefore the comparison of the selected methods is made according to these two criteria. Three groups of datasets containing different kind of data are used for methods evaluation.  The factors that influence speed or accuracy are determined. The rank of investigated methods based on research results is presented in this paper. DOI: http://dx.doi.org/10.5755/j01.itc.47.1.18813},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Information Technology and Control},
	author = {Zubova, Jelena and Kurasova, Olga and Liutvinavičius, Marius},
	month = feb,
	year = {2018},
	note = {Number: 1},
	keywords = {data visualization},
	pages = {151--160},
}

@article{samudrala_software_2014,
	title = {A software framework for data dimensionality reduction: application to chemical crystallography},
	volume = {3},
	issn = {2193-9772},
	shorttitle = {A software framework for data dimensionality reduction},
	url = {https://doi.org/10.1186/s40192-014-0017-5},
	doi = {10.1186/s40192-014-0017-5},
	abstract = {Materials science research has witnessed an increasing use of data mining techniques in establishing process‐structure‐property relationships. Significant advances in high‐throughput experiments and computational capability have resulted in the generation of huge amounts of data. Various statistical methods are currently employed to reduce the noise, redundancy, and the dimensionality of the data to make analysis more tractable. Popular methods for reduction (like principal component analysis) assume a linear relationship between the input and output variables. Recent developments in non‐linear reduction (neural networks, self‐organizing maps), though successful, have computational issues associated with convergence and scalability. Another significant barrier to use dimensionality reduction techniques in materials science is the lack of ease of use owing to their complex mathematical formulations. This paper reviews various spectral‐based techniques that efficiently unravel linear and non‐linear structures in the data which can subsequently be used to tractably investigate process‐structure‐property relationships. In addition, we describe techniques (based on graph‐theoretic analysis) to estimate the optimal dimensionality of the low‐dimensional parametric representation. We show how these techniques can be packaged into a modular, computationally scalable software framework with a graphical user interface ‐ Scalable Extensible Toolkit for Dimensionality Reduction (SETDiR). This interface helps to separate out the mathematics and computational aspects from the materials science applications, thus significantly enhancing utility to the materials science community. The applicability of this framework in constructing reduced order models of complicated materials dataset is illustrated with an example dataset of apatites described in structural descriptor space. Cluster analysis of the low‐dimensional plots yielded interesting insights into the correlation between several structural descriptors like ionic radius and covalence with characteristic properties like apatite stability. This information is crucial as it can promote the use of apatite materials as a potential host system for immobilizing toxic elements.},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Integrating Materials and Manufacturing Innovation},
	author = {Samudrala, Sai Kiranmayee and Balachandran, Prasanna Venkataraman and Zola, Jaroslaw and Rajan, Krishna and Ganapathysubramanian, Baskar},
	month = dec,
	year = {2014},
	keywords = {Apatites, High‐throughput analysis, Materials science, Non‐linear dimensionality reduction, Process‐structure‐property},
	pages = {205--224},
}

@inproceedings{marcellin_overview_2000,
	title = {An overview of {JPEG}-2000},
	url = {https://ieeexplore.ieee.org/abstract/document/838192},
	doi = {10.1109/DCC.2000.838192},
	abstract = {JPEG-2000 is an emerging standard for still image compression. This paper provides a brief history of the JPEG-2000 standardization process, an overview of the standard, and some description of the capabilities provided by the standard. Part I of the JPEG-2000 standard specifies the minimum compliant decoder, while Part II describes optional, value-added extensions. Although the standard specifies only the decoder and bitstream syntax, in this paper we describe JPEG-2000 from the point of view of encoding. We take this approach, as we believe it is more amenable to a compact description more easily understood by most readers.},
	urldate = {2024-10-17},
	booktitle = {Proceedings {DCC} 2000. {Data} {Compression} {Conference}},
	author = {Marcellin, M.W. and Gormish, M.J. and Bilgin, A. and Boliek, M.P.},
	month = mar,
	year = {2000},
	note = {ISSN: 1068-0314},
	keywords = {Bandwidth, Bit rate, Decoding, Digital images, History, Image coding, Image storage, Propagation losses, Standardization, Transform coding},
	pages = {523--541},
}

@article{saccenti_use_2015,
	title = {On the use of the observation-wise k-fold operation in {PCA} cross-validation},
	volume = {29},
	copyright = {Copyright © 2015 John Wiley \& Sons, Ltd.},
	issn = {1099-128X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.2726},
	doi = {10.1002/cem.2726},
	abstract = {Cross-validation (CV) is a common approach for determining the optimal number of components in a principal component analysis model. To guarantee the independence between model testing and calibration, the observation-wise k-fold operation is commonly implemented in each cross-validation step. This operation renders the CV algorithm computationally intensive, and it is the main limitation to apply CV on very large data sets. In this paper, we carry out an empirical and theoretical investigation of the use of this operation in the element-wise k-fold (ekf) algorithm, the state-of-the-art CV algorithm. We show that when very large data sets need to be cross-validated and the computational time is a matter of concern, the observation-wise k-fold operation can be skipped. The theoretical properties of the resulting modified algorithm, referred to as column-wise k-fold (ckf) algorithm, are derived. Also, its performance is evaluated with several artificial and real data sets. We suggest the ckf algorithm to be a valid alternative to the standard ekf to reduce the computational time needed to cross-validate a data set. Copyright © 2015 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {8},
	urldate = {2024-10-17},
	journal = {Journal of Chemometrics},
	author = {Saccenti, Edoardo and Camacho, José},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cem.2726},
	keywords = {cross-validation, dimensionality assessment, principal component analysis},
	pages = {467--478},
}

@article{josse_selecting_2012,
	title = {Selecting the number of components in principal component analysis using cross-validation approximations},
	volume = {56},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947311004099},
	doi = {10.1016/j.csda.2011.11.012},
	abstract = {Cross-validation is a tried and tested approach to select the number of components in principal component analysis (PCA), however, its main drawback is its computational cost. In a regression (or in a non parametric regression) setting, criteria such as the general cross-validation one (GCV) provide convenient approximations to leave-one-out cross-validation. They are based on the relation between the prediction error and the residual sum of squares weighted by elements of a projection matrix (or a smoothing matrix). Such a relation is then established in PCA using an original presentation of PCA with a unique projection matrix. It enables the definition of two cross-validation approximation criteria: the smoothing approximation of the cross-validation criterion (SACV) and the GCV criterion. The method is assessed with simulations and gives promising results.},
	number = {6},
	urldate = {2024-10-17},
	journal = {Computational Statistics \& Data Analysis},
	author = {Josse, Julie and Husson, François},
	month = jun,
	year = {2012},
	keywords = {Cross-validation, Generalized cross-validation, Number of components, PCA, Smoothing matrix},
	pages = {1869--1879},
}

@article{hubert_fast_2007,
	title = {Fast cross-validation of high-breakdown resampling methods for {PCA}},
	volume = {51},
	issn = {0167-9473},
	url = {https://doi.org/10.1016/j.csda.2006.08.031},
	doi = {10.1016/j.csda.2006.08.031},
	abstract = {Cross-validation (CV) is a very popular technique for model selection and model validation. The general procedure of leave-one-out CV (LOO-CV) is to exclude one observation from the data set, to construct the fit of the remaining observations and to evaluate that fit on the item that was left out. In classical procedures such as least-squares regression or kernel density estimation, easy formulas can be derived to compute this CV fit or the residuals of the removed observations. However, when high-breakdown resampling algorithms are used, it is no longer possible to derive such closed-form expressions. High-breakdown methods are developed to obtain estimates that can withstand the effects of outlying observations. Fast algorithms are presented for LOO-CV when using a high-breakdown method based on resampling, in the context of robust covariance estimation by means of the MCD estimator and robust principal component analysis. A robust PRESS curve is introduced as an exploratory tool to select the number of principal components. Simulation results and applications on real data show the accuracy and the gain in computation time of these fast CV algorithms.},
	number = {10},
	urldate = {2024-10-17},
	journal = {Comput. Stat. Data Anal.},
	author = {Hubert, Mia and Engelen, Sanne},
	month = jun,
	year = {2007},
	pages = {5013--5024},
}

@article{diana_cross-validation_2002-1,
	title = {Cross-validation methods in principal component analysis: {A} comparison},
	volume = {11},
	issn = {1613-981X},
	shorttitle = {Cross-validation methods in principal component analysis},
	url = {https://doi.org/10.1007/BF02511446},
	doi = {10.1007/BF02511446},
	abstract = {In principal component analysis (PCA), it is crucial to know how many principal components (PCs) should be retained in order to account for most of the data variability. A class of “objective” rules for finding this quantity is the class of cross-validation (CV) methods. In this work we compare three CV techniques showing how the performance of these methods depends on the covariance matrix structure. Finally we propose a rule for the choice of the “best” CV method and give an application to real data.},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Statistical Methods and Applications},
	author = {Diana, Giancarlo and Tommasi, Chiara},
	month = feb,
	year = {2002},
	keywords = {Principal component analysis, cross-validation methods},
	pages = {71--82},
}

@article{camacho_cross-validation_2014,
	title = {Cross-validation in {PCA} models with the element-wise \textit{k}-fold (\textit{ekf}) algorithm: {Practical} aspects},
	volume = {131},
	issn = {0169-7439},
	shorttitle = {Cross-validation in {PCA} models with the element-wise \textit{k}-fold (\textit{ekf}) algorithm},
	url = {https://www.sciencedirect.com/science/article/pii/S0169743913002335},
	doi = {10.1016/j.chemolab.2013.12.003},
	abstract = {This is the second paper of a series devoted to provide theoretical and practical results and new algorithms for the selection of the number of Principal Components (PCs) in Principal Component Analysis (PCA) using cross-validation. The study is especially focused on the element-wise k-fold (ekf), which is among the most used algorithms for that purpose. In this paper, a taxonomy of PCA applications is proposed and it is argued that cross-validatory algorithms computing the prediction error in observable variables, like ekf, are only suited for a class of applications. A number of cross-validation methods, several of which are original, are compared in two applications of this class: missing data imputation and compression. The results show that the ekf is especially suited for missing data applications while other traditional cross-validation methods, those by Wold and Eastment and Krzanowski, are not found to provide useful outcomes in any of the two applications. These results are of special value considering that the methods investigated are computed in the main commercial software packets for chemometrics. Finally, the choice of the missing data algorithm within ekf is also investigated.},
	urldate = {2024-10-17},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Camacho, José and Ferrer, Alberto},
	month = feb,
	year = {2014},
	keywords = {Compression, Cross-validation, Missing data, Number of components, Principal Component Analysis},
	pages = {37--50},
}

@inproceedings{rajan_bayesian_1994,
	title = {Bayesian model order selection for the {Karhunen}-{Loeve} transform and the singular value decomposition},
	volume = {iv},
	url = {https://ieeexplore.ieee.org/document/389798},
	doi = {10.1109/ICASSP.1994.389798},
	abstract = {Discusses model order selection in relation to the discrete Karhunen-Loeve transform (DKLT) and the singular value decomposition (SVD). There are many applications of the DKLT and SVD where it is necessary to discard some of the small singular values that may represent corrupted signal information. Bayesian methods allow to determine the DKLT model order evidence which indicates the optimal number of basis vectors to choose for reconstruction such that the signal is not over-parameterised. Evidence methods can also be used for the SVD to determine the number of singular values (and hence the effective rank) of a singular or ill-conditioned matrix,.{\textless}{\textgreater}},
	urldate = {2024-10-17},
	booktitle = {Proceedings of {ICASSP} '94. {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Rajan, J.J. and Rayner, P.J.W.},
	month = apr,
	year = {1994},
	note = {ISSN: 1520-6149},
	keywords = {Bayesian methods, Contracts, Density functional theory, Discrete transforms, Eigenvalues and eigenfunctions, Humans, Karhunen-Loeve transforms, Probability density function, Singular value decomposition, Vectors},
	pages = {IV/393--IV/396 vol.4},
}

@inproceedings{minka_automatic_2000,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'00},
	title = {Automatic choice of dimensionality for {PCA}},
	abstract = {A central issue in principal component analysis (PCA) is choosing the number of principal components to be retained. By interpreting PCA as density estimation, we show how to use Bayesian model selection to estimate the true dimensionality of the data. The resulting estimate is simple to compute yet guaranteed to pick the correct dimensionality, given enough data. The estimate involves an integral over the Steifel manifold of k-frames, which is difficult to compute exactly. But after choosing an appropriate parameterization and applying Laplace's method, an accurate and practical estimator is obtained. In simulations, it is convincingly better than cross-validation and other proposed algorithms, plus it runs much faster.},
	urldate = {2024-10-16},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Minka, Thomas P.},
	month = jan,
	year = {2000},
	pages = {577--583},
}

@article{krzanowski_cross-validation_1987,
	title = {Cross-{Validation} in {Principal} {Component} {Analysis}},
	volume = {43},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2531996},
	doi = {10.2307/2531996},
	abstract = {This paper describes a form of cross-validation, in the context of principal component analysis, which has a number of useful aspects as regards multivariate data inspection and description. Topics covered include choice of dimensionality, identification of influential observations, and selection of important variables. The methods are motivated by and illustrated on a well-known data set.},
	number = {3},
	urldate = {2024-10-17},
	journal = {Biometrics},
	author = {Krzanowski, W. J.},
	year = {1987},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {575--584},
}

@article{eastment_cross-validatory_1982,
	title = {Cross-{Validatory} {Choice} of the {Number} of {Components} from a {Principal} {Component} {Analysis}},
	volume = {24},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1267581},
	doi = {10.2307/1267581},
	abstract = {A method is described for choosing the number of components to retain in a principal component analysis when the aim is dimensionality reduction. The correspondence between principal component analysis and the singular value decomposition of the data matrix is used. The method is based on successively predicting each element in the data matrix after deleting the corresponding row and column of the matrix, and makes use of recently published algorithms for updating a singular value decomposition. These are very fast, which renders the proposed technique a practicable one for routine data analysis.},
	number = {1},
	urldate = {2024-10-17},
	journal = {Technometrics},
	author = {Eastment, H. T. and Krzanowski, W. J.},
	year = {1982},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
	pages = {73--77},
}

@article{wold_cross-validatory_1978,
	title = {Cross-{Validatory} {Estimation} of the {Number} of {Components} in {Factor} and {Principal} {Components} {Models}},
	volume = {20},
	issn = {0040-1706},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1978.10489693},
	doi = {10.1080/00401706.1978.10489693},
	abstract = {By means of factor analysis (FA) or principal components analysis (PCA) a matrix Y with the elements y ik is approximated by the model Here the parameters α, β and θ express the systematic part of the data yik, “signal,” and the residuals ∊ ik express the “random” part, “noise.” When applying FA or PCA to a matrix of real data obtained, for example, by characterizing N chemical mixtures by M measured variables, one major problem is the estimation of the rank A of the matrix Y, i.e. the estimation of how much of the data y ik is “signal” and how much is “noise.” Cross validation can be used to approach this problem. The matrix Y is partitioned and the rank A is determined so as to maximize the predictive properties of model (I) when the parameters are estimated on one part of the matrix Y and the prediction tested on another part of the matrix Y.},
	number = {4},
	urldate = {2024-10-17},
	journal = {Technometrics},
	author = {Wold, Svante},
	month = nov,
	year = {1978},
	note = {Publisher: ASA Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00401706.1978.10489693},
	keywords = {Eigenvector decomposition, Factor analysis, Principal components, Rank determination, Singular value decomposition},
	pages = {397--405},
}

@article{becht_dimensionality_2019,
	title = {Dimensionality reduction for visualizing single-cell data using {UMAP}},
	volume = {37},
	copyright = {2018 Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/nbt.4314},
	doi = {10.1038/nbt.4314},
	abstract = {A benchmarking analysis on single-cell RNA-seq and mass cytometry data reveals the best-performing technique for dimensionality reduction.},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Nature Biotechnology},
	author = {Becht, Etienne and McInnes, Leland and Healy, John and Dutertre, Charles-Antoine and Kwok, Immanuel W. H. and Ng, Lai Guan and Ginhoux, Florent and Newell, Evan W.},
	month = jan,
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Data mining, Immunology},
	pages = {38--44},
}

@article{maaten_visualizing_2008,
	title = {Visualizing {Data} using t-{SNE}},
	volume = {9},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v9/vandermaaten08a.html},
	abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images ofobjects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
	number = {86},
	urldate = {2024-10-17},
	journal = {Journal of Machine Learning Research},
	author = {Maaten, Laurens van der and Hinton, Geoffrey},
	year = {2008},
	pages = {2579--2605},
}

@article{cook_fisher_2007,
	title = {Fisher {Lecture}: {Dimension} {Reduction} in {Regression}},
	volume = {22},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Fisher {Lecture}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-22/issue-1/Fisher-Lecture-Dimension-Reduction-in-Regression/10.1214/088342306000000682.full},
	doi = {10.1214/088342306000000682},
	abstract = {Beginning with a discussion of R. A. Fisher’s early written remarks that relate to dimension reduction, this article revisits principal components as a reductive method in regression, develops several model-based extensions and ends with descriptions of general approaches to model-based and model-free dimension reduction in regression. It is argued that the role for principal components and related methodology may be broader than previously seen and that the common practice of conditioning on observed values of the predictors may unnecessarily limit the choice of regression methodology.},
	number = {1},
	urldate = {2024-10-17},
	journal = {Statistical Science},
	author = {Cook, R. Dennis},
	month = feb,
	year = {2007},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Grassmann manifolds, central subspace, inverse regression, minimum average variance estimation, principal components, principal fitted components, sliced inverse regression, sufficient dimension reduction},
	pages = {1--26},
}

@article{wang_role_2014,
	title = {The {Role} of {Dimensionality} {Reduction} in {Classification}},
	volume = {28},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8975},
	doi = {10.1609/aaai.v28i1.8975},
	abstract = {Dimensionality reduction (DR) is often used as a preprocessing step in classiﬁcation, but usually one ﬁrst ﬁxes the DR mapping, possibly using label information, and then learns a classiﬁer (a ﬁlter approach). Best performance would be obtained by optimizing the classiﬁcation error jointly over DR mapping and classiﬁer (a wrapper approach), but this is a difﬁcult nonconvex problem, particularly with nonlinear DR. Using the method of auxiliary coordinates, we give a simple, efﬁcient algorithm to train a combination of nonlinear DR and a classiﬁer, and apply it to a RBF mapping with a linear SVM. This alternates steps where we train the RBF mapping and a linear SVM as usual regression and classiﬁcation, respectively, with a closedform step that coordinates both. The resulting nonlinear low-dimensional classiﬁer achieves classiﬁcation errors competitive with the state-of-the-art but is fast at training and testing, and allows the user to trade off runtime for classiﬁcation accuracy easily. We then study the role of nonlinear DR in linear classiﬁcation, and the interplay between the DR mapping, the number of latent dimensions and the number of classes. When trained jointly, the DR mapping takes an extreme role in eliminating variation: it tends to collapse classes in latent space, erasing all manifold structure, and lay out class centroids so they are linearly separable with maximum margin.},
	language = {en},
	number = {1},
	urldate = {2024-10-17},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Wang, Weiran and Carreira-Perpinan, Miguel},
	month = jun,
	year = {2014},
}

@inproceedings{niu_dimensionality_2011,
	title = {Dimensionality {Reduction} for {Spectral} {Clustering}},
	url = {https://proceedings.mlr.press/v15/niu11a.html},
	abstract = {Spectral clustering is a flexible clustering methodology that is applicable to a variety of data types and has the particular virtue that it makes few assumptions on cluster shapes. It has become popular in a variety of application areas, particularly in computational vision and bioinformatics. The approach appears, however, to be particularly sensitive to irrelevant and noisy dimensions in the data. We thus introduce an approach that automatically learns the relevant dimensions and spectral clustering simultaneously. We pursue an augmented form of spectral clustering in which an explicit projection operator is incorporated in the relaxed optimization functional. We optimize this functional over both the projection and the spectral embedding. Experiments on simulated and real data show that this approach yields significant improvements in the performance of spectral clustering.},
	language = {en},
	urldate = {2024-10-17},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Niu, Donglin and Dy, Jennifer and Jordan, Michael I.},
	month = jun,
	year = {2011},
	note = {ISSN: 1938-7228},
	pages = {552--560},
}

@article{ding_functional_2022,
	title = {Functional {PCA} {With} {Covariate}-{Dependent} {Mean} and {Covariance} {Structure}},
	volume = {64},
	issn = {0040-1706, 1537-2723},
	url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2021.2008502},
	doi = {10.1080/00401706.2021.2008502},
	abstract = {Incorporating covariates into functional principal component analysis (PCA) can substantially improve the representation efficiency of the principal components and predictive performance. However, many existing functional PCA methods do not make use of covariates, and those that do often have high computational cost or make overly simplistic assumptions that are violated in practice. In this article, we propose a new framework, called Covariate Dependent Functional Principal Component Analysis (CD-FPCA), in which both the mean and covariance structure depend on covariates. We propose a corresponding estimation algorithm, which makes use of spline basis representations and roughness penalties, and is substantially more computationally efficient than competing approaches of adequate estimation and prediction accuracy. A key aspect of our work is our novel approach for modeling the covariance function and ensuring that it is symmetric positive semi-definite. We demonstrate the advantages of our methodology through a simulation study and an astronomical data analysis.},
	language = {en},
	number = {3},
	urldate = {2024-10-08},
	journal = {Technometrics},
	author = {Ding, Fei and He, Shiyuan and Jones, David E. and Huang, Jianhua Z.},
	month = jul,
	year = {2022},
	pages = {335--345},
}

@article{jiang_eigen-adjusted_2022,
	title = {Eigen-{Adjusted} {Functional} {Principal} {Component} {Analysis}},
	volume = {31},
	issn = {1061-8600, 1537-2715},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2022.2067550},
	doi = {10.1080/10618600.2022.2067550},
	abstract = {Functional Principal Component Analysis (FPCA) has become a widely-used dimension reduction tool for functional data analysis. When additional covariates are available, existing FPCA models integrate them either in the mean function or in both the mean function and the covariance function. However, methods of the ﬁrst kind are not suitable for data that display second-order variation, while those of the second kind are time-consuming and make it diﬃcult to perform subsequent statistical analyses on the dimension-reduced representations. To tackle these issues, we introduce an eigen-adjusted FPCA model that integrates covariates in the covariance function only through its eigenvalues. In particular, diﬀerent structures on the covariatespeciﬁc eigenvalues – corresponding to diﬀerent practical problems – are discussed to illustrate the model’s ﬂexibility as well as utility. To handle functional observations under diﬀerent sampling schemes, we employ local linear smoothers to estimate the mean function and the pooled covariance function, and a weighted least square approach to estimate the covariate-speciﬁc eigenvalues. The convergence rates of the proposed estimators are further investigated under the diﬀerent sampling schemes.},
	language = {en},
	number = {4},
	urldate = {2024-10-08},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Jiang, Ci-Ren and Lila, Eardi and Aston, John A. D. and Wang, Jane-Ling},
	month = oct,
	year = {2022},
	pages = {1141--1152},
}

@misc{gunning_understanding_2024,
	title = {An {Understanding} of {Principal} {Differential} {Analysis}},
	url = {http://arxiv.org/abs/2406.18484},
	doi = {10.48550/arXiv.2406.18484},
	abstract = {In functional data analysis, replicate observations of a smooth functional process and its derivatives offer a unique opportunity to flexibly estimate continuous-time ordinary differential equation models. Ramsay (1996) first proposed to estimate a linear ordinary differential equation from functional data in a technique called Principal Differential Analysis, by formulating a functional regression in which the highest-order derivative of a function is modelled as a time-varying linear combination of its lower-order derivatives. Principal Differential Analysis was introduced as a technique for data reduction and representation, using solutions of the estimated differential equation as a basis to represent the functional data. In this work, we re-formulate PDA as a generative statistical model in which functional observations arise as solutions of a deterministic ODE that is forced by a smooth random error process. This viewpoint defines a flexible class of functional models based on differential equations and leads to an improved understanding and characterisation of the sources of variability in Principal Differential Analysis. It does, however, result in parameter estimates that can be heavily biased under the standard estimation approach of PDA. Therefore, we introduce an iterative bias-reduction algorithm that can be applied to improve parameter estimates. We also examine the utility of our approach when the form of the deterministic part of the differential equation is unknown and possibly non-linear, where Principal Differential Analysis is treated as an approximate model based on time-varying linearisation. We demonstrate our approach on simulated data from linear and non-linear differential equations and on real data from human movement biomechanics. Supplementary R code for this manuscript is available at {\textbackslash}url\{https://github.com/edwardgunning/UnderstandingOfPDAManuscript\}.},
	urldate = {2024-10-06},
	publisher = {arXiv},
	author = {Gunning, Edward and Hooker, Giles},
	month = jun,
	year = {2024},
	note = {arXiv:2406.18484 [stat]},
	keywords = {Statistics - Methodology},
}

@misc{gunning_analysing_2024,
	title = {Analysing kinematic data from recreational runners using functional data analysis},
	url = {http://arxiv.org/abs/2408.08200},
	doi = {10.48550/arXiv.2408.08200},
	abstract = {We present a multivariate functional mixed effects model for kinematic data from a large number of recreational runners. The runners' sagittal plane hip and knee angles are modelled jointly as a bivariate function with random effects functions used to account for the dependence among measurements from either side of the body. The model is fitted by first applying multivariate functional principal component analysis (mv-FPCA) and then modelling the mv-FPCA scores using scalar linear mixed effects models. Simulation and bootstrap approaches are introduced to construct simultaneous confidence bands for the fixed effects functions, and covariance functions are reconstructed to summarise the variability structure in the data and thoroughly investigate the suitability of the proposed model. In our scientific application, we observe a statistically significant effect of running speed on both the hip and knee angles. We also observe strong within-subject correlations, reflecting the highly idiosyncratic nature of running technique. Our approach is more generally applicable to modelling multiple streams of smooth kinematic or kinetic data measured repeatedly for multiple subjects in complex experimental designs.},
	urldate = {2024-10-06},
	publisher = {arXiv},
	author = {Gunning, Edward and Golovkine, Steven and Simpkin, Andrew J. and Burke, Aoife and Dillon, Sarah and Gore, Shane and Moran, Kieran and O'Connor, Siobhan and Whyte, Enda and Bargary, Norma},
	month = aug,
	year = {2024},
	note = {arXiv:2408.08200 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology},
}

@misc{gunning_multivariate_2024,
	title = {A {Multivariate} {Multilevel} {Longitudinal} {Functional} {Model} for {Repeatedly} {Observed} {Human} {Movement} {Data}},
	url = {http://arxiv.org/abs/2408.08481},
	doi = {10.48550/arXiv.2408.08481},
	abstract = {Biomechanics and human movement research often involves measuring multiple kinematic or kinetic variables regularly throughout a movement, yielding data that present as smooth, multivariate, time-varying curves and are naturally amenable to functional data analysis. It is now increasingly common to record the same movement repeatedly for each individual, resulting in curves that are serially correlated and can be viewed as longitudinal functional data. We present a new approach for modelling multivariate multilevel longitudinal functional data, with application to kinematic data from recreational runners collected during a treadmill run. For each stride, the runners' hip, knee and ankle angles are modelled jointly as smooth multivariate functions that depend on subject-specific covariates. Longitudinally varying multivariate functional random effects are used to capture the dependence among adjacent strides and changes in the multivariate functions over the course of the treadmill run. A basis modelling approach is adopted to fit the model -- we represent each observation using a multivariate functional principal components basis and model the basis coefficients using scalar longitudinal mixed effects models. The predicted random effects are used to understand and visualise changes in the multivariate functional data over the course of the treadmill run. In our application, our method quantifies the effects of scalar covariates on the multivariate functional data, revealing a statistically significant effect of running speed at the hip, knee and ankle joints. Analysis of the predicted random effects reveals that individuals' kinematics are generally stable but certain individuals who exhibit strong changes during the run can also be identified. A simulation study is presented to demonstrate the efficacy of the proposed methodology under realistic data-generating scenarios.},
	urldate = {2024-10-06},
	publisher = {arXiv},
	author = {Gunning, Edward and Golovkine, Steven and Simpkin, Andrew J. and Burke, Aoife and Dillon, Sarah and Gore, Shane and Moran, Kieran and O'Connor, Siobhan and Whyte, Enda and Bargary, Norma},
	month = aug,
	year = {2024},
	note = {arXiv:2408.08481 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology},
}

@article{bramah_is_2018,
	title = {Is {There} a {Pathological} {Gait} {Associated} {With} {Common} {Soft} {Tissue} {Running} {Injuries}?},
	volume = {46},
	issn = {1552-3365},
	doi = {10.1177/0363546518793657},
	abstract = {BACKGROUND: Previous research has demonstrated clear associations between specific running injuries and patterns of lower limb kinematics. However, there has been minimal research investigating whether the same kinematic patterns could underlie multiple different soft tissue running injuries. If they do, such kinematic patterns could be considered global contributors to running injuries.
HYPOTHESIS: Injured runners will demonstrate differences in running kinematics when compared with injury-free controls. These kinematic patterns will be consistent among injured subgroups.
STUDY DESIGN: Controlled laboratory study.
METHODS: The authors studied 72 injured runners and 36 healthy controls. The injured group contained 4 subgroups of runners with either patellofemoral pain, iliotibial band syndrome, medial tibial stress syndrome, or Achilles tendinopathy (n = 18 each). Three-dimensional running kinematics were compared between injured and healthy runners and then between the 4 injured subgroups. A logistic regression model was used to determine which parameters could be used to identify injured runners.
RESULTS: The injured runners demonstrated greater contralateral pelvic drop (CPD) and forward trunk lean at midstance and a more extended knee and dorsiflexed ankle at initial contact. The subgroup analysis of variance found that these kinematic patterns were consistent across each of the 4 injured subgroups. CPD was found to be the most important variable predicting the classification of participants as healthy or injured. Importantly, for every 1° increase in pelvic drop, there was an 80\% increase in the odds of being classified as injured.
CONCLUSION: This study identified a number of global kinematic contributors to common running injuries. In particular, we found injured runners to run with greater peak CPD and trunk forward lean as well as an extended knee and dorsiflexed ankle at initial contact. CPD appears to be the variable most strongly associated with common running-related injuries.
CLINICAL RELEVANCE: The identified kinematic patterns may prove beneficial for clinicians when assessing for biomechanical contributors to running injuries.},
	language = {eng},
	number = {12},
	journal = {The American Journal of Sports Medicine},
	author = {Bramah, Christopher and Preece, Stephen J. and Gill, Niamh and Herrington, Lee},
	month = oct,
	year = {2018},
	pmid = {30193080},
	keywords = {Adult, Biomechanical Phenomena, Female, Gait, Humans, Knee Joint, Lower Extremity, Male, Running, Soft Tissue Injuries, gait, injury, kinematics, running},
	pages = {3023--3031},
}

@misc{noauthor_is_nodate,
	title = {Is {There} a {Pathological} {Gait} {Associated} {With} {Common} {Soft} {Tissue} {Running} {Injuries}? - {Christopher} {Bramah}, {Stephen} {J}. {Preece}, {Niamh} {Gill}, {Lee} {Herrington}, 2018},
	url = {https://journals.sagepub.com/doi/full/10.1177/0363546518793657},
	urldate = {2024-08-14},
}

@article{messier_2-year_2018,
	title = {A 2-{Year} {Prospective} {Cohort} {Study} of {Overuse} {Running} {Injuries}: {The} {Runners} and {Injury} {Longitudinal} {Study} ({TRAILS})},
	volume = {46},
	issn = {1552-3365},
	shorttitle = {A 2-{Year} {Prospective} {Cohort} {Study} of {Overuse} {Running} {Injuries}},
	doi = {10.1177/0363546518773755},
	abstract = {BACKGROUND: The National Center for Injury Prevention and Control, noting flaws in previous running injury research, called for more rigorous prospective designs and comprehensive analyses to define the origin of running injuries.
PURPOSE: To determine the risk factors that differentiate recreational runners who remain uninjured from those diagnosed with an overuse running injury during a 2-year observational period.
STUDY DESIGN: Cohort study; Level of evidence, 2.
METHODS: Inclusion criteria were running a minimum of 5 miles per week and being injury free for at least the past 6 months. Data were collected at baseline on training, medical and injury histories, demographics, anthropometrics, strength, gait biomechanics, and psychosocial variables. Injuries occurring over the 2-year observation period were diagnosed by an orthopaedic surgeon on the basis of predetermined definitions.
RESULTS: Of the 300 runners who entered the study, 199 (66\%) sustained at least 1 injury, including 73\% of women and 62\% of men. Of the injured runners, 111 (56\%) sustained injuries more than once. In bivariate analyses, significant ( P ≤ .05) factors at baseline that predicted injury were as follows: Short Form Health Survey-12 mental component score (lower mental health-related quality of life), Positive and Negative Affect Scale negative affect score (more negative emotions), sex (higher percentage of women were injured), and knee stiffness (greater stiffness was associated with injury); subsequently, knee stiffness was the lone significant predictor of injury (odds ratio = 1.18) in a multivariable analysis. Flexibility, quadriceps angle, arch height, rearfoot motion, strength, footwear, and previous injury were not significant risk factors for injury.
CONCLUSION: The results of this study indicate the following: (1) among recreational runners, women sustain injuries at a higher rate than men; (2) greater knee stiffness, more common in runners with higher body weights (≥80 kg), significantly increases the odds of sustaining an overuse running injury; and (3) contrary to several long-held beliefs, flexibility, arch height, quadriceps angle, rearfoot motion, lower extremity strength, weekly mileage, footwear, and previous injury are not significant etiologic factors across all overuse running injuries.},
	language = {eng},
	number = {9},
	journal = {The American Journal of Sports Medicine},
	author = {Messier, Stephen P. and Martin, David F. and Mihalko, Shannon L. and Ip, Edward and DeVita, Paul and Cannon, D. Wayne and Love, Monica and Beringer, Danielle and Saldana, Santiago and Fellin, Rebecca E. and Seay, Joseph F.},
	month = jul,
	year = {2018},
	pmid = {29791183},
	keywords = {Adult, Athletic Performance, Biomechanical Phenomena, Cumulative Trauma Disorders, Female, Humans, Longitudinal Studies, Male, Middle Aged, Prospective Studies, Risk Factors, Running, United States, Young Adult, etiology, injury, overuse, running},
	pages = {2211--2221},
}

@misc{noauthor_2-year_nodate,
	title = {A 2-{Year} {Prospective} {Cohort} {Study} of {Overuse} {Running} {Injuries}: {The} {Runners} and {Injury} {Longitudinal} {Study} ({TRAILS}) - {Stephen} {P}. {Messier}, {David} {F}. {Martin}, {Shannon} {L}. {Mihalko}, {Edward} {Ip}, {Paul} {DeVita}, {D}. {Wayne} {Cannon}, {Monica} {Love}, {Danielle} {Beringer}, {Santiago} {Saldana}, {Rebecca} {E}. {Fellin}, {Joseph} {F}. {Seay}, 2018},
	url = {https://journals.sagepub.com/doi/10.1177/0363546518773755},
	urldate = {2024-08-14},
}

@article{li_latent_2023,
	title = {Latent factor model for multivariate functional data},
	volume = {79},
	copyright = {© 2023 The Authors. Biometrics published by Wiley Periodicals LLC on behalf of International Biometric Society.},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13924},
	doi = {10.1111/biom.13924},
	abstract = {For multivariate functional data, a functional latent factor model is proposed, extending the traditional latent factor model for multivariate data. The proposed model uses unobserved stochastic processes to induce the dependence among the different functions, and thus, for a large number of functions, may provide a more parsimonious and interpretable characterization of the otherwise complex dependencies between the functions. Sufficient conditions are provided to establish the identifiability of the proposed model. The performance of the proposed model is assessed through simulation studies and an application to electroencephalography data.},
	language = {en},
	number = {4},
	urldate = {2024-08-14},
	journal = {Biometrics},
	author = {Li, Ruonan and Xiao, Luo},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13924},
	keywords = {covariance function, fPCA, functional data, model identifiability, penalized splines},
	pages = {3307--3318},
}

@article{liu_multivariate_2022,
	title = {Multivariate {Functional} {Regression} {Via} {Nested} {Reduced}-{Rank} {Regularization}},
	volume = {31},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2021.1960850},
	doi = {10.1080/10618600.2021.1960850},
	abstract = {We propose a nested reduced-rank regression (NRRR) approach in fitting a regression model with multivariate functional responses and predictors to achieve tailored dimension reduction and facilitate model interpretation and visualization. Our approach is based on a two-level low-rank structure imposed on the functional regression surfaces. A global low-rank structure identifies a small set of latent principal functional responses and predictors that drives the underlying regression association. A local low-rank structure then controls the complexity and smoothness of the association between the principal functional responses and predictors. The functional problem boils down to an integrated matrix approximation task through basis expansion, where the blocks of an integrated low-rank matrix share some common row space and/or column space. This nested reduced-rank structure also finds potential applications in multivariate time series modeling and tensor regression. A blockwise coordinate descent algorithm is developed. We establish the consistency of NRRR and show through nonasymptotic analysis that it can achieve at least a comparable error rate to that of the reduced-rank regression. Simulation studies demonstrate the effectiveness of NRRR. We apply the proposed methods in an electricity demand problem to relate daily electricity consumption trajectories with daily temperatures. Supplementary files for this article are available online.},
	number = {1},
	urldate = {2024-08-14},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Liu, Xiaokang and Ma, Shujie and Chen, Kun},
	month = jan,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2021.1960850},
	keywords = {Dimension reduction, Matrix approximation, Multi-scale learning},
	pages = {231--240},
}

@article{zhu_one-way_2022,
	title = {One-way {MANOVA} for functional data via {Lawley}–{Hotelling} trace test},
	volume = {192},
	issn = {0047-259X},
	url = {https://www.sciencedirect.com/science/article/pii/S0047259X22000884},
	doi = {10.1016/j.jmva.2022.105095},
	abstract = {Functional data arise from various fields of study and there have been numerous works on their analysis. However, most of existing methods consider the univariate case and methodology for multivariate functional data analysis is rather limited. In this article, we consider testing equality of vectors of mean functions for multivariate functional data, i.e., functional one-way multivariate analysis of variance (MANOVA). To this aim, we study asymptotic null distribution of the functional Lawley–Hotelling trace (FLH) test statistic and approximate it by a Welch–Satterthwaite type χ2-approximation. We describe two approaches to estimating the parameters in the χ2-approximation ratio-consistently. The resulting FLH test has the correct asymptotic level, is root-n consistent in detecting local alternatives, and is computationally efficient. The numerical performance is examined via some simulation studies and application to three real data examples. The proposed FLH test is comparable with four existing tests based on permutation in terms of size control and power. The major advantage is that it is much faster to compute.},
	urldate = {2024-08-14},
	journal = {Journal of Multivariate Analysis},
	author = {Zhu, Tianming and Zhang, Jin-Ting and Cheng, Ming-Yen},
	month = nov,
	year = {2022},
	keywords = {-type mixtures, Lawley–Hotelling trace test, Multivariate functional data, Root- consistency, Welch–Satterthwaite -approximation},
	pages = {105095},
}

@article{diquigiovanni_conformal_2022,
	title = {Conformal prediction bands for multivariate functional data},
	volume = {189},
	issn = {0047-259X},
	url = {https://www.sciencedirect.com/science/article/pii/S0047259X21001573},
	doi = {10.1016/j.jmva.2021.104879},
	abstract = {Motivated by the pressing request of methods able to create prediction sets in a general regression framework for a multivariate functional response, we propose a set of conformal predictors that produce finite-sample either valid or exact multivariate simultaneous prediction bands under the mild assumption of exchangeable regression pairs. The fact that the prediction bands can be built around any regression estimator and that can be easily found in closed form yields a very widely usable method, which is fairly straightforward to implement. In addition, we first introduce and then describe a specific conformal predictor that guarantees an asymptotic result in terms of efficiency and inducing prediction bands able to modulate their width based on the local behavior and magnitude of the functional data. The method is investigated and analyzed through a simulation study and a real-world application in the field of urban mobility.},
	urldate = {2024-08-14},
	journal = {Journal of Multivariate Analysis},
	author = {Diquigiovanni, Jacopo and Fontana, Matteo and Vantini, Simone},
	month = may,
	year = {2022},
	keywords = {Conformal Prediction, Distribution-free prediction set, Exact prediction set, Finite-sample prediction set, Functional data, Prediction band},
	pages = {104879},
}

@article{jiang_analysis_2022,
	title = {Analysis of multivariate non-gaussian functional data: {A} semiparametric latent process approach},
	volume = {189},
	issn = {0047-259X},
	shorttitle = {Analysis of multivariate non-gaussian functional data},
	url = {https://www.sciencedirect.com/science/article/pii/S0047259X21001664},
	doi = {10.1016/j.jmva.2021.104888},
	abstract = {Commonly assumed for multivariate functional regression models are normality and structural dependence, which, however, may not hold in practice. To relax these restrictions, we propose a new semiparametric transformation latent process functional regression model for multivariate functional data. Our model does not require normality assumptions or any specific dependence structures among multivariate response curves or intra-individual variability across time. We propose a combined likelihood- and estimating equation-based method to estimate parameters, transformation functions and covariance structures. We establish theoretical properties, including n−consistency and asymptotic normality, for the proposed estimators. The utility of the method is illustrated via extensive simulations and analyses of an elderly cognitive evolution dataset, which yield a better fit than the other competing methods and some interesting findings.},
	urldate = {2024-08-14},
	journal = {Journal of Multivariate Analysis},
	author = {Jiang, Jiakun and Lin, Huazhen and Zhong, Qingzhi and Li, Yi},
	month = may,
	year = {2022},
	keywords = {Functional regression analysis, Latent process, Normal transformation model, Semi-parametric},
	pages = {104888},
}

@article{meyer_bayesian_2015,
	title = {Bayesian {Function}-on-{Function} {Regression} for {Multilevel} {Functional} {Data}},
	volume = {71},
	issn = {0006-341X},
	url = {https://doi.org/10.1111/biom.12299},
	doi = {10.1111/biom.12299},
	abstract = {Medical and public health research increasingly involves the collection of complex and high dimensional data. In particular, functional data—where the unit of observation is a curve or set of curves that are finely sampled over a grid—is frequently obtained. Moreover, researchers often sample multiple curves per person resulting in repeated functional measures. A common question is how to analyze the relationship between two functional variables. We propose a general function-on-function regression model for repeatedly sampled functional data on a fine grid, presenting a simple model as well as a more extensive mixed model framework, and introducing various functional Bayesian inferential procedures that account for multiple testing. We examine these models via simulation and a data analysis with data from a study that used event-related potentials to examine how the brain processes various types of images.},
	number = {3},
	urldate = {2024-08-14},
	journal = {Biometrics},
	author = {Meyer, Mark J. and Coull, Brent A. and Versace, Francesco and Cinciripini, Paul and Morris, Jeffrey S.},
	month = sep,
	year = {2015},
	pages = {563--574},
}

@article{golovkine_clustering_2022,
	title = {Clustering multivariate functional data using unsupervised binary trees},
	volume = {168},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947321002103},
	doi = {10.1016/j.csda.2021.107376},
	abstract = {A model-based clustering algorithm is proposed for a general class of functional data for which the components could be curves or images. The random functional data realizations could be measured with errors at discrete, and possibly random, points in the definition domain. The idea is to build a set of binary trees by recursive splitting of the observations. The number of groups are determined in a data-driven way. The new algorithm provides easily interpretable results and fast predictions for online data sets. Results on simulated datasets reveal good performance in various complex settings. The methodology is applied to the analysis of vehicle trajectories on a German roundabout.},
	urldate = {2024-08-14},
	journal = {Computational Statistics \& Data Analysis},
	author = {Golovkine, Steven and Klutchnikoff, Nicolas and Patilea, Valentin},
	month = apr,
	year = {2022},
	keywords = {Gaussian mixtures, Model-based clustering, Multivariate functional principal components},
	pages = {107376},
}

@phdthesis{zohner_feature_2021,
	address = {United States -- Texas},
	type = {Ph.{D}.},
	title = {Feature {Learning} and {Bayesian} {Functional} {Regression} for {High}-{Dimensional} {Complex} {Data}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/2715479373/abstract/89C838326EDE4980PQ/1},
	abstract = {In recent years, technological innovations have facilitated the collection of complex, high-dimensional data that pose substantial modeling challenges. Most of the time, these complex objects are strongly characterized by internal structure that makes sparse representations possible. If we can learn a sparse set of features that accurately captures the salient features of a given object, then we can model these features using standard statistical tools including clustering, regression and classification. The key question is how well this sparse set of features captures the salient information in the objects. In this thesis, we develop methodology for evaluating latent feature representations for functional data and for using these latent features within functional regression frameworks to build flexible models. In the first project, we introduce a graphical latent feature representation tool (GLaRe) to learn features and assess how well a given feature learning approach captures the salient information in a data object. In the second project, we build on this feature learning methodology to propose a basis strategy for fitting functional regression models when the domain is a closed manifold. This methodology is applied to MRI data to characterize patterns of infant cortical thickness development in the first two years of life. In the third project, we adapt our feature learning and Bayesian functional regression methodology to high-frequency data streams. We model high-frequency intraocular pressure data streams using custom bases for quantile representations of the underlying distribution, and provide insights into the etiology of glaucoma.},
	language = {English},
	urldate = {2024-05-14},
	school = {Rice University},
	author = {Zohner, Ye Emma Mariam},
	year = {2021},
	note = {ISBN: 9798841721215},
	keywords = {Bayesian statistics, Functional mixed models, High-frequency data streams, Infant cortical thickness, Intraocular pressure, Latent feature representation, Manifold data},
}

@article{wand_semiparametric_2008,
	title = {On {Semiparametric} {Regression} with {O}'sullivan {Penalized} {Splines}},
	volume = {50},
	copyright = {© 2008 Australian Statistical Publishing Association Inc.},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2008.00507.x},
	doi = {10.1111/j.1467-842X.2008.00507.x},
	abstract = {An exposition on the use of O'Sullivan penalized splines in contemporary semiparametric regression, including mixed model and Bayesian formulations, is presented. O'Sullivan penalized splines are similar to P-splines, but have the advantage of being a direct generalization of smoothing splines. Exact expressions for the O'Sullivan penalty matrix are obtained. Comparisons between the two types of splines reveal that O'Sullivan penalized splines more closely mimic the natural boundary behaviour of smoothing splines. Implementation in modern computing environments such as Matlab, r and bugs is discussed.},
	language = {en},
	number = {2},
	urldate = {2024-05-08},
	journal = {Australian \& New Zealand Journal of Statistics},
	author = {Wand, M. P. and Ormerod, J. T.},
	year = {2008},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-842X.2008.00507.x},
	keywords = {Markov chain Monte Carlo, P-splines, additive models, mixed models, smoothing splines},
	pages = {179--198},
}

@article{wilhelm_impact_2022,
	title = {Impact of warmer climate periods on flood hazard in the {European} {Alps}},
	volume = {15},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1752-0908},
	url = {https://www.nature.com/articles/s41561-021-00878-y},
	doi = {10.1038/s41561-021-00878-y},
	abstract = {Flooding is a pervasive natural hazard—costly in both human and economic terms—and climate change will probably exacerbate risks around the world. Mountainous areas, such as the densely populated European Alps, are of particular concern as topography and atmospheric conditions can result in large and sudden floods. In addition, the Alps are experiencing a high warming rate, which is probably leading to more heavy rainfall events. Here, we compile palaeoflood records to test the still uncertain impact these climatic trends might have on flood frequency and magnitude in the European Alps. We demonstrate that a warming of 0.5–1.2 °C, whether naturally or anthropogenically forced, led to a 25–50\% decrease in the frequency of large (≥10 yr return period) floods. This decreasing trend is not conclusive in records covering less than 200 years but persistent in those ranging from 200 to 9,000 years. By contrast, extreme ({\textgreater}100 yr) floods may increase with a similar degree of warming in certain small alpine catchments impacted by local intensification of extreme rainfall. Our results show how long, continuous palaeoflood records can be used to disentangle complex climate–flooding relationships and assist in improving risk assessment and management at a regional scale.},
	language = {en},
	number = {2},
	urldate = {2024-05-03},
	journal = {Nature Geoscience},
	author = {Wilhelm, B. and Rapuc, W. and Amann, B. and Anselmetti, F. S. and Arnaud, F. and Blanchet, J. and Brauer, A. and Czymzik, M. and Giguet-Covex, C. and Gilli, A. and Glur, L. and Grosjean, M. and Irmler, R. and Nicolle, M. and Sabatier, P. and Swierczynski, T. and Wirth, S. B.},
	month = feb,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Hydrology, Natural hazards, Palaeoclimate},
	pages = {118--123},
}

@article{telschow_confidence_2023,
	title = {Confidence tubes for curves on {SO}(3) and identification of subject-specific gait change after kneeling},
	volume = {72},
	issn = {0035-9254},
	url = {https://doi.org/10.1093/jrsssc/qlad060},
	doi = {10.1093/jrsssc/qlad060},
	abstract = {In order to identify changes of gait patterns, e.g. due to prolonged occupational kneeling, which might be a major risk factor for the development of knee osteoarthritis, we develop confidence tubes for curves following a perturbation model on SO(3) using the Gaussian kinematic formula which are equivariant under gait similarities and have precise coverage even for small sample sizes. Applying them to gait curves from eight volunteers undergoing kneeling tasks and adjusting for different walking speeds and marker replacement at different visits, allows us to identify at which phases of the gait cycle the gait pattern changed due to kneeling.},
	number = {5},
	urldate = {2024-03-11},
	journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Telschow, Fabian J E and Pierrynowski, Michael R and Huckemann, Stephan F},
	month = nov,
	year = {2023},
	pages = {1354--1374},
}

@article{telschow_functional_2021,
	title = {Functional inference on rotational curves under sample-specific group actions and identification of human gait},
	volume = {48},
	copyright = {© 2020 Board of the Foundation of the Scandinavian Journal of Statistics},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12488},
	doi = {10.1111/sjos.12488},
	abstract = {Inspired by the problem of gait reproducibility (reidentifying individuals across doctor's visits) we develop two-sample permutation tests under a sample-specific group action on Lie groups with a bi-invariant Riemannian metric. These tests rely on consistent estimators and pairwise curve alignment. To this end, we propose Gaussian perturbation models and for the special case of curves on the group of 3D rotations we provide asymptotic consistency and, employing a quaternion point of view, fast spatial alignment of pointwise extrinsic mean curves. In our application to rotations of the tibia versus the femur at the knee joint under the spatial action of marker placement and the temporal action of different walking speeds, obtained from an experiment, we solve the problem of gait reproducibility.},
	language = {en},
	number = {4},
	urldate = {2024-03-11},
	journal = {Scandinavian Journal of Statistics},
	author = {Telschow, Fabian J.E. and Pierrynowski, Michael R. and Huckemann, Stephan F.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12488},
	keywords = {Gaussian perturbation models, Lie groups, functional data analysis, permutation testing, quaternions},
	pages = {1256--1276},
}

@misc{gertheiss_functional_2023,
	title = {Functional {Data} {Analysis}: {An} {Introduction} and {Recent} {Developments}},
	shorttitle = {Functional {Data} {Analysis}},
	url = {http://arxiv.org/abs/2312.05523},
	doi = {10.48550/arXiv.2312.05523},
	abstract = {Functional data analysis (FDA) is a statistical framework that allows for the analysis of curves, images, or functions on higher dimensional domains. The goals of FDA, such as descriptive analyses, classification, and regression, are generally the same as for statistical analyses of scalar-valued or multivariate data, but FDA brings additional challenges due to the high- and infinite dimensionality of observations and parameters, respectively. This paper provides an introduction to FDA, including a description of the most common statistical analysis techniques, their respective software implementations, and some recent developments in the field. The paper covers fundamental concepts such as descriptives and outliers, smoothing, amplitude and phase variation, and functional principal component analysis. It also discusses functional regression, statistical inference with functional data, functional classification and clustering, and machine learning approaches for functional data analysis. The methods discussed in this paper are widely applicable in fields such as medicine, biophysics, neuroscience, and chemistry, and are increasingly relevant due to the widespread use of technologies that allow for the collection of functional data. Sparse functional data methods are also relevant for longitudinal data analysis. All presented methods are demonstrated using available software in R by analyzing a data set on human motion and motor control. To facilitate the understanding of the methods, their implementation, and hands-on application, the code for these practical examples is made available on Github: https://github.com/davidruegamer/FDA\_tutorial .},
	urldate = {2024-03-08},
	publisher = {arXiv},
	author = {Gertheiss, Jan and Rügamer, David and Liew, Bernard X. W. and Greven, Sonja},
	month = dec,
	year = {2023},
	note = {arXiv:2312.05523 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology},
}

@book{crainiceanu_functional_2024,
	address = {Boca Raton},
	edition = {1st edition},
	title = {Functional {Data} {Analysis} with {R}},
	isbn = {978-1-03-224471-6},
	abstract = {Emerging technologies generate data sets of increased size and complexity that require new or updated statistical inferential methods and scalable, reproducible software. These data sets often involve measurements of a continuous underlying process, and benefit from a functional data perspective. Functional Data Analysis with R presents many ideas for handling functional data including dimension reduction techniques, smoothing, functional regression, structured decompositions of curves, and clustering. The idea is for the reader to be able to immediately reproduce the results in the book, implement these methods, and potentially design new methods and software that may be inspired by these approaches.Features:Functional regression models receive a modern treatment that allows extensions to many practical scenarios and development of state-of-the-art software.The connection between functional regression, penalized smoothing, and mixed effects models is used as the cornerstone for inference.Multilevel, longitudinal, and structured functional data are discussed with emphasis on emerging functional data structures.Methods for clustering functional data before and after smoothing are discussed.Multiple new functional data sets with dense and sparse sampling designs from various application areas are presented, including the NHANES linked accelerometry and mortality data, COVID-19 mortality data, CD4 counts data, and the CONTENT child growth study.Step-by-step software implementations are included, along with a supplementary website (www.FunctionalDataAnalysis.com) featuring software, data, and tutorials.More than 100 plots for visualization of functional data are presented.Functional Data Analysis with R is primarily aimed at undergraduate, master's, and PhD students, as well as data scientists and researchers working on functional data analysis. The book can be read at different levels and combines state-of-the-art software, methods, and inference. It can be used for self-learning, teaching, and research, and will particularly appeal to anyone who is interested in practical methods for hands-on, problem-forward functional data analysis. The reader should have some basic coding experience, but expertise in R is not required.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {Crainiceanu, Ciprian M. and Goldsmith, Jeff and Leroux, Andrew and Cui, Erjia},
	month = mar,
	year = {2024},
}

@article{gellar_variable-domain_2014,
	title = {Variable-{Domain} {Functional} {Regression} for {Modeling} {ICU} {Data}},
	volume = {109},
	issn = {0162-1459},
	doi = {10.1080/01621459.2014.940044},
	abstract = {We introduce a class of scalar-on-function regression models with subject-specific functional predictor domains. The fundamental idea is to consider a bivariate functional parameter that depends both on the functional argument and on the width of the functional predictor domain. Both parametric and nonparametric models are introduced to fit the functional coefficient. The nonparametric model is theoretically and practically invariant to functional support transformation, or support registration. Methods were motivated by and applied to a study of association between daily measures of the Intensive Care Unit (ICU) Sequential Organ Failure Assessment (SOFA) score and two outcomes: in-hospital mortality, and physical impairment at hospital discharge among survivors. Methods are generally applicable to a large number of new studies that record a continuous variables over unequal domains.},
	language = {eng},
	number = {508},
	journal = {Journal of the American Statistical Association},
	author = {Gellar, Jonathan E. and Colantuoni, Elizabeth and Needham, Dale M. and Crainiceanu, Ciprian M.},
	month = dec,
	year = {2014},
	pmid = {25663725},
	pmcid = {PMC4315944},
	keywords = {Functional data analysis, Longitudinal data, Nonparametric statistics, Scalar-on-function regression, Variable-domain functional regression, Varying-coeffcient model},
	pages = {1425--1439},
}

@book{clarkson_sfunctional_2005,
	address = {New York},
	edition = {2005th edition},
	title = {S+{Functional} {Data} {Analysis}: {User}'s {Manual} for {Windows} ®},
	isbn = {978-0-387-24969-8},
	shorttitle = {S+{Functional} {Data} {Analysis}},
	abstract = {This book can be considered a companion to two other highly acclaimed books involving James Ramsay and Bernard Silverman: Functional Data Analysis, Second Edition (2005) and Applied Functional Data Analysis (2002). This user's manual also provides the documentation for the S+FDA library for S­Plus.},
	language = {English},
	publisher = {Springer},
	author = {Clarkson, Douglas B. and Fraley, Chris and Gu, Charles and Ramsay, James},
	month = jul,
	year = {2005},
}

@book{noauthor_s_2005,
	address = {New York},
	title = {S+ {Functional} {Data} {Analysis}},
	isbn = {978-0-387-24969-8},
	url = {http://link.springer.com/10.1007/0-387-28393-5},
	language = {en},
	urldate = {2024-02-24},
	publisher = {Springer-Verlag},
	year = {2005},
	doi = {10.1007/0-387-28393-5},
	keywords = {Generalized linear model, cluster analysis, clustering, correlation, data analysis},
}

@article{besse_principal_1986,
	title = {Principal components analysis of sampled functions},
	volume = {51},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02293986},
	doi = {10.1007/BF02293986},
	abstract = {This paper describes a technique for principal components analysis of data consisting ofn functions each observed atp argument values. This problem arises particularly in the analysis of longitudinal data in which some behavior of a number of subjects is measured at a number of points in time. In such cases information about the behavior of one or more derivatives of the function being sampled can often be very useful, as for example in the analysis of growth or learning curves. It is shown that the use of derivative information is equivalent to a change of metric for the row space in classical principal components analysis. The reproducing kernel for the Hilbert space of functions plays a central role, and defines the best interpolating functions, which are generalized spline functions. An example is offered of how sensitivity to derivative information can reveal interesting aspects of the data.},
	language = {en},
	number = {2},
	urldate = {2024-02-24},
	journal = {Psychometrika},
	author = {Besse, Philippe and Ramsay, J. O.},
	month = jun,
	year = {1986},
	keywords = {Green's functions, Hilbert space of functions, interpolation, reproducing kernel, smoothing, spline functions},
	pages = {285--311},
}

@article{pini_interval-wise_2017,
	title = {Interval-wise testing for functional data},
	volume = {29},
	issn = {1048-5252},
	url = {https://doi.org/10.1080/10485252.2017.1306627},
	doi = {10.1080/10485252.2017.1306627},
	abstract = {In the framework of null hypothesis significance testing for functional data, we propose a procedure able to select intervals of the domain imputable for the rejection of a null hypothesis. An unadjusted p-value function and an adjusted one are the output of the procedure, namely interval-wise testing. Depending on the sort and level α of type-I error control, significant intervals can be selected by thresholding the two p-value functions at level α. We prove that the unadjusted (adjusted) p-value function point-wise (interval-wise) controls the probability of type-I error and it is point-wise (interval-wise) consistent. To enlighten the gain in terms of interpretation of the phenomenon under study, we applied the interval-wise testing to the analysis of a benchmark functional data set, i.e. Canadian daily temperatures. The new procedure provides insights that current state-of-the-art procedures do not, supporting similar advantages in the analysis of functional data with less prior knowledge.},
	number = {2},
	urldate = {2024-02-23},
	journal = {Journal of Nonparametric Statistics},
	author = {Pini, A. and Vantini, S.},
	month = apr,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10485252.2017.1306627},
	keywords = {62G09, 62G10, 62H15, 62H99, Inference, canadian temperatures, domain selection, functional data},
	pages = {407--424},
}

@book{knuth_literate_1992,
	address = {Stanford, Calif.},
	edition = {1st edition},
	title = {Literate {Programming}},
	isbn = {978-0-937073-80-3},
	language = {English},
	publisher = {Center for the Study of Language and Inf},
	author = {Knuth, Donald E.},
	month = jun,
	year = {1992},
}

@article{knuth_literate_1984,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620},
	url = {https://doi.org/10.1093/comjnl/27.2.97},
	doi = {10.1093/comjnl/27.2.97},
	abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
	number = {2},
	urldate = {2024-02-18},
	journal = {The Computer Journal},
	author = {Knuth, D. E.},
	month = jan,
	year = {1984},
	pages = {97--111},
}

@article{knuth_literate_1984-1,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620},
	url = {https://doi.org/10.1093/comjnl/27.2.97},
	doi = {10.1093/comjnl/27.2.97},
	abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
	number = {2},
	urldate = {2024-02-18},
	journal = {The Computer Journal},
	author = {Knuth, D. E.},
	month = jan,
	year = {1984},
	pages = {97--111},
}

@article{daubechies_wavelet_1990,
	title = {The wavelet transform, time-frequency localization and signal analysis},
	volume = {36},
	issn = {1557-9654},
	url = {https://ieeexplore.ieee.org/abstract/document/57199},
	doi = {10.1109/18.57199},
	abstract = {Two different procedures for effecting a frequency analysis of a time-dependent signal locally in time are studied. The first procedure is the short-time or windowed Fourier transform; the second is the wavelet transform, in which high-frequency components are studied with sharper time resolution than low-frequency components. The similarities and the differences between these two methods are discussed. For both schemes a detailed study is made of the reconstruction method and its stability as a function of the chosen time-frequency density. Finally, the notion of time-frequency localization is made precise, within this framework, by two localization theorems.{\textless}{\textgreater}},
	number = {5},
	urldate = {2024-02-14},
	journal = {IEEE Transactions on Information Theory},
	author = {Daubechies, I.},
	month = sep,
	year = {1990},
	note = {Conference Name: IEEE Transactions on Information Theory},
	keywords = {Fourier transforms, Lattices, Physics, Proposals, Reconstruction algorithms, Signal analysis, Signal resolution, Time frequency analysis, Wavelet analysis, Wavelet transforms},
	pages = {961--1005},
}

@article{malfait_historical_2003,
	title = {The {Historical} {Functional} {Linear} {Model}},
	volume = {31},
	issn = {0319-5724},
	url = {https://www.jstor.org/stable/3316063},
	doi = {10.2307/3316063},
	abstract = {The authors develop a functional linear model in which the values at time t of a sample of curves yi(t) are explained in a feed-forward sense by the values of covariate curves xi(s) observed at times s ≤ t. They give special attention to the case s ∈ [t - δ, t], where the lag parameter δ is estimated from the data. They use the finite element method to estimate the bivariate parameter regression function β(s, t), which is defined on the triangular domain s ≤ t. They apply their model to the problem of predicting the acceleration of the lower lip during speech on the basis of electromyographical recordings from a muscle depressing the lip. They also provide simulation results to guide the calibration of the fitting process. /// Les auteurs décrivent un modèle linéaire fonctionnel dans lequel les valeurs au temps t d'un échantillon de courbes yi(t) sont expliquées par les valeurs observées aux temps s ≤ t de courbes covariables xi(s). Ils accordent une attention particulière au cas où s ∈ [t - δ, t], δ représentant un paramètre de délai estimé à partir des données. Ils emploient la méthode des éléments finis pour estimer la fonction paramètre β(s, t) bivariée définie sur le domaine triangulaire s ≤ t. Ils appliquent leur modèle à la prévision de courbes d'accélération de la lèvre inférieure d'un locuteur à partir d'enregistrements électromyographiques d'un muscle abaissant celle-ci. Ils présentent aussi des résultats de simulation pouvant guider le processus de calibration intervenant dans l'ajustement du modèle.},
	number = {2},
	urldate = {2024-02-10},
	journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
	author = {Malfait, Nicole and Ramsay, James O.},
	year = {2003},
	note = {Publisher: [Statistical Society of Canada, Wiley]},
	pages = {115--128},
}

@phdthesis{brockhaus_boosting_2016,
	type = {Text.{PhDThesis}},
	title = {Boosting functional regression models},
	url = {https://edoc.ub.uni-muenchen.de/19868/},
	abstract = {In functional data analysis, the data consist of functions that are defined on a continuous domain. In practice, functional variables are observed on some discrete grid. Regression models are important tools to capture the impact of explanatory variables on the response and are challenging in the case of functional data. In this thesis, a generic framework is proposed that includes scalar-on-function, function-on-scalar and function-on-function regression models. Within this framework, quantile regression models, generalized additive models and generalized additive models for location, scale and shape can be derived by optimizing the corresponding loss functions. The additive predictors can contain a variety of covariate effects, for example linear, smooth and interaction effects of scalar and functional covariates. 
In the first part, the functional linear array model is introduced. This model is suited for responses observed on a common grid and covariates that do not vary over the domain of the response. Array models achieve computational efficiency by taking advantage of the Kronecker product in the design matrix. In the second part, the focus is on models without array structure, which are capable to capture situations with responses observed on irregular grids and/or time-varying covariates. This includes in particular models with historical functional effects. For situations, in which the functional response and covariate are both observed over the same time domain, a historical functional effect induces an association between response and covariate such that only past values of the covariate influence the current value of the response. In this model class, effects with more general integration limits, like lag and lead effects, can be specified. In the third part, the framework is extended to generalized additive models for location, scale and shape where all parameters of the conditional response distribution can depend on covariate effects. The conditional response distribution can be modeled very flexibly by relating each distribution parameter with a link function to a linear predictor. 
For all parts, estimation is conducted by a component-wise gradient boosting algorithm. Boosting is an ensemble method that pursues a divide-and-conquer strategy for optimizing an expected loss criterion. This provides great flexibility for the regression models. For example, minimizing the check function yields quantile regression and minimizing the negative log-likelihood generalized additive models for location, scale and shape. The estimator is updated iteratively to minimize the loss criterion along the steepest gradient descent. The model is represented as a sum of simple (penalized) regression models, the so called base-learners, that separately fit the negative gradient in each step where only the best-fitting base-learner is updated.  Component-wise boosting allows for high-dimensional data settings and for automatic, data-driven variable selection. To adapt boosting for regression with functional data, the loss is integrated over the domain of the response and base-learners suited to functional effects are implemented. To enhance the availability of functional regression models for practitioners, a comprehensive implementation of the methods is provided in the {\textbackslash}textsf\{R\} add-on package {\textbackslash}pkg\{FDboost\}. 
The flexibility of the regression framework is highlighted by several applications from different fields. Some features of the functional linear array model are illustrated using data on curing resin for car production, heat values of fossil fuels and Canadian climate data. These require function-on-scalar, scalar-on-function and function-on-function regression models, respectively. The methodological developments for non-array models are motivated by biotechnological data on fermentations, modeling a key process variable by a historical functional model. The motivating application for functional generalized additive models for location, scale and shape is a time series on stock returns where expectation and standard deviation are modeled depending on scalar and functional covariates.},
	language = {de},
	urldate = {2024-02-07},
	school = {Ludwig-Maximilians-Universität München},
	author = {Brockhaus, Sarah},
	month = aug,
	year = {2016},
}

@misc{wrobel_registr_2022,
	title = {registr: {Curve} {Registration} for {Exponential} {Family} {Functional} {Data}},
	copyright = {MIT + file LICENSE},
	shorttitle = {registr},
	url = {https://cran.r-project.org/web/packages/registr/index.html},
	abstract = {A method for performing joint registration and functional principal component analysis for curves (functional data) that are generated from exponential family distributions. This mainly implements the algorithms described in 'Wrobel et al. (2019)' {\textless}doi:10.1111/biom.12963{\textgreater} and further adapts them to potentially incomplete curves where (some) curves are not observed from the beginning and/or until the end of the common domain. Curve registration can be used to better understand patterns in functional data by separating curves into phase and amplitude variability. This software handles both binary and continuous functional data, and is especially applicable in accelerometry and wearable technology.},
	urldate = {2024-02-05},
	author = {Wrobel, Julia and Bauer, Alexander and McDonnell, Erin and Scheipl, Fabian and Goldsmith, Jeff},
	month = oct,
	year = {2022},
	keywords = {FunctionalData},
}

@article{besse_principal_1986-1,
	title = {Principal components analysis of sampled functions},
	volume = {51},
	issn = {1860-0980},
	doi = {10.1007/BF02293986},
	abstract = {Describes a technique for principal-components analysis of data consisting of n functions each observed at p argument values. This problem arises particularly in the analysis of longitudinal behavioral data, in which information about the derivatives of the function can often be useful (e.g., in the analysis of growth or learning curves). The technique is illustrated by data on tongue movements during speech. (24 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychometrika},
	author = {Besse, Philippe and Ramsay, J. O.},
	year = {1986},
	note = {Place: Germany
Publisher: Springer},
	keywords = {Factor Analysis, Statistical Analysis},
	pages = {285--311},
}

@article{dannenmaier_application_2020,
	title = {Application of functional data analysis to explore movements: walking, running and jumping - {A} systematic review},
	volume = {77},
	issn = {09666362},
	shorttitle = {Application of functional data analysis to explore movements},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636220300631},
	doi = {10.1016/j.gaitpost.2020.02.002},
	abstract = {Background Signals are continuously captured during the recording of motion data. Statistical analysis, however, usually uses only a few aspects of the recorded data. Functional data analysis offers the possibility to analyze the entire signal over time. Research question The review is based on the question of how functional data analysis is used in the study of lower limb movements. Methods The literature search was based on the databases EMBASE, PUBMED and OVID MEDLINE. All articles on the application of functional data analysis to motion-associated variables trajectories, ground reaction force,electromyography were included. The references were assessed independently by two reviewers. Results In total 1448 articles were found in the search. Finally, 13 articles were included in the review. All were of moderate methodological quality. The publication year of the studies ranges from 2009 to 2019. Healthy volunteers and persons with cruciate ligament injuries, knee osteoarthritis, gluteal tendinopathy, idiopathic torsional deformities, slipped capital femoral epiphysis and chronic ankle instability were examined in the studies. Movements were analyzed on basis of kinematics (3D motion analysis), ground reaction forces and electromyography. Functional Data Analysis was used in terms of landmark registration, functional principal component analysis, functional t-test and functional ANOVA. Significance Functional data analysis provides the possibility to gain detailed and in-depth insights into the analysis of motion patterns. As a result of the increase in references over the past year, the FDA is becoming more important in the analysis of continuous signals and the explorative analysis of movement data.},
	language = {en},
	urldate = {2024-01-23},
	journal = {Gait \& Posture},
	author = {Dannenmaier, Julia and Kaltenbach, Christina and Kölle, Theresa and Krischak, Gert},
	month = mar,
	year = {2020},
	pages = {182--189},
}

@article{cattell_scree_1966,
	title = {The {Scree} {Test} {For} {The} {Number} {Of} {Factors}},
	volume = {1},
	issn = {0027-3171},
	url = {https://doi.org/10.1207/s15327906mbr0102_10},
	doi = {10.1207/s15327906mbr0102_10},
	number = {2},
	urldate = {2024-01-22},
	journal = {Multivariate Behavioral Research},
	author = {Cattell, Raymond B.},
	month = apr,
	year = {1966},
	pmid = {26828106},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/s15327906mbr0102\_10},
	pages = {245--276},
}

@article{stone_cross-validatory_1974,
	title = {Cross-{Validatory} {Choice} and {Assessment} of {Statistical} {Predictions}},
	volume = {36},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2984809},
	abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
	number = {2},
	urldate = {2024-01-22},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Stone, M.},
	year = {1974},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {111--147},
}

@phdthesis{gunning_statistical_2024,
	title = {Statistical modelling of second-generation functional data with application in biomechanics and human movement research},
	url = {https://researchrepository.ul.ie/articles/thesis/Statistical_modelling_of_second-generation_functional_data_with_application_in_biomechanics_and_human_movement_research/24948066},
	abstract = {In recent years, the data being collected in human movement biomechanics have
increased in size and complexity. Improvements in data acquisition and processing
mean that more data can be recorded and extracted for each individual, producing
datasets of increased volume that are multivariate in nature and exhibit complex
dependence structures due to repeated measurements.
Functional data analysis is a branch of statistics that is well suited to the
analysis of continuous biomechanical data, e.g., kinematics or kinetics that are
recorded throughout a movement, because it treats the measured data streams as
smooth, time-varying functions. Traditional functional data analysis tools have
been developed for independent, univariate samples of functional data, so they
are not flexible enough to fully leverage the richness of modern biomechanical
datasets. There is a growing need to adapt and extend these tools to modern
data structures and characteristics. To address this challenge, this thesis develops
new statistical approaches for structured functional data, as motivated by a large
study on running-related injuries, where kinematic data from recreational runners
were captured during a treadmill run with the goal of understanding running
technique and its links to injury. The motivating biomechanical dataset is rich
in size and structure as it contains repeated measurements of multiple kinematic
variables from a large number of individuals. Thus, it presents methodological
and computational challenges and facilitates the development of novel statistical
methodology that is generally applicable in a variety of fields.
The first challenge addressed in this thesis is the development of multivariate
functional mixed effects modelling techniques, to allow the kinematic data from
multiple body parts (e.g., hip and knee) to be analysed simultaneously. The
mixed effects modelling framework readily incorporates covariate information and
facilitates appropriate modelling of the complex dependence structure between
observations from each individual (i.e., each individual has multiple repetitions
of the movement/strides, measurements are made on both sides of the body).
This work is divided into two sequential contributions. Firstly, a multivariate
functional mixed effects model is developed for a subset of the motivating dataset,
which contains average hip angle and knee angle curves for each individual on
either side of the body. As the second contribution, the modelling framework
is extended to handle the full collection of strides in the motivating dataset,
resulting in a multivariate multilevel longitudinal functional model which uses a
longitudinal functional data analysis approach to capture temporal dependence
among the adjacent strides.
The second challenge addressed in this thesis is the estimation of continuoustime
ordinary differential equations from functional data. A re-formulation of
Principal Differential Analysis, a classical technique for estimating differential
equations from functional data, is developed. The new formulation is based on
a generative statistical model, providing a better understanding of the technique
from a statistical perspective and broadening its applicability. The methodology
is demonstrated on simulated data from ordinary differential equation models and
on a subset of kinematic data from the motivating dataset for this thesis.},
	school = {University of Limerick},
	author = {Gunning, Edward},
	year = {2024},
}

@incollection{hall_principal_2010,
	title = {Principal component analysis for functional data: {Methodology}, theory, and discussion},
	isbn = {978-0-19-956844-4},
	shorttitle = {Principal component analysis for functional data},
	url = {https://doi.org/10.1093/oxfordhb/9780199568444.013.8},
	abstract = {This article discusses the methodology and theory of principal component analysis (PCA) for functional data. It first provides an overview of PCA in the context of finite-dimensional data and infinite-dimensional data, focusing on functional linear regression, before considering the applications of PCA for functional data analysis, principally in cases of dimension reduction. It then describes adaptive methods for prediction and weighted least squares in functional linear regression. It also examines the role of principal components in the assessment of density for functional data, showing how principal component functions are linked to the amount of probability mass contained in a small ball around a given, fixed function, and how this property can be used to define a simple, easily estimable density surrogate. The article concludes by explaining the use of PCA for estimating log-density.},
	urldate = {2024-01-16},
	booktitle = {The {Oxford} {Handbook} of {Functional} {Data} {Analysis}},
	publisher = {Oxford University Press},
	author = {Hall, Peter},
	editor = {Ferraty, Frédéric and Romain, Yves},
	month = nov,
	year = {2010},
	doi = {10.1093/oxfordhb/9780199568444.013.8},
	pages = {0},
}

@misc{horsak_gaitrec_2020,
	title = {{GaitRec}, a large-scale ground reaction force dataset of healthy and impaired gait},
	doi = {10.6084/m9.figshare.c.4788012.v1},
	abstract = {The quantification of ground reaction forces (GRF) is a standard tool for clinicians to quantify and analyze human locomotion. Such recordings produce a vast amount of complex data and variables which are difficult to comprehend. This makes data interpretation challenging. Machine learning approaches seem to be promising tools to support clinicians in identifying and categorizing specific gait patterns. However, the quality of such approaches strongly depends on the amount of available annotated data to train the underlying models. Therefore, we present GaitRec, a comprehensive and completely annotated large-scale dataset containing bi-lateral GRF walking trials of 2,084 patients with various musculoskeletal impairments and data from 211 healthy controls. The dataset comprises data of patients after joint replacement, fractures, ligament ruptures, and related disorders at the hip, knee, ankle or calcaneus during their entire stay(s) at a rehabilitation center. The data sum up to a total of 75,732 bi-lateral walking trials and enable researchers to classify gait patterns at a large-scale as well as to analyze the entire recovery process of patients.},
	language = {en},
	publisher = {figshare},
	author = {Horsak, Brian and Slijepcevic, Djordje and Raberger, Anna-Maria and Schwab, Caterine and Worisch, Marianne and Zeppelzauer, Matthias},
	month = apr,
	year = {2020},
}

@article{dillon_running_2023,
	title = {Running towards injury? {A} prospective investigation of factors associated with running injuries},
	volume = {18},
	issn = {1932-6203},
	shorttitle = {Running towards injury?},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288814},
	doi = {10.1371/journal.pone.0288814},
	abstract = {Background Given the high incidence and heavy burden of running related injuries, large-scale, prospective multifactorial investigations examining potential risk factors are warranted. This study aimed to identify factors associated with running related injuries and to evaluate their potential in injury screening. Study design Prospective cohort study. Materials and methods Two hundred and seventy-four recreational runners were recruited. Clinical measures (strength, range of motion, foot position), injury and training history (via questionnaire), impact loading (via accelerometery) and running technique measures were collected at baseline. Runners were tracked for injury for one year via fortnightly check-ins. A binary logistic regression, (injury versus no injury), was performed for each variable univariably, and then adjusting for age, sex and mileage. A multivariable regression was also performed to evaluate the model’s discriminative ability. Results Of the 225 runners included in the final analysis 52\% experienced a running related injury. Injury history in the past year, less navicular drop, and measures of running technique (knee, hip, and pelvis kinematics) were associated with increased odds of injury (p {\textless} .05). The multivariable logistic regression model was statistically significant, χ2(11) = 56.45, p {\textless} .001, correctly classifying 74\% of cases with a sensitivity and specificity of 72\% and 76\%, respectively. The area under the receiver operating characteristic curve was 0.79 (CI95\% = 0.73–0.85), demonstrating acceptable discriminative ability. Conclusions This study found a number of clinical and running technique factors to be associated with prospective running related injuries among recreational runners. With the exception of injury history, the factors identified as being significantly associated with injury may be modifiable and therefore, could form the basis of interventions. Range of motion, spatiotemporal parameters and strength measures were not associated with injury and thus their utilisation in injury prevention practices should be reconsidered.},
	language = {en},
	number = {8},
	urldate = {2024-01-09},
	journal = {PLOS ONE},
	author = {Dillon, Sarah and Burke, Aoife and Whyte, Enda F. and O’Connor, Siobhán and Gore, Shane and Moran, Kieran A.},
	month = aug,
	year = {2023},
	note = {Publisher: Public Library of Science},
	keywords = {Anthropometry, Feet, Hip, Kinematics, Knees, Pelvis, Running, Traumatic injury risk factors},
	pages = {e0288814},
}

@misc{golovkine_estimation_2023,
	title = {On the estimation of the number of components in multivariate functional principal component analysis},
	url = {http://arxiv.org/abs/2311.04540},
	doi = {10.48550/arXiv.2311.04540},
	abstract = {Happ and Greven (2018) developed a methodology for principal components analysis of multivariate functional data for data observed on different dimensional domains. Their approach relies on an estimation of univariate functional principal components for each univariate functional feature. In this paper, we present extensive simulations to investigate choosing the number of principal components to retain. We show empirically that the conventional approach of using a percentage of variance explained threshold for each univariate functional feature may be unreliable when aiming to explain an overall percentage of variance in the multivariate functional data, and thus we advise practitioners to be careful when using it.},
	urldate = {2023-11-15},
	publisher = {arXiv},
	author = {Golovkine, Steven and Gunning, Edward and Simpkin, Andrew J. and Bargary, Norma},
	month = nov,
	year = {2023},
	note = {arXiv:2311.04540 [stat]},
	keywords = {62R10, Statistics - Machine Learning, Statistics - Methodology},
}

@article{newans_utility_2022,
	title = {The {Utility} of {Mixed} {Models} in {Sport} {Science}: {A} {Call} for {Further} {Adoption} in {Longitudinal} {Data} {Sets}},
	volume = {17},
	issn = {1555-0273, 1555-0265},
	shorttitle = {The {Utility} of {Mixed} {Models} in {Sport} {Science}},
	url = {https://journals.humankinetics.com/view/journals/ijspp/17/8/article-p1289.xml},
	doi = {10.1123/ijspp.2021-0496},
	abstract = {Purpose: Sport-science research consistently contains repeated measures and imbalanced data sets. This study calls for further adoption of mixed models when analyzing longitudinal sport-science data sets. Mixed models were used to understand whether the level of competition affected the intensity of women’s rugby league match play. Methods: A total of 472 observations were used to compare the mean speed of female rugby league athletes recorded during club-, state-, and international-level competition. As athletes featured in all 3 levels of competition and there were multiple matches within each competition (ie, repeated measures), the authors demonstrated that mixed models are the appropriate statistical approach for these data. Results: The authors determined that if a repeated-measures analysis of variance (ANOVA) were used for the statistical analysis in the present study, at least 48.7\% of the data would have been omitted to meet ANOVA assumptions. Using a mixed model, the authors determined that mean speed recorded during Trans-Tasman Test matches was 73.4 m·min−1, while the mean speeds for National Rugby League Women and State of Origin matches were 77.6 and 81.6 m·min−1, respectively. Random effects of team, athlete, and match all accounted for variations in mean speed, which otherwise could have concealed the main effects of position and level of competition had less flexible ANOVAs been used. Conclusion: These data clearly demonstrate the appropriateness of applying mixed models to typical data sets acquired in the professional sport setting. Mixed models should be more readily used within sport science, especially in observational, longitudinal data sets such as movement pattern analyses.},
	language = {en},
	number = {8},
	urldate = {2023-11-08},
	journal = {International Journal of Sports Physiology and Performance},
	author = {Newans, Tim and Bellinger, Phillip and Drovandi, Christopher and Buxton, Simon and Minahan, Clare},
	month = jul,
	year = {2022},
	note = {Publisher: Human Kinetics
Section: International Journal of Sports Physiology and Performance},
	pages = {1289--1295},
}

@misc{noauthor_utility_nodate,
	title = {The {Utility} of {Mixed} {Models} in {Sport} {Science}: {A} {Call} for {Further} {Adoption} in {Longitudinal} {Data} {Sets} in: {International} {Journal} of {Sports} {Physiology} and {Performance} {Volume} 17 {Issue} 8 (2022)},
	url = {https://journals.humankinetics.com/view/journals/ijspp/17/8/article-p1289.xml},
	urldate = {2023-11-08},
}

@article{broman_data_2018,
	title = {Data {Organization} in {Spreadsheets}},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1375989},
	doi = {10.1080/00031305.2017.1375989},
	abstract = {Spreadsheets are widely used software tools for data entry, storage, analysis, and visualization. Focusing on the data entry and storage aspects, this article offers practical recommendations for organizing spreadsheet data to reduce errors and ease later analyses. The basic principles are: be consistent, write dates like YYYY-MM-DD, do not leave any cells empty, put just one thing in a cell, organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row), create a data dictionary, do not include calculations in the raw data files, do not use font color or highlighting as data, choose good names for things, make backups, use data validation to avoid data entry errors, and save the data in plain text files.},
	number = {1},
	urldate = {2023-11-08},
	journal = {The American Statistician},
	author = {Broman, Karl W. and Woo, Kara H.},
	month = jan,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2017.1375989},
	keywords = {Data management, Data organization, Microsoft Excel, Spreadsheets},
	pages = {2--10},
}

@article{wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	copyright = {Copyright (c) 2013 Hadley  Wickham},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v059.i10},
	doi = {10.18637/jss.v059.i10},
	abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
	language = {en},
	urldate = {2023-11-08},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	month = sep,
	year = {2014},
	pages = {1--23},
}

@article{altman_cost_2006,
	title = {The cost of dichotomising continuous variables},
	volume = {332},
	copyright = {© 2006 BMJ Publishing Group Ltd.},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/content/332/7549/1080.1},
	doi = {10.1136/bmj.332.7549.1080},
	abstract = {Measurements of continuous variables are made in all branches of medicine, aiding in the diagnosis and treatment of patients. In clinical practice it is helpful to label individuals as having or not having an attribute, such as being “hypertensive” or “obese” or having “high cholesterol,” depending on the value of a continuous variable.

Categorisation of continuous variables is also common in clinical research, but here such simplicity is gained at some cost. Though grouping may help data presentation, notably in tables, categorisation is unnecessary for statistical analysis and it has some serious drawbacks. Here we consider the impact of converting continuous data to two groups (dichotomising), as this is the most common approach in clinical research.1

What are the perceived advantages of forcing all individuals into two groups? A common argument is that it greatly simplifies the statistical analysis and leads to easy interpretation and presentation of results. A …},
	language = {en},
	number = {7549},
	urldate = {2023-11-08},
	journal = {BMJ},
	author = {Altman, Douglas G. and Royston, Patrick},
	month = may,
	year = {2006},
	pmid = {16675816},
	note = {Publisher: British Medical Journal Publishing Group
Section: Practice},
	pages = {1080},
}

@article{dai_principal_2018,
	title = {Principal component analysis for functional data on {Riemannian} manifolds and spheres},
	volume = {46},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-46/issue-6B/Principal-component-analysis-for-functional-data-on-Riemannian-manifolds-and/10.1214/17-AOS1660.full},
	doi = {10.1214/17-AOS1660},
	abstract = {Functional data analysis on nonlinear manifolds has drawn recent interest. Sphere-valued functional data, which are encountered, for example, as movement trajectories on the surface of the earth are an important special case. We consider an intrinsic principal component analysis for smooth Riemannian manifold-valued functional data and study its asymptotic properties. Riemannian functional principal component analysis (RFPCA) is carried out by first mapping the manifold-valued data through Riemannian logarithm maps to tangent spaces around the Fréchet mean function, and then performing a classical functional principal component analysis (FPCA) on the linear tangent spaces. Representations of the Riemannian manifold-valued functions and the eigenfunctions on the original manifold are then obtained with exponential maps. The tangent-space approximation yields upper bounds to residual variances if the Riemannian manifold has nonnegative curvature. We derive a central limit theorem for the mean function, as well as root-\$n\$ uniform convergence rates for other model components. Our applications include a novel framework for the analysis of longitudinal compositional data, achieved by mapping longitudinal compositional data to trajectories on the sphere, illustrated with longitudinal fruit fly behavior patterns. RFPCA is shown to outperform an unrestricted FPCA in terms of trajectory recovery and prediction in applications and simulations.},
	number = {6B},
	urldate = {2023-11-07},
	journal = {The Annals of Statistics},
	author = {Dai, Xiongtao and Müller, Hans-Georg},
	month = dec,
	year = {2018},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G05, 62G20, 62G99, Compositional data, Dimension reduction, Functional data analysis, Riemannian manifold, Uniform convergence, central limit theorem, functional principal component analysis, principal geodesic analysis, trajectory},
	pages = {3334--3361},
}

@book{gelman_data_2007,
	address = {Cambridge},
	edition = {1st edition},
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}},
	isbn = {978-0-521-68689-1},
	abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Gelman, Andrew},
	month = jun,
	year = {2007},
}

@misc{gelman_data_2006,
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}},
	url = {https://www.cambridge.org/highereducation/books/data-analysis-using-regression-and-multilevel-hierarchical-models/32A29531C7FD730C3A68951A17C9D983},
	abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
	language = {en},
	urldate = {2023-10-22},
	journal = {Higher Education from Cambridge University Press},
	author = {Gelman, Andrew and Hill, Jennifer},
	month = dec,
	year = {2006},
	doi = {10.1017/CBO9780511790942},
	note = {ISBN: 9780511790942
Publisher: Cambridge University Press},
}

@misc{noauthor_data_nodate,
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models} {\textbar} {Higher} {Education} from {Cambridge}},
	url = {https://www.cambridge.org/highereducation/books/data-analysis-using-regression-and-multilevel-hierarchical-models/32A29531C7FD730C3A68951A17C9D983#overview},
	urldate = {2023-10-22},
}

@article{lake_renyi_2006,
	title = {Renyi entropy measures of heart rate {Gaussianity}},
	volume = {53},
	issn = {1558-2531},
	url = {https://ieeexplore.ieee.org/document/1561516},
	doi = {10.1109/TBME.2005.859782},
	abstract = {Sample entropy and approximate entropy are measures that have been successfully utilized to study the deterministic dynamics of heart rate (HR). A complementary stochastic point of view and a heuristic argument using the Central Limit Theorem suggests that the Gaussianity of HR is a complementary measure of the physiological complexity of the underlying signal transduction processes. Renyi entropy (or q-entropy) is a widely used measure of Gaussianity in many applications. Particularly important members of this family are differential (or Shannon) entropy (q=1) and quadratic entropy (q=2). We introduce the concepts of differential and conditional Renyi entropy rate and, in conjunction with Burg's theorem, develop a measure of the Gaussianity of a linear random process. Robust algorithms for estimating these quantities are presented along with estimates of their standard errors.},
	number = {1},
	urldate = {2023-10-18},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lake, D.E.},
	month = jan,
	year = {2006},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	pages = {21--27},
}

@article{lake_accurate_2011,
	title = {Accurate estimation of entropy in very short physiological time series: the problem of atrial fibrillation detection in implanted ventricular devices},
	volume = {300},
	issn = {0363-6135},
	shorttitle = {Accurate estimation of entropy in very short physiological time series},
	url = {https://journals.physiology.org/doi/full/10.1152/ajpheart.00561.2010},
	doi = {10.1152/ajpheart.00561.2010},
	abstract = {Entropy estimation is useful but difficult in short time series. For example, automated detection of atrial fibrillation (AF) in very short heart beat interval time series would be useful in patients with cardiac implantable electronic devices that record only from the ventricle. Such devices require efficient algorithms, and the clinical situation demands accuracy. Toward these ends, we optimized the sample entropy measure, which reports the probability that short templates will match with others within the series. We developed general methods for the rational selection of the template length m and the tolerance matching r. The major innovation was to allow r to vary so that sufficient matches are found for confident entropy estimation, with conversion of the final probability to a density by dividing by the matching region volume, 2rm. The optimized sample entropy estimate and the mean heart beat interval each contributed to accurate detection of AF in as few as 12 heartbeats. The final algorithm, called the coefficient of sample entropy (COSEn), was developed using the canonical MIT-BIH database and validated in a new and much larger set of consecutive Holter monitor recordings from the University of Virginia. In patients over the age of 40 yr old, COSEn has high degrees of accuracy in distinguishing AF from normal sinus rhythm in 12-beat calculations performed hourly. The most common errors are atrial or ventricular ectopy, which increase entropy despite sinus rhythm, and atrial flutter, which can have low or high entropy states depending on dynamics of atrioventricular conduction.},
	number = {1},
	urldate = {2023-10-18},
	journal = {American Journal of Physiology-Heart and Circulatory Physiology},
	author = {Lake, Douglas E. and Moorman, J. Randall},
	month = jan,
	year = {2011},
	note = {Publisher: American Physiological Society},
	keywords = {heart rate, heart rate variability, statistical analysis},
	pages = {H319--H325},
}

@article{dai_principal_2018-1,
	title = {Principal component analysis for functional data on {Riemannian} manifolds and spheres},
	volume = {46},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-46/issue-6B/Principal-component-analysis-for-functional-data-on-Riemannian-manifolds-and/10.1214/17-AOS1660.full},
	doi = {10.1214/17-AOS1660},
	abstract = {Functional data analysis on nonlinear manifolds has drawn recent interest. Sphere-valued functional data, which are encountered, for example, as movement trajectories on the surface of the earth are an important special case. We consider an intrinsic principal component analysis for smooth Riemannian manifold-valued functional data and study its asymptotic properties. Riemannian functional principal component analysis (RFPCA) is carried out by first mapping the manifold-valued data through Riemannian logarithm maps to tangent spaces around the Fréchet mean function, and then performing a classical functional principal component analysis (FPCA) on the linear tangent spaces. Representations of the Riemannian manifold-valued functions and the eigenfunctions on the original manifold are then obtained with exponential maps. The tangent-space approximation yields upper bounds to residual variances if the Riemannian manifold has nonnegative curvature. We derive a central limit theorem for the mean function, as well as root-\$n\$ uniform convergence rates for other model components. Our applications include a novel framework for the analysis of longitudinal compositional data, achieved by mapping longitudinal compositional data to trajectories on the sphere, illustrated with longitudinal fruit fly behavior patterns. RFPCA is shown to outperform an unrestricted FPCA in terms of trajectory recovery and prediction in applications and simulations.},
	number = {6B},
	urldate = {2023-10-18},
	journal = {The Annals of Statistics},
	author = {Dai, Xiongtao and Müller, Hans-Georg},
	month = dec,
	year = {2018},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G05, 62G20, 62G99, Compositional data, Dimension reduction, Functional data analysis, Riemannian manifold, Uniform convergence, central limit theorem, functional principal component analysis, principal geodesic analysis, trajectory},
	pages = {3334--3361},
}

@article{brard_novel_2022,
	title = {A {Novel} {Walking} {Activity} {Recognition} {Model} for {Rotation} {Time} {Series} {Collected} by a {Wearable} {Sensor} in a {Free}-{Living} {Environment}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/9/3555},
	doi = {10.3390/s22093555},
	abstract = {Solutions to assess walking deficiencies are widespread and largely used in healthcare. Wearable sensors are particularly appealing, as they offer the possibility to monitor gait in everyday life, outside a facility in which the context of evaluation biases the measure. While some wearable sensors are powerful enough to integrate complex walking activity recognition models, non-invasive lightweight sensors do not always have the computing or memory capacity to run them. In this paper, we propose a walking activity recognition model that offers a viable solution to this problem for any wearable sensors that measure rotational motion of body parts. Specifically, the model was trained and tuned using data collected by a motion sensor in the form of a unit quaternion time series recording the hip rotation over time. This time series was then transformed into a real-valued time series of geodesic distances between consecutive quaternions. Moving average and moving standard deviation versions of this time series were fed to standard machine learning classification algorithms. To compare the different models, we used metrics to assess classification performance (precision and accuracy) while maintaining the detection prevalence at the level of the prevalence of walking activities in the data, as well as metrics to assess change point detection capability and computation time. Our results suggest that the walking activity recognition model with a decision tree classifier yields the best compromise in terms of precision and computation time. The sensor that was used had purposely low computing and memory capacity so that reported performances can be thought of as the lower bounds of what can be achieved. Walking activity recognition is performed online, i.e., on-the-fly, which further extends the range of applicability of our model to sensors with very low memory capacity.},
	language = {en},
	number = {9},
	urldate = {2023-10-18},
	journal = {Sensors},
	author = {Brard, Raphaël and Bellanger, Lise and Chevreuil, Laurent and Doistau, Fanny and Drouin, Pierre and Stamm, Aymeric},
	month = jan,
	year = {2022},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {IMU, human activity recognition, machine learning, time series segmentation, unit quaternion time series, walk detection},
	pages = {3555},
}

@article{drouin_semi-supervised_2023,
	title = {Semi-supervised clustering of quaternion time series: {Application} to gait analysis in multiple sclerosis using motion sensor data},
	volume = {42},
	copyright = {© 2022 The Authors. Statistics in Medicine published by John Wiley \& Sons Ltd.},
	issn = {1097-0258},
	shorttitle = {Semi-supervised clustering of quaternion time series},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9625},
	doi = {10.1002/sim.9625},
	abstract = {Recent approaches in gait analysis involve the use of wearable motion sensors to extract spatio-temporal parameters that characterize multiple aspects of an individual's gait. In particular, the medical community could largely benefit from this type of devices as they could provide the clinicians with a valuable tool for assessing gait impairment. Motion sensor data are however complex and there is an urgent unmet need to develop sound statistical methods for analyzing such data and extracting clinically relevant information. In this article, we measure gait by following the hip rotation over time and the resulting statistical unit is a time series of unit quaternions. We explore the possibility to form groups of patients with similar walking impairment by taking into account their walking data and their global decease severity with semi-supervised clustering. We generalize a compromise-based method named hclustcompro to unit quaternion time series by combining it with the proper dissimilarity quaternion dynamic time warping. We apply this method on patients diagnosed with multiple sclerosis to form groups of patients with similar walking deficiencies while accounting for the clinical assessment of their overall disability. We also compare the compromise-based clustering approach with the method mergeTrees that falls into a sub-class of ensemble clustering named collaborative clustering. The results provide a first proof of both the interest of using wearable motion sensors for assessing gait impairment and the use of prior knowledge to guide the clustering process. It also demonstrates that compromise-based clustering is a more appropriate approach in this context.},
	language = {en},
	number = {4},
	urldate = {2023-10-18},
	journal = {Statistics in Medicine},
	author = {Drouin, Pierre and Stamm, Aymeric and Chevreuil, Laurent and Graillot, Vincent and Barbin, Laetitia and Gourraud, Pierre-Antoine and Laplaud, David-Axel and Bellanger, Lise},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9625},
	keywords = {human gait analysis, quaternion time series, semi-supervised clustering, wearable sensors},
	pages = {433--456},
}

@article{ballante_smoothing_2023,
	title = {Smoothing method for unit quaternion time series in a classification problem: an application to motion data},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Smoothing method for unit quaternion time series in a classification problem},
	url = {https://www.nature.com/articles/s41598-023-36480-y},
	doi = {10.1038/s41598-023-36480-y},
	abstract = {Smoothing orientation data is a fundamental task in different fields of research. Different methods of smoothing time series in quaternion algebras have been described in the literature, but their application is still an open point. This paper develops a smoothing approach for smoothing quaternion time series to obtain good performance in classification problems. Starting from an existing method which involves an angular velocity transformation of unit quaternion time series, a new method which employ the logarithm function to transform the quaternion time series to a real three-dimensional time series is proposed. Empirical evidences achieved on real data set and artificially noisy data sets confirm the effectiveness of the proposed method compared with the classical approach based on angular velocity transformation. The R functions developed for this paper will be provided in a Github repository.},
	language = {en},
	number = {1},
	urldate = {2023-10-18},
	journal = {Scientific Reports},
	author = {Ballante, Elena and Bellanger, Lise and Drouin, Pierre and Figini, Silvia and Stamm, Aymeric},
	month = jun,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Biomedical engineering, Computational science, Mathematics and computing, Scientific data},
	pages = {9366},
}

@article{telschow_confidence_2023,
	title = {Confidence tubes for curves on {SO}(3) and identification of subject-specific gait change after kneeling},
	issn = {0035-9254},
	url = {https://doi.org/10.1093/jrsssc/qlad060},
	doi = {10.1093/jrsssc/qlad060},
	abstract = {In order to identify changes of gait patterns, e.g. due to prolonged occupational kneeling, which might be a major risk factor for the development of knee osteoarthritis, we develop confidence tubes for curves following a perturbation model on SO(3) using the Gaussian kinematic formula which are equivariant under gait similarities and have precise coverage even for small sample sizes. Applying them to gait curves from eight volunteers undergoing kneeling tasks and adjusting for different walking speeds and marker replacement at different visits, allows us to identify at which phases of the gait cycle the gait pattern changed due to kneeling.},
	urldate = {2023-10-18},
	journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Telschow, Fabian J E and Pierrynowski, Michael R and Huckemann, Stephan F},
	month = aug,
	year = {2023},
	pages = {qlad060},
}

@article{telschow_confidence_2023-1,
	title = {Confidence tubes for curves on {SO}(3) and identification of subject-specific gait change after kneeling},
	issn = {0035-9254},
	url = {https://doi.org/10.1093/jrsssc/qlad060},
	doi = {10.1093/jrsssc/qlad060},
	abstract = {In order to identify changes of gait patterns, e.g. due to prolonged occupational kneeling, which might be a major risk factor for the development of knee osteoarthritis, we develop confidence tubes for curves following a perturbation model on SO(3) using the Gaussian kinematic formula which are equivariant under gait similarities and have precise coverage even for small sample sizes. Applying them to gait curves from eight volunteers undergoing kneeling tasks and adjusting for different walking speeds and marker replacement at different visits, allows us to identify at which phases of the gait cycle the gait pattern changed due to kneeling.},
	urldate = {2023-10-18},
	journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Telschow, Fabian J E and Pierrynowski, Michael R and Huckemann, Stephan F},
	month = aug,
	year = {2023},
	pages = {qlad060},
}

@article{telschow_functional_2021,
	title = {Functional inference on rotational curves under sample-specific group actions and identification of human gait},
	volume = {48},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12488},
	doi = {10.1111/sjos.12488},
	abstract = {Inspired by the problem of gait reproducibility (reidentifying individuals across doctor's visits) we develop two-sample permutation tests under a sample-specific group action on Lie groups with a bi-invariant Riemannian metric. These tests rely on consistent estimators and pairwise curve alignment. To this end, we propose Gaussian perturbation models and for the special case of curves on the group of 3D rotations we provide asymptotic consistency and, employing a quaternion point of view, fast spatial alignment of pointwise extrinsic mean curves. In our application to rotations of the tibia versus the femur at the knee joint under the spatial action of marker placement and the temporal action of different walking speeds, obtained from an experiment, we solve the problem of gait reproducibility.},
	language = {en},
	number = {4},
	urldate = {2023-10-18},
	journal = {Scandinavian Journal of Statistics},
	author = {Telschow, Fabian J.E. and Pierrynowski, Michael R. and Huckemann, Stephan F.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12488},
	keywords = {Gaussian perturbation models, Lie groups, functional data analysis, permutation testing, quaternions},
	pages = {1256--1276},
}

@misc{noauthor_analysis_nodate,
	title = {Analysis of {Rotational} {Deformations} {From} {Directional} {Data}: {Journal} of {Computational} and {Graphical} {Statistics}: {Vol} 24, {No} 2},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2014.914947},
	urldate = {2023-10-18},
}

@article{rancourt_using_2000,
	title = {Using {Orientation} {Statistics} to {Investigate} {Variations} in {Human} {Kinematics}},
	volume = {49},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2680862},
	abstract = {This paper applies orientation statistics to investigate variations in upper limb posture of human subjects drilling at six different locations on a vertical panel. Some of the drilling locations are kinematically equivalent in that the same posture could be used for these locations. Upper limb posture is measured by recording the co-ordinates of four markers attached to the subject's hand, forearm, arm and torso. A 3 × 3 rotation characterizes the relative orientation of one body segment with respect to another. Replicates are available since each subject drilled at the same location five times. Upper limb postures for the six drilling locations are compared by one-way analysis-of-variance tests for rotations. These tests rely on tangent space approximations at the estimated modal rotation of the sample. A parameterization of rotations in terms of unit quaternions simplifies the computations. The analysis detects significant differences in posture between all pairs of drilling locations. The smallest changes, less than 10⚬ at all joints, are obtained for the kinematically equivalent pairs of locations. A short discussion of the biomechanical interpretation of these findings is presented.},
	number = {1},
	urldate = {2023-10-18},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Rancourt, Denis and Rivest, Louis-Paul and Asselin, Jerome},
	year = {2000},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {81--94},
}

@article{schulz_analysis_2015,
	title = {Analysis of {Rotational} {Deformations} {From} {Directional} {Data}},
	volume = {24},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2014.914947},
	doi = {10.1080/10618600.2014.914947},
	abstract = {This article discusses a novel framework to analyze rotational deformations of real three-dimensional objects. The rotational deformations such as twisting or bending have been observed as the major variation in some medical applications, where the features of the deformed three-dimensional objects are directional data. We propose modeling and estimation of the global deformations in terms of generalized rotations of directions. The proposed method can be cast as a generalized small circle fitting on the unit sphere. We also discuss the estimation of descriptors for more complex deformations composed of two simple deformations. The proposed method can be used for a number of different three-dimensional object models. Two analyses of three-dimensional object data are presented in detail: one using skeletal representations in medical image analysis and the other from biomechanical gait analysis of the knee joint. Supplementary materials for this article are available online.},
	number = {2},
	urldate = {2023-10-18},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Schulz, Jörn and Jung, Sungkyu and Huckemann, Stephan and Pierrynowski, Michael and Marron, J. S. and Pizer, Stephen M.},
	month = apr,
	year = {2015},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2014.914947},
	keywords = {Axis of rotation, Directional statistics, Skeletal model, Small circle, Three-dimensional object},
	pages = {539--560},
}

@article{pataky_using_2020,
	title = {Using directional statistics to test hypotheses regarding rigid body attitude: {Comparison} to univariate and multivariate {Cardan} angle tests},
	volume = {111},
	issn = {0021-9290},
	shorttitle = {Using directional statistics to test hypotheses regarding rigid body attitude},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929020303997},
	doi = {10.1016/j.jbiomech.2020.109976},
	abstract = {Rigid body attitude and single-joint kinematics are typically expressed using three Cardan angles which represent rotations in anatomical planes. It was recently shown in the Biomechanics literature that Cardan angles inaccurately estimate true mean attitude due to an important mathematical inadequacy: attitude under-representation; at least four quantities are needed to unambiguously specify attitude. Directional statistics, which is the multivariate generalization of (univariate) circular statistics, solves this problem using four-dimensional unit vectors and the mathematics of hyperspherical geometry. The purpose of this study was to compare the results of directional analysis to the results of uni- and multi-variate Cardan analysis for representative joint kinematic data during gait. We analyzed hip, knee and pelvis data from three open datasets and report exemplary results for knee kinematics in v-cut vs. side shuffle tasks. We also conducted Monte Carlo simulations, using synthetic data with precisely controlled true angular effects, to systematically compare directional and Cardan analyses. Results show that directional analysis yielded considerably smaller p values (p{\textless}0.03) than Cardan analysis (p{\textgreater}0.055) for the exemplary dataset. Simulation results confirmed that directional analysis is considerably more powerful (i.e., much more able to detect true angular effects) than both uni- and multi-variate Cardan analysis. These results suggest that directional statistics should be used to analyse attitude, including 3D joint kinematics, to avoid false negatives.},
	urldate = {2023-10-18},
	journal = {Journal of Biomechanics},
	author = {Pataky, Todd C. and Challis, John H.},
	month = oct,
	year = {2020},
	keywords = {Biomechanics, Human movement, Joint angles, Kinematics, Three dimensional orientation},
	pages = {109976},
}

@misc{noauthor_asymptotic_nodate,
	title = {{AN} {ASYMPTOTIC} {THEORY} {FOR} {LINEAR} {MODEL} {SELECTION} on {JSTOR}},
	url = {https://www-jstor-org.proxy.lib.ul.ie/stable/24306073},
	urldate = {2023-10-12},
}

@article{stone_cross-validatory_1974-1,
	title = {Cross-{Validatory} {Choice} and {Assessment} of {Statistical} {Predictions}},
	volume = {36},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2984809},
	abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
	number = {2},
	urldate = {2023-10-12},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Stone, M.},
	year = {1974},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {111--147},
}

@article{phinyomark_kinematic_2015,
	title = {Kinematic gait patterns in healthy runners: {A} hierarchical cluster analysis},
	volume = {48},
	issn = {0021-9290},
	shorttitle = {Kinematic gait patterns in healthy runners},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929015005199},
	doi = {10.1016/j.jbiomech.2015.09.025},
	abstract = {Previous studies have demonstrated distinct clusters of gait patterns in both healthy and pathological groups, suggesting that different movement strategies may be represented. However, these studies have used discrete time point variables and usually focused on only one specific joint and plane of motion. Therefore, the first purpose of this study was to determine if running gait patterns for healthy subjects could be classified into homogeneous subgroups using three-dimensional kinematic data from the ankle, knee, and hip joints. The second purpose was to identify differences in joint kinematics between these groups. The third purpose was to investigate the practical implications of clustering healthy subjects by comparing these kinematics with runners experiencing patellofemoral pain (PFP). A principal component analysis (PCA) was used to reduce the dimensionality of the entire gait waveform data and then a hierarchical cluster analysis (HCA) determined group sets of similar gait patterns and homogeneous clusters. The results show two distinct running gait patterns were found with the main between-group differences occurring in frontal and sagittal plane knee angles (P{\textless}0.001), independent of age, height, weight, and running speed. When these two groups were compared to PFP runners, one cluster exhibited greater while the other exhibited reduced peak knee abduction angles (P{\textless}0.05). The variability observed in running patterns across this sample could be the result of different gait strategies. These results suggest care must be taken when selecting samples of subjects in order to investigate the pathomechanics of injured runners.},
	number = {14},
	urldate = {2023-10-10},
	journal = {Journal of Biomechanics},
	author = {Phinyomark, Angkoon and Osis, Sean and Hettinga, Blayne A. and Ferber, Reed},
	month = nov,
	year = {2015},
	keywords = {Biomechanics, Clustering, Kinematics, Principal component analysis, Running gait},
	pages = {3897--3904},
}

@article{pieruccini-faria_gait_2021,
	title = {Gait variability across neurodegenerative and cognitive disorders: {Results} from the {Canadian} {Consortium} of {Neurodegeneration} in {Aging} ({CCNA}) and the {Gait} and {Brain} {Study}},
	volume = {17},
	copyright = {© 2021 The Authors. Alzheimer's \& Dementia published by Wiley Periodicals LLC on behalf of Alzheimer's Association},
	issn = {1552-5279},
	shorttitle = {Gait variability across neurodegenerative and cognitive disorders},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/alz.12298},
	doi = {10.1002/alz.12298},
	abstract = {Introduction Gait impairment is common in neurodegenerative disorders. Specifically, gait variability—the stride-to-stride fluctuations in distance and time—has been associated with neurodegeneration and cognitive impairment. However, quantitative comparisons of gait impairments across the cognitive spectrum of dementias have not been systematically investigated. Methods Older adults (N = 500) with subjective cognitive impairment, Parkinson disease (PD), mild cognitive impairment (MCI), PD-MCI, Alzheimer's disease (AD), PD-dementia, Lewy body dementia, and frontotemporal dementia, as well cognitive normal controls, who were assessed for their gait and cognitive performance. Results Factor analyses grouped 11 quantitative gait parameters and identified four independent gait domains: rhythm, pace, variability, and postural control, for group comparisons and classification analysis. Among these domains, only high gait variability was associated with lower cognitive performance and accurately discriminated AD from other neurodegenerative and cognitive conditions. Discussion Our findings indicate that high gait variability is a marker of cognitive-cortical dysfunction, which can help to identify Alzheimer's disease dementia.},
	language = {en},
	number = {8},
	urldate = {2023-09-08},
	journal = {Alzheimer's \& Dementia},
	author = {Pieruccini-Faria, Frederico and Black, Sandra E. and Masellis, Mario and Smith, Eric E. and Almeida, Quincy J. and Li, Karen Z. H. and Bherer, Louis and Camicioli, Richard and Montero-Odasso, Manuel},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/alz.12298},
	keywords = {biomarker, cognition, dementia, gait variability, neurodegenerative diseases},
	pages = {1317--1328},
}

@article{argunsah_bayram_influence_2021,
	title = {The influence of biofeedback on physiological and kinematic variables of treadmill running},
	volume = {21},
	issn = {2474-8668},
	url = {https://doi.org/10.1080/24748668.2020.1861898},
	doi = {10.1080/24748668.2020.1861898},
	abstract = {Biofeedback is used for enhancing performance through providing real-time stimulus to the individual during physical activities. This randomised controlled trial aimed investigating the changes in physiological and kinematic variables of treadmill running in response to biofeedback. 24 age-matched, healthy, and recreationally active participants were randomly assigned to biofeedback and no-biofeedback groups. During 15-min treadmill running, group-based knee ROM, COM and heart rate were collected and analysed. Heart rate change was statistically significant for no-biofeedback group (156.60 ± 5.18, 160.20 ± 5.22 and 163.60 ± 5.93 F (2, 9) = 13.878, p {\textless} 0.001). No such change was found for biofeedback group (152.20 ± 6.63, 152.10 ± 6.12 and 155.30 ± 6.22 F (2, 9) = 2.787, p = 0.088). According to the Pearson Correlation Coefficient and RMSE techniques knee movement was highly correlated (initial-mid R2 = 0.995, RMSE = 1.558; initial-final R2 = 0.994, RMSE = 1.407) for biofeedback group compared to no biofeedback group (initial-mid R2 = 0.989, RMSE = 1.988; initial-final R2 = 0.985, RMSE = 4.978). Heart rate and COM variability were minimised; correspondingly, consistent knee movement was obtained in biofeedback group. Future research should determine if muscle involvement in motion and fatigue are regulated with biofeedback.},
	number = {1},
	urldate = {2023-09-08},
	journal = {International Journal of Performance Analysis in Sport},
	author = {Argunsah Bayram, Hande and Yalcin, Begum},
	month = jan,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/24748668.2020.1861898},
	keywords = {IMU, Knee joint, balance, centre of mass, heart rate},
	pages = {156--169},
}

@article{mohr_whole-body_2023,
	title = {Whole-body kinematic adaptations to running on an unstable, irregular, and compliant surface},
	volume = {0},
	issn = {1476-3141},
	url = {https://doi.org/10.1080/14763141.2023.2222022},
	doi = {10.1080/14763141.2023.2222022},
	abstract = {The goal of this study was to investigate whole-body kinematic adaptations when running on an unstable, irregular, and compliant surface in comparison to running on asphalt. We hypothesised that the gait pattern (H1) and its stride-to-stride variability (H2) would be affected by the unstable surface but that variability related to some movement features would be reduced over multiple testing days indicative of gait optimisation (H3). Fifteen runners ran on a woodchip and asphalt track on five testing days while their whole-body movements were captured using inertial motion capture and examined using joint angle and principal component analysis. Joint angles and stride-to-stride variability in eight principal running movements were subjected to surface by day analyses of variance. The woodchip track compared to asphalt resulted in (H1) a more crouched gait pattern including more leg flexion and forward trunk lean and (H2) higher stride-to-stride variability in most investigated principal running movements. However, (H3) stride-to-stride variability did not systematically change over testing days. Running on an unstable, irregular, and more compliant surface leads to the adoption a gait pattern and control strategy that are more robust against disturbances caused by the surface but may pose certain risks for overuse injury in trail runners.},
	number = {0},
	urldate = {2023-09-08},
	journal = {Sports Biomechanics},
	author = {Mohr, M. and Peer, L. and De Michiel, A. and van Andel, S. and Federolf, P.},
	month = jun,
	year = {2023},
	pmid = {37317805},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2023.2222022},
	keywords = {Gait variability, gait analysis, inertial motion capture, principal component analysis, trail running},
	pages = {1--15},
}

@article{di_multilevel_2009,
	title = {Multilevel functional principal component analysis},
	volume = {3},
	issn = {1932-6157},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2835171/},
	doi = {10.1214/08-AOAS206SUPP},
	abstract = {The Sleep Heart Health Study (SHHS) is a comprehensive landmark study of sleep and its impacts on health outcomes. A primary metric of the SHHS is the in-home polysomnogram, which includes two electroencephalographic (EEG) channels for each subject, at two visits. The volume and importance of this data presents enormous challenges for analysis. To address these challenges, we introduce multilevel functional principal component analysis (MFPCA), a novel statistical methodology designed to extract core intra- and inter-subject geometric components of multilevel functional data. Though motivated by the SHHS, the proposed methodology is generally applicable, with potential relevance to many modern scientific studies of hierarchical or longitudinal functional outcomes. Notably, using MFPCA, we identify and quantify associations between EEG activity during sleep and adverse cardiovascular outcomes.},
	number = {1},
	urldate = {2020-08-23},
	journal = {The Annals of Applied Statistics},
	author = {Di, Chong-Zhi and Crainiceanu, Ciprian M. and Caffo, Brian S. and Punjabi, Naresh M.},
	month = mar,
	year = {2009},
	pmid = {20221415},
	pmcid = {PMC2835171},
	pages = {458--488},
}

@article{scheipl_functional_2015,
	title = {Functional {Additive} {Mixed} {Models}},
	volume = {24},
	issn = {1061-8600},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4560367/},
	doi = {10.1080/10618600.2014.901914},
	abstract = {We propose an extensive framework for additive regression models for correlated functional responses, allowing for multiple partially nested or crossed functional random effects with flexible correlation structures for, e.g., spatial, temporal, or longitudinal functional data. Additionally, our framework includes linear and nonlinear effects of functional and scalar covariates that may vary smoothly over the index of the functional response. It accommodates densely or sparsely observed functional responses and predictors which may be observed with additional error and includes both spline-based and functional principal component-based terms. Estimation and inference in this framework is based on standard additive mixed models, allowing us to take advantage of established methods and robust, flexible algorithms. We provide easy-to-use open source software in the pffr() function for the R-package refund. Simulations show that the proposed method recovers relevant effects reliably, handles small sample sizes well and also scales to larger data sets. Applications with spatially and longitudinally observed functional data demonstrate the flexibility in modeling and interpretability of results of our approach.},
	number = {2},
	urldate = {2021-03-09},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Scheipl, Fabian and Staicu, Ana-Maria and Greven, Sonja},
	month = apr,
	year = {2015},
	pmid = {26347592},
	pmcid = {PMC4560367},
	pages = {477--501},
}

@article{zhang_testing_2017,
	title = {Testing {Gait} with {Ankle}-{Foot} {Orthoses} in {Children} with {Cerebral} {Palsy} by {Using} {Functional} {Mixed}-{Effects} {Analysis} of {Variance}},
	volume = {7},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5594035/},
	doi = {10.1038/s41598-017-11282-1},
	abstract = {Existing statistical methods extract insufficient information from 3-dimensional gait data, rendering clinical interpretation of impaired movement patterns sub-optimal. We propose an alternative approach based on functional data analysis that may be worthy ...},
	language = {en},
	number = {1},
	urldate = {2020-09-16},
	journal = {Scientific Reports},
	author = {Zhang, Bairu and Twycross-Lewis, Richard and Großmann, Heiko and Morrissey, Dylan},
	year = {2017},
	pmid = {28894132},
	note = {Publisher: Nature Publishing Group},
	pages = {11081},
}

@article{zipunnikov_multilevel_2011,
	title = {Multilevel {Functional} {Principal} {Component} {Analysis} for {High}-{Dimensional} {Data}},
	volume = {20},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/jcgs.2011.10122},
	doi = {10.1198/jcgs.2011.10122},
	abstract = {We propose fast and scalable statistical methods for the analysis of hundreds or thousands of high-dimensional vectors observed at multiple visits. The proposed inferential methods do not require loading the entire dataset at once in the computer memory and instead use only sequential access to data. This allows deployment of our methodology on low-resource computers where computations can be done in minutes on extremely large datasets. Our methods are motivated by and applied to a study where hundreds of subjects were scanned using Magnetic Resonance Imaging (MRI) at two visits roughly five years apart. The original data possess over ten billion measurements. The approach can be applied to any type of study where data can be unfolded into a long vector including densely observed functions and images. Supplemental materials are provided with source code for simulations, some technical details and proofs, and additional imaging results of the brain study.},
	number = {4},
	urldate = {2021-05-14},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Zipunnikov, Vadim and Caffo, Brian and Yousem, David M. and Davatzikos, Christos and Schwartz, Brian S. and Crainiceanu, Ciprian M.},
	month = jan,
	year = {2011},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jcgs.2011.10122},
	keywords = {Brain imaging data, MRI, Voxel-based morphology},
	pages = {852--873},
}

@article{zipunnikov_multilevel_2011-1,
	title = {Multilevel {Functional} {Principal} {Component} {Analysis} for {High}-{Dimensional} {Data}},
	volume = {20},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/jcgs.2011.10122},
	doi = {10.1198/jcgs.2011.10122},
	abstract = {We propose fast and scalable statistical methods for the analysis of hundreds or thousands of high-dimensional vectors observed at multiple visits. The proposed inferential methods do not require loading the entire dataset at once in the computer memory and instead use only sequential access to data. This allows deployment of our methodology on low-resource computers where computations can be done in minutes on extremely large datasets. Our methods are motivated by and applied to a study where hundreds of subjects were scanned using Magnetic Resonance Imaging (MRI) at two visits roughly five years apart. The original data possess over ten billion measurements. The approach can be applied to any type of study where data can be unfolded into a long vector including densely observed functions and images. Supplemental materials are provided with source code for simulations, some technical details and proofs, and additional imaging results of the brain study.},
	number = {4},
	urldate = {2023-04-04},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Zipunnikov, Vadim and Caffo, Brian and Yousem, David M. and Davatzikos, Christos and Schwartz, Brian S. and Crainiceanu, Ciprian M.},
	month = jan,
	year = {2011},
	pmid = {25960627},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jcgs.2011.10122},
	keywords = {Brain imaging data, MRI, Voxel-based morphology},
	pages = {852--873},
}

@article{xiao_fast_2016,
	title = {Fast covariance estimation for high-dimensional functional data},
	volume = {26},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-014-9485-x},
	doi = {10.1007/s11222-014-9485-x},
	abstract = {We propose two fast covariance smoothing methods and associated software that scale up linearly with the number of observations per function. Most available methods and software cannot smooth covariance matrices of dimension \$\$J{\textgreater}500\$\$; a recently introduced sandwich smoother is an exception but is not adapted to smooth covariance matrices of large dimensions, such as \$\$J= 10\{,\}000\$\$. We introduce two new methods that circumvent those problems: (1) a fast implementation of the sandwich smoother for covariance smoothing; and (2) a two-step procedure that first obtains the singular value decomposition of the data matrix and then smoothes the eigenvectors. These new approaches are at least an order of magnitude faster in high dimensions and drastically reduce computer memory requirements. The new approaches provide instantaneous (a few seconds) smoothing for matrices of dimension \$\$J=10\{,\}000\$\$and very fast (\$\${\textless}\$\$10 min) smoothing for \$\$J=100\{,\}000\$\$. R functions, simulations, and data analysis provide ready to use, reproducible, and scalable tools for practical data analysis of noisy high-dimensional functional data.},
	language = {en},
	number = {1},
	urldate = {2023-06-18},
	journal = {Statistics and Computing},
	author = {Xiao, Luo and Zipunnikov, Vadim and Ruppert, David and Crainiceanu, Ciprian M},
	month = jan,
	year = {2016},
	keywords = {FACE, Penalized splines, Sandwich smoother, Singular value decomposition, Smoothing, fPCA},
	pages = {409--421},
}

@misc{xiao_face_2022,
	title = {face: {Fast} {Covariance} {Estimation} for {Sparse} {Functional} {Data}},
	copyright = {GPL-3},
	shorttitle = {face},
	url = {https://cran.r-project.org/web/packages/face/index.html},
	abstract = {We implement the Fast Covariance Estimation for Sparse Functional Data paper published in Statistics and Computing {\textless}doi:10.1007/s11222-017-9744-8{\textgreater}.},
	urldate = {2023-06-18},
	author = {Xiao, Luo and Li, Cai and Checkley, William and Crainiceanu, Ciprian M},
	month = jul,
	year = {2022},
	keywords = {FunctionalData},
}

@article{warmenhoven_pca_2021,
	title = {{PCA} of waveforms and functional {PCA}: {A} primer for biomechanics},
	volume = {116},
	issn = {0021-9290},
	shorttitle = {{PCA} of waveforms and functional {PCA}},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929020305303},
	doi = {10.1016/j.jbiomech.2020.110106},
	abstract = {Principal components analysis (PCA) of waveforms and functional PCA (fPCA) are statistical approaches used to explore patterns of variability in biomechanical curve data, with fPCA being an accepted statistical method grounded within the functional data analysis (FDA) statistical framework. This technical note demonstrates that PCA of waveforms is the most rudimentary form of FDA, and consequently can be rationalised within the FDA framework of statistical processes. Mathematical proofing applied demonstrations of both techniques, and an example of when fPCA may be of greater benefit to control over smoothing of functional principal components is provided using an open access motion sickness dataset. Finally, open access software is provided with this paper as means of priming the biomechanics community for using these methods as a part of future functional data explorations.},
	urldate = {2023-08-30},
	journal = {Journal of Biomechanics},
	author = {Warmenhoven, John and Bargary, Norma and Liebl, Dominik and Harrison, Andrew J. and Robinson, Mark A. and Gunning, Edward and Hooker, Giles},
	month = feb,
	year = {2021},
	keywords = {Curves, PCA, Statistics, Variability},
	pages = {110106},
}

@phdthesis{wrobel_functional_2019,
	type = {Doctoral {Thesis}},
	title = {Functional data analytics for wearable device and neuroscience data},
	abstract = {This thesis uses methods from functional data analysis (FDA) to solve problems from three scientific
areas of study. While the areas of application are quite distinct, the common thread of
functional data analysis ties them together. The first chapter describes interactive open-source
software for explaining and disseminating results of functional analyses. Chapters two and three
use curve alignment, or registration, to solve common problems in accelerometry and neuroimaging,
respectively. The final chapter introduces a novel regression method for modeling functional
outcomes that are trajectories over time.
The first chapter of this thesis details a software package for interactively visualizing functional
data analyses. The software is designed to work for a wide range of datasets and several types
of analyses. This chapter describes that software and provides an overview of FDA in different
contexts. The second chapter introduces a framework for curve alignment, or registration, of
exponential family functional data. The approach distinguishes itself from previous registration
methods in its ability to handle dense binary observations with computational efficiency. Motivation
comes from the Baltimore Longitudinal Study on Aging, in which accelerometer data provides
valuable insights into the timing of sedentary behavior. The third chapter takes lessons learned
about curve registration from the second chapter and use them to develop methods in an entirely
new context: large multisite brain imaging studies. Scanner effects in multisite imaging studies
are non-biological variability due to technical differences across sites and scanner hardware. This
method identifies and removes scanner effects by registering cumulative distribution functions of
image intensities values. In the final chapter the focus shifts from curve registration to regression.
Described within this chapter is an entirely new nonlinear regression framework that draws from
both functional data analysis and systems of ordinary equations. This model is motivated by the
neurobiology of skilled movement, and was developed to capture the relationship between neural
activity and arm movement in mice.},
	school = {Columbia University},
	author = {Wrobel, Julia},
	year = {2019},
}

@phdthesis{liebl_contributions_2013,
	type = {Doctoral {Thesis}},
	title = {Contributions to {Functional} {Data} {Analysis} with {Applications} to {Modeling} {Time} {Series} and {Panel} {Data}},
	url = {http://www.uni-koeln.de/},
	abstract = {In Chapter 1 we propose a new perspective on modeling and forecasting electricity spot prices. Our approach is motivated by the data-generating process of electricity spot prices, which is well described what is called the merit order model. The merit order model is a micro economic model based on the assumption that spot prices on electricity exchanges are determined by the marginal generation costs of the last power plant that is required to cover the demand. The resulting merit order curve reflects the increasing generation costs of the installed power plants. Correspondingly, we suggest interpreting hourly electricity spot prices as noisy discretization points of smooth price functions. 

These price functions are modeled by a functional factor model (FFM) for which we discuss a two-step estimation procedure. The first step is a classical pre-smoothing step in order to estimate the single price functions from the noisy discretization points. The second step then aims for a robust estimation of a finite set of common basis functions from the pre-smoothed price functions. In doing this, we carefully consider the issue of finding an optimal smoothing parameter. 

The presentation of our functional factor model concludes with an extensive forecast study which compares our FFM with alternative time series models that have been successfully applied in the literature on electricity spot prices. The forecast study clearly confirms the superior power of our functional factor model and the use of price functions as underlying structures of electricity spot prices in general. 

A slightly modified version of Chapter 1 is forthcoming as a single-authored article in "The Annals of Applied Statistics"; see Liebl (2013).

Chapter 2 further discusses the problem of modeling electricity spot prices. On the one hand, we extend the concept of price function introduced in Chapter 1 using covariables. On the other hand, we focus on a generally deeper theoretical consideration of the involved multivariate nonparametric regression model, which is used as a tool for FPCA. 

We extend existing theoretical results with respect to FPCA for sparse functional data by considering the asymptotic bias and variance of the multivariate local linear estimator of the mean and the covariance functions. Here, we carefully consider the effects of between-correlations, which are caused by the time series context, and the effects of within-correlations, which are caused by the functional nature of the data.

In order to demonstrate the usefulness of our model we analyze the effects of Germany's nuclear moratorium on March 14, 2011. This event describes a natural experiment, since in the course of Germany's nuclear moratorium on March 14, 2011, eight nuclear power plants were phased out [Nestle (2012)]. The data set analyzed in Chapter 2 covers exactly one year before and one year after Germany's nuclear power phase-out. We apply our model separately to these two time spans in order to contrast the different market situations. 

In Chapter 3 we pick up the successful application of FDA within the literature on panel data models. Recent panel data models allow us to control for complex unobserved heterogeneity effects by the incorporation of latent factor models. This new kind of panel data models extends the classical concept of individual random (scalar) effects to random processes or random functions [see, e.g., Bai, Kao and Ng (2009), Bai (2009), and Kneip, Sickles and Sond (2012)]. 

Even though this class of panel models is of high relevance for practical problems such as stochastic frontier analysis, they are still rarely applied in the empirical literature. Our implementation of these methods in the statistical software package of phtt provides a first step towards facilitating their application. 

As the estimation procedure of Kneip, Sickles and Sond (2012) involves nonparametric smoothing methods, the choice of a reliable procedure to find an optimal smoothing parameter is most important for implementing the estimation procedure in a statistical software package. We consider this problem and suggest to use the technique of ``parameter-cascading'' in  order to approximate an upper bound for the optimal smoothing parameter [see also Cao and Ramsay (2010)].

The final optimal smoothing parameter lies somewhere between this approximated upper bound and zero. Knowledge of this interval allows for a robust implementation of the computationally costly cross validation criterion.

A slightly modified version of Chapter 3 is accepted as a co-authored article for the "Journal of Statistical Software"; see Bada and Liebl (2013).},
	language = {en},
	urldate = {2020-08-12},
	school = {Universität zu Köln},
	author = {Liebl, Dominik},
	year = {2013},
}

@article{wang_functional_2016,
	title = {Functional {Data} {Analysis}},
	volume = {3},
	url = {https://doi.org/10.1146/annurev-statistics-041715-033624},
	doi = {10.1146/annurev-statistics-041715-033624},
	abstract = {With the advance of modern technology, more and more data are being recorded continuously during a time interval or intermittently at several discrete time points. These are both examples of functional data, which has become a commonly encountered type of data. Functional data analysis (FDA) encompasses the statistical methodology for such data. Broadly interpreted, FDA deals with the analysis and theory of data that are in the form of functions. This paper provides an overview of FDA, starting with simple statistical notions such as mean and covariance functions, then covering some core techniques, the most popular of which is functional principal component analysis (FPCA). FPCA is an important dimension reduction tool, and in sparse data situations it can be used to impute functional data that are sparsely observed. Other dimension reduction approaches are also discussed. In addition, we review another core technique, functional linear regression, as well as clustering and classification of functional data. Beyond linear and single- or multiple- index methods, we touch upon a few nonlinear approaches that are promising for certain applications. They include additive and other nonlinear functional regression models and models that feature time warping, manifold learning, and empirical differential equations. The paper concludes with a brief discussion of future directions.},
	number = {1},
	urldate = {2023-08-30},
	journal = {Annual Review of Statistics and Its Application},
	author = {Wang, Jane-Ling and Chiou, Jeng-Min and Müller, Hans-Georg},
	year = {2016},
	note = {\_eprint: https://doi.org/10.1146/annurev-statistics-041715-033624},
	keywords = {clustering and classification, functional additive model, functional correlation, functional linear regression, functional principal component analysis, time warping},
	pages = {257--295},
}

@article{sergazinov_case_2023,
	title = {A case study of glucose levels during sleep using multilevel fast function on scalar regression inference},
	volume = {(Advance Online Publication https://doi.org/10.1111/biom.13878)},
	copyright = {© 2023 The International Biometric Society.},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13878},
	doi = {10.1111/biom.13878},
	abstract = {Continuous glucose monitors (CGMs) are increasingly used to measure blood glucose levels and provide information about the treatment and management of diabetes. Our motivating study contains CGM data during sleep for 174 study participants with type II diabetes mellitus measured at a 5-min frequency for an average of 10 nights. We aim to quantify the effects of diabetes medications and sleep apnea severity on glucose levels. Statistically, this is an inference question about the association between scalar covariates and functional responses observed at multiple visits (sleep periods). However, many characteristics of the data make analyses difficult, including (1) nonstationary within-period patterns; (2) substantial between-period heterogeneity, non-Gaussianity, and outliers; and (3) large dimensionality due to the number of study participants, sleep periods, and time points. For our analyses, we evaluate and compare two methods: fast univariate inference (FUI) and functional additive mixed models (FAMMs). We extend FUI and introduce a new approach for testing the hypotheses of no effect and time invariance of the covariates. We also highlight areas for further methodological development for FAMM. Our study reveals that (1) biguanide medication and sleep apnea severity significantly affect glucose trajectories during sleep and (2) the estimated effects are time invariant.},
	language = {en},
	urldate = {2023-08-30},
	journal = {Biometrics},
	author = {Sergazinov, Renat and Leroux, Andrew and Cui, Erjia and Crainiceanu, Ciprian and Aurora, R. Nisha and Punjabi, Naresh M. and Gaynanova, Irina},
	month = may,
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13878},
	keywords = {CGM, actigraphy, diabetes, sleep apnea, wearables},
}

@article{de_leeuw_journal_2009,
	title = {Journal of {Statistical} {Software}},
	volume = {1},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.10},
	doi = {10.1002/wics.10},
	abstract = {The Journal of Statistical Software is an e-journal that publishes and reviews open source statistical software. We discuss the history, motivation, and implementation of the journal. Copyright © 2009 John Wiley \& Sons, Inc. This article is categorized under: Applications of Computational Statistics {\textgreater} Organizations and Publications},
	language = {en},
	number = {1},
	urldate = {2023-05-31},
	journal = {WIREs Computational Statistics},
	author = {de Leeuw, Jan},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.10},
	keywords = {e-journal, journal, open access, open source},
	pages = {128--129},
}

@article{warmenhoven_force_2018,
	title = {A force profile analysis comparison between functional data analysis, statistical parametric mapping and statistical non-parametric mapping in on-water single sculling},
	volume = {21},
	issn = {1440-2440},
	url = {http://www.sciencedirect.com/science/article/pii/S1440244018300914},
	doi = {10.1016/j.jsams.2018.03.009},
	abstract = {Objectives
To examine whether the Functional Data Analysis (FDA), Statistical Parametric Mapping (SPM) and Statistical non-Parametric Mapping (SnPM) hypothesis testing techniques differ in their ability to draw inferences in the context of a single, simple experimental design.
Design
The sample data used is cross-sectional (two-sample gender comparison) and evaluation of differences between statistical techniques used a combination of descriptive and qualitative assessments.
Methods
FDA, SPM and SnPM t-tests were applied to sample data of twenty highly skilled male and female rowers, rowing at 32 strokes per minute in a single scull boat. Statistical differences for gender were assessed by applying two t-tests (one for each side of the boat).
Results
The t-statistic values were identical for all three methods (with the FDA t-statistic presented as an absolute measure). The critical t-statistics (tcrit) were very similar between the techniques, with SPM tcrit providing a marginally higher tcrit than the FDA and SnPM tcrit values (which were identical). All techniques were successful in identifying consistent sections of the force waveform, where male and female rowers were shown to differ significantly (p{\textless}0.05).
Conclusions
This is the first study to show that FDA, SPM and SnPM t-tests provide consistent results when applied to sports biomechanics data. Though the results were similar, selection of one technique over another by applied researchers and practitioners should be based on the underlying parametric assumption of SPM, as well as contextual factors related to the type of waveform data to be analysed and the experimental research question of interest.},
	language = {en},
	number = {10},
	urldate = {2020-09-15},
	journal = {Journal of Science and Medicine in Sport},
	author = {Warmenhoven, John and Harrison, Andrew J. and Robinson, Mark A. and Vanrenterghem, Jos and Bargary, Norma and Smith, Richard and Cobley, Stephen and Draper, Conny and Donnelly, Cyril and Pataky, Todd},
	month = oct,
	year = {2018},
	keywords = {Hypothesis testing, Movement, Statistics, Waveform},
	pages = {1100--1105},
}

@techreport{warmenhoven_unlocking_2020,
	type = {preprint},
	title = {Unlocking sports medicine research data while maintaining participant privacy via synthetic datasets},
	url = {https://osf.io/f3rz7},
	abstract = {There is an opportunity for sports medicine to progress research ideation using synthetic datasets, maintaining research momentum when data collection is not feasible. These processes maximise the potential for application of open science practice, while retaining the commitment to privacy and ethics. Synthetic data could lead to more sustainable use of data, particularly in the form of hypothesis generation through exploratory research applied to synthetic datasets.},
	urldate = {2020-09-15},
	institution = {SportRxiv},
	author = {Warmenhoven, John and Harrison, Andrew J. and Quintana, Daniel S and Hooker, Giles and Gunning, Edward and Bargary, Norma},
	month = aug,
	year = {2020},
	doi = {10.31236/osf.io/f3rz7},
}

@article{warmenhoven_considerations_2019,
	title = {Considerations for the use of functional principal components analysis in sports biomechanics: examples from on-water rowing},
	volume = {18},
	issn = {1476-3141},
	shorttitle = {Considerations for the use of functional principal components analysis in sports biomechanics},
	url = {https://doi.org/10.1080/14763141.2017.1392594},
	doi = {10.1080/14763141.2017.1392594},
	abstract = {The proliferation of new biomechanical technology in laboratory and field settings facilitates the capture of data-sets consisting of complex time-series. An understanding of the appropriate statistical approaches for analysing and interpreting these data-sets is required and the functional data analysis (FDA) family of statistical techniques has emerged in the biomechanical literature. Given the use of FDA is currently in its infancy with biomechanical data, this paper will form the first of a two part series aiming to address practical issues surrounding the application of FDA techniques in biomechanics. This work focuses on functional principal components analysis (fPCA), which is explored using existing literature and sample data from an on-water rowing database. In particular methodological considerations for the implementation of fPCA such as temporal normalisation of data, removal of unwanted forms of variation in a data-set and documented methods for preserving the original temporal properties within a set of curves are explored in detail as a part of this review. Limitations and strengths of the technique are outlined and recommendations are provided to encourage the appropriate use of fPCA within the field of applied sports biomechanics.},
	number = {3},
	urldate = {2020-09-15},
	journal = {Sports Biomechanics},
	author = {Warmenhoven, John and Cobley, Stephen and Draper, Conny and Harrison, Andrew J. and Bargary, Norma and Smith, Richard},
	month = may,
	year = {2019},
	pmid = {29141500},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2017.1392594},
	keywords = {FDA, curve, statistics, waveform},
	pages = {317--341},
}

@article{warmenhoven_bivariate_2019,
	title = {Bivariate functional principal components analysis: considerations for use with multivariate movement signatures in sports biomechanics},
	volume = {18},
	issn = {1752-6116},
	shorttitle = {Bivariate functional principal components analysis},
	doi = {10.1080/14763141.2017.1384050},
	abstract = {Sporting performance is often investigated through graphical observation of key technical variables that are representative of whole movements. The presence of differences between athletes in such variables has led to terms such as movement signatures being used. These signatures can be multivariate (multiple time-series observed concurrently), and also be composed of variables measured relative to different scales. Analytical techniques from areas of statistics such as Functional Data Analysis (FDA) present a practical alternative for analysing multivariate signatures. When applied to concurrent bivariate time-series multivariate functional principal components analysis (referred to as bivariate fPCA or bfPCA in this paper) has demonstrated preliminary application in biomechanical contexts. Despite this, given the infancy of bfPCA in sports biomechanics there are still necessary considerations for its use with non-conventional or complex bivariate structures. This paper focuses on the application of bfPCA to the force-angle graph in on-water rowing, which is a bivariate structure composed of variables with different units. A normalisation approach is proposed to investigate and standardise differences in variability between the two variables. The results of bfPCA applied to the non-normalised data and normalised data are then compared. Considerations and recommendations for the application of bfPCA in this context are also provided.},
	language = {eng},
	number = {1},
	journal = {Sports Biomechanics},
	author = {Warmenhoven, John and Cobley, Stephen and Draper, Conny and Harrison, Andrew J. and Bargary, Norma and Smith, Richard},
	month = feb,
	year = {2019},
	pmid = {29125036},
	keywords = {Adult, Biomechanical Phenomena, FDA, Female, Humans, Movement, Principal Component Analysis, Sports, Water Sports, biomechanics, rowing, statistics},
	pages = {10--27},
}

@article{warmenhoven_how_2018,
	title = {How gender and boat-side affect shape characteristics of force–angle profiles in single sculling: {Insights} from functional data analysis},
	volume = {21},
	issn = {1440-2440},
	shorttitle = {How gender and boat-side affect shape characteristics of force–angle profiles in single sculling},
	url = {http://www.sciencedirect.com/science/article/pii/S1440244017309982},
	doi = {10.1016/j.jsams.2017.08.010},
	abstract = {Objectives
To examine whether gender or side of the boat influenced shape characteristics of the force–angle profile in on-water single sculling.
Design
Cross-sectional study design.
Methods
Bivariate functional principal components analysis (bfPCA) was applied to force–angle data to identify the main modes of variance in curves of forty highly skilled male and female rowers (national and international level), rowing at 32 strokes per minute in a single scull boat.
Results
Separate discriminant function analyses for each side of the boat showed strong classification of rowers for gender. Force application close to (or closely around) the perpendicular oar position was demonstrated to be different between genders. A mixed ANOVA exploring gender, boat side and their interaction revealed that bow and stroke side forces were also statistically different from each other independently of gender. A main effect, independent of side of the boat, was also present for gender and no interaction was found between gender and boat side. Bow side forces seemingly acted as a driver of power and peak force production, while stroke side forces may have acted as a mediator of propulsive forces with an additional potential role in steering due to known asymmetrical offsets in boat rigging.
Conclusions
Results demonstrate that propulsive force differences according to gender and boat-side are evident and must be acknowledged and accounted for before force–angle graphs are explored relative to performance measures.},
	language = {en},
	number = {5},
	urldate = {2020-09-29},
	journal = {Journal of Science and Medicine in Sport},
	author = {Warmenhoven, John and Cobley, Stephen and Draper, Conny and Harrison, Andrew J. and Bargary, Norma and Smith, Richard},
	month = may,
	year = {2018},
	keywords = {Biomechanics, Force, Gender, Profile, Rowing},
	pages = {533--537},
}

@article{warmenhoven_pca_2020,
	title = {{PCA} of {Waveforms} and {Functional} {PCA}: {A} {Primer} for {Biomechanics}},
	issn = {0021-9290},
	shorttitle = {{PCA} of {Waveforms} and {Functional} {PCA}},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929020305303},
	doi = {10.1016/j.jbiomech.2020.110106},
	abstract = {Principal components analysis (PCA) of waveforms and functional PCA (fPCA) are statistical approaches used to explore patterns of variability in biomechanical curve data, with fPCA being an accepted statistical method grounded within the functional data analysis (FDA) statistical framework. This technical note demonstrates that PCA of waveforms is the most rudimentary form of FDA, and consequently can be rationalised within the FDA framework of statistical processes. Mathematical proofing applied demonstrations of both techniques, and an example of when fPCA may be of greater benefit to control over smoothing of functional principal components is provided using an open access motion sickness dataset. Finally, open access software is provided with this paper as means of priming the biomechanics community for using these methods as a part of future functional data explorations.},
	language = {en},
	urldate = {2020-11-06},
	journal = {Journal of Biomechanics},
	author = {Warmenhoven, John and Bargary, Norma and Liebl, Dominik and Harrison, Andrew J. and Robinson, Mark and Gunning, Edward and Hooker, Giles},
	month = oct,
	year = {2020},
	keywords = {PCA, curves, statistics, variability},
	pages = {110106},
}

@incollection{ramsay_two-stage_2017,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Two-{Stage} {Least} {Squares} or {Gradient} {Matching}},
	isbn = {978-1-4939-7190-9},
	url = {https://doi.org/10.1007/978-1-4939-7190-9_8},
	abstract = {This chapterGradient matching{\textbar}(presents indirect methods of fitting parameters to ordinary differential equation models. Rather than solving the ODE, we instead obtain non-parametric estimates of the state trajectory and its derivative. This allows the right hand side of the ODE to be fit to the estimated derivatives, which is often numerically easier than the trajectory matching described in Chap. 7. We discuss the ways in which this approach allows us to diagnose model mis-specification, and develop confidence intervals for parameters. We also examine the related approach of fitting the trajectory to the integral of the right hand side function.},
	language = {en},
	urldate = {2022-06-12},
	booktitle = {Dynamic {Data} {Analysis}: {Modeling} {Data} with {Differential} {Equations}},
	publisher = {Springer},
	author = {Ramsay, James O. and Hooker, Giles},
	editor = {Ramsay, James and Hooker, Giles},
	year = {2017},
	doi = {10.1007/978-1-4939-7190-9_8},
	keywords = {Gradient Matching, Integrated Matching, Refinery Data, Rosenzweig MacArthur Model, Trajectory Matching},
	pages = {137--160},
}

@book{ramsay_dynamic_2017,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Dynamic {Data} {Analysis} {Modeling} {Data} with {Differential} {Equations}},
	isbn = {978-1-4939-7190-9},
	url = {https://doi.org/10.1007/978-1-4939-7190-9_8},
	language = {en},
	urldate = {2022-06-12},
	publisher = {Springer},
	author = {Ramsay, James O. and Hooker, Giles},
	year = {2017},
	doi = {10.1007/978-1-4939-7190-9_8},
	keywords = {Gradient Matching, Integrated Matching, Refinery Data, Rosenzweig MacArthur Model, Trajectory Matching},
}

@book{pinheiro_mixed-effects_2006,
	title = {Mixed-{Effects} {Models} in {S} and {S}-{PLUS}},
	isbn = {978-0-387-22747-4},
	abstract = {An overview of the theory and application of linear and nonlinear mixed-effects models in the analysis of grouped data, such as longitudinal data, repeated measures, and multilevel data. The authors present a unified model-building strategy for both models and apply this to the analysis of over 20 real datasets from a wide variety of areas, including pharmacokinetics, agriculture, and manufacturing. Much emphasis is placed on the use of graphical displays at the various phases of the model-building process, starting with exploratory plots of the data and concluding with diagnostic plots to assess the adequacy of a fitted model. The NLME library for analyzing mixed-effects models in S and S-PLUS, developed by the authors, provides the underlying software for implementing the methods presented. This balanced mix of real data examples, modeling software, and theory makes the book a useful reference for practitioners who use, or intend to use, mixed-effects models in their data analyses. It can also be used as a text for a one-semester graduate-level applied course.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Pinheiro, José  S and Bates, Douglas},
	month = may,
	year = {2006},
	note = {Google-Books-ID: ZRnoBwAAQBAJ},
	keywords = {Computers / Database Administration \& Management, Computers / Information Technology, Computers / Languages / General, Computers / Mathematical \& Statistical Software},
}

@misc{leroux_fast_2023,
	title = {Fast {Generalized} {Functional} {Principal} {Components} {Analysis}},
	url = {http://arxiv.org/abs/2305.02389},
	doi = {10.48550/arXiv.2305.02389},
	abstract = {We propose a new fast generalized functional principal components analysis (fast-GFPCA) algorithm for dimension reduction of non-Gaussian functional data. The method consists of: (1) binning the data within the functional domain; (2) fitting local random intercept generalized linear mixed models in every bin to obtain the initial estimates of the person-specific functional linear predictors; (3) using fast functional principal component analysis to smooth the linear predictors and obtain their eigenfunctions; and (4) estimating the global model conditional on the eigenfunctions of the linear predictors. An extensive simulation study shows that fast-GFPCA performs as well or better than existing state-of-the-art approaches, it is orders of magnitude faster than existing general purpose GFPCA methods, and scales up well with both the number of observed curves and observations per curve. Methods were motivated by and applied to a study of active/inactive physical activity profiles obtained from wearable accelerometers in the NHANES 2011-2014 study. The method can be implemented by any user familiar with mixed model software, though the R package fastGFPCA is provided for convenience.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Leroux, Andrew and Crainiceanu, M and Wrobel, Julia},
	month = jun,
	year = {2023},
	note = {arXiv:2305.02389 [stat]},
	keywords = {Statistics - Methodology},
}

@article{greven_longitudinal_2010,
	title = {Longitudinal functional principal component analysis},
	volume = {4},
	issn = {1935-7524},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3131008/},
	doi = {10.1214/10-EJS575},
	abstract = {We introduce models for the analysis of functional data observed at
                    multiple time points. The dynamic behavior of functional data is decomposed into
                    a time-dependent population average, baseline (or static) subject-specific
                    variability, longitudinal (or dynamic) subject-specific variability,
                    subject-visit-specific variability and measurement error. The model can be
                    viewed as the functional analog of the classical longitudinal mixed effects
                    model where random effects are replaced by random processes. Methods have wide
                    applicability and are computationally feasible for moderate and large data sets.
                    Computational feasibility is assured by using principal component bases for the
                    functional processes. The methodology is motivated by and applied to a diffusion
                    tensor imaging (DTI) study designed to analyze differences and changes in brain
                    connectivity in healthy volunteers and multiple sclerosis (MS) patients. An R
                    implementation is provided., 87},
	urldate = {2020-09-24},
	journal = {Electronic journal of statistics},
	author = {Greven, Sonja and Crainiceanu, Ciprian M and Caffo, Brian and Reich, Daniel},
	year = {2010},
	pmid = {21743825},
	pmcid = {PMC3131008},
	pages = {1022--1054},
}

@misc{goldsmith_refund_2020,
	title = {refund: {Regression} with {Functional} {Data}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {Refund},
	url = {https://CRAN.R-project.org/package=refund},
	abstract = {Methods for regression for functional data, including function-on-scalar, scalar-on-function, and function-on-function regression. Some of the functions are applicable to image data.},
	urldate = {2021-02-08},
	author = {Goldsmith, Jeff and Scheipl, Fabian and Huang, Lei and Wrobel, Julia and Di, Chong-Zhi and Gellar, Jonathan and Harezlak, Jaroslaw and McLean, Mathew W. and Swihart, Bruce and Xiao, Luo and Crainiceanu, Ciprian M and Reiss, Philip T. and Chen, Yakuan and Greven, Sonja and Huo, Lan and Kundu, Madan Gopal and Park, So Young and Miller, David L. and Staicu, Ana-Maria},
	month = dec,
	year = {2020},
	keywords = {FunctionalData},
}

@article{eckmann_liapunov_1986,
	title = {Liapunov exponents from time series},
	volume = {34},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.34.4971},
	doi = {10.1103/PhysRevA.34.4971},
	abstract = {We analyze in detail an algorithm for computing Liapunov exponents from an experimental time series. As an application, a hydrodynamic experiment is investigated.},
	number = {6},
	urldate = {2023-08-10},
	journal = {Physical Review A},
	author = {Eckmann, Jean-Pierre and Kamphorst, S. Oliffson and Ruelle, D. and Ciliberto, S.},
	month = dec,
	year = {1986},
	note = {Publisher: American Physical Society},
	pages = {4971--4979},
}

@article{di_multilevel_2014,
	title = {Multilevel sparse functional principal component analysis},
	volume = {3},
	issn = {0038-9986},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4032817/},
	doi = {10.1002/sta4.50},
	abstract = {We consider analysis of sparsely sampled multilevel functional data, where the basic observational unit is a function and data have a natural hierarchy of basic units. An example is when functions are recorded at multiple visits for each subject. Multilevel functional principal component analysis (MFPCA; Di et al. 2009) was proposed for such data when functions are densely recorded. Here we consider the case when functions are sparsely sampled and may contain only a few observations per function. We exploit the multilevel structure of covariance operators and achieve data reduction by principal component decompositions at both between and within subject levels. We address inherent methodological differences in the sparse sampling context to: 1) estimate the covariance operators; 2) estimate the functional principal component scores; 3) predict the underlying curves. Through simulations the proposed method is able to discover dominating modes of variations and reconstruct underlying curves well even in sparse settings. Our approach is illustrated by two applications, the Sleep Heart Health Study and eBay auctions.},
	number = {1},
	urldate = {2021-05-14},
	journal = {Stat},
	author = {Di, Chong-Zhi and Crainiceanu, Ciprian M. and Jank, Wolfgang S.},
	month = jan,
	year = {2014},
	pmid = {24872597},
	pmcid = {PMC4032817},
	pages = {126--143},
}

@incollection{scott_multilevel_2013,
	title = {Multilevel {Functional} {Data} {Analysis}},
	isbn = {978-0-85702-564-7 978-1-4462-4760-0},
	url = {http://methods.sagepub.com/book/the-sage-handbook-of-multilevel-modeling/n13.xml},
	urldate = {2022-02-22},
	booktitle = {The {SAGE} {Handbook} of {Multilevel} {Modeling}},
	publisher = {SAGE Publications Ltd},
	author = {Crainiceanu, Ciprian M and Caffo, Brian and Morris, Jeffrey},
	collaborator = {Scott, Marc and Simonoff, Jeffrey and Marx, Brian},
	year = {2013},
	doi = {10.4135/9781446247600.n13},
	pages = {223--248},
}

@article{hebert-losier_one-leg_2015,
	title = {One-leg hop kinematics 20 years following anterior cruciate ligament rupture: {Data} revisited using functional data analysis},
	volume = {30},
	issn = {0268-0033},
	shorttitle = {One-leg hop kinematics 20years following anterior cruciate ligament rupture},
	url = {http://www.sciencedirect.com/science/article/pii/S0268003315002223},
	doi = {10.1016/j.clinbiomech.2015.08.010},
	abstract = {Background
Despite interventions, anterior cruciate ligament ruptures can cause long-term deficits. To assist in identifying and treating deficiencies, 3D-motion analysis is used for objectivizing data. Conventional statistics are commonly employed to analyze kinematics, reducing continuous data series to discrete variables. Conversely, functional data analysis considers the entire data series.
Methods
Here, we employ functional data analysis to examine and compare the entire time-domain of knee-kinematic curves from one-leg hops between and within three groups. All subjects (n=95) were part of a long-term follow-up study involving anterior cruciate ligament ruptures treated {\textasciitilde}20years ago conservatively with physiotherapy only or with reconstructive surgery and physiotherapy, and matched knee-healthy controls.
Findings
Between-group differences (injured leg, treated groups; non-dominant leg, controls) were identified during the take-off and landing phases, and in the sagittal (flexion/extension) rather than coronal (abduction/adduction) and transverse (internal/external) planes. Overall, surgical and control groups demonstrated comparable knee-kinematic curves. However, compared to controls, the physiotherapy-only group exhibited less flexion during the take-off (0–55\% of the normalized phase) and landing (44–73\%) phase. Between-leg differences were absent in controls and the surgically treated group, but observed during the flight (4–22\%, injured leg{\textgreater}flexion) and the landing (57–85\%, injured leg{\textless}internal rotation) phases in the physiotherapy-only group.
Interpretation
Functional data analysis identified specific functional knee-joint deviations from controls persisting 20years post anterior cruciate ligament rupture, especially when treated conservatively. This approach is suggested as a means for comprehensively analyzing complex movements, adding to previous analyses.},
	language = {en},
	number = {10},
	urldate = {2020-09-16},
	journal = {Clinical Biomechanics},
	author = {Hébert-Losier, Kim and Pini, Alessia and Vantini, Simone and Strandberg, Johan and Abramowicz, Konrad and Schelin, Lina and Häger, Charlotte K.},
	month = dec,
	year = {2015},
	keywords = {Biomechanics, Curve analysis, Functional outcomes, Interval testing procedure, Lower extremity, Rehabilitation},
	pages = {1153--1161},
}

@phdthesis{dillon_investigation_2022,
	type = {Doctoral {Thesis}},
	title = {An investigation of the factors associated with running-related injuries among recreational runners},
	url = {https://doras.dcu.ie/27694/},
	abstract = {Background:
Running-related injuries (RRIs) occur when load exceeds tissue strength and therefore, purportedly result from a complex interaction of factors. However, research regarding factors associated with RRI remains inconclusive. Very few prospective, multifactorial, large-scale studies exist exploring general or specific RRIs, with even fewer examining segmental loading and running technique throughout the body. Additionally, although runners who have never been injured or have not been recently injured may have distinctive factors explaining their resistance to (re-)injury, this has seldom been examined.

Aims:
Primary aim: To prospectively investigate factors associated with general and specific RRIs using a multifactorial, large-scale approach.
Secondary aim: To retrospectively investigate differences in clinical and loading factors between injury-resistant and recently injured runners.

Methods:
This thesis incorporates work from four research questions (Chapters 3, 4, 5, 6) and one methodological chapter (Section 8.3). A baseline assessment of 274 recreational runners examined: (1) loading (via impact accelerations), (2) running technique (via motion analysis) and (3) clinical measures of: strength, range of motion and foot alignment, (4) demographics and injury and training history. RRIs were tracked for one year.

Results:
There was a 1-year incidence of general RRI of 52\%, and 14\% for calf-complex injury. Prospectively, running technique and foot alignment were associated with both general (Chapter 5) and calf-complex injuries (Chapter 6). Some factors were injury-specific, including running pace and sagittal plane motion. Overall, there was a limited potential identified for the use of any measure in RRI screening. Retrospectively, recently injured runners displayed greater lower back loading compared to those injured {\textgreater}2 years ago and strength differences (plantar flexion and hip abduction) were noted among runners with and without a history of RRI (Chapters 3,4).

Conclusion:
This thesis adds important insights into potential factors that are associated with RRIs. These may form the basis of intervention programmes.},
	language = {en},
	urldate = {2023-01-14},
	school = {Dublin City University. School of Health and Human Performance},
	author = {Dillon, Sarah},
	month = nov,
	year = {2022},
	note = {Publication Title: Sarah, Dillon ORCID: 0000-0002-6659-2606 {\textless}https://orcid.org/0000-0002-6659-2606{\textgreater}  (2022) An investigation of the factors associated with running-related injuries among recreational runners.  PhD thesis, Dublin City University.},
}

@phdthesis{cederbaum_functional_2017,
	type = {Doctoral {Thesis}},
	title = {Functional {Linear} {Mixed} {Models} for {Complex} {Correlation} {Structures} and {General} {Sampling} {Grids}},
	abstract = {Technological advances allow today's scientists in various  elds to collect an increasing amount of
data consisting of functional observations rather than single data points. Intense research in statistical
methodology for functional data during the last years has aimed at developing methods that
exploit the whole potential of this type of data. Many of the proposed approaches assume that the
functional observations are independent. This may be very restrictive in practice, where correlation
is frequently induced by, e.g., repeated observations per subject or grouping in the data.
The main focus of this thesis is on the analysis of functional data with complex correlation structures.
Functional linear mixed models that represent functional counterparts to scalar linear mixed models
are applied to analyze correlated functional data. The random e ects of scalar linear mixed models
are replaced by functions that vary over the same domain as the observed data.
In addition to assuming independent functional observations, most existing methods are restricted to
functional observation that are available at a typically large number of observation points that are
the same across all curves. This strong requirement is often not met in applications, where functional
observations are frequently evaluated at curve-speci c\{\vphantom{\}}possibly few\{\vphantom{\}}irregularly spaced points. To
overcome this restriction, special methodological emphasis of this thesis is placed on the extension of
functional linear mixed models and their estimation to data that are observed on unequal grids or
even sparsely.
This thesis develops a new estimation framework that addresses both complex correlation structures
between functional observations as well as observations on general sampling grids. Previous work
is either less general in the assumed correlation structure or does not allow for general grids and
sparseness. The functional nature of the data is accounted for by expanding all model terms in the
additive predictor in suitable bases. For the functional random e ects, bases of functional principal
components are chosen. These can be seen as natural functional extensions of multivariate principal
components and thus represent the dominant modes of variation in the data. Using only the most important
directions provides the dimension reduction critically important for functional data analysis.
In analogy to the multivariate case, the functional principal components of the functional random
e ects correspond to the eigenfunctions of their respective covariance operators. How to estimate
covariances of latent processes is non-trivial and thus constitutes an essential element in this thesis.
In the  rst two parts of this work, two novel method of moments estimators for covariances of latent
processes are proposed. They di er in the generality of the assumed correlation structures and the
supported sampling grids. Both covariance estimation methods involve bivariate smoothing of one or
multiple covariances. In the third part, a fast symmetric bivariate smoothing approach is proposed
that is particularly suited to estimate smooth covariances by taking advantage of their symmetry. Its
application considerably reduces computation time and memory requirements.
The proposed modeling framework is evaluated in extensive simulation studies. The relevance of the
proposed methods is highlighted in applications to data from speech production research as well as
from medical studies. To allow the practical application of the methods, open-source implementations
are provided in the two R add-on packages denseFLMM and sparseFLMM.},
	school = {Ludwig-Maximilians-Universität München},
	author = {Cederbaum, Jona},
	month = jun,
	year = {2017},
}

@article{szczesna_datasets_2023,
	title = {Datasets for learning of unknown characteristics of dynamical systems},
	volume = {10},
	copyright = {2023 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-023-01978-7},
	doi = {10.1038/s41597-023-01978-7},
	abstract = {The ability to uncover characteristics based on empirical measurement is an important step in understanding the underlying system that gives rise to an observed time series. This is especially important for biological signals whose characteristic contributes to the underlying dynamics of the physiological processes. Therefore, by studying such signals, the physiological systems that generate them can be better understood. The datasets presented consist of 33,000 time series of 15 dynamical systems (five chaotic and ten non-chaotic) of the first, second, or third order. Here, the order of a dynamical system means its dimension. The non-chaotic systems were divided into the following classes: periodic, quasi-periodic, and non-periodic. The aim is to propose datasets for machine learning methods, in particular deep learning techniques, to analyze unknown dynamical system characteristics based on obtained time series. In technical validation, three classifications experiments were conducted using two types of neural networks with long short-term memory modules and convolutional layers.},
	language = {en},
	number = {1},
	urldate = {2023-08-10},
	journal = {Scientific Data},
	author = {Szczęsna, Agnieszka and Augustyn, Dariusz and Harężlak, Katarzyna and Josiński, Henryk and Świtoński, Adam and Kasprowski, Paweł},
	month = feb,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Scientific data},
	pages = {79},
}

@article{ionides_comment_2007,
	title = {Comment: {Parameter} estimation for differential equations: a generalized smoothing approach},
	volume = {69},
	shorttitle = {Comment: {Parameter} estimation for differential equations},
	doi = {10.1111/j.1467-9868.2007.00610.x},
	number = {5},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Ionides, Edward L.},
	year = {2007},
	pages = {741--796},
}

@article{ramsay_parameter_2007,
	title = {Parameter estimation for differential equations: a generalized smoothing approach},
	volume = {69},
	copyright = {© 2007 Royal Statistical Society},
	issn = {1467-9868},
	shorttitle = {Parameter estimation for differential equations},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2007.00610.x},
	doi = {10.1111/j.1467-9868.2007.00610.x},
	abstract = {Summary. We propose a new method for estimating parameters in models that are defined by a system of non-linear differential equations. Such equations represent changes in system outputs by linking the behaviour of derivatives of a process to the behaviour of the process itself. Current methods for estimating parameters in differential equations from noisy data are computationally intensive and often poorly suited to the realization of statistical objectives such as inference and interval estimation. The paper describes a new method that uses noisy measurements on a subset of variables to estimate the parameters defining a system of non-linear differential equations. The approach is based on a modification of data smoothing methods along with a generalization of profiled estimation. We derive estimates and confidence intervals, and show that these have low bias and good coverage properties respectively for data that are simulated from models in chemical engineering and neurobiology. The performance of the method is demonstrated by using real world data from chemistry and from the progress of the autoimmune disease lupus.},
	language = {en},
	number = {5},
	urldate = {2023-07-24},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Ramsay, J. O. and Hooker, G. and Campbell, D. and Cao, J.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2007.00610.x},
	keywords = {Differential equation, Dynamic system, Estimating equation, Functional data analysis, Gauss, Newton method, Parameter cascade, Profiled estimation},
	pages = {741--796},
}

@article{ionides_inference_2006,
	title = {Inference for nonlinear dynamical systems},
	volume = {103},
	number = {49},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ionides, Edward L. and Bretó, Carles and King, Aaron A.},
	year = {2006},
	note = {Publisher: National Acad Sciences},
	pages = {18438--18443},
}

@misc{noauthor_parameter_nodate,
	title = {Parameter estimation for differential equations: a generalized smoothing approach - {Ramsay} - 2007 - {Journal} of the {Royal} {Statistical} {Society}: {Series} {B} ({Statistical} {Methodology}) - {Wiley} {Online} {Library}},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2007.00610.x},
	urldate = {2023-08-10},
}

@article{sano_measurement_1985,
	title = {Measurement of the {Lyapunov} {Spectrum} from a {Chaotic} {Time} {Series}},
	volume = {55},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.55.1082},
	doi = {10.1103/PhysRevLett.55.1082},
	abstract = {The exponential divergence or convergence of nearby trajectories (Lyapunov exponents) is conceptually the most basic indicator of deterministic chaos. We propose a new method to determine the spectrum of several Lyapunov exponents (including positive, zero, and even negative ones) from the observed time series of a single variable. We have applied the method to various known model systems and also to the Rayleigh-Bénard experiment, and have elucidated the dependence of the Lyapunov exponents on the Rayleigh number.},
	number = {10},
	urldate = {2023-08-10},
	journal = {Physical Review Letters},
	author = {Sano, M. and Sawada, Y.},
	month = sep,
	year = {1985},
	note = {Publisher: American Physical Society},
	pages = {1082--1085},
}

@book{gunning_functional_2023,
	series = {{SpringerBriefs} in {Statistics}},
	title = {Functional {Data} {Analysis} in {Biomechanics}: {A} concise review of core techniques, applications and emerging areas},
	publisher = {SpringerBriefs in Statistics (Accepted)},
	author = {Gunning, Edward and Warmenhoven, John and Harrison, Andrew J. and Bargary, Norma},
	year = {2023},
}

@article{gunning_understanding_2023,
	title = {An {Understanding} of {Principal} {Differential} {Analysis}},
	journal = {In Preparation},
	author = {Gunning, Edward and Hooker, Giles},
	year = {2023},
}

@article{varah_spline_1982,
	title = {A {Spline} {Least} {Squares} {Method} for {Numerical} {Parameter} {Estimation} in {Differential} {Equations}},
	volume = {3},
	issn = {0196-5204},
	url = {https://epubs.siam.org/doi/10.1137/0903003},
	doi = {10.1137/0903003},
	abstract = {A domain decomposition method for solving large bivariate scattered data fitting problems with bivariate minimal energy, discrete least-squares, and penalized least-squares splines is described. The method is based on splitting the domain into smaller domains, solving the associated smaller fitting problems, and combining the coefficients to get a global fit. Explicit error bounds are established for how well our locally constructed spline fits approximate the global fits. Some numerical examples are given to illustrate the effectiveness of the method.},
	number = {1},
	urldate = {2023-07-25},
	journal = {SIAM Journal on Scientific and Statistical Computing},
	author = {Varah, J. M.},
	month = mar,
	year = {1982},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {28--46},
}

@misc{noauthor_parameter_nodate-1,
	title = {Parameter estimation for differential equations: a generalized smoothing approach - {Ramsay} - 2007 - {Journal} of the {Royal} {Statistical} {Society}: {Series} {B} ({Statistical} {Methodology}) - {Wiley} {Online} {Library}},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2007.00610.x},
	urldate = {2023-07-24},
}

@article{hooker_comments_2010,
	title = {Comments on: {Dynamic} relations for sparsely sampled {Gaussian} processes},
	volume = {19},
	issn = {1863-8260},
	shorttitle = {Comments on},
	url = {https://doi.org/10.1007/s11749-009-0178-2},
	doi = {10.1007/s11749-009-0178-2},
	language = {en},
	number = {1},
	urldate = {2023-07-21},
	journal = {TEST},
	author = {Hooker, Giles},
	month = may,
	year = {2010},
	keywords = {Dynamic Relation, Functional Data Analysis, Gaussian Process, Nonlinear Dynamical Model, Nonparametric Regression},
	pages = {50--53},
}

@article{hooker_forcing_2009,
	title = {Forcing {Function} {Diagnostics} for {Nonlinear} {Dynamics}},
	volume = {65},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2008.01172.x},
	doi = {10.1111/j.1541-0420.2008.01172.x},
	abstract = {This article investigates the problem of model diagnostics for systems described by nonlinear ordinary differential equations (ODEs). I propose modeling lack of fit as a time-varying correction to the right-hand side of a proposed differential equation. This correction can be described as being a set of additive forcing functions, estimated from data. Representing lack of fit in this manner allows us to graphically investigate model inadequacies and to suggest model improvements. I derive lack-of-fit tests based on estimated forcing functions. Model building in partially observed systems of ODEs is particularly difficult and I consider the problem of identification of forcing functions in these systems. The methods are illustrated with examples from computational neuroscience.},
	language = {en},
	number = {3},
	urldate = {2023-07-21},
	journal = {Biometrics},
	author = {Hooker, Giles},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2008.01172.x},
	keywords = {Diagnostics, Goodness of fit, Neural dynamics, Nonlinear dynamics},
	pages = {928--936},
}

@article{trail_functional_2014,
	title = {Functional data analysis for dynamical system identification of behavioral processes},
	volume = {19},
	issn = {1939-1463},
	doi = {10.1037/a0034035},
	abstract = {Efficient new technology has made it straightforward for behavioral scientists to collect anywhere from several dozen to several thousand dense, repeated measurements on one or more time-varying variables. These intensive longitudinal data (ILD) are ideal for examining complex change over time but present new challenges that illustrate the need for more advanced analytic methods. For example, in ILD the temporal spacing of observations may be irregular, and individuals may be sampled at different times. Also, it is important to assess both how the outcome changes over time and the variation between participants’ time-varying processes to make inferences about a particular intervention’s effectiveness within the population of interest. The methods presented in this article integrate 2 innovative ILD analytic techniques: functional data analysis and dynamical systems modeling. An empirical application is presented using data from a smoking cessation clinical trial. Study participants provided 42 daily assessments of pre-quit and post-quit withdrawal symptoms. Regression splines were used to approximate smooth functions of craving and negative affect and to estimate the variables’ derivatives for each participant. We then modeled the dynamics of nicotine craving using standard input–output dynamical systems models. These models provide a more detailed characterization of the post-quit craving process than do traditional longitudinal models, including information regarding the type, magnitude, and speed of the response to an input. The results, in conjunction with standard engineering control theory techniques, could potentially be used by tobacco researchers to develop a more effective smoking intervention. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Methods},
	author = {Trail, Jessica B. and Collins, Linda M. and Rivera, Daniel E. and Li, Runze and Piper, Megan E. and Baker, Timothy B.},
	year = {2014},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Analysis, Clinical Trials, Data Collection, Experimental Design, Longitudinal Studies, Smoking Cessation},
	pages = {175--187},
}

@article{verzelen_inferring_2012,
	title = {Inferring stochastic dynamics from functional data},
	volume = {99},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/ass015},
	doi = {10.1093/biomet/ass015},
	abstract = {In most current data modelling for time-dynamic systems, one works with a prespecified differential equation and attempts to estimate its parameters. In contrast, we demonstrate that in the case of functional data, the equation itself can be inferred. Assuming only that the dynamics are described by a first-order nonlinear differential equation with a random component, we obtain data-adaptive dynamic equations from the observed data via a simple smoothing-based procedure. We prove consistency and introduce diagnostics to ascertain the fraction of variance that is explained by the deterministic part of the equation. This approach is shown to yield useful insights into the time-dynamic nature of human growth.},
	number = {3},
	urldate = {2023-07-20},
	journal = {Biometrika},
	author = {Verzelen, Nicolas and Tao, Wenwen and Müller, Hans-Georg},
	month = sep,
	year = {2012},
	pages = {533--550},
}

@article{gunning_multivariate_2023,
	title = {A {Multivariate} {Multilevel} {Longitudinal} {Functional} {Model} for {Repeatedly}-{Observed} {Human}-{Movement} {Data}},
	journal = {In Preparation},
	author = {Gunning, Edward and Golovkine, Steven and Simpkin, Andrew J. and Bargary, Norma},
	year = {2023},
}

@article{chi_models_1989,
	title = {Models for {Longitudinal} {Data} with {Random} {Effects} and {AR}(1) {Errors}},
	volume = {84},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2289929},
	doi = {10.2307/2289929},
	abstract = {For longitudinal data on several individuals, linear models that contain both random effects across individuals and autocorrelation in the within-individual errors are studied. A score test for autocorrelation in the within-individual errors for the "conditional independence" random effects model is first developed. An explicit maximum likelihood estimation procedure using the scoring method for the model with random effects and (autoregressive) AR(1) errors is then derived. Empirical Bayes estimation of the random effects and prediction of future responses of an individual based on this random effects with AR(1) errors model are also considered. A numerical example is presented to illustrate these methods.},
	number = {406},
	urldate = {2023-07-15},
	journal = {Journal of the American Statistical Association},
	author = {Chi, Eric M. and Reinsel, Gregory C.},
	year = {1989},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {452--459},
}

@article{chi_models_1989-1,
	title = {Models for {Longitudinal} {Data} with {Random} {Effects} and {AR}(1) {Errors}},
	volume = {84},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2289929},
	doi = {10.2307/2289929},
	abstract = {For longitudinal data on several individuals, linear models that contain both random effects across individuals and autocorrelation in the within-individual errors are studied. A score test for autocorrelation in the within-individual errors for the "conditional independence" random effects model is first developed. An explicit maximum likelihood estimation procedure using the scoring method for the model with random effects and (autoregressive) AR(1) errors is then derived. Empirical Bayes estimation of the random effects and prediction of future responses of an individual based on this random effects with AR(1) errors model are also considered. A numerical example is presented to illustrate these methods.},
	number = {406},
	urldate = {2023-07-15},
	journal = {Journal of the American Statistical Association},
	author = {Chi, Eric M. and Reinsel, Gregory C.},
	year = {1989},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {452--459},
}

@misc{noauthor_notitle_nodate,
}

@article{orendurff_little_2018,
	title = {A little bit faster: {Lower} extremity joint kinematics and kinetics as recreational runners achieve faster speeds},
	volume = {71},
	issn = {0021-9290},
	shorttitle = {A little bit faster},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929018300964},
	doi = {10.1016/j.jbiomech.2018.02.010},
	abstract = {There appears a linear relationship between small increases in running speed and cardiovascular health benefits. Encouraging or coaching recreational runners to increase their running speed to derive these health benefits might be more effective if their joint level kinematic and kinetic strategy was understood. The aim of this investigation was to compare the peak sagittal plane motions, moments, and powers of the hip, knee and ankle at 85\%, 100\%, 115\% and 130\% of self-selected running speed. Overground running data were collected in 12 recreational runners (6 women, 6 men) with a full body marker set using a 12-camera Vicon MX system with an AMTI force plate. Kinematics and kinetics were analyzed with Vicon Nexus software. Participants chose to run at 2.6 ± 0.5 m/s (85\%); 3.0 ± 0.5 m/s (100\%); 3.3 ± 0.5 m/s (115\%); and 3.7 ± 0.5 m/s (130\%); these four speeds approximately correspond to 6:24-, 5:33-, 5:03-, and 4:30-min kilometer running paces. Running speed had a significant effect (P {\textless} 0.05) on peak kinematic and kinetic variables of the hips, knees and ankles, with peak sagittal hip moments invariant (P {\textgreater} 0.54) and the peak sagittal ankle power generation (P {\textless} 0.0001) the most highly responsive variable. The timing of the peak sagittal extensor moments and powers at the hip, knee and ankle were distributed across stance in a sequential manner. This study shows that running speed affects lower limb joint kinematics and kinetics and suggests that specific intersegmental kinetic strategies might exist across the narrow range of running speeds.},
	language = {en},
	urldate = {2023-07-12},
	journal = {Journal of Biomechanics},
	author = {Orendurff, Michael S. and Kobayashi, Toshiki and Tulchin-Francis, Kirsten and Tullock, Ann Marie Herring and Villarosa, Chris and Chan, Charles and Kraus, Emily and Strike, Siobhan},
	month = apr,
	year = {2018},
	keywords = {Health benefits, Inverse dynamics, Jogging, Moments, Powers},
	pages = {167--175},
}

@article{volkmann_multivariate_2021,
	title = {Multivariate functional additive mixed models},
	copyright = {© 2020 Statistical Modeling Society},
	shorttitle = {Multivariate functional additive mixed models},
	url = {https://journals.sagepub.com/doi/full/10.1177/1471082X211056158},
	doi = {10.1177/1471082X211056158},
	abstract = {Multivariate functional data can be intrinsically multivariate like movement trajectories in 2D or complementary such as precipitation, temperature and wind spe...},
	language = {en},
	urldate = {2021-12-09},
	journal = {Statistical Modelling},
	author = {Volkmann, Alexander and Stöcker, Almond and Scheipl, Fabian and Greven, Sonja},
	month = dec,
	year = {2021},
	note = {Publisher: SAGE PublicationsSage India: New Delhi, India},
}

@article{richter_machine_2021,
	title = {Machine learning in sports science: challenges and opportunities},
	volume = {0},
	issn = {1476-3141},
	shorttitle = {Machine learning in sports science},
	url = {https://doi.org/10.1080/14763141.2021.1910334},
	doi = {10.1080/14763141.2021.1910334},
	number = {0},
	urldate = {2023-07-11},
	journal = {Sports Biomechanics},
	author = {Richter, Chris and O’Reilly, Martin and Delahunt, Eamonn},
	month = apr,
	year = {2021},
	pmid = {33874846},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2021.1910334},
	pages = {1--7},
}

@article{matabuena_estimating_2023,
	title = {Estimating {Knee} {Movement} {Patterns} of {Recreational} {Runners} {Across} {Training} {Sessions} {Using} {Multilevel} {Functional} {Regression} {Models}},
	volume = {77},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2022.2105950},
	doi = {10.1080/00031305.2022.2105950},
	abstract = {Modern wearable monitors and laboratory equipment allow the recording of high-frequency data that can be used to quantify human movement. However, currently, data analysis approaches in these domains remain limited. This article proposes a new framework to analyze biomechanical patterns in sport training data recorded across multiple training sessions using multilevel functional models. We apply the methods to subsecond-level data of knee location trajectories collected in 19 recreational runners during a medium-intensity continuous run (MICR) and a high-intensity interval training (HIIT) session, with multiple steps recorded in each participant-session. We estimate functional intra-class correlation coefficient to evaluate the reliability of recorded measurements across multiple sessions of the same training type. Furthermore, we obtained a vectorial representation of the three hierarchical levels of the data and visualize them in a low-dimensional space. Finally, we quantified the differences between genders and between two training types using functional multilevel regression models that incorporate covariate information. We provide an overview of the relevant methods and make both data and the R code for all analyses freely available online on GitHub. Thus, this work can serve as a helpful reference for practitioners and guide for a broader audience of researchers interested in modeling repeated functional measures at different resolution levels in the context of biomechanics and sports science applications.},
	number = {2},
	urldate = {2023-07-11},
	journal = {The American Statistician},
	author = {Matabuena, Marcos and Karas, Marta and Riazati, Sherveen and Caplan, Nick and Hayes, Philip R.},
	month = apr,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2022.2105950},
	keywords = {Biomechanics, Knee movement, Multilevel functional data analysis, Patterns, Subsecond-level data, Wearable sensors},
	pages = {169--181},
}

@misc{ramsay_fda_2020,
	title = {fda: {Functional} {Data} {Analysis}. {R} package version 5.5.1.},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {fda},
	url = {https://CRAN.R-project.org/package=fda},
	abstract = {These functions were developed to support functional data analysis as described in Ramsay, J. O. and Silverman, B. W. (2005) Functional Data Analysis. New York: Springer and in Ramsay, J. O., Hooker, Giles, and Graves, Spencer (2009). Functional Data Analysis with R and Matlab (Springer). The package includes data sets and script files working many examples including all but one of the 76 figures in this latter book. Matlab versions are available by ftp from {\textless}http://www.psych.mcgill.ca/misc/fda/downloads/FDAfuns/{\textgreater}.},
	urldate = {2020-10-10},
	author = {Ramsay, James O. and Graves, Spencer and Hooker, Giles},
	month = aug,
	year = {2020},
	keywords = {FunctionalData},
}

@article{arel-bundock_modelsummary_2022,
	title = {modelsummary: {Data} and {Model} {Summaries} in {R}},
	volume = {103},
	shorttitle = {modelsummary},
	url = {https://www.jstatsoft.org/article/view/v103i01},
	doi = {10.18637/jss.v103.i01},
	abstract = {modelsummary is a package to summarize data and statistical models in R. It supports over one hundred types of models out-of-the-box, and allows users to report the results of those models side-by-side in a table, or in coefficient plots. It makes it easy to execute common tasks such as computing robust standard errors, adding significance stars, and manipulating coefficient and model labels. Beyond model summaries, the package also includes a suite of tools to produce highly flexible data summary tables, such as dataset overviews, correlation matrices, (multi-level) cross-tabulations, and balance tables (also known as "Table 1"). The appearance of the tables produced by modelsummary can be customized using external packages such as kableExtra, gt, flextable, or huxtable; the plots can be customized using ggplot2. Tables can be exported to many output formats, including HTML, LaTeX, Text/Markdown, Microsoft Word, Powerpoint, Excel, RTF, PDF, and image files. Tables and plots can be embedded seamlessly in rmarkdown, knitr, or Sweave dynamic documents. The modelsummary package is designed to be simple, robust, modular, and extensible.},
	language = {en-US},
	number = {1},
	urldate = {2023-06-30},
	journal = {Journal of Statistical Software},
	author = {Arel-Bundock, Vincent},
	month = jul,
	year = {2022},
	pages = {1--23},
}

@article{shang_grouped_2017,
	title = {Grouped {Functional} {Time} {Series} {Forecasting}: {An} {Application} to {Age}-{Specific} {Mortality} {Rates}},
	volume = {26},
	issn = {1061-8600},
	shorttitle = {Grouped {Functional} {Time} {Series} {Forecasting}},
	url = {https://doi.org/10.1080/10618600.2016.1237877},
	doi = {10.1080/10618600.2016.1237877},
	abstract = {Age-specific mortality rates are often disaggregated by different attributes, such as sex, state, and ethnicity. Forecasting age-specific mortality rates at the national and sub-national levels plays an important role in developing social policy. However, independent forecasts at the sub-national levels may not add up to the forecasts at the national level. To address this issue, we consider reconciling forecasts of age-specific mortality rates, extending the methods of Hyndman et al. in 2011 to functional time series, where age is considered as a continuum. The grouped functional time series methods are used to produce point forecasts of mortality rates that are aggregated appropriately across different disaggregation factors. For evaluating forecast uncertainty, we propose a bootstrap method for reconciling interval forecasts. Using the regional age-specific mortality rates in Japan, obtained from the Japanese Mortality Database, we investigate the one- to ten-step-ahead point and interval forecast accuracies between the independent and grouped functional time series forecasting methods. The proposed methods are shown to be useful for reconciling forecasts of age-specific mortality rates at the national and sub-national levels. They also enjoy improved forecast accuracy averaged over different disaggregation factors. Supplementary materials for the article are available online.},
	number = {2},
	urldate = {2023-07-02},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Shang, Han Lin and Hyndman, Rob J.},
	month = apr,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2016.1237877},
	keywords = {Bottom-up, Forecast reconciliation, Hierarchical time series forecasting, Japanese mortality database, Optimal combination},
	pages = {330--343},
}

@article{tang_clustering_2022,
	title = {Clustering and forecasting multiple functional time series},
	volume = {16},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-16/issue-4/Clustering-and-forecasting-multiple-functional-time-series/10.1214/22-AOAS1602.full},
	doi = {10.1214/22-AOAS1602},
	abstract = {Modeling and forecasting homogeneous age-specific mortality rates of multiple countries could lead to improvements in long-term forecasting. Data fed into joint models are often grouped according to nominal attributes, such as geographic regions, ethnic groups, and socioeconomic status, which may still contain heterogeneity and deteriorate the forecast results. Our paper proposes a novel clustering technique to pursue homogeneity among multiple functional time series, based on functional panel data modeling, to address this issue. Using a functional panel data model with fixed effects, we can extract common functional time series features. These common features could be decomposed into two components: the functional time trend and the mode of variations of functions (functional pattern). The functional time trend reflects the dynamics across time, while the functional pattern captures the fluctuations within curves. The proposed clustering method searches for homogeneous age-specific mortality rates of multiple countries by accounting for both the modes of variations and the temporal dynamics among curves. We demonstrate that the proposed clustering technique outperforms other existing methods through a Monte Carlo simulation and could handle complicated cases with slow decaying eigenvalues. In empirical data analysis we find that the clustering results of age-specific mortality rates can be explained by the combination of geographic region, ethnic groups, and socioeconomic status. We further show that our model produces more accurate forecasts than several benchmark methods in forecasting age-specific mortality rates.},
	number = {4},
	urldate = {2023-07-02},
	journal = {The Annals of Applied Statistics},
	author = {Tang, Chen and Shang, Han Lin and Yang, Yanrong},
	month = dec,
	year = {2022},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Functional panel data, age-specific mortality forecasting, functional principal component analysis, functional time series, multilevel functional data},
	pages = {2523--2553},
}

@article{hormann_dynamic_2015,
	title = {Dynamic functional principal components},
	volume = {77},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/24774739},
	abstract = {We address the problem of dimension reduction for time series of functional data (Xt : t ∈ ℤ). Such functional time series frequently arise, for example, when a continuous time process is segmented into some smaller natural units, such as days. Then each Xt represents one intraday curve. We argue that functional principal component analysis, though a key technique in the field and a benchmark for any competitor, does not provide an adequate dimension reduction in a time series setting. Functional principal component analysis indeed is a static procedure which ignores the essential information that is provided by the serial dependence structure of the functional data under study. Therefore, inspired by Brillinger's theory of dynamic principal components, we propose a dynamic version of functional principal component analysis which is based on a frequency domain approach. By means of a simulation study and an empirical illustration, we show the considerable improvement that the dynamic approach entails when compared with the usual static procedure.},
	number = {2},
	urldate = {2023-07-02},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Hörmann, Siegfried and Kidziński, Łukasz and Hallin, Marc},
	year = {2015},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {319--348},
}

@misc{dahl_xtable_2019,
	title = {xtable: {Export} {Tables} to {LaTeX} or {HTML}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {xtable},
	url = {https://cran.r-project.org/web/packages/xtable/index.html},
	abstract = {Coerce data to LaTeX and HTML tables.},
	urldate = {2023-06-30},
	author = {Dahl, David B. and Scott, David and Roosen, Charles and Magnusson, Arni and Swinton, Jonathan},
	month = apr,
	year = {2019},
	keywords = {ReproducibleResearch},
}

@misc{sharpsteen_tikzdevice_2020,
	title = {{tikzDevice}: {R} {Graphics} {Output} in {LaTeX} {Format}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {{tikzDevice}},
	url = {https://cran.r-project.org/web/packages/tikzDevice/index.html},
	abstract = {Provides a graphics output device for R that records plots in a LaTeX-friendly format. The device transforms plotting commands issued by R functions into LaTeX code blocks. When included in a LaTeX document, these blocks are interpreted with the help of 'TikZ'—a graphics package for TeX and friends written by Till Tantau. Using the 'tikzDevice', the text of R plots can contain LaTeX commands such as mathematical formula. The device also allows arbitrary LaTeX code to be inserted into the output stream.},
	urldate = {2023-06-30},
	author = {Sharpsteen, Charlie and Bracken, Cameron},
	year = {2020},
	keywords = {ReproducibleResearch},
}

@book{wickham_ggplot2_2016,
	address = {New York},
	series = {Use {R}!},
	title = {ggplot2: {Elegant} {Graphics} for {Data} {Analysis}},
	isbn = {978-3-319-24277},
	url = {https://ggplot2.tidyverse.org},
	urldate = {2023-06-30},
	publisher = {Springer-Verlag},
	author = {Wickham, Hadley},
	year = {2016},
	doi = {10.1007/978-3-319-24277-4},
	keywords = {RStudio, base graphics, data analysis of graphics, ggplot2 1.0, grammar of graphics, knitr, lattice graphics, multi-layer graphs, statistical graphics, visualization},
}

@misc{golovkine_use_2023,
	title = {On the use of the {Gram} matrix for multivariate functional principal components analysis},
	url = {http://arxiv.org/abs/2306.12949},
	doi = {10.48550/arXiv.2306.12949},
	abstract = {Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.},
	urldate = {2023-06-27},
	publisher = {arXiv},
	author = {Golovkine, Steven and Gunning, Edward and Simpkin, Andrew J. and Bargary, Norma},
	month = jun,
	year = {2023},
	note = {arXiv:2306.12949 [stat]},
	keywords = {62R10, Statistics - Machine Learning, Statistics - Methodology},
}

@misc{noauthor_use_nodate,
	title = {‪{On} the use of the {Gram} matrix for multivariate functional principal components analysis‬},
	url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=R9NHmz4AAAAJ&citation_for_view=R9NHmz4AAAAJ:d1gkVwhDpl0C},
	abstract = {‪S Golovkine, E Gunning, AJ Simpkin, N Bargary‬, ‪arXiv preprint arXiv:2306.12949, 2023‬},
	urldate = {2023-06-27},
}

@book{harrell_jr_regression_2015,
	address = {Cham Heidelberg New York},
	edition = {2nd ed. 2015 edition},
	title = {Regression {Modeling} {Strategies}: {With} {Applications} to {Linear} {Models}, {Logistic} and {Ordinal} {Regression}, and {Survival} {Analysis}},
	isbn = {978-3-319-19424-0},
	shorttitle = {Regression {Modeling} {Strategies}},
	abstract = {This highly anticipated second edition features new chapters and sections, 225 new references, and comprehensive R software. In keeping with the previous edition, this book is about the art and science of data analysis and predictive modelling, which entails choosing and using multiple tools. Instead of presenting isolated techniques, this text emphasises problem solving strategies that address the many issues arising when developing multi-variable models using real data and not standard textbook examples. Regression Modelling Strategies presents full-scale case studies of non-trivial data-sets instead of over-simplified illustrations of each method. These case studies use freely available R functions that make the multiple imputation, model building, validation and interpretation tasks described in the book relatively easy to do. Most of the methods in this text apply to all regression models, but special emphasis is given to multiple regression using generalised least squares for longitudinal data, the binary logistic model, models for ordinal responses, parametric survival regression models and the Cox semi parametric survival model. A new emphasis is given to the robust analysis of continuous dependent variables using ordinal regression.As in the first edition, this text is intended for Masters' or PhD. level graduate students who have had a general introductory probability and statistics course and who are well versed in ordinary multiple regression and intermediate algebra. The book will also serve as a reference for data analysts and statistical methodologists, as it contains an up-to-date survey and bibliography of modern statistical modelling techniques.},
	language = {English},
	publisher = {Springer},
	author = {Harrell Jr, Frank E.},
	month = aug,
	year = {2015},
}

@article{zhou_modeling_2018,
	title = {Modeling {Subject}-{Specific} {Nonautonomous} {Dynamics}},
	volume = {28},
	issn = {1017-0405},
	url = {https://www.jstor.org/stable/26384248},
	abstract = {We consider modeling non-autonomous dynamical systems for a group of subjects. The proposed model involves a common baseline gradient function and a multiplicative time-dependent subject-specific effect that accounts for phase and amplitude variations in the rate of change across subjects. The baseline gradient function is represented in a spline basis and the subject-specific effect is modeled as a polynomial in time with random coefficients. We establish appropriate identifiability conditions and propose an estimator based on the hierarchical likelihood. We prove consistency and asymptotic normality of the proposed estimator under a regime of moderate-to-dense observations per subject. Simulation studies and an application to the Berkeley Growth Data demonstrate the effectiveness of the proposed methodology.},
	number = {1},
	urldate = {2023-06-25},
	journal = {Statistica Sinica},
	author = {Zhou, Siyuan and Paul, Debashis and Peng, Jie},
	year = {2018},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {423--447},
}

@misc{golovkine_use_2023,
	title = {On the use of the {Gram} matrix for multivariate functional principal components analysis},
	url = {http://arxiv.org/abs/2306.12949},
	doi = {10.48550/arXiv.2306.12949},
	abstract = {Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.},
	urldate = {2023-06-23},
	publisher = {arXiv},
	author = {Golovkine, Steven and Gunning, Edward and Simpkin, Andrew J. and Bargary, Norma},
	month = jun,
	year = {2023},
	note = {arXiv:2306.12949 [stat]},
	keywords = {62R10, Statistics - Machine Learning, Statistics - Methodology},
}

@misc{bates_parsimonious_2018,
	title = {Parsimonious {Mixed} {Models}},
	url = {http://arxiv.org/abs/1506.04967},
	doi = {10.48550/arXiv.1506.04967},
	abstract = {The analysis of experimental data with mixed-effects models requires decisions about the specification of the appropriate random-effects structure. Recently, Barr, Levy, Scheepers, and Tily, 2013 recommended fitting `maximal' models with all possible random effect components included. Estimation of maximal models, however, may not converge. We show that failure to converge typically is not due to a suboptimal estimation algorithm, but is a consequence of attempting to fit a model that is too complex to be properly supported by the data, irrespective of whether estimation is based on maximum likelihood or on Bayesian hierarchical modeling with uninformative or weakly informative priors. Importantly, even under convergence, overparameterization may lead to uninterpretable models. We provide diagnostic tools for detecting overparameterization and guiding model simplification.},
	urldate = {2023-06-22},
	publisher = {arXiv},
	author = {Bates, Douglas and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald},
	month = may,
	year = {2018},
	note = {arXiv:1506.04967 [stat]},
	keywords = {Statistics - Methodology},
}

@misc{soetaert_desolve_2023,
	title = {{deSolve}: {Solvers} for {Initial} {Value} {Problems} of {Differential} {Equations} (`{ODE}', `{DAE}', `{DDE}')},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {{deSolve}},
	url = {https://CRAN.R-project.org/package=deSolve},
	abstract = {Functions that solve initial value problems of a system of first-order ordinary differential equations ('ODE'), of partial differential equations ('PDE'), of differential algebraic equations ('DAE'), and of delay differential equations. The functions provide an interface to the FORTRAN functions 'lsoda', 'lsodar', 'lsode', 'lsodes' of the 'ODEPACK' collection, to the FORTRAN functions 'dvode', 'zvode' and 'daspk' and a C-implementation of solvers of the 'Runge-Kutta' family with fixed or variable time steps. The package contains routines designed for solving 'ODEs' resulting from 1-D, 2-D and 3-D partial differential equations ('PDE') that have been converted to 'ODEs' by numerical differencing.},
	urldate = {2023-04-15},
	author = {Soetaert, Karline and Petzoldt, Thomas and Setzer, R. Woodrow and Brown, Peter N. and Byrne, George D. and Hairer, Ernst and Hindmarsh, Alan C. and Moler, Cleve and Petzold, Linda R. and Saad, Youcef and Ulrich, Clement W.},
	month = mar,
	year = {2023},
	keywords = {DifferentialEquations, Epidemiology},
}

@article{crainiceanu_bootstrap-based_2012,
	title = {Bootstrap-based inference on the difference in the means of two correlated functional processes},
	volume = {31},
	issn = {0277-6715},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3966027/},
	doi = {10.1002/sim.5439},
	abstract = {We propose nonparametric inference methods on the mean difference between two correlated functional processes. We compare methods that (1) incorporate different levels of smoothing of the mean and covariance; (2) preserve the sampling design; and (3) use parametric and nonparametric estimation of the mean functions. We apply our method to estimating the mean difference between average normalized δ power of sleep electroencephalograms for 51 subjects with severe sleep apnea and 51 matched controls in the first 4 h after sleep onset. We obtain data from the Sleep Heart Health Study, the largest community cohort study of sleep. Although methods are applied to a single case study, they can be applied to a large number of studies that have correlated functional data.},
	number = {26},
	urldate = {2022-01-10},
	journal = {Statistics in Medicine},
	author = {Crainiceanu, Ciprian M. and Staicu, Ana-Maria and Ray, Shubankar and Punjabi, Naresh},
	month = nov,
	year = {2012},
	pmid = {22855258},
	pmcid = {PMC3966027},
	pages = {3223--3240},
}

@article{liebl_modeling_2013,
	title = {Modeling and {Forecasting} {Electricity} {Spot} {Prices}: {A} {Functional} {Data} {Perspective}},
	volume = {7},
	issn = {1932-6157},
	shorttitle = {Modeling and {Forecasting} {Electricity} {Spot} {Prices}},
	url = {https://www.jstor.org/stable/23566485},
	abstract = {Classical time series models have serious difficulties in modeling and forecasting the enormous fluctuations of electricity spot prices. Markov regime switch models belong to the most often used models in the electricity literature. These models try to capture the fluctuations of electricity spot prices by using different regimes, each with its own mean and covariance structure. Usually one regime is dedicated to moderate prices and another is dedicated to high prices. However, these models show poor performance and there is no theoretical justification for this kind of classification. The merit order model, the most important micro-economic pricing model for electricity spot prices, however, suggests a continuum of mean levels with a functional dependence on electricity demand. We propose a new statistical perspective on modeling and forecasting electricity spot prices that accounts for the merit order model. In a first step, the functional relation between electricity spot prices and electricity demand is modeled by daily price-demand functions. In a second step, we parameterize the series of daily price-demand functions using a functional factor model. The power of this new perspective is demonstrated by a forecast study that compares our functional factor model with two established classical time series models as well as two alternative functional data models.},
	number = {3},
	urldate = {2023-06-17},
	journal = {The Annals of Applied Statistics},
	author = {Liebl, Dominik},
	year = {2013},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1562--1592},
}

@article{bai_discussion_2017,
	title = {Discussion of the paper ‘{A} general framework for functional regression modelling’},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681335},
	doi = {10.1177/1471082X16681335},
	abstract = {This discussion provides our reaction to the article by Greven and Scheipl. It contains an overview of their article and a description of the many areas of research that remain open and could benefit from further methodological and computational development.},
	language = {en},
	number = {1-2},
	urldate = {2023-06-15},
	journal = {Statistical Modelling},
	author = {Bai, Jiawei and Ivanescu, Andrada and Crainiceanu, Ciprian M.},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	pages = {36--44},
}

@article{knief_violating_2021,
	title = {Violating the normality assumption may be the lesser of two evils},
	volume = {53},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-021-01587-5},
	doi = {10.3758/s13428-021-01587-5},
	abstract = {When data are not normally distributed, researchers are often uncertain whether it is legitimate to use tests that assume Gaussian errors, or whether one has to either model a more specific error structure or use randomization techniques. Here we use Monte Carlo simulations to explore the pros and cons of fitting Gaussian models to non-normal data in terms of risk of type I error, power and utility for parameter estimation. We find that Gaussian models are robust to non-normality over a wide range of conditions, meaning that p values remain fairly reliable except for data with influential outliers judged at strict alpha levels. Gaussian models also performed well in terms of power across all simulated scenarios. Parameter estimates were mostly unbiased and precise except if sample sizes were small or the distribution of the predictor was highly skewed. Transformation of data before analysis is often advisable and visual inspection for outliers and heteroscedasticity is important for assessment. In strong contrast, some non-Gaussian models and randomization techniques bear a range of risks that are often insufficiently known. High rates of false-positive conclusions can arise for instance when overdispersion in count data is not controlled appropriately or when randomization procedures ignore existing non-independencies in the data. Hence, newly developed statistical methods not only bring new opportunities, but they can also pose new threats to reliability. We argue that violating the normality assumption bears risks that are limited and manageable, while several more sophisticated approaches are relatively error prone and particularly difficult to check during peer review. Scientists and reviewers who are not fully aware of the risks might benefit from preferentially trusting Gaussian mixed models in which random effects account for non-independencies in the data.},
	language = {en},
	number = {6},
	urldate = {2023-06-15},
	journal = {Behavior Research Methods},
	author = {Knief, Ulrich and Forstmeier, Wolfgang},
	month = dec,
	year = {2021},
	keywords = {Hypothesis testing, Linear model, Normality, Regression},
	pages = {2576--2590},
}

@article{wang_assessing_2009,
	title = {Assessing time-dependent association between scalp {EEG} and muscle activation: {A} functional random-effects model approach},
	volume = {177},
	issn = {0165-0270},
	shorttitle = {Assessing time-dependent association between scalp {EEG} and muscle activation},
	url = {https://www.sciencedirect.com/science/article/pii/S016502700800575X},
	doi = {10.1016/j.jneumeth.2008.09.030},
	abstract = {This study investigates time-dependent associations between source strength estimated from high-density scalp electroencephalogram (EEG) and force of voluntary handgrip contraction at different intensity levels. We first estimate source strength from raw EEG signals collected during voluntary muscle contractions at different levels and then propose a functional random-effects model approach in which both functional fixed effects and functional random-effects are considered for the data. Two estimation procedures for the functional model are discussed. The first estimation procedure is a two-step method which involves no iterations. It can flexibly use different smoothing methods and smoothing parameters. The second estimation procedure benefits from the connection between linear mixed models and regression splines and can be fitted using existing software. Functional ANOVA is then suggested to assess the experimental effects from the functional point of view. The statistical analysis shows that the time-dependent source strength function exhibits a nonlinear feature, where a bump is detected around the force onset time. However, there is the lack of significant variations in source strength on different force levels and different cortical areas. The proposed functional random-effects model procedure can be applied to other types of functional data in neuroscience.},
	language = {en},
	number = {1},
	urldate = {2023-06-14},
	journal = {Journal of Neuroscience Methods},
	author = {Wang, X. F. and Yang, Qi and Fan, Zhaozhi and Sun, Chang-Kai and Yue, Guang H.},
	month = feb,
	year = {2009},
	keywords = {EEG, Fatigue, Functional data, Functional random-effects model, Muscle activation, Source strength},
	pages = {232--240},
}

@misc{pinheiro_nlme_2022,
	title = {nlme: {Linear} and {Nonlinear} {Mixed} {Effects} {Models}. {R} package version 3.1-155},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {nlme},
	url = {https://CRAN.R-project.org/package=nlme},
	abstract = {Fit and compare Gaussian linear and nonlinear mixed-effects models.},
	urldate = {2022-06-03},
	author = {Pinheiro, José  S and Bates, Douglas and DebRoy, Saikat and Sarkar, Deepayan and Heisterkamp, Siem and Van Willigen, Bert and Ranke, Johannes},
	month = mar,
	year = {2022},
	keywords = {ChemPhys, Econometrics, Environmetrics, Finance, OfficialStatistics, Psychometrics, Spatial, SpatioTemporal},
}

@article{asar_linear_2020,
	title = {Linear {Mixed} {Effects} {Models} for {Non}-{Gaussian} {Continuous} {Repeated} {Measurement} {Data}},
	volume = {69},
	issn = {0035-9254},
	url = {https://doi.org/10.1111/rssc.12405},
	doi = {10.1111/rssc.12405},
	abstract = {We consider the analysis of continuous repeated measurement outcomes that are collected longitudinally. A standard framework for analysing data of this kind is a linear Gaussian mixed effects model within which the outcome variable can be decomposed into fixed effects, time invariant and time-varying random effects, and measurement noise. We develop methodology that, for the first time, allows any combination of these stochastic components to be non-Gaussian, using multivariate normal variance–mean mixtures. To meet the computational challenges that are presented by large data sets, i.e. in the current context, data sets with many subjects and/or many repeated measurements per subject, we propose a novel implementation of maximum likelihood estimation using a computationally efficient subsampling-based stochastic gradient algorithm. We obtain standard error estimates by inverting the observed Fisher information matrix and obtain the predictive distributions for the random effects in both filtering (conditioning on past and current data) and smoothing (conditioning on all data) contexts. To implement these procedures, we introduce an R package: ngme. We reanalyse two data sets, from cystic fibrosis and nephrology research, that were previously analysed by using Gaussian linear mixed effects models.},
	number = {5},
	urldate = {2023-06-12},
	journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Asar, Özgür and Bolin, David and Diggle, Peter J. and Wallin, Jonas},
	month = nov,
	year = {2020},
	pages = {1015--1065},
}

@article{wood_fast_2011,
	title = {Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models},
	volume = {73},
	copyright = {© 2010 Royal Statistical Society},
	issn = {1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2010.00749.x},
	doi = {10.1111/j.1467-9868.2010.00749.x},
	abstract = {Summary. Recent work by Reiss and Ogden provides a theoretical basis for sometimes preferring restricted maximum likelihood (REML) to generalized cross-validation (GCV) for smoothing parameter selection in semiparametric regression. However, existing REML or marginal likelihood (ML) based methods for semiparametric generalized linear models (GLMs) use iterative REML or ML estimation of the smoothing parameters of working linear approximations to the GLM. Such indirect schemes need not converge and fail to do so in a non-negligible proportion of practical analyses. By contrast, very reliable prediction error criteria smoothing parameter selection methods are available, based on direct optimization of GCV, or related criteria, for the GLM itself. Since such methods directly optimize properly defined functions of the smoothing parameters, they have much more reliable convergence properties. The paper develops the first such method for REML or ML estimation of smoothing parameters. A Laplace approximation is used to obtain an approximate REML or ML for any GLM, which is suitable for efficient direct optimization. This REML or ML criterion requires that Newton–Raphson iteration, rather than Fisher scoring, be used for GLM fitting, and a computationally stable approach to this is proposed. The REML or ML criterion itself is optimized by a Newton method, with the derivatives required obtained by a mixture of implicit differentiation and direct methods. The method will cope with numerical rank deficiency in the fitted model and in fact provides a slight improvement in numerical robustness on the earlier method of Wood for prediction error criteria based smoothness selection. Simulation results suggest that the new REML and ML methods offer some improvement in mean-square error performance relative to GCV or Akaike's information criterion in most cases, without the small number of severe undersmoothing failures to which Akaike's information criterion and GCV are prone. This is achieved at the same computational cost as GCV or Akaike's information criterion. The new approach also eliminates the convergence failures of previous REML- or ML-based approaches for penalized GLMs and usually has lower computational cost than these alternatives. Example applications are presented in adaptive smoothing, scalar on function regression and generalized additive model selection.},
	language = {en},
	number = {1},
	urldate = {2023-06-05},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Wood, Simon N.},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2010.00749.x},
	keywords = {Adaptive smoothing, Generalized additive mixed model, Generalized additive model, Generalized cross-validation, Marginal likelihood, Model selection, Penalized generalized linear model, Penalized regression splines, Restricted maximum likelihood, Scalar on function regression, Stable computation},
	pages = {3--36},
}

@misc{wood_mgcv_2023,
	title = {mgcv: {Mixed} {GAM} {Computation} {Vehicle} with {Automatic} {Smoothness} {Estimation}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {mgcv},
	url = {https://cran.r-project.org/web/packages/mgcv/index.html},
	abstract = {Generalized additive (mixed) models, some of their extensions and other generalized ridge regression with multiple smoothing parameter estimation by (Restricted) Marginal Likelihood, Generalized Cross Validation and similar, or using iterated nested Laplace approximation for fully Bayesian inference. See Wood (2017) {\textless}doi:10.1201/9781315370279{\textgreater} for an overview. Includes a gam() function, a wide variety of smoothers, 'JAGS' support and distributions beyond the exponential family.},
	urldate = {2023-06-05},
	author = {Wood, Simon N.},
	month = mar,
	year = {2023},
	keywords = {Bayesian, Econometrics, Environmetrics, MixedModels, Spatial},
}

@article{liu_functional_2012,
	title = {Functional mixed effects models},
	volume = {4},
	copyright = {Copyright © 2012 Wiley Periodicals, Inc.},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1226},
	doi = {10.1002/wics.1226},
	abstract = {Functional mixed effects model (FMM) is a mixed effects modeling framework that both the fixed effects and the random effects are modeled by nonparametric curves. The combination of mixed effects model and nonparametric smoothing enables FMMs to handle outcomes with complex profiles and at the same time to incorporate complex experimental designs and include covariates. Estimation and inference can be performed either using techniques from linear mixed effects models or using fully Bayesian approaches. As in functional data analysis, inference in FMMs is preliminary and needs to be further investigated. Several software packages have been developed to implement FMMs, although computational challenges do exist no matter which smoothing method is used. WIREs Comput Stat 2012, 4:527–534. doi: 10.1002/wics.1226 This article is categorized under: Statistical Models {\textgreater} Classification Models},
	language = {en},
	number = {6},
	urldate = {2021-03-09},
	journal = {WIREs Computational Statistics},
	author = {Liu, Ziyue and Guo, Wensheng},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1226},
	keywords = {functional data analysis, mixed effects, nonparametric smoothing},
	pages = {527--534},
}

@article{degras_simultaneous_2017,
	title = {Simultaneous confidence bands for the mean of functional data},
	volume = {9},
	copyright = {© 2017 The Authors. WIREs Computational Statistics published by Wiley Periodicals, Inc.},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1397},
	doi = {10.1002/wics.1397},
	abstract = {The mean function is a central object of inquiry in the analysis of functional data. Typical questions related to the mean function include quantifying estimation uncertainty, testing parametric models, and making comparisons between populations. To make probabilistic statements about the mean function over its entire domain, rather than at a single location, it is necessary to infer all of its values simultaneously. Pointwise inference is not appropriate for this task and indeed produces anticonservative results, i.e., the coverage level of confidence regions is too low and the significance level of hypothesis tests too high. In contrast, simultaneous confidence bands (SCB) provide a flexible framework for conducting simultaneous inference on the mean function and other functional parameters. They also offer powerful visualization tools for communicating analytic results to interdisciplinary audiences. The construction of SCB in the context of functional data requires specific theory and methods. In particular, it is not addressed by the nonparametric regression literature. Although software is available to perform individual steps of an SCB procedure, resources that provide end-to-end computations are scarce. Applications of SCB to one- and two-sample inferences are illustrated here with the R package SCBmeanfd. WIREs Comput Stat 2017, 9:e1397. doi: 10.1002/wics.1397 This article is categorized under: Statistical and Graphical Methods of Data Analysis {\textgreater} Nonparametric Methods Statistical and Graphical Methods of Data Analysis {\textgreater} Statistical Graphics and Visualization Data: Types and Structure {\textgreater} Time Series, Stochastic Processes, and Functional Data},
	language = {en},
	number = {3},
	urldate = {2021-03-24},
	journal = {WIREs Computational Statistics},
	author = {Degras, David},
	year = {2017},
	keywords = {Functional data, R package, bootstrap, hypothesis test, mean function, nonparametric smoothing, simultaneous confidence bands},
	pages = {e1397},
}

@article{cui_fast_2023,
	title = {Fast {Multilevel} {Functional} {Principal} {Component} {Analysis}},
	volume = {32},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2022.2115500},
	doi = {10.1080/10618600.2022.2115500},
	abstract = {We introduce fast multilevel functional principal component analysis (fast MFPCA), which scales up to high dimensional functional data measured at multiple visits. The new approach is orders of magnitude faster than and achieves comparable estimation accuracy with the original MFPCA. Methods are motivated by the National Health and Nutritional Examination Survey (NHANES), which contains minute-level physical activity information of more than 10, 000 participants over multiple days and 1440 observations per day. While MFPCA takes more than five days to analyze these data, fast MFPCA takes less than five minutes. A theoretical study of the proposed method is also provided. The associated function mfpca.face is available in the R package refund. Supplementary materials for this article are available online.},
	number = {2},
	urldate = {2023-06-05},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cui, Erjia and Li, Ruonan and Crainiceanu, Ciprian M. and Xiao, Luo},
	month = apr,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2022.2115500},
	keywords = {Functional principal component analysis, Mixed model equations, Multilevel models},
	pages = {366--377},
}

@article{xiong_state_2023,
	title = {The {State} of {Play} of {Reproducibility} in {Statistics}: {An} {Empirical} {Analysis}},
	volume = {77},
	issn = {0003-1305},
	shorttitle = {The {State} of {Play} of {Reproducibility} in {Statistics}},
	url = {https://doi.org/10.1080/00031305.2022.2131625},
	doi = {10.1080/00031305.2022.2131625},
	abstract = {Reproducibility, the ability to reproduce the results of published papers or studies using their computer code and data, is a cornerstone of reliable scientific methodology. Studies where results cannot be reproduced by the scientific community should be treated with caution. Over the past decade, the importance of reproducible research has been frequently stressed in a wide range of scientific journals such as Nature and Science and international magazines such as The Economist. However, multiple studies have demonstrated that scientific results are often not reproducible across research areas such as psychology and medicine. Statistics, the science concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data, prides itself on its openness when it comes to sharing both computer code and data. In this article, we examine reproducibility in the field of statistics by attempting to reproduce the results in 93 published papers in prominent journals using functional magnetic resonance imaging (fMRI) data during the 2010–2021 period. Overall, from both the computer code and the data perspective, among all the 93 examined papers, we could only reproduce the results in 14 (15.1\%) papers, that is, the papers provide both executable computer code (or software) with the real fMRI data, and our results matched the results in the paper. Finally, we conclude with some author-specific and journal-specific recommendations to improve the research reproducibility in statistics.},
	number = {2},
	urldate = {2023-06-01},
	journal = {The American Statistician},
	author = {Xiong, Xin and Cribben, Ivor},
	month = apr,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2022.2131625},
	keywords = {Computer code access, Data access, Open science, Replicability, Reproducibility, Reproducibility policy},
	pages = {115--126},
}

@article{peng_reproducible_2021,
	title = {Reproducible {Research}: {A} {Retrospective}},
	volume = {42},
	shorttitle = {Reproducible {Research}},
	url = {https://doi.org/10.1146/annurev-publhealth-012420-105110},
	doi = {10.1146/annurev-publhealth-012420-105110},
	abstract = {Advances in computing technology have spurred two extraordinary phenomena in science: large-scale and high-throughput data collection coupled with the creation and implementation of complex statistical algorithms for data analysis. These two phenomena have brought about tremendous advances in scientific discovery but have raised two serious concerns. The complexity of modern data analyses raises questions about the reproducibility of the analyses, meaning the ability of independent analysts to recreate the results claimed by the original authors using the original data and analysis techniques. Reproducibility is typically thwarted by a lack of availability of the original data and computer code. A more general concern is the replicability of scientific findings, which concerns the frequency with which scientific claims are confirmed by completely independent investigations. Although reproducibility and replicability are related, they focus on different aspects of scientific progress. In this review, we discuss the origins of reproducible research, characterize the current status of reproducibility in public health research, and connect reproducibility to current concerns about the replicability of scientific findings. Finally, we describe a path forward for improving both the reproducibility and replicability of public health research in the future.},
	number = {1},
	urldate = {2023-06-01},
	journal = {Annual Review of Public Health},
	author = {Peng, Roger D. and Hicks, Stephanie C.},
	year = {2021},
	pmid = {33467923},
	note = {\_eprint: https://doi.org/10.1146/annurev-publhealth-012420-105110},
	keywords = {data analysis, replicability, reproducibility},
	pages = {79--93},
}

@article{peng_reproducible_2009,
	title = {Reproducible research and {Biostatistics}},
	volume = {10},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxp014},
	doi = {10.1093/biostatistics/kxp014},
	number = {3},
	urldate = {2023-06-01},
	journal = {Biostatistics},
	author = {Peng, Roger D.},
	month = jul,
	year = {2009},
	pages = {405--408},
}

@article{lynch_test_2018,
	title = {A test of weak separability for multi-way functional data, with application to brain connectivity studies},
	volume = {105},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/asy048},
	doi = {10.1093/biomet/asy048},
	abstract = {This paper concerns the modelling of multi-way functional data where double or multiple indices are involved. We introduce a concept of weak separability. The weakly separable structure supports the use of factorization methods that decompose the signal into its spatial and temporal components. The analysis reveals interesting connections to the usual strongly separable covariance structure, and provides insights into tensor methods for multi-way functional data. We propose a formal test for the weak separability hypothesis, where the asymptotic null distribution of the test statistic is a chi-squared-type mixture. The method is applied to study brain functional connectivity derived from source localized magnetoencephalography signals during motor tasks.},
	number = {4},
	urldate = {2023-05-31},
	journal = {Biometrika},
	author = {Lynch, Brian and Chen, Kehui},
	month = dec,
	year = {2018},
	pages = {815--831},
}

@article{reimherr_functional_2014,
	title = {A {Functional} {Data} {Analysis} {Approach} for {Genetic} {Association} {Studies}},
	volume = {8},
	issn = {1932-6157},
	url = {https://www.jstor.org/stable/24521739},
	abstract = {We present a new method based on Functional Data Analysis (FDA) for detecting associations between one or more scalar covariates and a longitudinal response, while correcting for other variables. Our methods exploit the temporal structure of longitudinal data in ways that are otherwise difficult with a multivariate approach. Our procedure, from an FDA perspective, is a departure from more established methods in two key aspects. First, the raw longitudinal phenotypes are assembled into functional trajectories prior to analysis. Second, we explore an association test that is not directly based on principal components. We instead focus on quantifying the reduction in L2 variability as a means of detecting associations. Our procedure is motivated by longitudinal genome wide association studies and, in particular, the childhood asthma management program (CAMP) which explores the long term effects of daily asthma treatments. We conduct a simulation study to better understand the advantages (and/or disadvantages) of an FDA approach compared to a traditional multivariate one. We then apply our methodology to data coming from CAMP. We find a potentially new association with a SNP negatively affecting lung function. Furthermore, this SNP seems to have an interaction effect with one of the treatments.},
	number = {1},
	urldate = {2023-05-25},
	journal = {The Annals of Applied Statistics},
	author = {Reimherr, Matthew and Nicolae, Dan},
	year = {2014},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {406--429},
}

@article{reimherr_functional_2014-1,
	title = {A {Functional} {Data} {Analysis} {Approach} for {Genetic} {Association} {Studies}},
	volume = {8},
	issn = {1932-6157},
	url = {https://www.jstor.org/stable/24521739},
	abstract = {We present a new method based on Functional Data Analysis (FDA) for detecting associations between one or more scalar covariates and a longitudinal response, while correcting for other variables. Our methods exploit the temporal structure of longitudinal data in ways that are otherwise difficult with a multivariate approach. Our procedure, from an FDA perspective, is a departure from more established methods in two key aspects. First, the raw longitudinal phenotypes are assembled into functional trajectories prior to analysis. Second, we explore an association test that is not directly based on principal components. We instead focus on quantifying the reduction in L2 variability as a means of detecting associations. Our procedure is motivated by longitudinal genome wide association studies and, in particular, the childhood asthma management program (CAMP) which explores the long term effects of daily asthma treatments. We conduct a simulation study to better understand the advantages (and/or disadvantages) of an FDA approach compared to a traditional multivariate one. We then apply our methodology to data coming from CAMP. We find a potentially new association with a SNP negatively affecting lung function. Furthermore, this SNP seems to have an interaction effect with one of the treatments.},
	number = {1},
	urldate = {2023-05-25},
	journal = {The Annals of Applied Statistics},
	author = {Reimherr, Matthew and Nicolae, Dan},
	year = {2014},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {406--429},
}

@article{mcfetridge_robust_2021,
	title = {Robust joint modelling of longitudinal and survival data: {Incorporating} a time-varying degrees-of-freedom parameter},
	volume = {63},
	issn = {1521-4036},
	shorttitle = {Robust joint modelling of longitudinal and survival data},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000253},
	doi = {10.1002/bimj.202000253},
	abstract = {Monitoring of individual biomarkers has the potential of explaining the hazard of survival outcomes. In practice, these measurements are intermittently observed and are known to be subject to substantial measurement error. Joint modelling of longitudinal and survival data enables us to associate intermittently measured error-prone biomarkers with risks of survival outcomes and thus plays an important role in the analysis of medical data. Most of the joint models available in the literature have been built on the Gaussian assumption. This makes them sensitive to outliers. In this work, we study a range of robust models to address this issue. Of particular interest is the common occurrence in medical data that outliers can occur with different frequencies over time, for example, in the period when patients adjust to treatment changes. Motivated by the analysis of data gathered from patients with primary biliary cirrhosis, a new model with a time-varying robustness is introduced. Through both the motivating example and a simulation study, this research not only stresses the need to account for longitudinal outliers in the analysis of medical data and in joint modelling research but also highlights the bias and inefficiency from not properly estimating the degrees-of-freedom parameter. This work presents a number of methods in addition to the time-varying robustness, and each method can be fitted using the R package robjm.},
	language = {en},
	number = {8},
	urldate = {2023-05-22},
	journal = {Biometrical Journal},
	author = {McFetridge, Lisa M. and Asar, Özgür and Wallin, Jonas},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000253},
	keywords = {degrees-of-freedom, longitudinal outliers, normal variance mixtures, robust joint model, t-distribution},
	pages = {1587--1606},
}

@article{chow_fitting_2016,
	title = {Fitting {Nonlinear} {Ordinary} {Differential} {Equation} {Models} with {Random} {Effects} and {Unknown} {Initial} {Conditions} {Using} the {Stochastic} {Approximation} {Expectation}–{Maximization} ({SAEM}) {Algorithm}},
	volume = {81},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/s11336-014-9431-z},
	doi = {10.1007/s11336-014-9431-z},
	abstract = {The past decade has evidenced the increased prevalence of irregularly spaced longitudinal data in social sciences. Clearly lacking, however, are modeling tools that allow researchers to fit dynamic models to irregularly spaced data, particularly data that show nonlinearity and heterogeneity in dynamical structures. We consider the issue of fitting multivariate nonlinear differential equation models with random effects and unknown initial conditions to irregularly spaced data. A stochastic approximation expectation–maximization algorithm is proposed and its performance is evaluated using a benchmark nonlinear dynamical systems model, namely, the Van der Pol oscillator equations. The empirical utility of the proposed technique is illustrated using a set of 24-h ambulatory cardiovascular data from 168 men and women. Pertinent methodological challenges and unresolved issues are discussed.},
	language = {en},
	number = {1},
	urldate = {2023-05-12},
	journal = {Psychometrika},
	author = {Chow, Sy-Miin and Lu, Zhaohua and Sherwood, Andrew and Zhu, Hongtu},
	month = mar,
	year = {2016},
	keywords = {differential equation, dynamic, longitudinal, nonlinear, stochastic EM},
	pages = {102--134},
}

@article{wang_modeling_2008,
	title = {Modeling {Price} {Dynamics} in {eBay} {Auctions} {Using} {Differential} {Equations}},
	volume = {103},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/27640147},
	abstract = {Empirical research of online auctions has grown dramatically in recent years. Studies using publicly available bid data from such websites as eBay.com have found many divergences of bidding behavior and auction outcomes compared with ordinary offline auctions and auction theory. Among the main differences between online and offline auctions are the former's longer duration, anonymity of bidders and sellers, and low barriers of entry. All of these factors lead to dynamics in the bid arrival and price process that change throughout the auction. In this work we examine the price process in a large and diverse set of eBay auctions, for both low- and high-valued items, in terms of item, auction, bidder, and seller characteristics. We propose a family of differential equation models that captures online auction dynamics. In particular, we show that a second-order linear differential equation well approximates the dynamics that occur in our diverse set of auctions. We also introduce a multiple-comparisons test for comparing dynamic models of auction subpopulations, which we use to compare subpopulations of auctions grouped by characteristics of the auction, item, seller, and bidders. We find that price dynamics change throughout the auction and are influenced mostly by factors that affect the level of uncertainty about the outcome (e.g., seller rating, item condition) and the level of competitiveness (e.g., early bidding, number of bids). We accomplish the modeling tasks within the framework of principal differential analysis and functional data models.},
	number = {483},
	urldate = {2023-05-09},
	journal = {Journal of the American Statistical Association},
	author = {Wang, Shanshan and Jank, Wolfgang and Shmueli, Galit and Smith, Paul},
	year = {2008},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1100--1118},
}

@article{dattner_differential_2021,
	title = {Differential equations in data analysis},
	volume = {13},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1534},
	doi = {10.1002/wics.1534},
	abstract = {Differential equations have proven to be a powerful mathematical tool in science and engineering, leading to better understanding, prediction, and control of dynamic processes. In this paper, we review the role played by differential equations in data analysis. More specifically, we consider the intersection between differential equations and data analysis in the light of modern statistical learning methodologies. This article is categorized under: Data: Types and Structure {\textgreater} Time Series, Stochastic Processes, and Functional Data Statistical and Graphical Methods of Data Analysis {\textgreater} Nonparametric Methods Statistical Models {\textgreater} Nonlinear Models},
	language = {en},
	number = {6},
	urldate = {2023-05-07},
	journal = {WIREs Computational Statistics},
	author = {Dattner, Itai},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1534},
	keywords = {data science, differential equations, dynamical system, statistical inference, statistical learning, time series},
	pages = {e1534},
}

@article{chow_practical_2019,
	title = {Practical {Tools} and {Guidelines} for {Exploring} and {Fitting} {Linear} and {Nonlinear} {Dynamical} {Systems} {Models}},
	volume = {54},
	issn = {0027-3171},
	url = {https://doi.org/10.1080/00273171.2019.1566050},
	doi = {10.1080/00273171.2019.1566050},
	abstract = {A dynamical system is a system of variables that show some regularity in how they evolve over time. Change concepts described in most dynamical systems models are by no means novel to social and behavioral scientists, but most applications of dynamic modeling techniques in these disciplines are grounded on a narrow subset of—typically linear—theories of change. I provide practical guidelines, recommendations, and software code for exploring and fitting dynamical systems models with linear and nonlinear change functions in the context of four illustrative examples. Cautionary notes, challenges, and unresolved issues in utilizing these techniques are discussed.},
	number = {5},
	urldate = {2023-05-07},
	journal = {Multivariate Behavioral Research},
	author = {Chow, Sy-Miin},
	month = sep,
	year = {2019},
	pmid = {30950646},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00273171.2019.1566050},
	keywords = {Differential equation, GAM, dynamical systems, functional data analysis, time-varying parameters},
	pages = {690--718},
}

@article{chow_comparison_2016,
	title = {A {Comparison} of {Two}-{Stage} {Approaches} for {Fitting} {Nonlinear} {Ordinary} {Differential} {Equation} {Models} with {Mixed} {Effects}},
	volume = {51},
	issn = {0027-3171},
	url = {https://doi.org/10.1080/00273171.2015.1123138},
	doi = {10.1080/00273171.2015.1123138},
	abstract = {Several approaches exist for estimating the derivatives of observed data for model exploration purposes, including functional data analysis (FDA; Ramsay \& Silverman, 2005), generalized local linear approximation (GLLA; Boker, Deboeck, Edler, \& Peel, 2010), and generalized orthogonal local derivative approximation (GOLD; Deboeck, 2010). These derivative estimation procedures can be used in a two-stage process to fit mixed effects ordinary differential equation (ODE) models. While the performance and utility of these routines for estimating linear ODEs have been established, they have not yet been evaluated in the context of nonlinear ODEs with mixed effects. We compared properties of the GLLA and GOLD to an FDA-based two-stage approach denoted herein as functional ordinary differential equation with mixed effects (FODEmixed) in a Monte Carlo (MC) study using a nonlinear coupled oscillators model with mixed effects. Simulation results showed that overall, the FODEmixed outperformed both the GLLA and GOLD across all the embedding dimensions considered, but a novel use of a fourth-order GLLA approach combined with very high embedding dimensions yielded estimation results that almost paralleled those from the FODEmixed. We discuss the strengths and limitations of each approach and demonstrate how output from each stage of FODEmixed may be used to inform empirical modeling of young children’s self-regulation.},
	number = {2-3},
	urldate = {2023-05-07},
	journal = {Multivariate Behavioral Research},
	author = {Chow, Sy-Miin and Bendezú, Jason J. and Cole, Pamela M. and Ram, Nilam},
	month = may,
	year = {2016},
	pmid = {27391255},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00273171.2015.1123138},
	keywords = {Differential equation, derivatives, dynamic, dynamical systems, functional data analysis},
	pages = {154--184},
}

@article{schielzeth_robustness_2020,
	title = {Robustness of linear mixed-effects models to violations of distributional assumptions},
	volume = {11},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13434},
	doi = {10.1111/2041-210X.13434},
	abstract = {Linear mixed-effects models are powerful tools for analysing complex datasets with repeated or clustered observations, a common data structure in ecology and evolution. Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation. Here we address the consequences of violations in distributional assumptions and the impact of missing random effect components on model estimates. In particular, we evaluate the effects of skewed, bimodal and heteroscedastic random effect and residual variances, of missing random effect terms and of correlated fixed effect predictors. We focus on bias and prediction error on estimates of fixed and random effects. Model estimates were usually robust to violations of assumptions, with the exception of slight upward biases in estimates of random effect variance if the generating distribution was bimodal but was modelled by Gaussian error distributions. Further, estimates for (random effect) components that violated distributional assumptions became less precise but remained unbiased. However, this particular problem did not affect other parameters of the model. The same pattern was found for strongly correlated fixed effects, which led to imprecise, but unbiased estimates, with uncertainty estimates reflecting imprecision. Unmodelled sources of random effect variance had predictable effects on variance component estimates. The pattern is best viewed as a cascade of hierarchical grouping factors. Variances trickle down the hierarchy such that missing higher-level random effect variances pool at lower levels and missing lower-level and crossed random effect variances manifest as residual variance. Overall, our results show remarkable robustness of mixed-effects models that should allow researchers to use mixed-effects models even if the distributional assumptions are objectively violated. However, this does not free researchers from careful evaluation of the model. Estimates that are based on data that show clear violations of key assumptions should be treated with caution because individual datasets might give highly imprecise estimates, even if they will be unbiased on average across datasets.},
	language = {en},
	number = {9},
	urldate = {2023-05-06},
	journal = {Methods in Ecology and Evolution},
	author = {Schielzeth, Holger and Dingemanse, Niels J. and Nakagawa, Shinichi and Westneat, David F. and Allegue, Hassen and Teplitsky, Céline and Réale, Denis and Dochtermann, Ned A. and Garamszegi, László Zsolt and Araya-Ajoy, Yimen G.},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13434},
	keywords = {biostatistics, correlated predictors, distributional assumptions, linear mixed-effects models, missing random effects, statistical quantification of individual differences (SQuID)},
	pages = {1141--1152},
}

@article{warrington_robustness_2014,
	title = {Robustness of the linear mixed effects model to error distribution assumptions and the consequences for genome-wide association studies},
	volume = {13},
	issn = {1544-6115},
	url = {https://www.degruyter.com/document/doi/10.1515/sagmb-2013-0066/html},
	doi = {10.1515/sagmb-2013-0066},
	abstract = {Genome-wide association studies have been successful in uncovering novel genetic variants that are associated with disease status or cross-sectional phenotypic traits. Researchers are beginning to investigate how genes play a role in the development of a trait over time. Linear mixed effects models (LMM) are commonly used to model longitudinal data; however, it is unclear if the failure to meet the models distributional assumptions will affect the conclusions when conducting a genome-wide association study. In an extensive simulation study, we compare coverage probabilities, bias, type 1 error rates and statistical power when the error of the LMM is either heteroscedastic or has a non-Gaussian distribution. We conclude that the model is robust to misspecification if the same function of age is included in the fixed and random effects. However, type 1 error of the genetic effect over time is inflated, regardless of the model misspecification, if the polynomial function for age in the fixed and random effects differs. In situations where the model will not converge with a high order polynomial function in the random effects, a reduced function can be used but a robust standard error needs to be calculated to avoid inflation of the type 1 error. As an illustration, a LMM was applied to longitudinal body mass index (BMI) data over childhood in the ALSPAC cohort; the results emphasised the need for the robust standard error to ensure correct inference of associations of longitudinal BMI with chromosome 16 single nucleotide polymorphisms.},
	language = {en},
	number = {5},
	urldate = {2023-05-05},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {Warrington, Nicole M. and Tilling, Kate and Howe, Laura D. and Paternoster, Lavinia and Pennell, Craig E. and Wu, Yan Yan and Briollais, Laurent},
	month = oct,
	year = {2014},
	note = {Publisher: De Gruyter},
	keywords = {ALSPAC, genome-wide association, longitudinal studies, misspecificiation, mixed model, robustness},
	pages = {567--587},
}

@article{jacqmin-gadda_robustness_2007,
	title = {Robustness of the linear mixed model to misspecified error distribution},
	volume = {51},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S016794730600185X},
	doi = {10.1016/j.csda.2006.05.021},
	abstract = {A simulation study is performed to investigate the robustness of the maximum likelihood estimator of fixed effects from a linear mixed model when the error distribution is misspecified. Inference for the fixed effects under the assumption of independent normally distributed errors with constant variance is shown to be robust when the errors are either non-gaussian or heteroscedastic, except when the error variance depends on a covariate included in the model with interaction with time. Inference is impaired when the errors are correlated. In the latter case, the model including a random slope in addition to the random intercept is more robust than the random intercept model. The use of Cholesky residuals and conditional residuals to evaluate the fit of a linear mixed model is also discussed.},
	language = {en},
	number = {10},
	urldate = {2023-05-05},
	journal = {Computational Statistics \& Data Analysis},
	author = {Jacqmin-Gadda, Hélène and Sibillot, Solenne and Proust, Cécile and Molina, Jean-Michel and Thiébaut, Rodolphe},
	month = jun,
	year = {2007},
	keywords = {Maximum likelihood estimator, Misspecification, Mixed model, Random-effect, Robustness},
	pages = {5142--5154},
}

@article{gunning_analyzing_2023,
	title = {Analyzing {Kinematic} {Data} from {Recreational} {Runners} using {Functional} {Data} {Analysis}},
	abstract = {We develop a multivariate functional mixed effects approach to model kinematic data from a large number of recreational runners (\$N=288\$). The hip and knee angles are treated jointly as a bivariate function and random-effects functions account for the dependence among measurements from both sides of the body. The model is fitted by first applying multivariate functional principal components analysis (mv-FPCA) and then modelling the mv-FPCA scores using scalar linear mixed effects models. Simulation and bootstrap approaches are used to construct simultaneous confidence bands for the fixed-effects functions, and covariance functions are reconstructed to summarise the variability structure in the data and thoroughly investigate the suitability of the proposed model. The scientific results were consistent with existing biomechanical knowledge and the model offered intuitive options for visualisation. The approach is more generally applicable to modelling multiple streams of kinematic or kinetic data measured repeatedly for multiple subjects.},
	journal = {Under Review},
	author = {Gunning, Edward and Golovkine, Steven and Simpkin, Andrew J. and Burke, Aoife and Dillon, Sarah and Gore, Shane and Moran, Kieran A. and O'Connor, Siobhán and Whyte and Bargary, Norma},
	month = mar,
	year = {2023},
}

@article{blickhan_intelligence_2006,
	title = {Intelligence by mechanics},
	volume = {365},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2006.1911},
	doi = {10.1098/rsta.2006.1911},
	abstract = {Research on the biomechanics of animal and human locomotion provides insight into basic principles of locomotion and respective implications for construction and control. Nearly elastic operation of the leg is necessary to reproduce the basic dynamics in walking and running. Elastic leg operation can be modelled with a spring-mass model. This model can be used as a template with respect to both gaits in the construction and control of legged machines. With respect to the segmented leg, the humanoid arrangement saves energy and ensures structural stability. With the quasi-elastic operation the leg inherits the property of self-stability, i.e. the ability to stabilize a system in the presence of disturbances without sensing the disturbance or its direct effects. Self-stability can be conserved in the presence of musculature with its crucial damping property. To ensure secure foothold visco-elastic suspended muscles serve as shock absorbers. Experiments with technically implemented leg models, which explore some of these principles, are promising.},
	number = {1850},
	urldate = {2023-04-19},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Blickhan, Reinhard and Seyfarth, Andre and Geyer, Hartmut and Grimmer, Sten and Wagner, Heiko and Günther, Michael},
	month = nov,
	year = {2006},
	note = {Publisher: Royal Society},
	keywords = {biomechanics, impact, run, segmentation, stability, walk},
	pages = {199--220},
}

@article{kulmala_running_2018,
	title = {Running in highly cushioned shoes increases leg stiffness and amplifies impact loading},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-35980-6},
	doi = {10.1038/s41598-018-35980-6},
	abstract = {Running shoe cushioning has become a standard method for managing impact loading and consequent injuries due to running. However, despite decades of shoe technology developments and the fact that shoes have become increasingly cushioned, aimed to ease the impact on runners’ legs, running injuries have not decreased. To better understand the shoe cushioning paradox, we examined impact loading and the spring-like mechanics of running in a conventional control running shoe and a highly cushioned maximalist shoe at two training speeds, 10 and 14.5 km/h. We found that highly cushioned maximalist shoes alter spring-like running mechanics and amplify rather than attenuate impact loading. This surprising outcome was more pronounced at fast running speed (14.5 km/h), where ground reaction force impact peak and loading rate were 10.7\% and 12.3\% greater, respectively, in the maximalist shoe compared to the conventional shoe, whereas only a slightly higher impact peak (6.4\%) was found at the 10 km/h speed with the maximalist shoe. We attribute the greater impact loading with the maximalist shoes to stiffer leg during landing compared to that of running with the conventional shoes. These discoveries may explain why shoes with more cushioning do not protect against impact-related running injuries.},
	language = {en},
	number = {1},
	urldate = {2023-04-19},
	journal = {Scientific Reports},
	author = {Kulmala, Juha-Pekka and Kosonen, Jukka and Nurminen, Jussi and Avela, Janne},
	month = nov,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Bone quality and biomechanics, Skeleton},
	pages = {17496},
}

@article{boland_study_2022,
	title = {A study of longitudinal trends in time-frequency transformations of {EEG} data during a learning experiment},
	volume = {167},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947321002012},
	doi = {10.1016/j.csda.2021.107367},
	abstract = {EEG experiments yield high-dimensional event-related potential (ERP) data in response to repeatedly presented stimuli throughout the experiment. Changes in the high-dimensional ERP signal throughout the duration of an experiment (longitudinally) is the main quantity of interest in learning paradigms, where they represent the learning dynamics. Typical analysis, which can be performed in the time or the frequency domain, average the ERP waveform across all trials, leading to the loss of the potentially valuable longitudinal information in the data. Longitudinal time-frequency transformation of ERP (LTFT-ERP) is proposed to retain information from both the time and frequency domains, offering distinct but complementary information on the underlying cognitive processes evoked, while still retaining the longitudinal dynamics in the ERP waveforms. LTFT-ERP begins by time-frequency transformations of the ERP data, collected across subjects, electrodes, conditions and trials throughout the duration of the experiment, followed by a data driven multidimensional principal components analysis (PCA) approach for dimension reduction. Following projection of the data onto leading directions of variation in the time and frequency domains, longitudinal learning dynamics are modeled within a mixed effects modeling framework. Applications to a learning paradigm in autism depict distinct learning patterns throughout the experiment among children diagnosed with Autism Spectrum Disorder and their typically developing peers. LTFT-ERP time-frequency joint transformations are shown to bring an additional level of specificity to interpretations of the longitudinal learning patterns related to underlying cognitive processes, which is lacking in single domain analysis (in the time or the frequency domain only). Simulation studies show the efficacy of the proposed methodology.},
	language = {en},
	urldate = {2023-04-14},
	journal = {Computational Statistics \& Data Analysis},
	author = {Boland, Joanna and Telesca, Donatello and Sugar, Catherine and Jeste, Shafali and Goldbeck, Cameron and Şentürk, Damla},
	month = mar,
	year = {2022},
	keywords = {Event-related potentials, Longitudinal functional data analysis, Mixed effects models, Multidimensional PCA, Wavelets},
	pages = {107367},
}

@article{shamshoian_bayesian_2022,
	title = {Bayesian analysis of longitudinal and multidimensional functional data},
	volume = {23},
	issn = {1468-4357},
	doi = {10.1093/biostatistics/kxaa041},
	abstract = {Multi-dimensional functional data arises in numerous modern scientific experimental and observational studies. In this article, we focus on longitudinal functional data, a structured form of multidimensional functional data. Operating within a longitudinal functional framework we aim to capture low dimensional interpretable features. We propose a computationally efficient nonparametric Bayesian method to simultaneously smooth observed data, estimate conditional functional means and functional covariance surfaces. Statistical inference is based on Monte Carlo samples from the posterior measure through adaptive blocked Gibbs sampling. Several operative characteristics associated with the proposed modeling framework are assessed comparatively in a simulated environment. We illustrate the application of our work in two case studies. The first case study involves age-specific fertility collected over time for various countries. The second case study is an implicit learning experiment in children with autism spectrum disorder.},
	language = {eng},
	number = {2},
	journal = {Biostatistics (Oxford, England)},
	author = {Shamshoian, John and Şentürk, Damla and Jeste, Shafali and Telesca, Donatello},
	month = apr,
	year = {2022},
	pmid = {33017019},
	pmcid = {PMC9007445},
	keywords = {Autism Spectrum Disorder, Bayes Theorem, Child, Factor analysis, Functional data analysis, Gaussian process, Humans, Longitudinal mixed model, Marginal covariance, Monte Carlo Method, Rank regularization, Tensor spline},
	pages = {558--573},
}

@article{koner_second-generation_2023,
	title = {Second-{Generation} {Functional} {Data}},
	volume = {10},
	url = {https://doi.org/10.1146/annurev-statistics-032921-033726},
	doi = {10.1146/annurev-statistics-032921-033726},
	abstract = {Modern studies from a variety of fields record multiple functional observations according to either multivariate, longitudinal, spatial, or time series designs. We refer to such data as second-generation functional data because their analysis—unlike typical functional data analysis, which assumes independence of the functions—accounts for the complex dependence between the functional observations and requires more advanced methods. In this article, we provide an overview of the techniques for analyzing second-generation functional data with a focus on highlighting the key methodological intricacies that stem from the need for modeling complex dependence, compared with independent functional data. For each of the four types of second-generation functional data presented—multivariate functional data, longitudinal functional data, functional time series and spatially functional data—we discuss how the widely popular functional principal component analysis can be extended to these settings to define, identify main directions of variation, and describe dependence among the functions. In addition to modeling, we also discuss prediction, statistical inference, and application to clustering. We close by discussing future directions in this area.},
	number = {1},
	urldate = {2023-04-14},
	journal = {Annual Review of Statistics and Its Application},
	author = {Koner, Salil and Staicu, Ana-Maria},
	year = {2023},
	note = {\_eprint: https://doi.org/10.1146/annurev-statistics-032921-033726},
	keywords = {functional principal component analysis, functional time series, longitudinal functional data, multivariate functional data, spatial functional data},
	pages = {547--572},
}

@article{scheffler_hybrid_2020,
	title = {Hybrid principal components analysis for region-referenced longitudinal functional {EEG} data},
	volume = {21},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxy034},
	doi = {10.1093/biostatistics/kxy034},
	abstract = {Electroencephalography (EEG) data possess a complex structure that includes regional, functional, and longitudinal dimensions. Our motivating example is a word segmentation paradigm in which typically developing (TD) children, and children with autism spectrum disorder (ASD) were exposed to a continuous speech stream. For each subject, continuous EEG signals recorded at each electrode were divided into one-second segments and projected into the frequency domain via fast Fourier transform. Following a spectral principal components analysis, the resulting data consist of region-referenced principal power indexed regionally by scalp location, functionally across frequencies, and longitudinally by one-second segments. Standard EEG power analyses often collapse information across the longitudinal and functional dimensions by averaging power across segments and concentrating on specific frequency bands. We propose a hybrid principal components analysis for region-referenced longitudinal functional EEG data, which utilizes both vector and functional principal components analyses and does not collapse information along any of the three dimensions of the data. The proposed decomposition only assumes weak separability of the higher-dimensional covariance process and utilizes a product of one dimensional eigenvectors and eigenfunctions, obtained from the regional, functional, and longitudinal marginal covariances, to represent the observed data, providing a computationally feasible non-parametric approach. A mixed effects framework is proposed to estimate the model components coupled with a bootstrap test for group level inference, both geared towards sparse data applications. Analysis of the data from the word segmentation paradigm leads to valuable insights about group-region differences among the TD and verbal and minimally verbal children with ASD. Finite sample properties of the proposed estimation framework and bootstrap inference procedure are further studied via extensive simulations.},
	number = {1},
	urldate = {2023-04-14},
	journal = {Biostatistics},
	author = {Scheffler, Aaron and Telesca, Donatello and Li, Qian and Sugar, Catherine A and Distefano, Charlotte and Jeste, Shafali and Şentürk, Damla},
	month = jan,
	year = {2020},
	pages = {139--157},
}

@article{chen_modelling_2017,
	title = {Modelling function-valued stochastic processes, with applications to fertility dynamics},
	volume = {79},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/44681767},
	abstract = {We introduce a simple and interpretable model for functional data analysis for situations where the observations at each location are functional rather than scalar. This new approach is based on a tensor product representation of the function-valued process and utilizes eigenfunctions of marginal kernels. The resulting marginal principal components and product principal components are shown to have nice properties. Given a sample of independent realizations of the underlying function-valued stochastic process, we propose straightforward fitting methods to obtain the components of this model and to establish asymptotic consistency and rates of convergence for the estimates proposed. The methods are illustrated by modelling the dynamics of annual fertility profile functions for 17 countries. This analysis demonstrates that the approach proposed leads to insightful interpretations of the model components and interesting conclusions.},
	number = {1},
	urldate = {2023-04-14},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Chen, Kehui and Delicado, Pedro and Müller, Hans-Georg},
	year = {2017},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {177--196},
}

@article{hasenstab_multi-dimensional_2017,
	title = {A multi-dimensional functional principal components analysis of {EEG} data},
	volume = {73},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12635},
	doi = {10.1111/biom.12635},
	abstract = {The electroencephalography (EEG) data created in event-related potential (ERP) experiments have a complex high-dimensional structure. Each stimulus presentation, or trial, generates an ERP waveform which is an instance of functional data. The experiments are made up of sequences of multiple trials, resulting in longitudinal functional data and moreover, responses are recorded at multiple electrodes on the scalp, adding an electrode dimension. Traditional EEG analyses involve multiple simplifications of this structure to increase the signal-to-noise ratio, effectively collapsing the functional and longitudinal components by identifying key features of the ERPs and averaging them across trials. Motivated by an implicit learning paradigm used in autism research in which the functional, longitudinal, and electrode components all have critical interpretations, we propose a multidimensional functional principal components analysis (MD-FPCA) technique which does not collapse any of the dimensions of the ERP data. The proposed decomposition is based on separation of the total variation into subject and subunit level variation which are further decomposed in a two-stage functional principal components analysis. The proposed methodology is shown to be useful for modeling longitudinal trends in the ERP functions, leading to novel insights into the learning patterns of children with Autism Spectrum Disorder (ASD) and their typically developing peers as well as comparisons between the two groups. Finite sample properties of MD-FPCA are further studied via extensive simulations.},
	language = {en},
	number = {3},
	urldate = {2023-04-14},
	journal = {Biometrics},
	author = {Hasenstab, Kyle and Scheffler, Aaron and Telesca, Donatello and Sugar, Catherine A. and Jeste, Shafali and DiStefano, Charlotte and Şentürk, Damla},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12635},
	keywords = {Electroencephalography, Event-related potentials data, Functional data analysis, Multilevel functional principal components},
	pages = {999--1009},
}

@article{mercer_functions_1909,
	title = {Functions of positive and negative type, and their connection the theory of integral equations},
	volume = {209},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.1909.0016},
	doi = {10.1098/rsta.1909.0016},
	abstract = {The present memoir is the outcome of an attempt to obtain the conditions under which a given symmetric and continuous function k(s, t) is definite, in the sense of Hilbert. At an early stage, however, it was found that the class of definite functions was too restricted to allow the determination of necessary and sufficient conditions in terms of the determinants of § 10. The discovery that this could be done for functions of positive or negative type, and the fact that almost all the theorems which are true of definite functions are, with slight modification, true of these, led finally to the abandonment of the original plan in favour of a discussion of the properties of functions belonging to the wider classes. The first part of the memoir is devoted to the definition of various terms employed, and to the re-statement of the consequences which follow from Hilbert’s theorem.},
	number = {441-458},
	urldate = {2023-04-12},
	journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
	author = {Mercer, James},
	month = jan,
	year = {1909},
	note = {Publisher: Royal Society},
	pages = {415--446},
}

@misc{noauthor_xvi_nodate,
	title = {{XVI}. {Functions} of positive and negative type, and their connection the theory of integral equations},
	url = {https://royalsocietypublishing.org/doi/epdf/10.1098/rsta.1909.0016},
	language = {en},
	urldate = {2023-04-12},
	doi = {10.1098/rsta.1909.0016},
}

@article{fox_measurement_2023,
	title = {Measurement error associated with gait cycle selection in treadmill running at various speeds},
	volume = {11},
	issn = {2167-8359},
	url = {https://peerj.com/articles/14921},
	doi = {10.7717/peerj.14921},
	abstract = {A common approach in the biomechanical analysis of running technique is to average data from several gait cycles to compute a ‘representative mean.’ However, the impact of the quantity and selection of gait cycles on biomechanical measures is not well understood. We examined the effects of gait cycle selection on kinematic data by: (i) comparing representative means calculated from varying numbers of gait cycles to ‘global’ means from the entire capture period; and (ii) comparing representative means from varying numbers of gait cycles sampled from different parts of the capture period. We used a public dataset (n = 28) of lower limb kinematics captured during a 30-second period of treadmill running at three speeds (2.5 m s−1, 3.5 m s−1 and 4.5 m s−1). ‘Ground truth’ values were determined by averaging data across all collected strides and compared to representative means calculated from random samples (1,000 samples) of n (range = 5–30) consecutive gait cycles. We also compared representative means calculated from n (range = 5–15) consecutive gait cycles randomly sampled (1,000 samples) from within the same data capture period. The mean, variance and range of the absolute error of the representative mean compared to the ‘ground truth’ mean progressively reduced across all speeds as the number of gait cycles used increased. Similar magnitudes of ‘error’ were observed between the 2.5 m s−1 and 3.5 m s−1 speeds at comparable gait cycle numbers —where the maximum errors were {\textless} 1.5 degrees even with a small number of gait cycles (i.e., 5–10). At the 4.5 m s−1 speed, maximum errors typically exceeded 2–4 degrees when a lower number of gait cycles were used. Subsequently, a higher number of gait cycles (i.e., 25–30) was required to achieve low errors (i.e., 1–2 degrees) at the 4.5 m s−1 speed. The mean, variance and range of absolute error of representative means calculated from different parts of the capture period was consistent irrespective of the number of gait cycles used. The error between representative means was low (i.e., {\textless} 1.5 degrees) and consistent across the different number of gait cycles at the 2.5 m s−1 and 3.5 m s−1 speeds, and consistent but larger (i.e., up to 2–4 degrees) at the 4.5 m s−1 speed. Our findings suggest that selecting as many gait cycles as possible from a treadmill running bout will minimise potential ‘error.’ Analysing a small sample (i.e., 5–10 cycles) will typically result in minimal ‘error’ (i.e., {\textless} 2 degrees), particularly at lower speeds (i.e., 2.5 m s−1 and 3.5 m s−1). Researchers and clinicians should consider the balance between practicalities of collecting and analysing a smaller number of gait cycles against the potential ‘error’ when determining their methodological approach. Irrespective of the number of gait cycles used, we recommend that the potential ‘error’ introduced by the choice of gait cycle number be considered when interpreting the magnitude of effects in treadmill-based running studies.},
	language = {en},
	urldate = {2023-04-12},
	journal = {PeerJ},
	author = {Fox, Aaron S. and Bonacci, Jason and Warmenhoven, John and Keast, Meghan F.},
	month = mar,
	year = {2023},
	note = {Publisher: PeerJ Inc.},
	pages = {e14921},
}

@book{soetaert_solving_2012,
	title = {Solving {Differential} {Equations} in {R}},
	isbn = {978-3-642-28070-2},
	abstract = {Mathematics plays an important role in many scientific and engineering disciplines. This book deals with the numerical solution of differential equations, a very important branch of mathematics. Our aim is to give a practical and theoretical account of how to solve a large variety of differential equations, comprising ordinary differential equations, initial value problems and boundary value problems, differential algebraic equations, partial differential equations and delay differential equations. The solution of differential equations using R is the main focus of this book. It is therefore intended for the practitioner, the student and the scientist, who wants to know how to use R for solving differential equations. However, it has been our goal that non-mathematicians should at least understand the basics of the methods, while obtaining entrance into the relevant literature that provides more mathematical background. Therefore, each chapter that deals with R examples is preceded by a chapter where the theory behind the numerical methods being used is introduced. In the sections that deal with the use of R for solving differential equations, we have taken examples from a variety of disciplines, including biology, chemistry, physics, pharmacokinetics. Many examples are well-known test examples, used frequently in the field of numerical analysis.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Soetaert, Karline and Cash, Jeff and Mazzia, Francesca},
	month = jun,
	year = {2012},
	note = {Google-Books-ID: TkFZ7TBGdzIC},
	keywords = {Computers / Computer Simulation, Computers / Mathematical \& Statistical Software, Mathematics / Counting \& Numeration, Mathematics / Differential Equations / General, Mathematics / Numerical Analysis, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@article{wood_confidence_2006,
	title = {On {Confidence} {Intervals} for {Generalized} {Additive} {Models} {Based} on {Penalized} {Regression} {Splines}},
	volume = {48},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2006.00450.x},
	doi = {10.1111/j.1467-842X.2006.00450.x},
	abstract = {Generalized additive models represented using low rank penalized regression splines, estimated by penalized likelihood maximisation and with smoothness selected by generalized cross validation or similar criteria, provide a computationally efficient general framework for practical smooth modelling. Various authors have proposed approximate Bayesian interval estimates for such models, based on extensions of the work of Wahba, G. (1983)[Bayesian confidence intervals for the cross validated smoothing spline. J. R. Statist. Soc. B45, 133–150] and Silverman, B.W. (1985)[Some aspects of the spline smoothing approach to nonparametric regression curve fitting. J. R. Statist. Soc. B47, 1–52] on smoothing spline models of Gaussian data, but testing of such intervals has been rather limited and there is little supporting theory for the approximations used in the generalized case. This paper aims to improve this situation by providing simulation tests and obtaining asymptotic results supporting the approximations employed for the generalized case. The simulation results suggest that while across-the-model performance is good, component-wise coverage probabilities are not as reliable. Since this is likely to result from the neglect of smoothing parameter variability, a simple and efficient simulation method is proposed to account for smoothing parameter uncertainty: this is demonstrated to substantially improve the performance of component-wise intervals.},
	language = {en},
	number = {4},
	urldate = {2023-04-04},
	journal = {Australian \& New Zealand Journal of Statistics},
	author = {Wood, Simon N.},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-842X.2006.00450.x},
	keywords = {Bayesian confidence interval, generalized additive model (GAM), generalized cross validation (GCV), multiple smoothing parameters, penalized regression spline},
	pages = {445--464},
}

@article{nychka_bayesian_1988,
	title = {Bayesian {Confidence} {Intervals} for {Smoothing} {Splines}},
	volume = {83},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478711},
	doi = {10.1080/01621459.1988.10478711},
	abstract = {The frequency properties of Wahba's Bayesian confidence intervals for smoothing splines are investigated by a large-sample approximation and by a simulation study. When the coverage probabilities for these pointwise confidence intervals are averaged across the observation points, the average coverage probability (ACP) should be close to the nominal level. From a frequency point of view, this agreement occurs because the average posterior variance for the spline is similar to a consistent estimate of the average squared error and because the average squared bias is a modest fraction of the total average squared error. These properties are independent of the Bayesian assumptions used to derive this confidence procedure, and they explain why the ACP is accurate for functions that are much smoother than the sample paths prescribed by the prior. This analysis accounts for the choice of the smoothing parameter (bandwidth) using cross-validation. In the case of natural splines an adaptive method for avoiding boundary effects is considered. The main disadvantage of this approach is that these confidence intervals are only valid in an average sense and may not be reliable if only evaluated at peaks or troughs in the estimate.},
	number = {404},
	urldate = {2023-04-04},
	journal = {Journal of the American Statistical Association},
	author = {Nychka, Douglas},
	month = dec,
	year = {1988},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1988.10478711},
	keywords = {Boundary effects, Cross-validation, Nonparametric regression, Smoothing parameter},
	pages = {1134--1143},
}

@article{van_der_pol_frequency_1927,
	title = {Frequency {Demultiplication}},
	volume = {120},
	copyright = {1927 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/120363a0},
	doi = {10.1038/120363a0},
	abstract = {IT is a well-known fact that when a sinusoidal E.M.F. (of the form E0 sin wt) is available, it is a relatively simple matter to design an electrical system such that alternating currents or potential differences will occur in the system, having a frequency which is a whole multiple of the applied E.M.F., e.g. 2w, 3w, etc. For example, when the E.M.F. E0, sin wt is applied to a diode-rectifier, the current in the anode circuit will include a component of double frequency, i.e. 2w. This is therefore one method of frequency multiplication. Several other methods could easily be mentioned.},
	language = {en},
	number = {3019},
	urldate = {2023-04-03},
	journal = {Nature},
	author = {Van Der Pol, Balth and Van Der Mark, J.},
	month = sep,
	year = {1927},
	note = {Number: 3019
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {363--364},
}

@article{soetaert_solving_2010,
	title = {Solving {Differential} {Equations} in {R}},
	volume = {1281},
	issn = {0094-243X},
	url = {https://aip.scitation.org/doi/abs/10.1063/1.3498463},
	doi = {10.1063/1.3498463},
	number = {1},
	urldate = {2023-04-03},
	journal = {AIP Conference Proceedings},
	author = {Soetaert, Karline and Meysman, Filip and Petzoldt, Thomas},
	month = sep,
	year = {2010},
	note = {Publisher: American Institute of Physics},
	pages = {31--34},
}

@article{wood_confidence_2006-1,
	title = {On {Confidence} {Intervals} for {Generalized} {Additive} {Models} {Based} on {Penalized} {Regression} {Splines}},
	volume = {48},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2006.00450.x},
	doi = {10.1111/j.1467-842X.2006.00450.x},
	abstract = {Generalized additive models represented using low rank penalized regression splines, estimated by penalized likelihood maximisation and with smoothness selected by generalized cross validation or similar criteria, provide a computationally efficient general framework for practical smooth modelling. Various authors have proposed approximate Bayesian interval estimates for such models, based on extensions of the work of Wahba, G. (1983)[Bayesian confidence intervals for the cross validated smoothing spline. J. R. Statist. Soc. B45, 133–150] and Silverman, B.W. (1985)[Some aspects of the spline smoothing approach to nonparametric regression curve fitting. J. R. Statist. Soc. B47, 1–52] on smoothing spline models of Gaussian data, but testing of such intervals has been rather limited and there is little supporting theory for the approximations used in the generalized case. This paper aims to improve this situation by providing simulation tests and obtaining asymptotic results supporting the approximations employed for the generalized case. The simulation results suggest that while across-the-model performance is good, component-wise coverage probabilities are not as reliable. Since this is likely to result from the neglect of smoothing parameter variability, a simple and efficient simulation method is proposed to account for smoothing parameter uncertainty: this is demonstrated to substantially improve the performance of component-wise intervals.},
	language = {en},
	number = {4},
	urldate = {2023-03-31},
	journal = {Australian \& New Zealand Journal of Statistics},
	author = {Wood, Simon N.},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-842X.2006.00450.x},
	keywords = {Bayesian confidence interval, generalized additive model (GAM), generalized cross validation (GCV), multiple smoothing parameters, penalized regression spline},
	pages = {445--464},
}

@article{durban_simple_2005,
	title = {Simple fitting of subject-specific curves for longitudinal data},
	volume = {24},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.1991},
	doi = {10.1002/sim.1991},
	abstract = {We present a simple semiparametric model for fitting subject-specific curves for longitudinal data. Individual curves are modelled as penalized splines with random coefficients. This model has a mixed model representation, and it is easily implemented in standard statistical software. We conduct an analysis of the long-term effect of radiation therapy on the height of children suffering from acute lymphoblastic leukaemia using penalized splines in the framework of semiparametric mixed effects models. The analysis revealed significant differences between therapies and showed that the growth rate of girls in the study cannot be fully explained by the group-average curve and that individual curves are necessary to reflect the individual response to treatment. We also show how to implement these models in S-PLUS and R in the appendix. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {8},
	urldate = {2023-03-30},
	journal = {Statistics in Medicine},
	author = {Durbán, M. and Harezlak, J. and Wand, M. P. and Carroll, R. J.},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.1991},
	keywords = {acute lymphoblastic leukaemia, linear mixed models, penalized splines, restricted likelihood ratio tests},
	pages = {1153--1167},
}

@article{wand_smoothing_2003,
	title = {Smoothing and mixed models},
	volume = {18},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s001800300142},
	doi = {10.1007/s001800300142},
	abstract = {Smoothing methods that use. basis functions with penalisation can be formulated as maximum likelihood estimators and best predictors in a mixed model framework. Such connections are at least a quarter of a century old but, perhaps with the advent of mixed model software, have led to a paradigm shift in the field of smoothing. The reason is that most, perhaps all, models involving smoothing can be expressed as a mixed model and hence enjoy the benefit of the growing body of methodology and software for general mixed model analysis. The handling of other complications such as clustering, missing data and measurement error is generally quite straightforward with mixed model representations of smoothing.},
	language = {en},
	number = {2},
	urldate = {2023-03-29},
	journal = {Computational Statistics},
	author = {Wand, M. P.},
	month = jul,
	year = {2003},
	keywords = {Best prediction, Generalised linear mixed models, Kriging, Maximum likelihood, Nonparametric regression, Restricted maximum likelihood, Variance components},
	pages = {223--249},
}

@article{shi_analysis_1996,
	title = {An {Analysis} of {Paediatric} {CD4} {Counts} for {Acquired} {Immune} {Deficiency} {Syndrome} {Using} {Flexible} {Random} {Curves}},
	volume = {45},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2986151},
	doi = {10.2307/2986151},
	abstract = {In this paper we analyse CD4 counts from infants born to mothers who are infected with the human immunodeficiency virus. A random effects model with linear or low order polynomials in time is unsatisfactory for these longitudinal data. We develop an alternative approach based on a flexible family of models for which both the fixed and the random effects are linear combinations of B-splines. The fixed and random parts are smooth functions of time and the covariance structure is parsimonious. The procedure allows estimates of each individual's smooth trajectory over time to be exhibited. Model selection, estimation and computation are discussed. Centile curves are presented that take into account the longitudinal nature of the data. We emphasize a graphical approach to the presentation of results.},
	number = {2},
	urldate = {2023-03-29},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Shi, Minggao and Weiss, Robert E. and Taylor, Jeremy M. G.},
	year = {1996},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {151--163},
}

@article{james_principal_2000,
	title = {Principal {Component} {Models} for {Sparse} {Functional} {Data}},
	volume = {87},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2673632},
	abstract = {The elements of a multivariate dataset are often curves rather than single points. Functional principal components can be used to describe the modes of variation of such curves. If one has complete measurements for each individual curve or, as is more common, one has measurements on a fine grid taken at the same time points for all curves, then many standard techniques may be applied. However, curves are often measured at an irregular and sparse set of time points which can differ widely across individuals. We present a technique for handling this more difficult case using a reduced rank mixed effects framework.},
	number = {3},
	urldate = {2023-03-29},
	journal = {Biometrika},
	author = {James, Gareth M. and Hastie, Trevor J. and Sugar, Catherine A.},
	year = {2000},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {587--602},
}

@article{rice_nonparametric_2001,
	title = {Nonparametric {Mixed} {Effects} {Models} for {Unequally} {Sampled} {Noisy} {Curves}},
	volume = {57},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2676868},
	abstract = {We propose a method of analyzing collections of related curves in which the individual curves are modeled as spline functions with random coefficients. The method is applicable when the individual curves are sampled at variable and irregularly spaced points. This produces a low-rank, low-frequency approximation to the covariance structure, which can be estimated naturally by the EM algorithm. Smooth curves for individual trajectories are constructed as best linear unbiased predictor (BLUP) estimates, combining data from that individual and the entire collection. This framework leads naturally to methods for examining the effects of covariates on the shapes of the curves. We use model selection techniques-Akaike information criterion (AIC), Bayesian information criterion (BIC), and cross-validation-to select the number of breakpoints for the spline approximation. We believe that the methodology we propose provides a simple, flexible, and computationally efficient means of functional data analysis.},
	number = {1},
	urldate = {2023-03-29},
	journal = {Biometrics},
	author = {Rice, John A. and Wu, Colin O.},
	year = {2001},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {253--259},
}

@article{rice_nonparametric_2001-1,
	title = {Nonparametric {Mixed} {Effects} {Models} for {Unequally} {Sampled} {Noisy} {Curves}},
	volume = {57},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2676868},
	abstract = {We propose a method of analyzing collections of related curves in which the individual curves are modeled as spline functions with random coefficients. The method is applicable when the individual curves are sampled at variable and irregularly spaced points. This produces a low-rank, low-frequency approximation to the covariance structure, which can be estimated naturally by the EM algorithm. Smooth curves for individual trajectories are constructed as best linear unbiased predictor (BLUP) estimates, combining data from that individual and the entire collection. This framework leads naturally to methods for examining the effects of covariates on the shapes of the curves. We use model selection techniques-Akaike information criterion (AIC), Bayesian information criterion (BIC), and cross-validation-to select the number of breakpoints for the spline approximation. We believe that the methodology we propose provides a simple, flexible, and computationally efficient means of functional data analysis.},
	number = {1},
	urldate = {2023-03-29},
	journal = {Biometrics},
	author = {Rice, John A. and Wu, Colin O.},
	year = {2001},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {253--259},
}

@book{fan_local_2017,
	address = {New York},
	title = {Local {Polynomial} {Modelling} and {Its} {Applications}: {Monographs} on {Statistics} and {Applied} {Probability} 66},
	isbn = {978-0-203-74872-5},
	shorttitle = {Local {Polynomial} {Modelling} and {Its} {Applications}},
	abstract = {Data-analytic approaches to regression problems, arising from many scientific disciplines are described in this book. The aim of these nonparametric methods is to relax assumptions on the form of a regression function and to let data search for a suitable function that describes the data well. The use of these nonparametric functions with parametric techniques can yield very powerful data analysis tools. Local polynomial modeling and its applications provides an up-to-date picture on state-of-the-art nonparametric regression techniques. The emphasis of the book is on methodologies rather than on theory, with a particular focus on applications of nonparametric techniques to various statistical problems. High-dimensional data-analytic tools are presented, and the book includes a variety of examples. This will be a valuable reference for research and applied statisticians, and will serve as a textbook for graduate students and others interested in nonparametric regression.},
	publisher = {Routledge},
	author = {Fan, Jianqing},
	month = oct,
	year = {2017},
	doi = {10.1201/9780203748725},
}

@article{berry_cross-validation_2021,
	title = {Cross-{Validation}, {Information} {Theory}, or {Maximum} {Likelihood}? {A} {Comparison} of {Tuning} {Methods} for {Penalized} {Splines}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-905X},
	shorttitle = {Cross-{Validation}, {Information} {Theory}, or {Maximum} {Likelihood}?},
	url = {https://www.mdpi.com/2571-905X/4/3/42},
	doi = {10.3390/stats4030042},
	abstract = {Functional data analysis techniques, such as penalized splines, have become common tools used in a variety of applied research settings. Penalized spline estimators are frequently used in applied research to estimate unknown functions from noisy data. The success of these estimators depends on choosing a tuning parameter that provides the correct balance between fitting and smoothing the data. Several different smoothing parameter selection methods have been proposed for choosing a reasonable tuning parameter. The proposed methods generally fall into one of three categories: cross-validation methods, information theoretic methods, or maximum likelihood methods. Despite the well-known importance of selecting an ideal smoothing parameter, there is little agreement in the literature regarding which method(s) should be considered when analyzing real data. In this paper, we address this issue by exploring the practical performance of six popular tuning methods under a variety of simulated and real data situations. Our results reveal that maximum likelihood methods outperform the popular cross-validation methods in most situations—especially in the presence of correlated errors. Furthermore, our results reveal that the maximum likelihood methods perform well even when the errors are non-Gaussian and/or heteroscedastic. For real data applications, we recommend comparing results using cross-validation and maximum likelihood tuning methods, given that these methods tend to perform similarly (differently) when the model is correctly (incorrectly) specified.},
	language = {en},
	number = {3},
	urldate = {2023-03-26},
	journal = {Stats},
	author = {Berry, Lauren N. and Helwig, Nathaniel E.},
	month = sep,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {functional data analysis, nonparametric regression, regularization, smoothing},
	pages = {701--724},
}

@article{reiss_smoothing_2009,
	title = {Smoothing {Parameter} {Selection} for a {Class} of {Semiparametric} {Linear} {Models}},
	volume = {71},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/40247585},
	abstract = {Spline-based approaches to non-parametric and semiparametric regression, as well as to regression of scalar outcomes on functional predictors, entail choosing a parameter controlling the extent to which roughness of the fitted function is penalized. We demonstrate that the equations determining two popular methods for smoothing parameter selection, generalized cross-validation and restricted maximum likelihood, share a similar form that allows us to prove several results which are common to both, and to derive a condition under which they yield identical values. These ideas are illustrated by application of functional principal component regression, a method for regressing scalars on functions, to two chemometric data sets.},
	number = {2},
	urldate = {2023-03-26},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Reiss, Philip T. and Ogden, R. Todd},
	year = {2009},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {505--523},
}

@article{stone_cross-validatory_1974,
	title = {Cross-{Validatory} {Choice} and {Assessment} of {Statistical} {Predictions}},
	volume = {36},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2984809},
	abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
	number = {2},
	urldate = {2023-03-24},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Stone, M.},
	year = {1974},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {111--147},
}

@article{park_longitudinal_2015,
	title = {Longitudinal functional data analysis},
	volume = {4},
	issn = {2049-1573},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.89},
	doi = {10.1002/sta4.89},
	abstract = {We consider dependent functional data that are correlated because of a longitudinal-based design: each subject is observed at repeated times and at each time, a functional observation (curve) is recorded. We propose a novel parsimonious modelling framework for repeatedly observed functional observations that allows to extract low-dimensional features. The proposed methodology accounts for the longitudinal design, is designed to study the dynamic behaviour of the underlying process, allows prediction of full future trajectory and is computationally fast. Theoretical properties of this framework are studied, and numerical investigations confirm excellent behaviour in finite samples. The proposed method is motivated by and applied to a diffusion tensor imaging study of multiple sclerosis. Copyright © 2015 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2023-03-16},
	journal = {Stat},
	author = {Park, So Young and Staicu, Ana-Maria},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.89},
	keywords = {dependent functional data, diffusion tensor imaging, functional principal component analysis, longitudinal design, multiple sclerosis},
	pages = {212--226},
}

@article{li_fast_2020,
	title = {Fast covariance estimation for multivariate sparse functional data},
	volume = {9},
	issn = {2049-1573},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.245},
	doi = {10.1002/sta4.245},
	abstract = {Covariance estimation is essential yet underdeveloped for analysing multivariate functional data. We propose a fast covariance estimation method for multivariate sparse functional data using bivariate penalized splines. The tensor-product B-spline formulation of the proposed method enables a simple spectral decomposition of the associated covariance operator and explicit expressions of the resulting eigenfunctions as linear combinations of B-spline bases, thereby dramatically facilitating subsequent principal component analysis. We derive a fast algorithm for selecting the smoothing parameters in covariance smoothing using leave-one-subject-out cross-validation. The method is evaluated with extensive numerical studies and applied to an Alzheimer's disease study with multiple longitudinal outcomes.},
	language = {en},
	number = {1},
	urldate = {2023-03-15},
	journal = {Stat},
	author = {Li, Cai and Xiao, Luo and Luo, Sheng},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.245},
	keywords = {bivariate smoothing, covariance function, functional principal component analysis, longitudinal data, multivariate functional data, prediction},
	pages = {e245},
}

@article{chiou_functional_2003,
	title = {Functional {Quasi}-{Likelihood} {Regression} {Models} with {Smooth} {Random} {Effects}},
	volume = {65},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/3647512},
	abstract = {We propose a class of semiparametric functional regression models to describe the influence of vector-valued covariates on a sample of response curves. Each observed curve is viewed as the realization of a random process, composed of an overall mean function and random components. The finite dimensional covariates influence the random components of the eigenfunction expansion through single-index models that include unknown smooth link and variance functions. The parametric components of the single-index models are estimated via quasi-score estimating equations with link and variance functions being estimated nonparametrically. We obtain several basic asymptotic results. The functional regression models proposed are illustrated with the analysis of a data set consisting of egg laying curves for 1000 female Mediterranean fruit-flies (medflies).},
	number = {2},
	urldate = {2023-03-08},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Chiou, Jeng-Min and Müller, Hans-Georg and Wang, Jane-Ling},
	year = {2003},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {405--423},
}

@article{reiss_functional_2007,
	title = {Functional {Principal} {Component} {Regression} and {Functional} {Partial} {Least} {Squares}},
	volume = {102},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/27639940},
	abstract = {Regression of a scalar response on signal predictors, such as near-infrared (NIR) spectra of chemical samples, presents a major challenge when, as is typically the case, the dimension of the signals far exceeds their number. Most solutions to this problem reduce the dimension of the predictors either by regressing on components [e.g., principal component regression (PCR) and partial least squares (PLS)] or by smoothing methods, which restrict the coefficient function to the span of a spline basis. This article introduces functional versions of PCR and PLS, which combine both of the foregoing dimension-reduction approaches. Two versions of functional PCR are developed, both using B-splines and roughness penalties. The regularized-components version applies such a penalty to the construction of the principal components (i.e., it uses functional principal components), whereas the regularized-regression version incorporates a penalty in the regression. For the latter form of functional PCR, the penalty parameter may be selected by generalized cross-validation, restricted maximum likelihood (REML), or a minimum mean integrated squared error criterion. Proceeding similarly, we develop two versions of functional PLS. Asymptotic convergence properties of regularized-regression functional PCR are demonstrated. A simulation study and split-sample validation with several NIR spectroscopy data sets indicate that functional PCR and functional PLS, especially the regularized-regression versions with REML, offer advantages over existing methods in terms of both estimation of the coefficient function and prediction of future observations.},
	number = {479},
	urldate = {2023-03-08},
	journal = {Journal of the American Statistical Association},
	author = {Reiss, Philip T. and Ogden, R. Todd},
	year = {2007},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {984--996},
}

@article{cardot_functional_1999,
	title = {Functional linear model},
	volume = {45},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S016771529900036X},
	doi = {10.1016/S0167-7152(99)00036-X},
	abstract = {In this paper, we study a regression model in which explanatory variables are sampling points of a continuous-time process. We propose an estimator of regression by means of a Functional Principal Component Analysis analogous to the one introduced by Bosq [(1991) NATO, ASI Series, pp. 509–529] in the case of Hilbertian AR processes. Both convergence in probability and almost sure convergence of this estimator are stated.},
	language = {en},
	number = {1},
	urldate = {2023-03-08},
	journal = {Statistics \& Probability Letters},
	author = {Cardot, Hervé and Ferraty, Frédéric and Sarda, Pascal},
	month = oct,
	year = {1999},
	keywords = {Convergence, Functional data analysis, Functional linear model, Hilbert spaces},
	pages = {11--22},
}

@incollection{hall_principal_2010,
	title = {Principal component analysis for functional data: {Methodology}, theory, and discussion},
	isbn = {978-0-19-956844-4},
	shorttitle = {Principal component analysis for functional data},
	url = {https://doi.org/10.1093/oxfordhb/9780199568444.013.8},
	abstract = {This article discusses the methodology and theory of principal component analysis (PCA) for functional data. It first provides an overview of PCA in the context of finite-dimensional data and infinite-dimensional data, focusing on functional linear regression, before considering the applications of PCA for functional data analysis, principally in cases of dimension reduction. It then describes adaptive methods for prediction and weighted least squares in functional linear regression. It also examines the role of principal components in the assessment of density for functional data, showing how principal component functions are linked to the amount of probability mass contained in a small ball around a given, fixed function, and how this property can be used to define a simple, easily estimable density surrogate. The article concludes by explaining the use of PCA for estimating log-density.This article discusses the methodology and theory of principal component analysis (PCA) for functional data. It first provides an overview of PCA in the context of finite-dimensional data and infinite-dimensional data, focusing on functional linear regression, before considering the applications of PCA for functional data analysis, principally in cases of dimension reduction. It then describes adaptive methods for prediction and weighted least squares in functional linear regression. It also examines the role of principal components in the assessment of density for functional data, showing how principal component functions are linked to the amount of probability mass contained in a small ball around a given, fixed function, and how this property can be used to define a simple, easily estimable density surrogate. The article concludes by explaining the use of PCA for estimating log-density.},
	urldate = {2023-03-08},
	booktitle = {The {Oxford} {Handbook} of {Functional} {Data} {Analysis}},
	publisher = {Oxford University Press},
	author = {Hall, Peter},
	editor = {Ferraty, Frédéric and Romain, Yves},
	month = nov,
	year = {2010},
	doi = {10.1093/oxfordhb/9780199568444.013.8},
	pages = {0},
}

@article{castro_principal_1986,
	title = {Principal {Modes} of {Variation} for {Processes} with {Continuous} {Sample} {Curves}},
	volume = {28},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1268982},
	doi = {10.2307/1268982},
	abstract = {Analysis of a process with continuous sample curves can be carried out in a manner similar to principal components analysis of vector processes. By appropriate definition of a best linear model in the continuous case, we show that principal modes of variation consist of eigenfunctions of the process covariance function C(s, t). Procedures for estimation of these eigenfunctions from a finite sample of observed curves are given, and results are compared with principal components analysis of the same data.},
	number = {4},
	urldate = {2023-03-08},
	journal = {Technometrics},
	author = {Castro, P. E. and Lawton, W. H. and Sylvestre, E. A.},
	year = {1986},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
	pages = {329--337},
}

@book{scott_sage_2013,
	address = {London},
	title = {The {SAGE} {Handbook} of {Multilevel} {Modeling}},
	isbn = {978-0-85702-564-7 978-1-4462-4760-0},
	url = {http://methods.sagepub.com/book/the-sage-handbook-of-multilevel-modeling},
	urldate = {2022-02-22},
	publisher = {SAGE Publications Ltd},
	author = {Scott, Marc and Simonoff, Jeffrey and Marx, Brian},
	year = {2013},
	doi = {10.4135/9781446247600},
}

@article{mccaffrey_estimating_1992,
	title = {Estimating the {Lyapunov} {Exponent} of a {Chaotic} {System} {With} {Nonparametric} {Regression}},
	volume = {87},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2290206},
	doi = {10.2307/2290206},
	abstract = {We discuss procedures based on nonparametric regression for estimating the dominant Lyapunov Exponent λ$_{\textrm{1}}$ from time series data generated by a nonlinear autoregressive system with additive noise. For systems with bounded fluctuations, {\textless}latex{\textgreater}\${\textbackslash}lambda\_1 {\textgreater} 0\${\textless}/latex{\textgreater} is the defining feature of chaos. Thus our procedures can be used to examine time series data for evidence of chaotic dynamics. We show that a consistent estimator of the partial derivatives of the autoregression function can be used to obtain a consistent estimator of λ$_{\textrm{1}}$. The rate of convergence we establish is quite slow; a better rate of convergence is derived heuristically and supported by simulations. Simulation results from several implementations-one "local" (thin-plate splines) and three "global" (neural nets, radial basis functions, and projection pursuit)-are presented for two deterministic chaotic systems. Local splines and neural nets yield accurate estimates of the Lyapunov exponent; however, the spline method is sensitive to the choice of the embedding dimension. Limited results for a noisy system suggest that the thin-plate spline and neural net regression methods also provide reliable values of the Lyapunov exponent in this case.},
	number = {419},
	urldate = {2023-02-24},
	journal = {Journal of the American Statistical Association},
	author = {McCaffrey, Daniel F. and Ellner, Stephen and Gallant, A. Ronald and Nychka, Douglas W.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {682--695},
}

@article{van_de_pol_cross-lags_2021,
	title = {Cross-lags and the unbiased estimation of life-history and demographic parameters},
	volume = {90},
	issn = {1365-2656},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1365-2656.13572},
	doi = {10.1111/1365-2656.13572},
	abstract = {Biological processes exhibit complex temporal dependencies due to the sequential nature of allocation decisions in organisms' life cycles, feedback loops and two-way causality. Consequently, longitudinal data often contain cross-lags: the predictor variable depends on the response variable of the previous time step. Although statisticians have warned that regression models that ignore such covariate endogeneity in time series are likely to be inappropriate, this has received relatively little attention in biology. Furthermore, the resulting degree of estimation bias remains largely unexplored. We use a graphical model and numerical simulations to understand why and how regression models that ignore cross-lags can be biased, and how this bias depends on the length and number of time series. Ecological and evolutionary examples are provided to illustrate that cross-lags may be more common than is typically appreciated and that they occur in functionally different ways. We show that routinely used regression models that ignore cross-lags are asymptotically unbiased. However, this offers little relief, as for most realistically feasible lengths of time-series conventional methods are biased. Furthermore, collecting time series on multiple subjects—such as populations, groups or individuals—does not help to overcome this bias when the analysis focusses on within-subject patterns (often the pattern of interest). Simulations, a literature search and a real-world empirical example together suggest that approaches that ignore cross-lags are likely biased in the direction opposite to the sign of the cross-lag (e.g. towards detecting density dependence of vital rates and against detecting life-history trade-offs and benefits of group living). Next, we show that multivariate (e.g. structural equation) models can dynamically account for cross-lags, and simultaneously address additional bias induced by measurement error, but only if the analysis considers multiple time series. We provide guidance on how to identify a cross-lag and subsequently specify it in a multivariate model, which can be far from trivial. Our tutorials with data and R code of the worked examples provide step-by-step instructions on how to perform such analyses. Our study offers insights into situations in which cross-lags can bias analysis of ecological and evolutionary time series and suggests that adopting dynamical models can be important, as this directly affects our understanding of population regulation, the evolution of life histories and cooperation, and possibly many other topics. Determining how strong estimation bias due to ignoring covariate endogeneity has been in the ecological literature requires further study, also because it may interact with other sources of bias.},
	language = {en},
	number = {10},
	urldate = {2023-02-19},
	journal = {Journal of Animal Ecology},
	author = {van de Pol, Martijn and Brouwer, Lyanne},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1365-2656.13572},
	keywords = {Malurus elegans, covariate endogeneity, density dependence, group living, measurement error, structural equation model, time-series length, trade-off},
	pages = {2234--2253},
}

@article{nychka_finding_1992,
	title = {Finding {Chaos} in {Noisy} {Systems}},
	volume = {54},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2346135},
	abstract = {In the past 20 years there has been much interest in the physical and biological sciences in non-linear dynamical systems that appear to have random, unpredictable behaviour. One important parameter of a dynamical system is the dominant Lyapunov exponent (LE). When the behaviour of the system is compared for two similar initial conditions, this exponent is related to the rate at which the subsequent trajectories diverge. A bounded system with a positive LE is one operational definition of chaotic behaviour. Most methods for determing the LE have assumed thousands of observations generated from carefully controlled physical experiments. Less attention has been given to estimating the LE for biological and economic systems that are subjected to random perturbations and observed over a limited amount of time. Using nonparametric regression techniques (neural networks and thin plate splines) it is possible to estimate the LE consistently. The properties of these methods have been studied with simulated data and are applied to a biological time series: marten fur returns for the Hudson Bay Company (1820-1900). On the basis of a nonparametric analysis there is little evidence for low dimensional chaos in these data. Although these methods appear to work well for systems perturbed by small amounts of noise, finding chaos in a system with a significant stochastic component may be difficult.},
	number = {2},
	urldate = {2023-02-19},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Nychka, Douglas and Ellner, Stephen and Gallant, A. Ronald and McCaffrey, Daniel},
	year = {1992},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {399--426},
}

@article{sandubete_dchaos_2021,
	title = {{DChaos}: {An} {R} {Package} for {Chaotic} {Time} {Series} {Analysis}},
	volume = {13},
	issn = {2073-4859},
	shorttitle = {{DChaos}},
	url = {https://journal.r-project.org/archive/2021/RJ-2021-036/index.html},
	language = {en},
	number = {1},
	urldate = {2023-02-19},
	journal = {The R Journal},
	author = {Sandubete, Julio E. and Escot, Lorenzo},
	year = {2021},
	pages = {232--252},
}

@article{tucker_geometric_nodate,
	title = {A geometric approach for computing tolerance bounds for elastic functional data},
	volume = {47},
	issn = {0266-4763},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8357056/},
	doi = {10.1080/02664763.2019.1645818},
	abstract = {We develop a method for constructing tolerance bounds for functional data with random warping variability. In particular, we define a generative, probabilistic model for the amplitude and phase components of such observations, which parsimoniously characterizes variability in the baseline data. Based on the proposed model, we define two different types of tolerance bounds that are able to measure both types of variability, and as a result, identify when the data has gone beyond the bounds of amplitude and/or phase. The first functional tolerance bounds are computed via a bootstrap procedure on the geometric space of amplitude and phase functions. The second functional tolerance bounds utilize functional Principal Component Analysis to construct a tolerance factor. This work is motivated by two main applications: process control and disease monitoring. The problem of statistical analysis and modeling of functional data in process control is important in determining when a production has moved beyond a baseline. Similarly, in biomedical applications, doctors use long, approximately periodic signals (such as the electrocardiogram) to diagnose and monitor diseases. In this context, it is desirable to identify abnormalities in these signals. We additionally consider a simulated example to assess our approach and compare it to two existing methods.},
	number = {3},
	urldate = {2023-02-17},
	journal = {Journal of Applied Statistics},
	author = {Tucker, J. Derek and Lewis, John R. and King, Caleb and Kurtek, Sebastian},
	pmid = {34385740},
	pmcid = {PMC8357056},
	pages = {481--505},
}

@misc{genz_mvtnorm_2021,
	title = {mvtnorm: {Multivariate} {Normal} and t {Distributions}},
	copyright = {GPL-2},
	shorttitle = {mvtnorm},
	url = {https://CRAN.R-project.org/package=mvtnorm},
	abstract = {Computes multivariate normal and t probabilities, quantiles, random deviates and densities.},
	urldate = {2023-02-16},
	author = {Genz, Alan and Bretz, Frank and Miwa, Tetsuhisa and Mi, Xuefei and Leisch, Friedrich and Scheipl, Fabian and Bornkamp, Bjoern and Maechler, Martin and Hothorn, Torsten},
	month = oct,
	year = {2021},
	keywords = {Distributions, Finance},
}

@article{li_fixed-effects_2022,
	title = {Fixed-effects inference and tests of correlation for longitudinal functional data},
	volume = {41},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9421},
	doi = {10.1002/sim.9421},
	abstract = {We propose an inferential framework for fixed effects in longitudinal functional models and introduce tests for the correlation structures induced by the longitudinal sampling procedure. The framework provides a natural extension of standard longitudinal correlation models for scalar observations to functional observations. Using simulation studies, we compare fixed effects estimation under correctly and incorrectly specified correlation structures and also test the longitudinal correlation structure. Finally, we apply the proposed methods to a longitudinal functional dataset on physical activity. The computer code for the proposed method is available at https://github.com/rli20ST758/FILF.},
	language = {en},
	number = {17},
	urldate = {2023-02-16},
	journal = {Statistics in Medicine},
	author = {Li, Ruonan and Xiao, Luo and Smirnova, Ekaterina and Cui, Erjia and Leroux, Andrew and Crainiceanu, Ciprian M.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9421},
	keywords = {accelerometry data, covariance function, hypothesis test, mixed effects model},
	pages = {3349--3364},
}

@misc{noauthor_fixedeffects_nodate,
	title = {Fixed‐effects inference and tests of correlation for longitudinal functional data - {Li} - 2022 - {Statistics} in {Medicine} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.9421},
	urldate = {2023-02-16},
}

@article{castanedo_review_2013,
	title = {A {Review} of {Data} {Fusion} {Techniques}},
	volume = {2013},
	issn = {2356-6140},
	url = {https://www.hindawi.com/journals/tswj/2013/704504/},
	doi = {10.1155/2013/704504},
	abstract = {The integration of data and knowledge from several sources is known as data fusion. This paper summarizes the state of the data fusion field and describes the most relevant studies. We first enumerate and explain different classification schemes for data fusion. Then, the most common algorithms are reviewed. These methods and algorithms are presented using three different categories: (i) data association, (ii) state estimation, and (iii) decision fusion.},
	language = {en},
	urldate = {2023-02-13},
	journal = {The Scientific World Journal},
	author = {Castanedo, Federico},
	month = oct,
	year = {2013},
	note = {Publisher: Hindawi},
	pages = {e704504},
}

@article{hyndman_robust_2007,
	title = {Robust forecasting of mortality and fertility rates: {A} functional data approach},
	volume = {51},
	issn = {0167-9473},
	shorttitle = {Robust forecasting of mortality and fertility rates},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947306002453},
	doi = {10.1016/j.csda.2006.07.028},
	abstract = {A new method is proposed for forecasting age-specific mortality and fertility rates observed over time. This approach allows for smooth functions of age, is robust for outlying years due to wars and epidemics, and provides a modelling framework that is easily adapted to allow for constraints and other information. Ideas from functional data analysis, nonparametric smoothing and robust statistics are combined to form a methodology that is widely applicable to any functional time series data observed discretely and possibly with error. The model is a generalization of the Lee–Carter (LC) model commonly used in mortality and fertility forecasting. The methodology is applied to French mortality data and Australian fertility data, and the forecasts obtained are shown to be superior to those from the LC method and several of its variants.},
	language = {en},
	number = {10},
	urldate = {2022-12-05},
	journal = {Computational Statistics \& Data Analysis},
	author = {Hyndman, Rob J. and Ullah, Shahid},
	month = jun,
	year = {2007},
	keywords = {Fertility forecasting, Functional data, Mortality forecasting, Nonparametric smoothing, Principal components, Robustness},
	pages = {4942--4956},
}

@article{xiao_quantifying_2015,
	title = {Quantifying the lifetime circadian rhythm of physical activity: a covariate-dependent functional approach},
	volume = {16},
	issn = {1465-4644},
	shorttitle = {Quantifying the lifetime circadian rhythm of physical activity},
	url = {https://doi.org/10.1093/biostatistics/kxu045},
	doi = {10.1093/biostatistics/kxu045},
	abstract = {Objective measurement of physical activity using wearable devices such as accelerometers may provide tantalizing new insights into the association between activity and health outcomes. Accelerometers can record quasi-continuous activity information for many days and for hundreds of individuals. For example, in the Baltimore Longitudinal Study on Aging physical activity was recorded every minute for \$773\$ adults for an average of \$7\$ days per adult. An important scientific problem is to separate and quantify the systematic and random circadian patterns of physical activity as functions of time of day, age, and gender. To capture the systematic circadian pattern, we introduce a practical bivariate smoother and two crucial innovations: (i) estimating the smoothing parameter using leave-one-subject-out cross validation to account for within-subject correlation and (ii) introducing fast computational techniques that overcome problems both with the size of the data and with the cross-validation approach to smoothing. The age-dependent random patterns are analyzed by a new functional principal component analysis that incorporates both covariate dependence and multilevel structure. For the analysis, we propose a practical and very fast trivariate spline smoother to estimate covariate-dependent covariances and their spectra. Results reveal several interesting, previously unknown, circadian patterns associated with human aging and gender.},
	number = {2},
	urldate = {2023-02-09},
	journal = {Biostatistics},
	author = {Xiao, Luo and Huang, Lei and Schrack, Jennifer A. and Ferrucci, Luigi and Zipunnikov, Vadim and Crainiceanu, Ciprian M.},
	month = apr,
	year = {2015},
	pages = {352--367},
}

@article{goldsmith_new_2016,
	title = {New {Insights} into {Activity} {Patterns} in {Children}, {Found} {Using} {Functional} {Data} {Analyses}},
	volume = {48},
	issn = {0195-9131},
	url = {https://journals.lww.com/acsm-msse/Fulltext/2016/09000/New_Insights_into_Activity_Patterns_in_Children,.11.aspx},
	doi = {10.1249/MSS.0000000000000968},
	abstract = {Introduction/Purpose 
        Continuous monitoring of activity using accelerometers and other wearable devices provides objective, unbiased measurement of physical activity in minute-by-minute or finer resolutions. Accelerometers have already been widely deployed in studies of healthy aging, recovery of function after heart surgery, and other outcomes. Although common analyses of accelerometer data focus on single summary variables, such as the total or average activity count, there is growing interest in the determinants of diurnal profiles of activity.
        Methods 
        We use tools from functional data analysis (FDA), an area with an established statistical literature, to treat complete 24-h diurnal profiles as outcomes in a regression model. We illustrate the use of such models by analyzing data collected in New York City from 420 children participating in a Head Start program. Covariates of interest include season, sex, body mass index z-score, presence of an asthma diagnosis, and mother’s birthplace.
        Results 
        The FDA model finds several meaningful associations between several covariates and diurnal profiles of activity. In some cases, including shifted activity patterns for children of foreign-born mothers and time-specific effects of asthma on activity, these associations exist for covariates that are not associated with average activity count.
        Conclusion 
        FDA provides a useful statistical framework for settings in which the effect of covariates on the timing of activity is of interest. The use of similar models in other applications should be considered, and we make code public to facilitate this process.},
	language = {en-US},
	number = {9},
	urldate = {2023-02-09},
	journal = {Medicine \& Science in Sports \& Exercise},
	author = {Goldsmith, Jeff and Liu, Xinyue and Jacobson, Judith S. and Rundle, Andrew},
	month = sep,
	year = {2016},
	pages = {1723},
}

@article{chen_functional_2019,
	title = {Functional {Data} {Analysis} of {Dynamic} {PET} {Data}},
	volume = {114},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2018.1497495},
	doi = {10.1080/01621459.2018.1497495},
	abstract = {One application of positron emission tomography (PET), a nuclear imaging technique, in neuroscience involves in vivo estimation of the density of various proteins (often, neuroreceptors) in the brain. PET scanning begins with the injection of a radiolabeled tracer that binds preferentially to the target protein; tracer molecules are then continuously delivered to the brain via the bloodstream. By detecting the radioactive decay of the tracer over time, dynamic PET data are constructed to reflect the concentration of the target protein in the brain at each time. The fundamental problem in the analysis of dynamic PET data involves estimating the impulse response function (IRF), which is necessary for describing the binding behavior of the injected radiotracer. Virtually all existing methods have three common aspects: summarizing the entire IRF with a single scalar measure; modeling each subject separately; and the imposition of parametric restrictions on the IRF. In contrast, we propose a functional data analytic approach that regards each subject’s IRF as the basic analysis unit, models multiple subjects simultaneously, and estimates the IRF nonparametrically. We pose our model as a linear mixed effect model in which population level fixed effects and subject-specific random effects are expanded using a B-spline basis. Shrinkage and roughness penalties are incorporated in the model to enforce identifiability and smoothness of the estimated curves, respectively, while monotonicity and nonnegativity constraints impose biological information on estimates. We illustrate this approach by applying it to clinical PET data with subjects belonging to three diagnosic groups. We explore differences among groups by means of pointwise confidence intervals of the estimated mean curves based on bootstrap samples. Supplementary materials for this article are available online.},
	number = {526},
	urldate = {2023-02-09},
	journal = {Journal of the American Statistical Association},
	author = {Chen, Yakuan and Goldsmith, Jeff and Ogden, R. Todd},
	month = apr,
	year = {2019},
	pmid = {31447493},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2018.1497495},
	keywords = {Bootstrap, Constrained estimation, Function-on-scalar regression, Nonparametric, Splines},
	pages = {595--609},
}

@article{leng_classification_2006,
	title = {Classification using functional data analysis for temporal gene expression data},
	volume = {22},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/bti742},
	doi = {10.1093/bioinformatics/bti742},
	abstract = {Motivation: Temporal gene expression profiles provide an important characterization of gene function, as biological systems are predominantly developmental and dynamic. We propose a method of classifying collections of temporal gene expression curves in which individual expression profiles are modeled as independent realizations of a stochastic process. The method uses a recently developed functional logistic regression tool based on functional principal components, aimed at classifying gene expression curves into known gene groups. The number of eigenfunctions in the classifier can be chosen by leave-one-out cross-validation with the aim of minimizing the classification error.Results: We demonstrate that this methodology provides low-error-rate classification for both yeast cell-cycle gene expression profiles and Dictyostelium cell-type specific gene expression patterns. It also works well in simulations. We compare our functional principal components approach with a B-spline implementation of functional discriminant analysis for the yeast cell-cycle data and simulations. This indicates comparative advantages of our approach which uses fewer eigenfunctions/base functions. The proposed methodology is promising for the analysis of temporal gene expression data and beyond.Availability: MATLAB programs are available upon request.Contact:  ileng@wfubmc.eduSupplementary information: Supplementary materials are available on the journal's website.},
	number = {1},
	urldate = {2023-02-09},
	journal = {Bioinformatics},
	author = {Leng, Xiaoyan and Müller, Hans-Georg},
	month = jan,
	year = {2006},
	pages = {68--76},
}

@article{ramsay_when_1982,
	title = {When the data are functions},
	volume = {47},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02293704},
	doi = {10.1007/BF02293704},
	abstract = {A datum is often a continuous functionx(t) of a variable such as time observed over some interval. One or more such functions are observed for each subject or unit of observation. The extension of classical data analytic techniques designed forp-variate observations to such data is discussed. The essential step is the expression of the classical problem in the language of functional analysis, after which the extension to functions is a straightforward matter. A schematic device called the duality diagram is a very useful tool for describing an analysis and for suggesting new possibilities. Least squares approximation, descriptive statistics, principal components analysis, and canonical correlation analysis are discussed within this broader framework.},
	language = {en},
	number = {4},
	urldate = {2023-02-09},
	journal = {Psychometrika},
	author = {Ramsay, J. O.},
	month = dec,
	year = {1982},
	keywords = {continuous data, duality diagram, functional analysis},
	pages = {379--396},
}

@article{dacunha_stability_2005,
	title = {Stability for time varying linear dynamic systems on time scales},
	volume = {176},
	issn = {0377-0427},
	url = {https://www.sciencedirect.com/science/article/pii/S0377042704003449},
	doi = {10.1016/j.cam.2004.07.026},
	abstract = {We study conditions under which the solutions of a time varying linear dynamic system of the form xΔ(t)=A(t)x(t) are stable on certain time scales. We give sufficient conditions for various types of stability, including Lyapunov-type stability criteria and eigenvalue conditions on “slowly varying'' systems that ensure exponential stability. Finally, perturbations of the unforced system are investigated, and an instability criterion is also developed.},
	language = {en},
	number = {2},
	urldate = {2023-02-07},
	journal = {Journal of Computational and Applied Mathematics},
	author = {DaCunha, Jeffrey J.},
	month = apr,
	year = {2005},
	keywords = {Continuous, Discrete, Linear system, Lyapunov, Slowly varying, Stability, Time scale, Time varying},
	pages = {381--410},
}

@inproceedings{herrick_wavelet-based_2006,
	title = {Wavelet-based functional mixed model analysis: {Computational} considerations},
	abstract = {Objective: Optimize a C++ implementation of the wavelet-based functional mixed model methodology of Morris and Carroll (2006) and test its performance on a variety of functional data sets representative of biomedical applications. Methods: Wavelet-based Functional Mixed Models is a new Bayesian method extending mixed models to irregular functional data (Morris and Carroll, 2006). These data sets are typically very large and can quickly run into memory and time constraints unless these issues are carefully managed in the software. Results: We reduced runtime and memory use by 1.) identifying and optimizing hotspots, 2.) using wavelet compression and other approximations to do less computation with minimal impact on results, and 3.) dividing the code into multiple executables to be run in parallel using a grid computing resource. We present rules of thumb for estimating memory requirements and computation times in terms of model and data set parameters.
Conclusion: We present examples and benchmarks demonstrating that it is practical to analyze very large data sets with readily available computing resources. This code is freely available on our website.},
	booktitle = {Joint {Statistical} {Meetings} 2006 {Proceedings}, {ASA} {Section} on {Statistical} {Computing}.},
	author = {Herrick, Richard C. and Morris, Jeffrey S},
	year = {2006},
}

@misc{r_core_team_r_2022,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2022},
}

@misc{borchers_pracma_2022,
	title = {pracma: {Practical} {Numerical} {Math} {Functions}},
	copyright = {GPL (≥ 3)},
	shorttitle = {pracma},
	url = {https://CRAN.R-project.org/package=pracma},
	abstract = {Provides a large number of functions from numerical analysis and linear algebra, numerical optimization, differential equations, time series, plus some well-known special mathematical functions. Uses 'MATLAB' function names where appropriate to simplify porting.},
	urldate = {2023-02-04},
	author = {Borchers, Hans W.},
	month = sep,
	year = {2022},
	keywords = {DifferentialEquations, NumericalMathematics},
}

@article{ramsay_differential_2000,
	title = {Differential equation models for statistical functions},
	volume = {28},
	issn = {1708-945X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.2307/3315975},
	doi = {10.2307/3315975},
	abstract = {Differential equations have been used in statistics to define functions such as probability densities. But the idea of using differential equation formulations of stochastic models has a much wider scope. The author gives several examples, including simultaneous estimation of a regression model and residual density, monotone smoothing, specification of a link function, differential equation models of data, and smoothing over complicated multidimensional domains. This paper aims to stimulate interest in this approach to functional estimation problems, rather than provide carefully worked out methods.},
	language = {en},
	number = {2},
	urldate = {2023-02-02},
	journal = {Canadian Journal of Statistics},
	author = {Ramsay, James O.},
	year = {2000},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2307/3315975},
	keywords = {Density estimation, dynamic models, multivariate smoothing, nonpara-metric regression, smoothing},
	pages = {225--240},
}

@article{fontanella_predictive_2019,
	title = {Predictive functional {ANOVA} models for longitudinal analysis of mandibular shape changes},
	volume = {61},
	issn = {1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201800228},
	doi = {10.1002/bimj.201800228},
	abstract = {In this paper, we introduce a Bayesian statistical model for the analysis of functional data observed at several time points. Examples of such data include the Michigan growth study where we wish to characterize the shape changes of human mandible profiles. The form of the mandible is often used by clinicians as an aid in predicting the mandibular growth. However, whereas many studies have demonstrated the changes in size that may occur during the period of pubertal growth spurt, shape changes have been less well investigated. Considering a group of subjects presenting normal occlusion, in this paper we thus describe a Bayesian functional ANOVA model that provides information about where and when the shape changes of the mandible occur during different stages of development. The model is developed by defining the notion of predictive process models for Gaussian process (GP) distributions used as priors over the random functional effects. We show that the predictive approach is computationally appealing and that it is useful to analyze multivariate functional data with unequally spaced observations that differ among subjects and times. Graphical posterior summaries show that our model is able to provide a biological interpretation of the morphometric findings and that they comprehensively describe the shape changes of the human mandible profiles. Compared with classical cephalometric analysis, this paper represents a significant methodological advance for the study of mandibular shape changes in two dimensions.},
	language = {en},
	number = {4},
	urldate = {2023-01-27},
	journal = {Biometrical Journal},
	author = {Fontanella, Lara and Ippoliti, Luigi and Valentini, Pasquale},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201800228},
	keywords = {Bayesian inference, Gaussian processes, analysis of variance, cephalometrics, functional data, mandible, morphometrics},
	pages = {918--933},
}

@techreport{vicon_plug-gait_2022,
	type = {Reference {Guide}},
	title = {Plug-{In} {Gait} {Reference} {Guide}},
	url = {https://docs.vicon.com/display/Nexus214/PDF+downloads+for+Vicon+Nexus?preview=/155746642/155746855/Vicon%20Nexus%20Reference%20Guide.pdf},
	urldate = {2023-01-26},
	institution = {Vicon},
	author = {Vicon},
	month = mar,
	year = {2022},
}

@misc{noauthor_pdf_nodate,
	title = {{PDF} downloads for {Vicon} {Nexus} - {Nexus} 2.14 {Documentation} - {Vicon} {Documentation}},
	url = {https://docs.vicon.com/display/Nexus214/PDF+downloads+for+Vicon+Nexus},
	urldate = {2023-01-26},
}

@misc{noauthor_plug-gait_nodate,
	title = {Plug-in {Gait} {Reference} {Guide} - {Nexus} 2.14 {Documentation} - {Vicon} {Documentation}},
	url = {https://docs.vicon.com/display/Nexus214/Plug-in+Gait+Reference+Guide},
	urldate = {2023-01-26},
}

@article{fukuchi_public_2017,
	title = {A public dataset of running biomechanics and the effects of running speed on lower extremity kinematics and kinetics},
	volume = {5},
	issn = {2167-8359},
	url = {https://peerj.com/articles/3298},
	doi = {10.7717/peerj.3298},
	abstract = {Background The goals of this study were (1) to present the set of data evaluating running biomechanics (kinematics and kinetics), including data on running habits, demographics, and levels of muscle strength and flexibility made available at Figshare (DOI: 10.6084/m9.figshare.4543435); and (2) to examine the effect of running speed on selected gait-biomechanics variables related to both running injuries and running economy. Methods The lower-extremity kinematics and kinetics data of 28 regular runners were collected using a three-dimensional (3D) motion-capture system and an instrumented treadmill while the subjects ran at 2.5 m/s, 3.5 m/s, and 4.5 m/s wearing standard neutral shoes. Results A dataset comprising raw and processed kinematics and kinetics signals pertaining to this experiment is available in various file formats. In addition, a file of metadata, including demographics, running characteristics, foot-strike patterns, and muscle strength and flexibility measurements is provided. Overall, there was an effect of running speed on most of the gait-biomechanics variables selected for this study. However, the foot-strike patterns were not affected by running speed. Discussion Several applications of this dataset can be anticipated, including testing new methods of data reduction and variable selection; for educational purposes; and answering specific research questions. This last application was exemplified in the study’s second objective.},
	language = {en},
	urldate = {2023-01-24},
	journal = {PeerJ},
	author = {Fukuchi, Reginaldo K. and Fukuchi, Claudiane A. and Duarte, Marcos},
	month = may,
	year = {2017},
	note = {Publisher: PeerJ Inc.},
	pages = {e3298},
}

@article{zhu_multivariate_2017,
	title = {Multivariate functional response regression, with application to fluorescence spectroscopy in a cervical pre-cancer study},
	volume = {111},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947317300245},
	doi = {10.1016/j.csda.2017.02.004},
	abstract = {Many scientific studies measure different types of high-dimensional signals or images from the same subject, producing multivariate functional data. These functional measurements carry different types of information about the scientific process, and a joint analysis that integrates information across them may provide new insights into the underlying mechanism for the phenomenon under study. Motivated by fluorescence spectroscopy data in a cervical pre-cancer study, a multivariate functional response regression model is proposed, which treats multivariate functional observations as responses and a common set of covariates as predictors. This novel modeling framework simultaneously accounts for correlations between functional variables and potential multi-level structures in data that are induced by experimental design. The model is fitted by performing a two-stage linear transformation—a basis expansion to each functional variable followed by principal component analysis for the concatenated basis coefficients. This transformation effectively reduces the intra- and inter-function correlations and facilitates fast and convenient calculation. A fully Bayesian approach is adopted to sample the model parameters in the transformed space, and posterior inference is performed after inverse-transforming the regression coefficients back to the original data domain. The proposed approach produces functional tests that flag local regions on the functional effects, while controlling the overall experiment-wise error rate or false discovery rate. It also enables functional discriminant analysis through posterior predictive calculation. Analysis of the fluorescence spectroscopy data reveals local regions with differential expressions across the pre-cancer and normal samples. These regions may serve as biomarkers for prognosis and disease assessment.},
	language = {en},
	urldate = {2023-01-20},
	journal = {Computational Statistics \& Data Analysis},
	author = {Zhu, Hongxiao and Morris, Jeffrey S. and Wei, Fengrong and Cox, Dennis D.},
	month = jul,
	year = {2017},
	keywords = {Bayesian methods, Fluorescence spectroscopy, Functional data analysis, Mixed models, Multivariate functional regression, Principal component analysis, Wavelets},
	pages = {88--101},
}

@article{taylor_repeatability_2010,
	title = {Repeatability and reproducibility of {OSSCA}, a functional approach for assessing the kinematics of the lower limb},
	volume = {32},
	issn = {0966-6362},
	url = {https://www.sciencedirect.com/science/article/pii/S0966636210001293},
	doi = {10.1016/j.gaitpost.2010.05.005},
	abstract = {Marker-based gait analysis of the lower limb that uses assumptions of generic anatomical morphology can be susceptible to errors, particularly in subjects with high levels of soft tissue coverage. We hypothesize that a functional approach for assessing skeletal kinematics, based on the application of techniques to reduce soft tissue artefact and functionally identify joint centres and axes, can more reliably (repeatably and reproducibly) assess the skeletal kinematics than a standard generic regression approach. Six healthy adults each performed 100 repetitions of a standardized motion, measured on four different days and by five different observers. Using OSSCA, a combination of functional approaches to reduce soft tissue artefact and identify joint centres and axes, the lengths of the femora and tibiae were determined to assess the inter-day and inter-observer reliability, and compared against a standard generic regression approach. The results indicate that the OSSCA was repeatable and reproducible (ICC lowest bound 0.87), but also provided an improvement over the regression approach (ICC lowest bound 0.69). Furthermore, the analysis of variance revealed a statistically significant variance for the factor “observers” (p{\textless}0.01; low-reproducibility) when using the regression approach for determining the femoral lengths. Here, this non-invasive, rapid and robust approach has been demonstrated to allow the repeatable and reproducible identification of skeletal landmarks, which is insensitive to marker placement and measurement session. The reliability of the OSSCA thus allows its application in clinical studies for reducing the uncertainty of approach-induced systematic errors.},
	language = {en},
	number = {2},
	urldate = {2023-01-17},
	journal = {Gait \& Posture},
	author = {Taylor, W. R. and Kornaropoulos, E. I. and Duda, G. N. and Kratzenstein, S. and Ehrig, R. M. and Arampatzis, A. and Heller, M. O.},
	month = jun,
	year = {2010},
	keywords = {Functional gait analysis, OCST, OSSCA, SARA, SCoRE},
	pages = {231--236},
}

@article{taylor_influence_2005,
	title = {On the influence of soft tissue coverage in the determination of bone kinematics using skin markers},
	volume = {23},
	issn = {1554-527X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1016/j.orthres.2005.02.006},
	doi = {10.1016/j.orthres.2005.02.006},
	abstract = {Accurate measurement of underlying bone positions is important for the understanding of normal movement and function, as well as for addressing clinical musculoskeletal or post-injury problems. Non-invasive measurement techniques are limited by the analysis technique and movement of peripheral soft tissues that can introduce significant measurement errors in reproducing the kinematics of the underlying bones when using external skin markers. Reflective markers, skeletally mounted to the right hind limb of three Merino-mix sheep were measured simultaneously with markers attached to the skin of each segment, during repetitions of gait trials. The movement of the skin markers relative to the underlying bone positions was then assessed using the Point Cluster Technique (PCT), raw averaging and the Optimal Common Shape Technique (OCST), a new approach presented in this manuscript. Errors in the position of the proximal joint centre, predicted from the corresponding skin markers, were shown to be phasic and strongly associated with the amount soft tissue coverage, averaging 8.5 mm for the femur, 2.8 for the tibia and 2.0 for the metatarsus. Although the results show a better prediction of bone kinematics associated with the Optimal Common Shape Technique, these errors were large for all three assessment techniques and much greater than the differences between the various techniques. Whilst individual markers moved up to 4 mm from the optimal marker set configuration, average peak errors of up to 16, 5 and 3 mm (hip, knee and tibio-metatarsal joints respectively) were observed, suggesting that a large amount of kinematic noise is produced from the synchronous shifting of marker sets, potentially as a result of underlying muscle firing and the inertial effects of heel impact. Current techniques are therefore limited in their ability to determine the kinematics of underlying bones based on skin markers, particularly in segments with more pronounced soft tissue coverage. © 2005 Orthopaedic Research Society. Published by Elsevier Ltd. All rights reserved.},
	language = {en},
	number = {4},
	urldate = {2023-01-17},
	journal = {Journal of Orthopaedic Research},
	author = {Taylor, William R. and Ehrig, Rainald M. and Duda, Georg N. and Schell, Hanna and Seebeck, Petra and Heller, Markus O.},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1016/j.orthres.2005.02.006},
	keywords = {Bone positions, Musculoskeletal kinematics, Skin markers},
	pages = {726--734},
}

@article{ehrig_survey_2007,
	title = {A survey of formal methods for determining functional joint axes},
	volume = {40},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929006004155},
	doi = {10.1016/j.jbiomech.2006.10.026},
	abstract = {Axes of rotation e.g. at the knee, are often generated from clinical gait analysis data to be used in the assessment of kinematic abnormalities, the diagnosis of disease, or the ongoing monitoring of a patient's condition. They are additionally used in musculoskeletal models to aid in the description of joint and segment kinematics for patient specific analyses. Currently available methods to describe joint axes from segment marker positions share the problem that when one segment is transformed into the coordinate system of another, artefacts associated with motion of the markers relative to the bone can become magnified. In an attempt to address this problem, a symmetrical axis of rotation approach (SARA) is presented here to determine a unique axis of rotation that can consider the movement of two dynamic body segments simultaneously, and then compared its performance in a survey against a number of previously proposed techniques. Using a generated virtual joint, with superimposed marker error conditions to represent skin movement artefacts, fitting methods (geometric axis fit, cylinder axis fit, algebraic axis fit) and transformation techniques (axis transformation technique, mean helical axis, Schwartz approach) were classified and compared with the SARA. Nearly all approaches were able to estimate the axis of rotation to within an RMS error of 0.1cm at large ranges of motion (90°). Although the geometric axis fit produced the least RMS error of approximately 1.2cm at lower ranges of motion (5°) with a stationary axis, the SARA and Axis Transformation Technique outperformed all other approaches under the most demanding marker artefact conditions for all ranges of motion. The cylinder and algebraic axis fit approaches were unable to compute competitive AoR estimates. Whilst these initial results using the SARA are promising and are fast enough to be determined “on-line”, the technique must now be proven in a clinical environment.},
	language = {en},
	number = {10},
	urldate = {2023-01-17},
	journal = {Journal of Biomechanics},
	author = {Ehrig, Rainald M. and Taylor, William R. and Duda, Georg N. and Heller, Markus O.},
	month = jan,
	year = {2007},
	keywords = {Axis of rotation},
	pages = {2150--2157},
}

@article{ehrig_survey_2006,
	title = {A survey of formal methods for determining the centre of rotation of ball joints},
	volume = {39},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S002192900500446X},
	doi = {10.1016/j.jbiomech.2005.10.002},
	abstract = {The determination of an accurate centre of rotation (CoR) from segment marker positions is of interest across a wide range of applications, but particularly for clinical gait analysis and for estimating the hip joint centre during surgical intervention of the knee, for limb alignment purposes. For the first time in this survey of formal methods, we classify, analyse and compare different methods (geometric, algebraic, bias compensated algebraic, and Pratt sphere fit methods, as well as the centre transformation technique, the Holzreiter approach, the helical pivot technique, the Schwartz transformation techniques, the minimal amplitude point method and the Stoddart approach) for the determination of spherical joint centres from marker position data. In addition, we propose a new method, the symmetrical CoR estimation or SCoRE, in which the coordinates of the joint centre must only remain constant relative to each segment, thus not requiring the assumption that one segment should remain at rest. For each method, 1000 CoR estimations were analysed with the application of isotropic, independent and identically distributed Gaussian noise (standard deviation 0.1cm) to each of the marker positions, to all markers on the segment simultaneously and the two in combination. For the test conditions used here, most techniques were capable of determining the CoR to within 0.3cm, as long as the spherical range of motion (RoM) of the joint was 45° or more. Under the most stringent conditions tested, however, the SCoRE was capable of best determining the CoR, to within approximately 1.2mm with a RoM of 20°. The correct selection and application of these methodologies should help improve the accuracy of surgical navigation and clinical kinematic measurement.},
	language = {en},
	number = {15},
	urldate = {2023-01-17},
	journal = {Journal of Biomechanics},
	author = {Ehrig, Rainald M. and Taylor, William R. and Duda, Georg N. and Heller, Markus O.},
	month = jan,
	year = {2006},
	keywords = {Ball joints, Centre of rotation, Joint centre},
	pages = {2798--2809},
}

@article{varin_overview_2011,
	title = {An {Overview} of {Composite} {Likelihood} {Methods}},
	volume = {21},
	issn = {1017-0405},
	url = {https://www.jstor.org/stable/24309261},
	abstract = {A survey of recent developments in the theory and application of composite likelihood is provided, building on the review paper of Varin (2008). A range of application areas, including geostatistics, spatial extremes, and space-time models, as well as clustered and longitudinal data and time series are considered. The important area of applications to statistical genetics is omitted, in light of Larribe and Fearnhead (2011). Emphasis is given to the development of the theory, and the current state of knowledge on efficiency and robustness of composite likelihood inference.},
	number = {1},
	urldate = {2023-01-16},
	journal = {Statistica Sinica},
	author = {Varin, Cristiano and Reid, Nancy and Firth, David},
	year = {2011},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {5--42},
}

@book{grimshaw_bios_2007,
	title = {{BIOS} {Instant} {Notes} in {Sport} and {Exercise} {Biomechanics}},
	isbn = {978-0-203-48830-0},
	url = {https://www.taylorfrancis.com/books/mono/10.4324/9780203488300/bios-instant-notes-sport-exercise-biomechanics-paul-grimshaw-neil-fowler-adrian-lees-adrian-burden},
	abstract = {Instant Notes Sport and Exercise Biomechanics provides a comprehensive overview of the key concepts in exercise and sport biomechanics. The kinematics of motion are reviewed in detail,\&nbsp;outlining the\&nbsp;physics of motion. Mechanical characteristics of motion, the mechanisms of injury, and the analysis of the sport technique\&nbsp;provides\&nbsp;a\&nbsp;source of valuable information.},
	language = {en},
	urldate = {2023-01-14},
	publisher = {Routledge},
	author = {Grimshaw, Paul and Fowler, Neil and Lees, Adrian and Burden, Adrian},
	month = apr,
	year = {2007},
	doi = {10.4324/9780203488300},
}

@article{goldsmith_generalized_2015,
	title = {Generalized multilevel function-on-scalar regression and principal component analysis},
	volume = {71},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12278},
	doi = {10.1111/biom.12278},
	abstract = {This manuscript considers regression models for generalized, multilevel functional responses: functions are generalized in that they follow an exponential family distribution and multilevel in that they are clustered within groups or subjects. This data structure is increasingly common across scientific domains and is exemplified by our motivating example, in which binary curves indicating physical activity or inactivity are observed for nearly 600 subjects over 5 days. We use a generalized linear model to incorporate scalar covariates into the mean structure, and decompose subject-specific and subject-day-specific deviations using multilevel functional principal components analysis. Thus, functional fixed effects are estimated while accounting for within-function and within-subject correlations, and major directions of variability within and between subjects are identified. Fixed effect coefficient functions and principal component basis functions are estimated using penalized splines; model parameters are estimated in a Bayesian framework using Stan, a programming language that implements a Hamiltonian Monte Carlo sampler. Simulations designed to mimic the application have good estimation and inferential properties with reasonable computation times for moderate datasets, in both cross-sectional and multilevel scenarios; code is publicly available. In the application we identify effects of age and BMI on the time-specific change in probability of being active over a 24-hour period; in addition, the principal components analysis identifies the patterns of activity that distinguish subjects and days within subjects.},
	language = {en},
	number = {2},
	urldate = {2023-01-13},
	journal = {Biometrics},
	author = {Goldsmith, Jeff and Zipunnikov, Vadim and Schrack, Jennifer},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12278},
	keywords = {Accelerometry, Bayesian inference, Generalized functional data, Hamiltonian Monte Carlo, Penalized splines},
	pages = {344--353},
}

@article{zhao_functional_2004,
	title = {The {Functional} {Data} {Analysis} {View} of {Longitudinal} {Data}},
	volume = {14},
	issn = {1017-0405},
	url = {https://www.jstor.org/stable/24307416},
	abstract = {Longitudinal data can be viewed as a type of functional data. The functional viewpoint is not typical for most analysts of longitudinal data, but provides a route for powerful new insights. The potential of this approach is demonstrated through an analysis of periodicities in a microarray gene expression data set.},
	number = {3},
	urldate = {2023-01-13},
	journal = {Statistica Sinica},
	author = {Zhao, Xin and Marron, J. S. and Wells, Martin T.},
	year = {2004},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {789--808},
}

@article{muller_functional_2005,
	title = {Functional {Modelling} and {Classification} of {Longitudinal} {Data}*},
	volume = {32},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2005.00429.x},
	doi = {10.1111/j.1467-9469.2005.00429.x},
	abstract = {Abstract. We review and extend some statistical tools that have proved useful for analysing functional data. Functional data analysis primarily is designed for the analysis of random trajectories and infinite-dimensional data, and there exists a need for the development of adequate statistical estimation and inference techniques. While this field is in flux, some methods have proven useful. These include warping methods, functional principal component analysis, and conditioning under Gaussian assumptions for the case of sparse data. The latter is a recent development that may provide a bridge between functional and more classical longitudinal data analysis. Besides presenting a brief review of functional principal components and functional regression, we develop some concepts for estimating functional principal component scores in the sparse situation. An extension of the so-called generalized functional linear model to the case of sparse longitudinal predictors is proposed. This extension includes functional binary regression models for longitudinal data and is illustrated with data on primary biliary cirrhosis.},
	language = {en},
	number = {2},
	urldate = {2023-01-13},
	journal = {Scandinavian Journal of Statistics},
	author = {Müller, Hans-Georg},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9469.2005.00429.x},
	keywords = {binary regression, discriminant analysis, functional data analysis, generalized functional linear model, logistic model, longitudinal data, principal components, sparseness, stochastic process},
	pages = {223--240},
}

@article{rice_functional_2004,
	title = {Functional and {Longitudinal} {Data} {Analysis}: {Perspectives} on {Smoothing}},
	volume = {14},
	issn = {1017-0405},
	shorttitle = {Functional and {Longitudinal} {Data} {Analysis}},
	url = {https://www.jstor.org/stable/24307409},
	abstract = {The perspectives and methods of functional data analysis and longitudinal data analysis for smoothing are contrasted and compared. Topics include kernel methods and random effects models for smoothing, basis function methods, and examination of correlates of curve shapes. Some directions in which methodology might advance are identified.},
	number = {3},
	urldate = {2023-01-13},
	journal = {Statistica Sinica},
	author = {Rice, John A.},
	year = {2004},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {631--647},
}

@article{fieuws_random-effects_2007,
	title = {Random-effects models for multivariate repeated measures},
	volume = {16},
	issn = {0962-2802},
	url = {https://doi.org/10.1177/0962280206075305},
	doi = {10.1177/0962280206075305},
	abstract = {Mixed models are widely used for the analysis of one repeatedly measured outcome. If more than one outcome is present, a mixed model can be used for each one. These separate models can be tied together into a multivariate mixed model by specifying a joint distribution for their random effects. This strategy has been used for joining multivariate longitudinal profiles or other types of multivariate repeated data. However, computational problems are likely to occur when the number of outcomes increases. A pairwise modeling approach, in which all possible bivariate mixed models are fitted and where inference follows from pseudo-likelihood arguments, has been proposed to circumvent the dimensional limitations in multivariate mixed models. An analysis on 22-variate longitudinal measurements of hearing thresholds illustrates the performance of the pairwise approach in the context of multivariate linear mixed models. For generalized linear mixed models, a data set containing repeated measurements of seven aspects of psycho-cognitive functioning will be analyzed.},
	language = {en},
	number = {5},
	urldate = {2023-01-11},
	journal = {Statistical Methods in Medical Research},
	author = {Fieuws, S. and Verbeke, Geert and Molenberghs, G.},
	month = oct,
	year = {2007},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {387--397},
}

@article{danaher_joint_2014,
	title = {The joint graphical lasso for inverse covariance estimation across multiple classes},
	volume = {76},
	issn = {1369-7412},
	doi = {10.1111/rssb.12033},
	abstract = {We consider the problem of estimating multiple related Gaussian graphical models from a high-dimensional data set with observations belonging to distinct classes. We propose the joint graphical lasso, which borrows strength across the classes in order to estimate multiple graphical models that share certain characteristics, such as the locations or weights of nonzero edges. Our approach is based upon maximizing a penalized log likelihood. We employ generalized fused lasso or group lasso penalties, and implement a fast ADMM algorithm to solve the corresponding convex optimization problems. The performance of the proposed method is illustrated through simulated and real data examples.},
	language = {eng},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series B, Statistical Methodology},
	author = {Danaher, Patrick and Wang, Pei and Witten, Daniela M.},
	month = mar,
	year = {2014},
	pmid = {24817823},
	pmcid = {PMC4012833},
	keywords = {Gaussian graphical model, alternating directions method of multipliers, generalized fused lasso, graphical lasso, group lasso, high-dimensional, network estimation},
	pages = {373--397},
}

@misc{schmutz_funhddc_2021,
	title = {{funHDDC}: {Univariate} and {Multivariate} {Model}-{Based} {Clustering} in {Group}-{Specific} {Functional} {Subspaces}},
	copyright = {GPL-2},
	shorttitle = {{funHDDC}},
	url = {https://CRAN.R-project.org/package=funHDDC},
	abstract = {The funHDDC algorithm allows to cluster functional univariate (Bouveyron and Jacques, 2011, {\textless}doi:10.1007/s11634-011-0095-6{\textgreater}) or multivariate data (Schmutz et al., 2018) by modeling each group within a specific functional subspace.},
	urldate = {2023-01-02},
	author = {Schmutz, A. and Bouveyron, J. Jacques \& C.},
	month = mar,
	year = {2021},
	keywords = {Cluster, FunctionalData},
}

@misc{noauthor_modelling_nodate,
	title = {Modelling kinematic data from recreational runners using multivariate functional mixed effects models},
	url = {https://www.overleaf.com/project/62e25dc82f019c08e13ce2f2},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2023-01-02},
}

@article{schielzeth_robustness_2020,
	title = {Robustness of linear mixed-effects models to violations of distributional assumptions},
	volume = {11},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13434},
	doi = {10.1111/2041-210X.13434},
	abstract = {Linear mixed-effects models are powerful tools for analysing complex datasets with repeated or clustered observations, a common data structure in ecology and evolution. Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation. Here we address the consequences of violations in distributional assumptions and the impact of missing random effect components on model estimates. In particular, we evaluate the effects of skewed, bimodal and heteroscedastic random effect and residual variances, of missing random effect terms and of correlated fixed effect predictors. We focus on bias and prediction error on estimates of fixed and random effects. Model estimates were usually robust to violations of assumptions, with the exception of slight upward biases in estimates of random effect variance if the generating distribution was bimodal but was modelled by Gaussian error distributions. Further, estimates for (random effect) components that violated distributional assumptions became less precise but remained unbiased. However, this particular problem did not affect other parameters of the model. The same pattern was found for strongly correlated fixed effects, which led to imprecise, but unbiased estimates, with uncertainty estimates reflecting imprecision. Unmodelled sources of random effect variance had predictable effects on variance component estimates. The pattern is best viewed as a cascade of hierarchical grouping factors. Variances trickle down the hierarchy such that missing higher-level random effect variances pool at lower levels and missing lower-level and crossed random effect variances manifest as residual variance. Overall, our results show remarkable robustness of mixed-effects models that should allow researchers to use mixed-effects models even if the distributional assumptions are objectively violated. However, this does not free researchers from careful evaluation of the model. Estimates that are based on data that show clear violations of key assumptions should be treated with caution because individual datasets might give highly imprecise estimates, even if they will be unbiased on average across datasets.},
	language = {en},
	number = {9},
	urldate = {2022-12-22},
	journal = {Methods in Ecology and Evolution},
	author = {Schielzeth, Holger and Dingemanse, Niels J. and Nakagawa, Shinichi and Westneat, David F. and Allegue, Hassen and Teplitsky, Céline and Réale, Denis and Dochtermann, Ned A. and Garamszegi, László Zsolt and Araya-Ajoy, Yimen G.},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13434},
	keywords = {biostatistics, correlated predictors, distributional assumptions, linear mixed-effects models, missing random effects, statistical quantification of individual differences (SQuID)},
	pages = {1141--1152},
}

@article{xun_sparse_2022,
	title = {Sparse estimation of historical functional linear models with a nested group bridge approach},
	volume = {50},
	issn = {1708-945X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11747},
	doi = {10.1002/cjs.11747},
	abstract = {The conventional historical functional linear model relates the current value of the functional response at time t to all past values of the functional covariate up to time t. Motivated by situations where it is more reasonable to assume that only recent, instead of all, past values of the functional covariate have an impact on the functional response, in this work we investigate the historical functional linear model with an unknown forward time lag into the history. In addition to estimating the bivariate regression coefficient function, we also aim to identify the historical time lag from the data, which is important in many applications. To this end, we propose an estimation procedure that uses the finite element method to conform naturally to the trapezoidal domain of the bivariate coefficient function. We use a nested group bridge penalty to facilitate simultaneous estimation of the bivariate coefficient function and the historical lag, and show that our proposed estimators are consistent. We demonstrate this method of estimation in a real data example investigating the effect of muscle activation recorded via the noninvasive electromyography (EMG) method on lip acceleration during speech production. In addition, we examine the finite sample performance of our proposed method in comparison with the conventional approach to estimation via simulation studies.},
	language = {en},
	number = {4},
	urldate = {2022-12-21},
	journal = {Canadian Journal of Statistics},
	author = {Xun, Xiaolei and Guan, Tianyu and Cao, Jiguo},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11747},
	keywords = {Finite element, function-on-function regression, functional data analysis, historical linear model, nested group bridge penalty},
	pages = {1254--1269},
}

@article{shi_inference_2021,
	title = {Inference in functional mixed regression models with applications to {Positron} {Emission} {Tomography} imaging data},
	volume = {40},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9087},
	doi = {10.1002/sim.9087},
	abstract = {In a function-on-scalar regression framework, we present some modeling strategies for functional mixed models and also some approaches for making inference about various aspects of the fixed effects. This is presented in the context of modeling positron emission tomography (PET) data in order to explore the density of various proteins of interest throughout the human brain. For this application, information about the density of the target protein in a given brain region is encapsulated in the impulse response function (IRF) of the region. Previous work on nonparametric estimation of the IRF is limited in that it is only able to model a single brain region at a time. We propose an extension, based on principles of functional data analysis, that will allow modeling of multiple brain regions simultaneously. Applicable more broadly to functional mixed regression modeling, we discuss two general approaches for permutation testing and describe valid strategies for identifying exchangeable units within the model and building corresponding permutation tests. We illustrate our methods with an application to PET data and explore the effects of depression and sex on the IRF.},
	language = {en},
	number = {21},
	urldate = {2022-12-21},
	journal = {Statistics in Medicine},
	author = {Shi, Baoyi and Ogden, R. Todd},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9087},
	keywords = {PET brain imaging, function-on-scalar regression, functional mixed models, permutation testing},
	pages = {4640--4659},
}

@article{hespanhol_junior_health_2017,
	title = {Health and {Economic} {Burden} of {Running}-{Related} {Injuries} in {Dutch} {Trailrunners}: {A} {Prospective} {Cohort} {Study}},
	volume = {47},
	issn = {1179-2035},
	shorttitle = {Health and {Economic} {Burden} of {Running}-{Related} {Injuries} in {Dutch} {Trailrunners}},
	doi = {10.1007/s40279-016-0551-8},
	abstract = {BACKGROUND: Trailrunning is becoming very popular. However, the risk and burden of running-related injuries (RRI) in trailrunning is not well established.
OBJECTIVE: To investigate the prevalence, injury rate, severity, nature, and economic burden of RRIs in Dutch trailrunners.
METHODS: This prospective cohort study included 228 trailrunners aged 18 years or over (range 23-67), and was conducted between October 2013 and December 2014. After completing the baseline questionnaire, the Oslo Sports Trauma Research Center Questionnaire on Health Problems was administered every 2 weeks to collect data on RRIs. Participants who reported RRIs were asked about healthcare utilization (direct costs) and absenteeism from paid work (indirect costs). RRI was defined as disorders of the musculoskeletal system or concussions experienced or sustained during participation in running.
RESULTS: The mean prevalence of RRIs measured over time was 22.4 \% [95 \% confidence interval (CI) 20.9-24.0], and the injury rate was 10.7 RRIs per 1000 h of running (95 \% CI 9.4-12.1). The prevalence was higher for overuse (17.7 \%; 95 \% CI 15.9-19.5) than for acute (4.1 \%; 95 \% CI 3.3-5.0) RRIs. Also, the injury rate was higher for overuse (8.1; 95 \% CI 6.9-9.3) than for acute (2.7; 95 \% CI 2.0-3.4) RRIs. The median of the severity score was 35.0 [25-75 \%, interquartile range (IQR) 22.0-55.7], and the median of the duration of RRIs was 2.0 weeks (IQR 2.0-6.0) during the study. The total economic burden of RRIs was estimated at €172.22 (95 \% CI 117.10-271.74) per RRI, and €1849.49 (95 \% CI 1180.62-3058.91) per 1000 h of running. An RRI was estimated to have a direct cost of €60.92 (95 \% CI 45.11-94.90) and an indirect cost of €111.30 (95 \% CI 61.02-192.75).
CONCLUSIONS: The health and economic burden of RRIs presented in this study are significant for trailrunners and for society. Therefore, efforts should be made in order to prevent RRIs in trailrunners.},
	language = {eng},
	number = {2},
	journal = {Sports Medicine (Auckland, N.Z.)},
	author = {Hespanhol Junior, Luiz Carlos and van Mechelen, Willem and Verhagen, Evert},
	month = feb,
	year = {2017},
	pmid = {27222128},
	pmcid = {PMC5266769},
	keywords = {Absenteeism, Adolescent, Adult, Aged, Athletic Injuries, Cost of Illness, Humans, Middle Aged, Prevalence, Prospective Studies, Running, Surveys and Questionnaires, Trauma Severity Indices, Young Adult},
	pages = {367--377},
}

@article{ceyssens_biomechanical_2019,
	title = {Biomechanical {Risk} {Factors} {Associated} with {Running}-{Related} {Injuries}: {A} {Systematic} {Review}},
	volume = {49},
	issn = {1179-2035},
	shorttitle = {Biomechanical {Risk} {Factors} {Associated} with {Running}-{Related} {Injuries}},
	url = {https://doi.org/10.1007/s40279-019-01110-z},
	doi = {10.1007/s40279-019-01110-z},
	abstract = {Running is a popular form of physical activity with many health benefits. However, the incidence and prevalence of running-related injuries (RRIs) is high. Biomechanical factors may be related to the development of RRIs.},
	language = {en},
	number = {7},
	urldate = {2022-11-18},
	journal = {Sports Medicine},
	author = {Ceyssens, Linde and Vanelderen, Romy and Barton, Christian and Malliaras, Peter and Dingenen, Bart},
	month = jul,
	year = {2019},
	pages = {1095--1115},
}

@article{willwacher_running-related_2022,
	title = {Running-{Related} {Biomechanical} {Risk} {Factors} for {Overuse} {Injuries} in {Distance} {Runners}: {A} {Systematic} {Review} {Considering} {Injury} {Specificity} and the {Potentials} for {Future} {Research}},
	volume = {52},
	issn = {1179-2035},
	shorttitle = {Running-{Related} {Biomechanical} {Risk} {Factors} for {Overuse} {Injuries} in {Distance} {Runners}},
	url = {https://doi.org/10.1007/s40279-022-01666-3},
	doi = {10.1007/s40279-022-01666-3},
	abstract = {Running overuse injuries (ROIs) occur within a complex, partly injury-specific interplay between training loads and extrinsic and intrinsic risk factors. Biomechanical risk factors (BRFs) are related to the individual running style. While BRFs have been reviewed regarding general ROI risk, no systematic review has addressed BRFs for specific ROIs using a standardized methodology.},
	language = {en},
	number = {8},
	urldate = {2022-11-18},
	journal = {Sports Medicine},
	author = {Willwacher, Steffen and Kurz, Markus and Robbin, Johanna and Thelen, Matthias and Hamill, Joseph and Kelly, Luke and Mai, Patrick},
	month = aug,
	year = {2022},
	pages = {1863--1877},
}

@article{berrendero_principal_2011,
	title = {Principal components for multivariate functional data},
	volume = {55},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947311001022},
	doi = {10.1016/j.csda.2011.03.011},
	abstract = {A principal component method for multivariate functional data is proposed. Data can be arranged in a matrix whose elements are functions so that for each individual a vector of p functions is observed. This set of p curves is reduced to a small number of transformed functions, retaining as much information as possible. The criterion to measure the information loss is the integrated variance. Under mild regular conditions, it is proved that if the original functions are smooth this property is inherited by the principal components. A numerical procedure to obtain the smooth principal components is proposed and the goodness of the dimension reduction is assessed by two new measures of the proportion of explained variability. The method performs as expected in various controlled simulated data sets and provides interesting conclusions when it is applied to real data sets.},
	language = {en},
	number = {9},
	urldate = {2022-11-15},
	journal = {Computational Statistics \& Data Analysis},
	author = {Berrendero, J. R. and Justel, A. and Svarc, M.},
	month = sep,
	year = {2011},
	keywords = {Dimension reduction, Eigenvalue functions, Explained variability},
	pages = {2619--2634},
}

@misc{noauthor_principal_nodate,
	title = {Principal components for multivariate functional data {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0167947311001022?token=0428E1082D1F95E625DF92CF96171C46F5C20E651E7AA785B868D4724B4250663BF8373338E168C2C21B3265CB33C842&originRegion=eu-west-1&originCreation=20221115212550},
	language = {en},
	urldate = {2022-11-15},
	doi = {10.1016/j.csda.2011.03.011},
}

@misc{sergazinov_case_2022,
	title = {A case study of glucose levels during sleep using fast function on scalar regression inference},
	url = {http://arxiv.org/abs/2205.08439},
	doi = {10.48550/arXiv.2205.08439},
	abstract = {Continuous glucose monitors (CGMs) are increasingly used to measure blood glucose levels and provide information about the treatment and management of diabetes. Our motivating study contains CGM data during sleep for 174 study participants with type II diabetes mellitus measured at a 5-minute frequency for an average of 10 nights. We aim to quantify the effects of diabetes medications and sleep apnea severity on glucose levels. Statistically, this is an inference question about the association between scalar covariates and functional responses. However, many characteristics of the data make analyses difficult, including (1) non-stationary within-day patterns; (2) substantial between-day heterogeneity, non-Gaussianity, and outliers; 3) large dimensionality due to the number of study participants, sleep periods, and time points. We evaluate and compare two methods: fast univariate inference (FUI) and functional additive mixed models (FAMM). We introduce a new approach for calculating p-values for testing a global null effect of covariates using FUI, and provide practical guidelines for speeding up FAMM computations, making it feasible for our data. While FUI and FAMM are philosophically different, they lead to similar point estimators in our study. In contrast to FAMM, FUI is fast, accounts for within-day correlations, and enables the construction of joint confidence intervals. Our analyses reveal that: (1) biguanide medication and sleep apnea severity significantly affect glucose trajectories during sleep, and (2) the estimated effects are time-invariant.},
	urldate = {2022-11-07},
	publisher = {arXiv},
	author = {Sergazinov, Renat and Leroux, Andrew and Cui, Erjia and Crainiceanu, Ciprian and Aurora, R. Nisha and Punjabi, Naresh M. and Gaynanova, Irina},
	month = may,
	year = {2022},
	note = {arXiv:2205.08439 [stat]},
	keywords = {Statistics - Applications, Statistics - Computation},
}

@book{fieller_basics_2016,
	address = {New York},
	title = {Basics of {Matrix} {Algebra} for {Statistics} with {R}},
	isbn = {978-1-315-37020-0},
	abstract = {A Thorough Guide to Elementary Matrix Algebra and Implementation in R
Basics of Matrix Algebra for Statistics with R provides a guide to elementary matrix algebra sufficient for undertaking specialized courses, such as multivariate data analysis and linear models. It also covers advanced topics, such as generalized inverses of singular and rectangular matrices and manipulation of partitioned matrices, for those who want to delve deeper into the subject.

The book introduces the definition of a matrix and the basic rules of addition, subtraction, multiplication, and inversion. Later topics include determinants, calculation of eigenvectors and eigenvalues, and differentiation of linear and quadratic forms with respect to vectors. The text explores how these concepts arise in statistical techniques, including principal component analysis, canonical correlation analysis, and linear modeling.

In addition to the algebraic manipulation of matrices, the book presents numerical examples that illustrate how to perform calculations by hand and using R. Many theoretical and numerical exercises of varying levels of difficulty aid readers in assessing their knowledge of the material. Outline solutions at the back of the book enable readers to verify the techniques required and obtain numerical answers.

Avoiding vector spaces and other advanced mathematics, this book shows how to manipulate matrices and perform numerical calculations in R. It prepares readers for higher-level and specialized studies in statistics.},
	publisher = {Chapman and Hall/CRC},
	author = {Fieller, Nick},
	month = dec,
	year = {2016},
	doi = {10.1201/9781315370200},
}

@misc{zhou_functional_2022,
	title = {Functional {Bayesian} {Networks} for {Discovering} {Causality} from {Multivariate} {Functional} {Data}},
	url = {http://arxiv.org/abs/2210.12832},
	doi = {10.48550/arXiv.2210.12832},
	abstract = {Multivariate functional data arise in a wide range of applications. One fundamental task is to understand the causal relationships among these functional objects of interest, which has not yet been fully explored. In this article, we develop a novel Bayesian network model for multivariate functional data where the conditional independence and causal structure are both encoded by a directed acyclic graph. Specifically, we allow the functional objects to deviate from Gaussian process, which is adopted by most existing functional data analysis models. The more reasonable non-Gaussian assumption is the key for unique causal structure identification even when the functions are measured with noises. A fully Bayesian framework is designed to infer the functional Bayesian network model with natural uncertainty quantification through posterior summaries. Simulation studies and real data examples are used to demonstrate the practical utility of the proposed model.},
	urldate = {2022-10-26},
	publisher = {arXiv},
	author = {Zhou, Fangting and He, Kejun and Wang, Kunbo and Xu, Yanxun and Ni, Yang},
	month = oct,
	year = {2022},
	note = {arXiv:2210.12832 [stat]},
	keywords = {Statistics - Methodology},
}

@article{park_simple_2018,
	title = {Simple fixed-effects inference for complex functional models},
	volume = {19},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxx026},
	doi = {10.1093/biostatistics/kxx026},
	abstract = {We propose simple inferential approaches for the fixed effects in complex functional mixed effects models. We estimate the fixed effects under the independence of functional residuals assumption and then bootstrap independent units (e.g. subjects) to conduct inference on the fixed effects parameters. Simulations show excellent coverage probability of the confidence intervals and size of tests for the fixed effects model parameters. Methods are motivated by and applied to the Baltimore Longitudinal Study of Aging, though they are applicable to other studies that collect correlated functional data.},
	number = {2},
	urldate = {2022-10-22},
	journal = {Biostatistics},
	author = {Park, So Young and Staicu, Ana-Maria and Xiao, Luo and Crainiceanu, Ciprian M},
	month = apr,
	year = {2018},
	pages = {137--152},
}

@article{jolliffe_principal_2016,
	title = {Principal component analysis: a review and recent developments},
	volume = {374},
	shorttitle = {Principal component analysis},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202},
	doi = {10.1098/rsta.2015.0202},
	abstract = {Large datasets are increasingly common and are often difficult to interpret. Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance. Finding such new variables, the principal components, reduces to solving an eigenvalue/eigenvector problem, and the new variables are defined by the dataset at hand, not a priori, hence making PCA an adaptive data analysis technique. It is adaptive in another sense too, since variants of the technique have been developed that are tailored to various different data types and structures. This article will begin by introducing the basic ideas of PCA, discussing what it can and cannot do. It will then describe some variants of PCA and their application.},
	number = {2065},
	urldate = {2022-10-20},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Jolliffe, Ian T. and Cadima, Jorge},
	month = apr,
	year = {2016},
	note = {Publisher: Royal Society},
	keywords = {dimension reduction, eigenvectors, multivariate analysis, palaeontology},
	pages = {20150202},
}

@article{becker_biomechanical_2017,
	title = {Biomechanical {Factors} {Associated} {With} {Achilles} {Tendinopathy} and {Medial} {Tibial} {Stress} {Syndrome} in {Runners}},
	volume = {45},
	issn = {0363-5465},
	url = {https://doi.org/10.1177/0363546517708193},
	doi = {10.1177/0363546517708193},
	abstract = {Background:There is disagreement in the literature regarding whether the excessive excursion or velocity of rearfoot eversion is related to the development of 2 common running injuries: Achilles tendinopathy (AT) and medial tibial stress syndrome (MTSS). An alternative hypothesis suggests that the duration of rearfoot eversion may be an important factor. However, the duration of eversion has received relatively little attention in the biomechanics literature.Hypothesis:Runners with AT or MTSS will demonstrate a longer duration of eversion but not greater excursion or velocity of eversion compared with healthy controls.Study Design:Controlled laboratory study.Methods:Forty-two runners participated in this study (13 with AT, 8 with MTSS, and 21 matched controls). Participants were evaluated for lower extremity alignment and flexibility, after which a 3-dimensional kinematic and kinetic running gait analysis was performed. Differences between the 2 injuries and between injured and control participants were evaluated for flexibility and alignment, rearfoot kinematics, and 3 ground-reaction force metrics. Binary logistic regression was used to evaluate which variables best predicted membership in the injured group.Results:Injured participants, compared with controls, demonstrated higher standing tibia varus angles (8.67° ± 1.79° vs 6.76° ± 1.75°, respectively; P = .002), reduced static dorsiflexion range of motion (6.14° ± 5.04° vs 11.19° ± 5.10°, respectively; P = .002), more rearfoot eversion at heel-off (?6.47° ± 5.58° vs 1.07° ± 2.26°, respectively; P {\textless} .001), and a longer duration of eversion (86.02\% ± 15.65\% stance vs 59.12\% ± 16.50\% stance, respectively; P {\textless} .001). There were no differences in the excursion or velocity of eversion. The logistic regression (?2 = 20.84, P {\textless} .001) revealed that every 1\% increase in the duration of eversion during the stance phase increased the odds of being in the injured group by 1.08 (95\% CI, 1.023-1.141; P = .006).Conclusion:Compared with healthy controls, runners currently symptomatic with AT or MTSS have a longer duration of eversion but not greater excursion or velocity of eversion.Clinical Relevance:Static measures of the tibia varus angle and dorsiflexion range of motion, along with dynamic measures of the duration of eversion, may be useful for identifying runners at risk of sustaining AT or MTSS.},
	language = {en},
	number = {11},
	urldate = {2022-10-20},
	journal = {The American Journal of Sports Medicine},
	author = {Becker, James and James, Stanley and Wayner, Robert and Osternig, Louis and Chou, Li-Shan},
	month = sep,
	year = {2017},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {2614--2621},
}

@article{bramah_is_2018,
	title = {Is {There} a {Pathological} {Gait} {Associated} {With} {Common} {Soft} {Tissue} {Running} {Injuries}?},
	volume = {46},
	issn = {0363-5465},
	url = {https://doi.org/10.1177/0363546518793657},
	doi = {10.1177/0363546518793657},
	abstract = {Background:Previous research has demonstrated clear associations between specific running injuries and patterns of lower limb kinematics. However, there has been minimal research investigating whether the same kinematic patterns could underlie multiple different soft tissue running injuries. If they do, such kinematic patterns could be considered global contributors to running injuries.Hypothesis:Injured runners will demonstrate differences in running kinematics when compared with injury-free controls. These kinematic patterns will be consistent among injured subgroups.Study Design:Controlled laboratory study.Methods:The authors studied 72 injured runners and 36 healthy controls. The injured group contained 4 subgroups of runners with either patellofemoral pain, iliotibial band syndrome, medial tibial stress syndrome, or Achilles tendinopathy (n = 18 each). Three-dimensional running kinematics were compared between injured and healthy runners and then between the 4 injured subgroups. A logistic regression model was used to determine which parameters could be used to identify injured runners.Results:The injured runners demonstrated greater contralateral pelvic drop (CPD) and forward trunk lean at midstance and a more extended knee and dorsiflexed ankle at initial contact. The subgroup analysis of variance found that these kinematic patterns were consistent across each of the 4 injured subgroups. CPD was found to be the most important variable predicting the classification of participants as healthy or injured. Importantly, for every 1° increase in pelvic drop, there was an 80\% increase in the odds of being classified as injured.Conclusion:This study identified a number of global kinematic contributors to common running injuries. In particular, we found injured runners to run with greater peak CPD and trunk forward lean as well as an extended knee and dorsiflexed ankle at initial contact. CPD appears to be the variable most strongly associated with common running-related injuries.Clinical Relevance:The identified kinematic patterns may prove beneficial for clinicians when assessing for biomechanical contributors to running injuries.},
	language = {en},
	number = {12},
	urldate = {2022-10-20},
	journal = {The American Journal of Sports Medicine},
	author = {Bramah, Christopher and Preece, Stephen J. and Gill, Niamh and Herrington, Lee},
	month = oct,
	year = {2018},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {3023--3031},
}

@misc{noauthor_modelling_nodate-1,
	title = {Modelling kinematic data from recreational runners using multivariate functional mixed effects models},
	url = {https://www.overleaf.com/project/62e25dc82f019c08e13ce2f2},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2022-10-20},
}

@article{mann_association_2015,
	title = {Association of previous injury and speed with running style and stride-to-stride fluctuations},
	volume = {25},
	issn = {1600-0838},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.12397},
	doi = {10.1111/sms.12397},
	abstract = {Running-related injuries remain problematic among recreational runners. We evaluated the association between having sustained a recent running-related injury and speed, and the strike index (a measure of footstrike pattern, SI) and spatiotemporal parameters of running. Forty-four previously injured and 46 previously uninjured runners underwent treadmill running at 80\%, 90\%, 100\%, 110\%, and 120\% of their preferred running speed. Participants wore a pressure insole device to measure SI, temporal parameters, and stride length (Slength) and stride frequency (Sfrequency) over 2-min intervals. Coefficient of variation and detrended fluctuation analysis provided information on stride-to-stride variability and correlative patterns. Linear mixed models were used to compare differences between groups and changes with speed. Previously injured runners displayed significantly higher stride-to-stride correlations of SI than controls (P = 0.046). As speed increased, SI, contact time (Tcontact), stride time (Tstride), and duty factor (DF) decreased (P {\textless} 0.001), whereas flight time (Tflight), Slength, and Sfrequency increased (P {\textless} 0.001). Stride-to-stride variability decreased significantly for SI, Tcontact, Tflight, and DF (P ≤ 0.005), as did correlative patterns for Tcontact, Tstride, DF, Slength, and Sfrequency (P ≤ 0.044). Previous running-related injury was associated with less stride-to-stride randomness of footstrike pattern. Overall, runners became more pronounced rearfoot strikers as running speed increased.},
	language = {en},
	number = {6},
	urldate = {2022-10-20},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Mann, R. and Malisoux, L. and Nührenbörger, C. and Urhausen, A. and Meijer, K. and Theisen, D.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.12397},
	keywords = {Strike index, detrended fluctuation analysis, running biomechanics, running-related injury},
	pages = {e638--e645},
}

@article{hreljac_evaluation_2000,
	title = {Evaluation of lower extremity overuse injury potential in runners},
	volume = {32},
	issn = {0195-9131},
	url = {https://journals.lww.com/acsm-msse/Fulltext/2000/09000/Evaluation_of_lower_extremity_overuse_injury.18.aspx},
	abstract = {HRELJAC, A., R. N. MARSHALL, and P. A. HUME. Evaluation of lower extremity overuse injury potential in runners. Med. Sci. Sports Exerc., Vol. 32, No. 9, pp. 1635–1641, 2000.
        Introduction 
        The purpose of this study was to identify biomechanical and anthropometric variables that contribute to overuse injuries in runners.
        Methods 
        Comparisons were made between a group of runners who had sustained at least one overuse running injury and a group of runners who had been injury free throughout their running careers. Groups were well matched in important training variables. Synchronized kinetic and rearfoot kinematic variables of both feet were collected by filming subjects running over a force platform at a speed of 4 m·s−1.
        Results 
        The injury-free group demonstrated significantly greater posterior thigh (hamstring) flexibility, as measured by a standard sit and reach test. This was the only anthropometric variable in which the groups differed. Within each group, there were no significant differences between left and right foot landing for any biomechanical variable. Biomechanical variables that demonstrated significantly lower values for the injury free group were the vertical force impact peak and the maximal vertical loading rate, with the maximal rate of rearfoot pronation and the touchdown supination angle showing a trend toward being greater in the injury free group.
        Conclusion 
        These results suggest that runners who have developed stride patterns that incorporate relatively low levels of impact forces, and a moderately rapid rate of pronation are at a reduced risk of incurring overuse running injuries.},
	language = {en-US},
	number = {9},
	urldate = {2022-10-20},
	journal = {Medicine \& Science in Sports \& Exercise},
	author = {Hreljac, Alan and Marshall, Robert N. and Hume, Patria A.},
	month = sep,
	year = {2000},
	pages = {1635--1641},
}

@article{bramah_is_2018-1,
	title = {Is {There} a {Pathological} {Gait} {Associated} {With} {Common} {Soft} {Tissue} {Running} {Injuries}?},
	volume = {46},
	issn = {0363-5465},
	url = {https://doi.org/10.1177/0363546518793657},
	doi = {10.1177/0363546518793657},
	abstract = {Background:Previous research has demonstrated clear associations between specific running injuries and patterns of lower limb kinematics. However, there has been minimal research investigating whether the same kinematic patterns could underlie multiple different soft tissue running injuries. If they do, such kinematic patterns could be considered global contributors to running injuries.Hypothesis:Injured runners will demonstrate differences in running kinematics when compared with injury-free controls. These kinematic patterns will be consistent among injured subgroups.Study Design:Controlled laboratory study.Methods:The authors studied 72 injured runners and 36 healthy controls. The injured group contained 4 subgroups of runners with either patellofemoral pain, iliotibial band syndrome, medial tibial stress syndrome, or Achilles tendinopathy (n = 18 each). Three-dimensional running kinematics were compared between injured and healthy runners and then between the 4 injured subgroups. A logistic regression model was used to determine which parameters could be used to identify injured runners.Results:The injured runners demonstrated greater contralateral pelvic drop (CPD) and forward trunk lean at midstance and a more extended knee and dorsiflexed ankle at initial contact. The subgroup analysis of variance found that these kinematic patterns were consistent across each of the 4 injured subgroups. CPD was found to be the most important variable predicting the classification of participants as healthy or injured. Importantly, for every 1° increase in pelvic drop, there was an 80\% increase in the odds of being classified as injured.Conclusion:This study identified a number of global kinematic contributors to common running injuries. In particular, we found injured runners to run with greater peak CPD and trunk forward lean as well as an extended knee and dorsiflexed ankle at initial contact. CPD appears to be the variable most strongly associated with common running-related injuries.Clinical Relevance:The identified kinematic patterns may prove beneficial for clinicians when assessing for biomechanical contributors to running injuries.},
	language = {en},
	number = {12},
	urldate = {2022-10-20},
	journal = {The American Journal of Sports Medicine},
	author = {Bramah, Christopher and Preece, Stephen J. and Gill, Niamh and Herrington, Lee},
	month = oct,
	year = {2018},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {3023--3031},
}

@article{van_middelkoop_risk_2008,
	title = {Risk factors for lower extremity injuries among male marathon runners},
	volume = {18},
	issn = {1600-0838},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0838.2007.00768.x},
	doi = {10.1111/j.1600-0838.2007.00768.x},
	abstract = {The aim of this study is to identify risk factors for lower extremity injuries in male marathon runners. A random sample of 1500 recreational male marathon runners was drawn. Possible risk factors were obtained from a baseline questionnaire 1 month before the start of the marathon. Information on injuries sustained shortly before or during the marathon was obtained using a post-race questionnaire. Of the 694 male runners who responded to the baseline and post-race questionnaire, 28\% suffered a self-reported running injury on the lower extremities in the month before or during the marathon run. More than six times race participation in the previous 12 months [odds ratio (OR) 1.66; confidence interval (CI) 1.08–2.56], a history of running injuries (OR 2.62; CI 1.82–3.78), high education level (OR 0.73; CI 0.51–1.04) and daily smoking (OR 0.23; CI 0.05–1.01) were associated with the occurrence of lower extremity injuries. Among the modifiable risk factor studies, a training distance {\textless}40 km a week is a strong protective factor of future calf injuries, and regular interval training is a strong protective factor for knee injuries. Other training characteristics appear to have little or no effect on future injuries.},
	language = {en},
	number = {6},
	urldate = {2022-10-20},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Van Middelkoop, M. and Kolkman, J. and Van Ochten, J. and Bierma-Zeinstra, S. M. A. and Koes, B. W.},
	year = {2008},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1600-0838.2007.00768.x},
	keywords = {injuries, marathon, risk factors, running},
	pages = {691--697},
}

@article{hesterberg_what_2015,
	title = {What {Teachers} {Should} {Know} {About} the {Bootstrap}: {Resampling} in the {Undergraduate} {Statistics} {Curriculum}},
	volume = {69},
	issn = {0003-1305},
	shorttitle = {What {Teachers} {Should} {Know} {About} the {Bootstrap}},
	url = {https://doi.org/10.1080/00031305.2015.1089789},
	doi = {10.1080/00031305.2015.1089789},
	abstract = {Bootstrapping has enormous potential in statistics education and practice, but there are subtle issues and ways to go wrong. For example, the common combination of nonparametric bootstrapping and bootstrap percentile confidence intervals is less accurate than using t-intervals for small samples, though more accurate for larger samples. My goals in this article are to provide a deeper understanding of bootstrap methods—how they work, when they work or not, and which methods work better—and to highlight pedagogical issues. Supplementary materials for this article are available online.[Received December 2014. Revised August 2015]},
	number = {4},
	urldate = {2022-10-19},
	journal = {The American Statistician},
	author = {Hesterberg, Tim C.},
	month = oct,
	year = {2015},
	pmid = {27019512},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2015.1089789},
	keywords = {Bias, Confidence intervals, Sampling distribution, Standard error, Statistical concepts, Teaching.},
	pages = {371--386},
}

@article{kenward_small_1997,
	title = {Small {Sample} {Inference} for {Fixed} {Effects} from {Restricted} {Maximum} {Likelihood}},
	volume = {53},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2533558},
	doi = {10.2307/2533558},
	abstract = {Restricted maximum likelihood (REML) is now well established as a method for estimating the parameters of the general Gaussian linear model with a structured covariance matrix, in particular for mixed linear models. Conventionally, estimates of precision and inference for fixed effects are based on their asymptotic distribution, which is known to be inadequate for some small-sample problems. In this paper, we present a scaled Wald statistic, together with an F approximation to its sampling distribution, that is shown to perform well in a range of small sample settings. The statistic uses an adjusted estimator of the covariance matrix that has reduced small sample bias. This approach has the advantage that it reproduces both the statistics and F distributions in those settings where the latter is exact, namely for Hotelling T2 type statistics and for analysis of variance F-ratios. The performance of the modified statistics is assessed through simulation studies of four different REML analyses and the methods are illustrated using three examples.},
	number = {3},
	urldate = {2022-10-19},
	journal = {Biometrics},
	author = {Kenward, Michael G. and Roger, James H.},
	year = {1997},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {983--997},
}

@misc{noauthor_sas_nodate,
	title = {{SAS} {Help} {Center}: {Mixed} {Models} {Theory}},
	url = {https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_mixed_details01.htm},
	urldate = {2022-10-19},
}

@book{noauthor_mixed-effects_nodate,
	title = {Mixed-{Effects} {Models} in {S} and {S}-{PLUS}},
	url = {https://link.springer.com/book/10.1007/b98882},
	language = {en},
	urldate = {2022-10-14},
}

@article{burke_comparison_2022,
	title = {Comparison of impact accelerations between injury-resistant and recently injured recreational runners},
	volume = {17},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0273716},
	doi = {10.1371/journal.pone.0273716},
	abstract = {Introduction/Purpose Previous injury has consistently been shown to be one of the greatest risk factors for running-related injuries (RRIs). Runners returning to participation following injury may still demonstrate injury-related mechanics (e.g. repetitive high impact loading), potentially exposing them to further injuries. The aim of this study was to determine if the magnitude (Peakaccel) and rate of loading (Rateaccel) at the tibia and sacrum differ between runners who have never been injured, those who have acquired injury resistance (runners who have not been injured in the past 2 years) and those who have been recently injured (RRI sustained 3–12 months ago). Methods Runners completed an online survey capturing details of their RRI history over the previous 2 years. Never injured runners were matched by sex, quarterly annual mileage and typical training speed to runners who had acquired injury resistance and to runners who had been recently injured. Differences in Peakaccel and Rateaccel of the tibia and sacrum were assessed between the three groups during a treadmill run at a set speed, with consideration for sex. Results A total of 147 runners made up the three injury status groups (n: 49 per group). There was a significant main effect of injury status for Peakaccel and Rateaccel at the sacrum, with recently injured runners demonstrating significantly greater Rateaccel than never injured and acquired injury resistant runners. There was also a significant main effect for sex, with females demonstrating greater tibial Peakaccel, sacrum Peakaccel and Rateaccel than males. Conclusion Rateaccel at the sacrum distinguishes recently injured runners from never injured runners and runners who may have acquired injury resistance, potentially highlighting poor impact acceleration attenuation in recently injured runners.},
	language = {en},
	number = {9},
	urldate = {2022-10-13},
	journal = {PLOS ONE},
	author = {Burke, Aoife and Dillon, Sarah and O’Connor, Siobhán and Whyte, Enda F. and Gore, Shane and Moran, Kieran A.},
	month = sep,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Accelerometers, Body limbs, Body weight, Hip, Inertia, Mechanical stress, Running, Traumatic injury risk factors},
	pages = {e0273716},
}

@article{saragiotto_what_2014,
	title = {What are the {Main} {Risk} {Factors} for {Running}-{Related} {Injuries}?},
	volume = {44},
	issn = {1179-2035},
	url = {https://doi.org/10.1007/s40279-014-0194-6},
	doi = {10.1007/s40279-014-0194-6},
	abstract = {Despite several studies that have been conducted on running injuries, the risk factors for running-related injuries are still not clear in the literature.},
	language = {en},
	number = {8},
	urldate = {2022-10-13},
	journal = {Sports Medicine},
	author = {Saragiotto, Bruno Tirotti and Yamato, Tiê Parma and Hespanhol Junior, Luiz Carlos and Rainbow, Michael J. and Davis, Irene S. and Lopes, Alexandre Dias},
	month = aug,
	year = {2014},
	keywords = {Main Risk Factor, Newcastle Ottawa Scale, Overuse Injury, Previous Injury, Prospective Cohort Study},
	pages = {1153--1163},
}

@article{lun_relation_2004,
	title = {Relation between running injury and static lower limb alignment in recreational runners},
	volume = {38},
	copyright = {Copyright 2004 British Journal of Sports Medicine},
	issn = {0306-3674, 1473-0480},
	url = {https://bjsm.bmj.com/content/38/5/576},
	doi = {10.1136/bjsm.2003.005488},
	abstract = {Objectives: To determine if measurements of static lower limb alignment are related to lower limb injury in recreational runners.
Methods: Static lower limb alignment was prospectively measured in 87 recreational runners. They were observed for the following six months for any running related musculoskeletal injuries of the lower limb. Injuries were defined according to six types: R1, R2, and R3 injuries caused a reduction in running mileage for one day, two to seven days, or more than seven days respectively; S1, S2, and S3 injuries caused stoppage of running for one day, two to seven days, or more than seven days respectively.
Results: At least one lower limb injury was suffered by 79\% of the runners during the observation period. When the data for all runners were pooled, 95\% confidence intervals calculated for the differences in the measurements of lower limb alignment between the injured and non-injured runners suggested that there were no differences. However, when only runners diagnosed with patellofemoral pain syndrome (n = 6) were compared with non-injured runners, differences were found in right ankle dorsiflexion (0.3 to 6.1), right knee genu varum (−0.9 to −0.3), and left forefoot varus (−0.5 to −0.4).
Conclusions: In recreational runners, there is no evidence that static biomechanical alignment measurements of the lower limbs are related to lower limb injury except patellofemoral pain syndrome. However, the effect of static lower limb alignment may be injury specific.},
	language = {en},
	number = {5},
	urldate = {2022-10-13},
	journal = {British Journal of Sports Medicine},
	author = {Lun, V. and Meeuwisse, W. H. and Stergiou, P. and Stefanyshyn, D.},
	month = oct,
	year = {2004},
	pmid = {15388542},
	note = {Publisher: British Association of Sport and Excercise Medicine
Section: Original article},
	keywords = {alignment, injury, lower limb, risk factor, running},
	pages = {576--580},
}

@article{dempster_prevalence_2021,
	title = {The {Prevalence} of {Lower} {Extremity} {Injuries} in {Running} and {Associated} {Risk} {Factors}: {A} {Systematic} {Review}},
	volume = {5},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2515-2270},
	shorttitle = {The {Prevalence} of {Lower} {Extremity} {Injuries} in {Running} and {Associated} {Risk} {Factors}},
	url = {http://paahjournal.com/article/10.5334/paah.109/},
	doi = {10.5334/paah.109},
	abstract = {Article: The Prevalence of Lower Extremity Injuries in Running and Associated Risk Factors: A Systematic Review},
	language = {en},
	number = {1},
	urldate = {2022-10-13},
	journal = {Physical Activity and Health},
	author = {Dempster, Jade and Dutheil, Frédéric and Ugbolue, Ukadike Chris},
	month = jul,
	year = {2021},
	note = {Number: 1
Publisher: Ubiquity Press},
	pages = {133--145},
}

@article{kakouris_systematic_2021,
	title = {A systematic review of running-related musculoskeletal injuries in runners},
	volume = {10},
	issn = {2095-2546},
	url = {https://www.sciencedirect.com/science/article/pii/S2095254621000454},
	doi = {10.1016/j.jshs.2021.04.001},
	abstract = {Objective
Running-related musculoskeletal injuries (RRMIs), especially stemming from overuse, frequently occur in runners. This study aimed to systematically review the literature and determine the incidence and prevalence proportion of RRMIs by anatomic location and specific pathology.
Methods
An electronic database search with no date beginning restrictions was performed in SPORTDiscus, PubMed, and MEDLINE up to June 2020. Prospective studies were used to find the anatomic location and the incidence proportion of each RRMI, whereas retrospective or cross-sectional studies were used to find the prevalence proportion of each RRMI. A separate analysis for ultramarathon runners was performed.
Results
The overall injury incidence and prevalence were 40.2\% ± 18.8\% and 44.6\% ± 18.4\% (mean ± SD), respectively. The knee, ankle, and lower leg accounted for the highest proportion of injury incidence, whereas the knee, lower leg, and foot/toes had the highest proportion of injury prevalence. Achilles tendinopathy (10.3\%), medial tibial stress syndrome (9.4\%), patellofemoral pain syndrome (6.3\%), plantar fasciitis (6.1\%), and ankle sprains (5.8\%) accounted for the highest proportion of injury incidence, whereas patellofemoral pain syndrome (16.7\%), medial tibial stress syndrome (9.1\%), plantar fasciitis (7.9\%), iliotibial band syndrome (7.9\%), and Achilles tendinopathy (6.6\%) had the highest proportion of injury prevalence. The ankle (34.5\%), knee (28.1\%), and lower leg (12.9\%) were the 3 most frequently injured sites among ultramarathoners.
Conclusion
The injury incidence proportions by anatomic location between ultramarathoners and non-ultramarathoners were not significantly different (p = 0.798). The pathologies with the highest incidence proportion of injuries were anterior compartment tendinopathy (19.4\%), patellofemoral pain syndrome (15.8\%), and Achilles tendinopathy (13.7\%). The interpretation of epidemiological data in RRMIs is limited due to several methodological issues encountered.},
	language = {en},
	number = {5},
	urldate = {2022-10-13},
	journal = {Journal of Sport and Health Science},
	author = {Kakouris, Nicolas and Yener, Numan and Fong, Daniel T. P.},
	month = sep,
	year = {2021},
	keywords = {Epidemiology, Injury, Injury prevention, Rehabilitation, Running},
	pages = {513--522},
}

@article{saragiotto_what_2014-1,
	title = {What are the {Main} {Risk} {Factors} for {Running}-{Related} {Injuries}?},
	volume = {44},
	issn = {1179-2035},
	url = {https://doi.org/10.1007/s40279-014-0194-6},
	doi = {10.1007/s40279-014-0194-6},
	abstract = {Despite several studies that have been conducted on running injuries, the risk factors for running-related injuries are still not clear in the literature.},
	language = {en},
	number = {8},
	urldate = {2022-10-13},
	journal = {Sports Medicine},
	author = {Saragiotto, Bruno Tirotti and Yamato, Tiê Parma and Hespanhol Junior, Luiz Carlos and Rainbow, Michael J. and Davis, Irene S. and Lopes, Alexandre Dias},
	month = aug,
	year = {2014},
	keywords = {Main Risk Factor, Newcastle Ottawa Scale, Overuse Injury, Previous Injury, Prospective Cohort Study},
	pages = {1153--1163},
}

@article{saragiotto_what_2014-2,
	title = {What are the main risk factors for running-related injuries?},
	volume = {44},
	issn = {1179-2035},
	doi = {10.1007/s40279-014-0194-6},
	abstract = {BACKGROUND: Despite several studies that have been conducted on running injuries, the risk factors for running-related injuries are still not clear in the literature.
OBJECTIVE: The aim of this study was to systematically review prospective cohort studies that investigated the risk factors for running injuries in general.
DATA SOURCES: We conducted electronic searches without restriction of language on EMBASE (1980 to Dec 2012), PUBMED (1946 to Dec 2012), CINAHL (1988 to Dec 2012) SPORTDiscus (1977 to Dec 2012), Latin American and Caribbean Centre on Health Sciences Information (1985 to Dec 2012) and Scientific Electronic Library Online (1998 to Dec 2012) databases, using subject headings, synonyms, relevant terms and variant spellings for each database.
STUDY SELECTION: Only prospective cohort studies investigating the risk factors for running-related musculoskeletal injuries were included in this review. Two independent reviewers screened each article and, if they did not reach a consensus, a third reviewer decided whether or not the article should be included.
STUDY APPRAISAL AND SYNTHESIS METHODS: Year of publication, type of runners, sample size, definition of running-related musculoskeletal injury, baseline characteristics, reported risk factors and the statistical measurement of risk or protection association were extracted from the articles. A scale adapted by the authors evaluated the risk of bias of the articles.
RESULTS: A total of 11 articles were considered eligible in this systematic review. A total of 4,671 pooled participants were analysed and 60 different predictive factors were investigated. The main risk factor reported was previous injury (last 12 months), reported in 5 of the 8 studies that investigated previous injuries as a risk factor. Only one article met the criteria for random selection of the sample and only six articles included a follow-up of 6 months or more. There was no association between gender and running injuries in most of the studies.
LIMITATIONS: It is possible that eligible articles for this review were published in journals that were not indexed in any of the searched databases. We found a great heterogeneity of statistical methods between studies, which prevented us from performing a meta-analysis.
CONCLUSIONS: The main risk factor identified in this review was previous injury in the last 12 months, although many risk factors had been investigated in the literature. Relatively few prospective studies were identified in this review, reducing the overall ability to detect risk factors. This highlights the need for more, well designed prospective studies in order to fully appreciate the risk factors associated with running.},
	language = {eng},
	number = {8},
	journal = {Sports Medicine (Auckland, N.Z.)},
	author = {Saragiotto, Bruno Tirotti and Yamato, Tiê Parma and Hespanhol Junior, Luiz Carlos and Rainbow, Michael J. and Davis, Irene S. and Lopes, Alexandre Dias},
	month = aug,
	year = {2014},
	pmid = {24809248},
	keywords = {Humans, Musculoskeletal System, Prospective Studies, Risk Factors, Running},
	pages = {1153--1163},
}

@article{yamato_consensus_2015,
	title = {A consensus definition of running-related injury in recreational runners: a modified {Delphi} approach},
	volume = {45},
	issn = {1938-1344},
	shorttitle = {A consensus definition of running-related injury in recreational runners},
	doi = {10.2519/jospt.2015.5741},
	abstract = {STUDY DESIGN: Delphi study.
OBJECTIVE: To reach a consensus definition of running-related injury in recreational runners through a modified Delphi approach.
BACKGROUND: Many studies have suggested the need for a standardized definition of running-related injury to provide uniformity to injury surveillance in running.
METHODS: We invited 112 researchers from running-related injury studies identified in a previous systematic review to classify words and terms frequently used in definitions of running-related injury in an online form during 3 rounds of study. In the last round, participants were asked to approve or disapprove the consensus definition. We considered an agreement level of at least 75\% to be a consensus.
RESULTS: Thirty-eight participants agreed to participate in the study. The response rates were 94.7\% (n = 36) for the first round, 83.3\% (n = 30) for the second round, and 86.7\% (n = 26) for the third round. A consensus definition of running-related injury was reached, with 80\% of participants approving the following: "Running-related (training or competition) musculoskeletal pain in the lower limbs that causes a restriction on or stoppage of running (distance, speed, duration, or training) for at least 7 days or 3 consecutive scheduled training sessions, or that requires the runner to consult a physician or other health professional."
CONCLUSION: The proposed standardized definition of running-related injury could assist in standardizing the definitions used in sport science research and facilitate between-study comparisons. Future studies testing the validity of the proposed consensus definition, as well as its accurate translation to other languages, are also needed.},
	language = {eng},
	number = {5},
	journal = {The Journal of Orthopaedic and Sports Physical Therapy},
	author = {Yamato, Tiê Parma and Saragiotto, Bruno Tirotti and Lopes, Alexandre Dias},
	month = may,
	year = {2015},
	pmid = {25808527},
	keywords = {Consensus, Delphi Technique, Humans, Leg Injuries, Recreation, Running, Terminology as Topic, jogging, judgement, lower extremity, terminology},
	pages = {375--380},
}

@article{hulteen_global_2017,
	title = {Global participation in sport and leisure-time physical activities: {A} systematic review and meta-analysis},
	volume = {95},
	issn = {0091-7435},
	shorttitle = {Global participation in sport and leisure-time physical activities},
	url = {https://www.sciencedirect.com/science/article/pii/S0091743516303838},
	doi = {10.1016/j.ypmed.2016.11.027},
	abstract = {This review aimed to determine the most popular physical activities performed by children, adolescents, and adults globally. Statistic bureau websites and article databases Scopus, ProQuest, SPORTDiscus, and Science Direct were searched between November 17th, 2014 and April 31st, 2015. Eligible studies were published in the last 10years with participation rates for specific physical activities among individuals five years or older. Data extraction for included articles (n=64) was assessed independently and agreed upon by two authors. A random-effects model was used to calculate participation rates in specific activities for each age group and region. In total 73,304 articles were retrieved and 64 articles representing 47 countries were included in the final meta-analysis. Among adults, walking was the most popular activity in the Americas (18.9\%; 95\% CI 10.2 to 32.5), Eastern Mediterranean (15.0\%; 95\% CI 5.8 to 33.6), Southeast Asia (39.3\%; 95\% CI 0.9 to 98.0) and Western Pacific (41.8\%; 95\% CI 25.2 to 60.6). In Europe and Africa, soccer (10.0\%; 95\% CI 6.5 to 15.1) and running (9.3\%; 95\% CI 0.9 to 53.9), respectively, were top activities. Child and adolescent participation results were highly dependent upon region. American youth team sport participation was high, while youth from the Eastern Mediterranean and Western Pacific were more likely to report participation in lifelong physical activities. Global data for adults reflects a consistent pattern of participation in running and walking. Among all age groups and regions soccer was popular. In children and adolescents, preferences were variable between regions.},
	language = {en},
	urldate = {2022-10-13},
	journal = {Preventive Medicine},
	author = {Hulteen, Ryan M. and Smith, Jordan J. and Morgan, Philip J. and Barnett, Lisa M. and Hallal, Pedro C. and Colyvas, Kim and Lubans, David R.},
	month = feb,
	year = {2017},
	keywords = {Adolescents, Adults, Children, Lifelong physical activities, Team sports},
	pages = {14--25},
}

@article{leardini_human_2005,
	title = {Human movement analysis using stereophotogrammetry. {Part} 3. {Soft} tissue artifact assessment and compensation},
	volume = {21},
	issn = {0966-6362},
	doi = {10.1016/j.gaitpost.2004.05.002},
	abstract = {When using optoelectronic stereophotogrammetry, skin deformation and displacement causes marker movement with respect to the underlying bone. This movement represents an artifact, which affects the estimation of the skeletal system kinematics, and is regarded as the most critical source of error in human movement analysis. A comprehensive review of the state-of-the-art for assessment, minimization and compensation of the soft tissue artifact (STA) is provided. It has been shown that STA is greater than the instrumental error associated with stereophotogrammetry, has a frequency content similar to the actual bone movement, is task dependent and not reproducible among subjects and, of lower limb segments, is greatest at the thigh. It has been shown that in in vivo experiments only motion about the flexion/extension axis of the hip, knees and ankles can be determined reliably. Motion about other axes at those joints should be regarded with much more caution as this artifact produces spurious effects with magnitudes comparable to the amount of motion actually occurring in those joints. Techniques designed to minimize the contribution of and compensate for the effects of this artifact can be divided up into those which model the skin surface and those which include joint motion constraints. Despite the numerous solutions proposed, the objective of reliable estimation of 3D skeletal system kinematics using skin markers has not yet been satisfactorily achieved and greatly limits the contribution of human movement analysis to clinical practice and biomechanical research. For STA to be compensated for effectively, it is here suggested that either its subject-specific pattern is assessed by ad hoc exercises or it is characterized from a large series of measurements on different subject populations. Alternatively, inclusion of joint constraints into a more general STA minimization approach may provide an acceptable solution.},
	language = {eng},
	number = {2},
	journal = {Gait \& Posture},
	author = {Leardini, Alberto and Chiari, Lorenzo and Della Croce, Ugo and Cappozzo, Aurelio},
	month = feb,
	year = {2005},
	pmid = {15639400},
	keywords = {Adipose Tissue, Artifacts, Biomechanical Phenomena, Humans, Movement, Photogrammetry},
	pages = {212--225},
}

@article{aguilera-morillo_multi-class_2020,
	title = {Multi-class classification of biomechanical data: {A} functional {LDA} approach based on multi-class penalized functional {PLS}},
	volume = {20},
	issn = {1471-082X},
	shorttitle = {Multi-class classification of biomechanical data},
	url = {https://doi.org/10.1177/1471082X19871157},
	doi = {10.1177/1471082X19871157},
	abstract = {A functional linear discriminant analysis approach to classify a set of kinematic data (human movement curves of individuals performing different physical activities) is performed. Kinematic data, usually collected in linear acceleration or angular rotation format, can be identified with functions in a continuous domain (time, percentage of gait cycle, etc.). Since kinematic curves are measured in the same sample of individuals performing different activities, they are a clear example of functional data with repeated measures. On the other hand, the sample curves are observed with noise. Then, a roughness penalty might be necessary in order to provide a smooth estimation of the discriminant functions, which would make them more interpretable. Moreover, because of the infinite dimension of functional data, a reduction dimension technique should be considered. To solve these problems, we propose a multi-class approach for penalized functional partial least squares (FPLS) regression. Then linear discriminant analysis (LDA) will be performed on the estimated FPLS components. This methodology is motivated by two case studies. The first study considers the linear acceleration recorded every two seconds in 30 subjects, related to three different activities (walking, climbing stairs and down stairs). The second study works with the triaxial angular rotation, for each joint, in 51 children when they completed a cycle walking under three conditions (walking, carrying a backpack and pulling a trolley). A simulation study is also developed for comparing the performance of the proposed functional LDA with respect to the corresponding multivariate and non-penalized approaches.},
	language = {en},
	number = {6},
	urldate = {2022-10-03},
	journal = {Statistical Modelling},
	author = {Aguilera-Morillo, M. Carmen and Aguilera, Ana M.},
	month = dec,
	year = {2020},
	note = {Publisher: SAGE Publications India},
	pages = {592--616},
}

@article{zhang_functional_2016,
	title = {Functional {CAR} models for large spatially correlated functional datasets},
	volume = {111},
	issn = {0162-1459},
	doi = {10.1080/01621459.2015.1042581},
	abstract = {We develop a functional conditional autoregressive (CAR) model for spatially correlated data for which functions are collected on areal units of a lattice. Our model performs functional response regression while accounting for spatial correlations with potentially nonseparable and nonstationary covariance structure, in both the space and functional domains. We show theoretically that our construction leads to a CAR model at each functional location, with spatial covariance parameters varying and borrowing strength across the functional domain. Using basis transformation strategies, the nonseparable spatial-functional model is computationally scalable to enormous functional datasets, generalizable to different basis functions, and can be used on functions defined on higher dimensional domains such as images. Through simulation studies, we demonstrate that accounting for the spatial correlation in our modeling leads to improved functional regression performance. Applied to a high-throughput spatially correlated copy number dataset, the model identifies genetic markers not identified by comparable methods that ignore spatial correlations.},
	language = {eng},
	number = {514},
	journal = {Journal of the American Statistical Association},
	author = {Zhang, Lin and Baladandayuthapani, Veerabhadran and Zhu, Hongxiao and Baggerly, Keith A. and Majewski, Tadeusz and Czerniak, Bogdan A. and Morris, Jeffrey S.},
	year = {2016},
	pmid = {28018013},
	pmcid = {PMC5176110},
	keywords = {Conditional autoregressive model, Functional data analysis, Functional regression, Spatial functional data, Whole-organ histology and genetic maps},
	pages = {772--786},
}

@article{brunton_discovering_2016,
	title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
	volume = {113},
	url = {https://www.pnas.org/doi/10.1073/pnas.1517384113},
	doi = {10.1073/pnas.1517384113},
	number = {15},
	urldate = {2022-09-21},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
	month = apr,
	year = {2016},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {3932--3937},
}

@misc{betancourt_taylor_2022,
	title = {Taylor {Regression} {Models}},
	url = {https://betanalpha.github.io/assets/case_studies/taylor_models.html, commit f99e798124a3d3cd77fc5779c9e8833e94d61a12},
	abstract = {Linear functions of the covariates are ubiquitous in the regression modeling, although it's not clear if that ubiquity is due to any universal utility or just mathematical simplicity. In this case study I consider linear functions of input covariates as local approximations of more general functional behavior within a neighborhood of covariate configurations. The theory of Taylor approximations grounds these models in an explicit context that offers interpretability and guidance for how they, and the heuristics that often accompany them, can be robustly applied in practice.},
	urldate = {2022-09-15},
	author = {Betancourt, Michael},
	month = jul,
	year = {2022},
}

@article{berk_assumption_2021,
	title = {Assumption {Lean} {Regression}},
	volume = {75},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2019.1592781},
	doi = {10.1080/00031305.2019.1592781},
	abstract = {It is well known that with observational data, models used in conventional regression analyses are commonly misspecified. Yet in practice, one tends to proceed with interpretations and inferences that rely on correct specification. Even those who invoke Box’s maxim that all models are wrong proceed as if results were generally useful. Misspecification, however, has implications that affect practice. Regression models are approximations to a true response surface and should be treated as such. Accordingly, regression parameters should be interpreted as statistical functionals. Importantly, the regressor distribution affects targets of estimation and regressor randomness affects the sampling variability of estimates. As a consequence, inference should be based on sandwich estimators or the pairs (x–y) bootstrap. Traditional prediction intervals lose their pointwise coverage guarantees, but empirically calibrated intervals can be justified for future populations. We illustrate the key concepts with an empirical application.},
	number = {1},
	urldate = {2022-09-15},
	journal = {The American Statistician},
	author = {Berk, Richard and Buja, Andreas and Brown, Lawrence and George, Edward and Kuchibhotla, Arun Kumar and Su, Weijie and Zhao, Linda},
	month = jan,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2019.1592781},
	keywords = {Foundational issues, Generalized linear models, Linear regression, Misspecified regression models, Regression functionals},
	pages = {76--84},
}

@book{kirk_optimal_2012,
	title = {Optimal {Control} {Theory}: {An} {Introduction}},
	isbn = {978-0-486-13507-6},
	shorttitle = {Optimal {Control} {Theory}},
	abstract = {Optimal control theory is the science of maximizing the returns from and minimizing the costs of the operation of physical, social, and economic processes. Geared toward upper-level undergraduates, this text introduces three aspects of optimal control theory: dynamic programming, Pontryagin\&\#39;s minimum principle, and numerical techniques for trajectory optimization.Chapters 1 and 2 focus on describing systems and evaluating their performances. Chapter 3 deals with dynamic programming. The calculus of variations and Pontryagin\&\#39;s minimum principle are the subjects of chapters 4 and 5, and chapter 6 examines iterative numerical techniques for finding optimal controls and trajectories. Numerous problems, intended to introduce additional topics as well as to illustrate basic concepts, appear throughout the text.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Kirk, Donald E.},
	month = apr,
	year = {2012},
	note = {Google-Books-ID: onuH0PnZwV4C},
	keywords = {Technology \& Engineering / Electronics / General},
}

@book{bressan_introduction_2007,
	address = {Springfield, Mont},
	edition = {1st edition},
	title = {Introduction to the {Mathematical} {Theory} of {Control}: 2},
	isbn = {978-1-60133-002-4},
	shorttitle = {Introduction to the {Mathematical} {Theory} of {Control}},
	language = {English},
	publisher = {American Institute for Mathematical Studies},
	author = {Bressan, Alberto and Piccoli, Benedetto},
	month = aug,
	year = {2007},
}

@article{horst_gutenberg_2021,
	title = {Gutenberg {Gait} {Database}, a ground reaction force database of level overground walking in healthy individuals},
	volume = {8},
	copyright = {2021 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-021-01014-6},
	doi = {10.1038/s41597-021-01014-6},
	abstract = {The Gutenberg Gait Database comprises data of 350 healthy individuals recorded in our laboratory over the past seven years. The database contains ground reaction force (GRF) and center of pressure (COP) data of two consecutive steps measured - by two force plates embedded in the ground - during level overground walking at self-selected walking speed. The database includes participants of varying ages, from 11 to 64 years. For each participant, up to eight gait analysis sessions were recorded, with each session comprising at least eight gait trials. The database provides unprocessed (raw) and processed (ready-to-use) data, including three-dimensional GRF and two-dimensional COP signals during the stance phase. These data records offer new possibilities for future studies on human gait, e.g., the application as a reference set for the analysis of pathological gait patterns, or for automatic classification using machine learning. In the future, the database will be expanded continuously to obtain an even larger and well-balanced database with respect to age, sex, and other gait-specific factors.},
	language = {en},
	number = {1},
	urldate = {2021-09-21},
	journal = {Scientific Data},
	author = {Horst, Fabian and Slijepcevic, Djordje and Simak, Marvin and Schöllhorn, Wolfgang I.},
	month = sep,
	year = {2021},
	pages = {232},
}

@article{glazier_beyond_2021,
	title = {Beyond animated skeletons: {How} can biomechanical feedback be used to enhance sports performance?},
	volume = {129},
	issn = {0021-9290},
	shorttitle = {Beyond animated skeletons},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929021004553},
	doi = {10.1016/j.jbiomech.2021.110686},
	abstract = {Biomechanical feedback technologies are becoming increasingly prevalent in elite athletic training environments but how the kinematic and kinetic data they produce can be best used to improve sports techniques and enhance sports performance is unclear. This paper draws on theoretical and empirical developments in the motor control, skill acquisition, and sports biomechanics literatures to offer practical guidance and strategic direction on this issue. It is argued that the information produced by biomechanical feedback technologies can only describe, with varying degrees of accuracy, what patterns of coordination and control are being adopted by the athlete but, crucially, it cannot prescribe how these patterns of coordination and control should be modified to enhance sports performance. As conventional statistical and theoretical modelling paradigms in applied sports biomechanics provide limited information about patterns of coordination and control, and do not permit the identification of athlete-specific optimum sports techniques, objective criteria on which to base technical modifications that will consistently lead to enhanced performance outcomes cannot reliably be established for individual athletes. Given these limitations, an alternative approach, which is harmonious with the tenets of dynamical systems theory and aligned with the pioneering insights of Bernstein (1967) on skill acquisition, is advocated. This approach involves using kinematic and kinetic data to channel the athlete’s search towards their own unique ‘optimum’ pattern of coordination and control as they actively explore their perceptual-motor workspace during practice. This approach appears to be the most efficacious use of kinematic and kinetic data given current biomechanical knowledge about sports techniques and the apparent inability of existing biomechanical modelling approaches to accurately predict how technique changes will impact on performance outcomes for individual athletes.},
	language = {en},
	urldate = {2021-10-13},
	journal = {Journal of Biomechanics},
	author = {Glazier, Paul S.},
	month = dec,
	year = {2021},
	keywords = {Control, Coordination, Kinematic, Kinetic, Knowledge of performance, Knowledge of results},
	pages = {110686},
}

@article{dillon_injury-resistant_2021,
	title = {Do {Injury}-{Resistant} {Runners} {Have} {Distinct} {Differences} in {Clinical} {Measures} {Compared} with {Recently} {Injured} {Runners}?},
	volume = {53},
	issn = {1530-0315},
	doi = {10.1249/MSS.0000000000002649},
	abstract = {INTRODUCTION: Although lower extremity muscle strength, joint motion, and functional foot alignment are commonly used, time-efficient clinical measures that have been proposed as risk factors for running-related injuries, it is unclear if these factors can distinguish injury resistance in runners.
PURPOSE: This study compares clinical measures, with consideration of sex, between recently injured runners (3 months to 1 yr prior), those with a high level of injury resistance who have been uninjured for at least 2 yr, and never-injured runners.
METHODS: Averaged bilateral values and between-limb symmetry angles of lower limb isometric muscle strength, joint motion, navicular drop, and foot posture index (FPI) were assessed in a cohort of recreational runners, and their injury history was recorded. Differences in clinical measures between injury groupings were examined, with consideration of sex.
RESULTS: Of the 223 runners tested, 116 had been recently injured, 61 had been injured {\textgreater}2 yr ago and were deemed to have acquired reinjury resistance, and 46 were never injured. Plantarflexion was greater in both recently injured (P = 0.001) and acquired reinjury resistance runners (P = 0.001) compared with never-injured runners. Recently injured runners displayed higher hip abduction strength compared with never-injured runners (P = 0.019, η2 = 0.038, small effect size). There were no statistically significant differences in the remaining measures between the injury groupings. With the exception of FPI, there was no interaction between sex and injury grouping for any of the measures.
CONCLUSION: Commonly used clinical measures of strength, joint motion, and functional foot alignment were not superior in injury-resistant runners compared with recently injured runners, questioning their relevance in identifying future injury resistance of runners.},
	language = {eng},
	number = {9},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Dillon, Sarah and Burke, Aoife and Whyte, Enda F. and O'Connor, Siobhán and Gore, Shane and Moran, Kieran A.},
	month = sep,
	year = {2021},
	pmid = {33899779},
	keywords = {Adult, Athletic Injuries, Female, Humans, Lower Extremity, Male, Middle Aged, Muscle Strength, Range of Motion, Articular, Risk Factors, Running, Sex Factors, Surveys and Questionnaires},
	pages = {1807--1817},
}

@misc{noauthor_injury-resistant_nodate,
	title = {Do {Injury}-{Resistant} {Runners} {Have} {Distinct} {Differences} in {Cli}... : {Medicine} \& {Science} in {Sports} \& {Exercise}},
	url = {https://journals.lww.com/acsm-msse/Abstract/2021/09000/Do_Injury_Resistant_Runners_Have_Distinct.2.aspx},
	urldate = {2022-07-28},
}

@techreport{dublin_city_university_dcu_2020,
	type = {Clinical trial registration},
	title = {The {DCU} {Running} {Injury} {Surveillance} {Centre} ({RISC}) {Study}: {A} {Prospective} {Investigation} of {Factors} {Relating} to {Running} {Injuries}},
	shorttitle = {The {DCU} {Running} {Injury} {Surveillance} {Centre} {Study}: {A} {Prospective} {Investigation} of {Factors} {Relating} to {Running} {Injuries}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03671395},
	abstract = {This study aims to prospectively investigate the relationship between a number of clinical and biomechanical variables and running-related injuries among a group of novice and recreational runners over a two year time period. To date, the incidence of running injuries among runners is high, with a lack of prospective research investigating the factors related to injury. It is thought that loading in excess of the tissues capabilities may be be a contributing factor to sustaining a running related injury. As such, this study hypothesizes that biomechanical factors may be related to injury.

Healthy participants will perform a battery of clinical tests at baseline, as well as completing a survey that details their injury history and training habits. Kinematic and kinetic motion analysis will be used as participants perform a series of functional movements and a treadmill run. Enrolled participants will be monitored for the occurrence of running-related injuries via email for the duration of the study.},
	number = {NCT03671395},
	urldate = {2022-07-27},
	institution = {clinicaltrials.gov},
	author = {{Dublin City University}},
	collaborator = {{Insight Centre for Data Analytics}},
	month = jul,
	year = {2020},
	note = {submitted: May 2, 2018},
}

@incollection{lamb_assessing_2017,
	edition = {2},
	title = {Assessing movement coordination},
	isbn = {978-0-203-09554-6},
	abstract = {In sports biomechanics, when considering sports and exercise techniques, emphasis is often put on discrete variables such as joint angles at certain events in the movement or durations of movement phases. Such techniques, however, are complex, requiring the coordinated movement of multiple body segments throughout the entire movement. In this chapter we discuss in detail, techniques for assessing movement coordination, including angle–angle diagrams, cross-correlation functions, phase planes, continuous relative phase and self-organising maps. Special emphasis is put on interpreting coordination patterns qualitatively.},
	booktitle = {Biomechanical {Evaluation} of {Movement} in {Sport} and {Exercise}},
	publisher = {Routledge},
	author = {Lamb, Peter F. and Bartlett, Roger M.},
	year = {2017},
	note = {Num Pages: 22},
}

@article{friedman_sparse_2008,
	title = {Sparse inverse covariance estimation with the graphical lasso},
	volume = {9},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxm045},
	doi = {10.1093/biostatistics/kxm045},
	abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm—the graphical lasso—that is remarkably fast: It solves a 1000-node problem (∼500000 parameters) in at most a minute and is 30–4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and Bühlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
	number = {3},
	urldate = {2022-07-26},
	journal = {Biostatistics},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	month = jul,
	year = {2008},
	pages = {432--441},
}

@article{fieuws_pairwise_2006,
	title = {Pairwise {Fitting} of {Mixed} {Models} for the {Joint} {Modeling} of {Multivariate} {Longitudinal} {Profiles}},
	volume = {62},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2006.00507.x},
	doi = {10.1111/j.1541-0420.2006.00507.x},
	abstract = {A mixed model is a flexible tool for joint modeling purposes, especially when the gathered data are unbalanced. However, computational problems due to the dimension of the joint covariance matrix of the random effects arise as soon as the number of outcomes and/or the number of used random effects per outcome increases. We propose a pairwise approach in which all possible bivariate models are fitted, and where inference follows from pseudo-likelihood arguments. The approach is applicable for linear, generalized linear, and nonlinear mixed models, or for combinations of these. The methodology will be illustrated for linear mixed models in the analysis of 22-dimensional, highly unbalanced, longitudinal profiles of hearing thresholds.},
	language = {en},
	number = {2},
	urldate = {2022-07-26},
	journal = {Biometrics},
	author = {Fieuws, Steffen and Verbeke, Geert},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2006.00507.x},
	keywords = {Correlated curves, Joint modeling, Mixed models, Multivariate longitudinal profiles, Pseudo likelihood},
	pages = {424--431},
}

@article{swartz_where_2020,
	title = {Where {Should} {I} {Publish} {My} {Sports} {Paper}?},
	volume = {74},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2018.1459842},
	doi = {10.1080/00031305.2018.1459842},
	abstract = {With the increasing fascination of sport in society and the increasing availability of sport-related data, there are great opportunities to carry out sports analytics research. In this article, we discuss some of the issues that are relevant to publishing in the field of sports analytics. Potential publication outlets are identified, some summary statistics are given, and some experiences and opinions are provided.},
	number = {2},
	urldate = {2022-07-15},
	journal = {The American Statistician},
	author = {Swartz, Tim B.},
	month = apr,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1459842},
	keywords = {Journals, Publishing, Sports analytics, Statistics in sport},
	pages = {103--108},
}

@book{drazin_nonlinear_1992,
	address = {Cambridge},
	series = {Cambridge {Texts} in {Applied} {Mathematics}},
	title = {Nonlinear {Systems}},
	isbn = {978-0-521-40668-0},
	url = {https://www.cambridge.org/core/books/nonlinear-systems/6983A49CB7BD5793B1316895AE2183DA},
	abstract = {The theories of bifurcation, chaos and fractals as well as equilibrium, stability and nonlinear oscillations, are part of the theory of the evolution of solutions of nonlinear equations. A wide range of mathematical tools and ideas are drawn together in the study of these solutions, and the results applied to diverse and countless problems in the natural and social sciences, even philosophy. The text evolves from courses given by the author in the UK and the United States. It introduces the mathematical properties of nonlinear systems, mostly difference and differential equations, as an integrated theory, rather than presenting isolated fashionable topics. Topics are discussed in as concrete a way as possible and worked examples and problems are used to explain, motivate and illustrate the general principles. The essence of these principles, rather than proof or rigour, is emphasized. More advanced parts of the text are denoted by asterisks, and the mathematical prerequisites are limited to knowledge of linear algebra and advanced calculus, thus making it ideally suited to both senior undergraduates and postgraduates from physics, engineering, chemistry, meteorology etc. as well as mathematics.},
	urldate = {2022-07-14},
	publisher = {Cambridge University Press},
	author = {Drazin, P. G.},
	year = {1992},
	doi = {10.1017/CBO9781139172455},
}

@article{morris_using_2019,
	title = {Using simulation studies to evaluate statistical methods},
	volume = {38},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8086},
	doi = {10.1002/sim.8086},
	abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
	language = {en},
	number = {11},
	urldate = {2022-07-07},
	journal = {Statistics in Medicine},
	author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8086},
	keywords = {Monte Carlo, graphics for simulation, simulation design, simulation reporting, simulation studies},
	pages = {2074--2102},
}

@article{chang_simultaneous_2017,
	title = {Simultaneous confidence bands for functional regression models},
	volume = {188},
	issn = {0378-3758},
	url = {https://www.sciencedirect.com/science/article/pii/S037837581730037X},
	doi = {10.1016/j.jspi.2017.03.002},
	abstract = {In recent years, the field of functional data analysis (FDA) has received a great deal of attention, and many useful theories and interesting applications have been reported. One topic of particular interest involves estimation of simultaneous confidence bands (SCB) for an unknown function. Degras (2011) proposed an estimator of SCBs for the mean function in a simple (no covariates) function-on-scalar regression model that relies on some assumptions on the tail behavior of the errors. In the case that such distributional assumptions do not hold, Degras also proposed a bootstrap method (sampling with replacement). We consider a more general function-on-scalar regression model that involves multiple covariates and allows the variance function of the functional responses to be dependent on the covariates (heterogeneity). In this general model, we propose a wild bootstrap method for estimating SCBs for the coefficient function. Some asymptotic results are provided for the simple case (no covariates) and simulation results for both the simple and general models.},
	language = {en},
	urldate = {2022-06-22},
	journal = {Journal of Statistical Planning and Inference},
	author = {Chang, Chung and Lin, Xuejing and Ogden, R. Todd},
	month = sep,
	year = {2017},
	keywords = {Functional regression model, Simultaneous confidence bands, Wild bootstrap},
	pages = {67--81},
}

@article{chang_simultaneous_2017-1,
	title = {Simultaneous confidence bands for functional regression models},
	volume = {188},
	issn = {0378-3758},
	url = {https://www.sciencedirect.com/science/article/pii/S037837581730037X},
	doi = {10.1016/j.jspi.2017.03.002},
	abstract = {In recent years, the field of functional data analysis (FDA) has received a great deal of attention, and many useful theories and interesting applications have been reported. One topic of particular interest involves estimation of simultaneous confidence bands (SCB) for an unknown function. Degras (2011) proposed an estimator of SCBs for the mean function in a simple (no covariates) function-on-scalar regression model that relies on some assumptions on the tail behavior of the errors. In the case that such distributional assumptions do not hold, Degras also proposed a bootstrap method (sampling with replacement). We consider a more general function-on-scalar regression model that involves multiple covariates and allows the variance function of the functional responses to be dependent on the covariates (heterogeneity). In this general model, we propose a wild bootstrap method for estimating SCBs for the coefficient function. Some asymptotic results are provided for the simple case (no covariates) and simulation results for both the simple and general models.},
	language = {en},
	urldate = {2022-06-22},
	journal = {Journal of Statistical Planning and Inference},
	author = {Chang, Chung and Lin, Xuejing and Ogden, R. Todd},
	month = sep,
	year = {2017},
	keywords = {Functional regression model, Simultaneous confidence bands, Wild bootstrap},
	pages = {67--81},
}

@article{goldsmith_variable_2017,
	title = {Variable selection in the functional linear concurrent model},
	volume = {36},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7254},
	doi = {10.1002/sim.7254},
	abstract = {We propose methods for variable selection in the context of modeling the association between a functional response and concurrently observed functional predictors. This data structure, and the need for such methods, is exemplified by our motivating example: a study in which blood pressure values are observed throughout the day, together with measurements of physical activity, location, posture, affect or mood, and other quantities that may influence blood pressure. We estimate the coefficients of the concurrent functional linear model using variational Bayes and jointly model residual correlation using functional principal components analysis. Latent binary indicators partition coefficient functions into included and excluded sets, incorporating variable selection into the estimation framework. The proposed methods are evaluated in simulations and real-data analyses, and are implemented in a publicly available R package with supporting interactive graphics for visualization. Copyright © 2017 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {14},
	urldate = {2022-06-20},
	journal = {Statistics in Medicine},
	author = {Goldsmith, Jeff and Schwartz, Joseph E.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7254},
	keywords = {ambulatory blood pressure, functional data, intensive longitudinal data, spline smoothing, variational Bayes, wearable devices},
	pages = {2237--2250},
}

@article{ghosal_score_2022,
	title = {A {Score} {Based} {Test} for {Functional} {Linear} {Concurrent} {Regression}},
	volume = {21},
	issn = {2452-3062},
	url = {https://www.sciencedirect.com/science/article/pii/S2452306221000617},
	doi = {10.1016/j.ecosta.2021.05.003},
	abstract = {A novel method for testing the null hypothesis of no effect of a covariate on the response is proposed in functional linear concurrent regression. An equivalent random effects formulation of the functional regression model is established under which the testing problem reduces to testing for zero variance component for random effects. For this purpose, a one-sided score test approach is used, which is an extension of the classical score test. Theoretical justification is provided as to why the proposed testing procedure has the correct levels (asymptotically) under null using standard assumptions. Using numerical simulations, the testing method is shown to have the desired type I error rate and higher power compared to a bootstrapped F test currently existing in the literature. The model and the testing procedure give good performances even when the data are sparsely observed, and the functional covariate is contaminated with noise. Applications of the proposed testing method are demonstrated on gait data and a study of child mortality.},
	language = {en},
	urldate = {2022-06-20},
	journal = {Econometrics and Statistics},
	author = {Ghosal, Rahul and Maity, Arnab},
	month = jan,
	year = {2022},
	keywords = {Functional linear concurrent regression, Functional principal component analysis, Hypothesis testing, Score test},
	pages = {114--130},
}

@article{maity_nonparametric_2017,
	title = {Nonparametric functional concurrent regression models},
	volume = {9},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1394},
	doi = {10.1002/wics.1394},
	abstract = {Function-on-function regression refers to the situation where both independent and dependent variables in a regression model are of functional nature. Functional concurrent regression is a specific type of function-on-function regression that relates the response function at a specific point to the covariate value at that point and the point itself. Standard functional concurrent models are linear (a linear combination of the covariates is used), and often criticized due to their linearity assumption and lack of flexibility. This gives rise to nonparametric functional concurrent regression that models the response function at a specific point using a multivariate nonparametric function of both the point and the covariate value at that point. Such models allow for much more flexibility and predictive accuracy, especially when the underlying relationship is nonlinear. In the past decade, several methods have been proposed to perform estimation, prediction and inference in the nonparametric concurrent models using various methods such as spline smoothing, Gaussian process regression and local polynomial kernel regression. Such models have been shown to be useful tools in functional regression as well as stepping stone for further development. WIREs Comput Stat 2017, 9:e1394. doi: 10.1002/wics.1394 This article is categorized under: Statistical and Graphical Methods of Data Analysis {\textgreater} Nonparametric Methods},
	language = {en},
	number = {2},
	urldate = {2022-06-20},
	journal = {WIREs Computational Statistics},
	author = {Maity, Arnab},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1394},
	keywords = {Functional concurrent regression, Functional data analysis, Gaussian process regression, Kernel smoothing, Nonparametric regression, Spline regression},
	pages = {e1394},
}

@incollection{ramsay_principal_2006,
	title = {Principal {Differential} {Analysis}},
	isbn = {978-0-471-66719-3},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471667196.ess5023.pub2},
	abstract = {Differential equation systems are often a natural way of describing sets of variables changing over time or space. For example, in controlling industrial systems, engineers consider the time course of a set of inputs and outputs for a system such as a chemical reactor with a view to developing useful feedback processes. Principal differential analysis uses functional data to estimate a system of linear differential equations that fit the data. The estimate minimizes an integrated squared error criterion. The coefficient functions that define the linear differential equation are estimated by expansions in terms of basis functions such as Fourier series or B-splines, and the estimates are calculated rapidly and without iteration.},
	language = {en},
	urldate = {2022-06-17},
	booktitle = {Encyclopedia of {Statistical} {Sciences}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Ramsay, James O.},
	year = {2006},
	doi = {10.1002/0471667196.ess5023.pub2},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471667196.ess5023.pub2},
	keywords = {differential euqation, dynamic model, linear differential equation, linear differential operator, principal component analysis},
}

@article{carroll_review_2001,
	title = {Review {Times} in {Statistical} {Journals}: {Tilting} at {Windmills}?},
	volume = {57},
	issn = {0006-341X},
	shorttitle = {Review {Times} in {Statistical} {Journals}},
	url = {https://www.jstor.org/stable/2676835},
	abstract = {Using limited data, I argue that the review times in statistics are far too long for the field to keep pace with the rapidly changing environment in science. I note that statisticians do not appear to believe in statistics because data on the review process are not widely available to members of the profession. I suggest a few changes that could be made to speed up the review process, although it would appear that a change in our culture is required before the problem will be solved.},
	number = {1},
	urldate = {2022-06-14},
	journal = {Biometrics},
	author = {Carroll, Raymond J.},
	year = {2001},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {1--6},
}

@article{marron_effective_1999,
	title = {Effective writing in mathematical statistics},
	volume = {53},
	issn = {1467-9574},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9574.00098},
	doi = {10.1111/1467-9574.00098},
	abstract = {Care should be taken in the writing of papers in mathematical statistics for two reasons. First this enhances a paper's chances to be accepted for publication in a top journal. Second the contributions of a paper will reach a wider audience if the main ideas are easily accessible. This paper gives suggestions for improvement in two directions: presentation of mathematics and organization of papers.},
	language = {en},
	number = {1},
	urldate = {2022-06-12},
	journal = {Statistica Neerlandica},
	author = {Marron, J. S.},
	year = {1999},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9574.00098},
	keywords = {presentation of mathematics, reviewing, writing},
	pages = {68--75},
}

@article{staniswalis_local_2017,
	title = {Local principal differential analysis: {Graphical} methods for functional data with covariates},
	volume = {46},
	issn = {0361-0918},
	shorttitle = {Local principal differential analysis},
	url = {https://doi.org/10.1080/03610918.2015.1043387},
	doi = {10.1080/03610918.2015.1043387},
	abstract = {We focus on principal differential analysis (PDA) of functional data for obtaining a low-dimensional representation of a collection of curves. PDA assumes there exists a linear differential operator that results in the zero-function when it is applied to each of the data curves, or equivalently, that the curves belong to a low-dimensional subspace of a normed linear space. PDA sets out to estimate this linear differential operator from the data and proceeds from there. Our contribution is to explain how subject covariates can be incorporated into a PDA analysis for graphical exploration of patterns in the data.},
	number = {3},
	urldate = {2022-06-12},
	journal = {Communications in Statistics - Simulation and Computation},
	author = {Staniswalis, Joan G. and Dodoo, Christopher and Sharma, Anu},
	month = mar,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03610918.2015.1043387},
	keywords = {62G08, CAEP curves, Differential operator, Low-dimensional approximation.},
	pages = {2346--2359},
}

@techreport{li_automatic_2022,
	title = {Automatic {Search} {Interval} for {Smoothing} {Parameter} in {Penalized} {Splines}},
	url = {http://arxiv.org/abs/2205.15157},
	abstract = {The selection of smoothing parameter is central to estimation of penalized splines. The best parameter value is often the one that optimizes a smoothness selection criterion, like the minimizer of generalized cross-validation error (GCV) and the maximizer of restricted likelihood (REML). To avoid ending up with an undesired local extremum rather than the global extremum, grid search should be used for optimization. Unfortunately, the method requires a pre-specified search interval that contains the unknown global extremum and there has not been any theory on how it could be provided. As a result, practitioners have to find it by trial and error. To overcome such difficulty, we develop novel algorithms to automatically find this interval. Our automatic search interval has four advantages. (i) It specifies a smoothing parameter range where the penalized least squares problem is numerically solvable. (ii) It is criterion-independent, so that different criteria like GCV and REML can be explored on the same parameter range. (iii) It is sufficiently wide to contain the global extremum of any criterion, so that for example, the global minimum of GCV and the global maximum of REML can both be identified. (iv) It is computationally cheap compared with grid search so that it carries no extra costs in practice. Our method is ready to use through R package gps ({\textgreater}= version 1.1). It may be embedded in other advanced statistical modeling methods that rely on penalized splines.},
	number = {arXiv:2205.15157},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Li, Zheyuan and Cao, Jiguo},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.15157},
	note = {arXiv:2205.15157 [stat]
type: article},
	keywords = {Statistics - Computation, Statistics - Methodology},
}

@inproceedings{yao_deep_2021,
	title = {Deep {Learning} for {Functional} {Data} {Analysis} with {Adaptive} {Basis} {Layers}},
	url = {https://proceedings.mlr.press/v139/yao21c.html},
	abstract = {Despite their widespread success, the application of deep neural networks to functional data remains scarce today. The infinite dimensionality of functional data means standard learning algorithms can be applied only after appropriate dimension reduction, typically achieved via basis expansions. Currently, these bases are chosen a priori without the information for the task at hand and thus may not be effective for the designated task. We instead propose to adaptively learn these bases in an end-to-end fashion. We introduce neural networks that employ a new Basis Layer whose hidden units are each basis functions themselves implemented as a micro neural network. Our architecture learns to apply parsimonious dimension reduction to functional inputs that focuses only on information relevant to the target rather than irrelevant variation in the input function. Across numerous classification/regression tasks with functional data, our method empirically outperforms other types of neural networks, and we prove that our approach is statistically consistent with low generalization error.},
	language = {en},
	urldate = {2022-06-09},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Yao, Junwen and Mueller, Jonas and Wang, Jane-Ling},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {11898--11908},
}

@article{g_e_white_effects_2022,
	title = {The effects of curve registration on linear models of jump performance and classification based on vertical ground reaction forces},
	volume = {140},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929022002123},
	doi = {10.1016/j.jbiomech.2022.111167},
	abstract = {Functional principal components define modes of variation in time series, which represent characteristic movement patterns in biomechanical data. Their usefulness however depends on the prior choices made in data processing. Recent research showed that better curve alignment achieved with registration (dynamic time warping) reduces errors in linear models predicting jump height. However, the efficacy of registration in different preprocessing combinations, including time normalisation, padding and feature extraction, is largely unknown. A more comprehensive analysis is needed, given the potential value of registration to machine learning in biomechanics. We evaluated popular preprocessing methods combined with registration, creating 512 models based on ground reaction force data from 385 countermovement jumps. The models either predicted jump height or classified jumps into those performed with or without arm swing. Our results show that the classification models benefited from registration in various forms, particularly when landmarks were placed at critical points. The best classifier achieved a 5.5 percentage point improvement over the equivalent unregistered model. However, registration was detrimental to the jump height models, although this performance variable may be a special case given its direct relationship with impulse. Our meta-models revealed the relative contributions made by various preprocessing operations, highlighting that registration does not generalise so well to new data. Nonetheless, our analysis shows the potential for registration in further biomechanical applications, particularly in classification, when combined with the other appropriate preprocessing operations.},
	language = {en},
	urldate = {2022-06-09},
	journal = {Journal of Biomechanics},
	author = {G. E. White, Mark and Neville, Jonathon and Rees, Paul and Summers, Huw and Bezodis, Neil},
	month = jul,
	year = {2022},
	keywords = {Analysis of Characterising Phases, Classification models, Countermovement jump, Curve registration, Dynamic Time Warping, Functional Principal Component Analysis},
	pages = {111167},
}

@article{alves_ground_2022,
	title = {Ground reaction forces and external hip joint moments predict in vivo hip contact forces during gait},
	volume = {135},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929022000938},
	doi = {10.1016/j.jbiomech.2022.111037},
	abstract = {Younger patients increasingly receive total hip arthroplasty (THA) as therapy for end-stage osteoarthritis. To maintain the long-term success of THA in such patients, avoiding extremely high hip loads, i.e., in vivo hip contact force (HCF), is considered essential. However, in vivo HCFs are difficult to determine and their direct measurement is limited to instrumented joint implants. It remains unclear whether external measurements of ground reaction forces (GRFs), a non-invasive, markerless and clinic-friendly measure can estimate in vivo HCFs. Using data from eight patients with instrumented hip implants, this study determined whether GRF time series data, alone or combined with other scalar variables such as hip joint moments (HJMs) and lean muscle volume (LMV), could predict the resultant HCF (rHCF) impulse using a functional linear modeling approach. Overall, single GRF time series data did not predict in vivo rHCF impulses. However, when GRF time series data were combined with LMV of the gluteus medius or sagittal HJM using a functional linear modeling approach, the in vivo rHCF impulse could be predicted from external measures only. Accordingly, this approach can predict in vivo rHCF impulses, and thus provide patients with useful insight regarding their gait behavior to avoid hip joint overloading.},
	language = {en},
	urldate = {2022-06-09},
	journal = {Journal of Biomechanics},
	author = {Alves, Sónia A. and Polzehl, Jörg and Brisson, Nicholas M. and Bender, Alwina and Agres, Alison N. and Damm, Philipp and Duda, Georg N.},
	month = apr,
	year = {2022},
	keywords = {Functional data analysis, Ground reaction forces, Hip joint moments, Total hip arthroplasty, hip contact forces},
	pages = {111037},
}

@article{acal_basis_2022,
	title = {Basis expansion approaches for functional analysis of variance with repeated measures},
	issn = {1862-5355},
	url = {https://doi.org/10.1007/s11634-022-00500-y},
	doi = {10.1007/s11634-022-00500-y},
	abstract = {The methodological contribution in this paper is motivated by biomechanical studies where data characterizing human movement are waveform curves representing joint measures such as flexion angles, velocity, acceleration, and so on. In many cases the aim consists of detecting differences in gait patterns when several independent samples of subjects walk or run under different conditions (repeated measures). Classic kinematic studies often analyse discrete summaries of the sample curves discarding important information and providing biased results. As the sample data are obviously curves, a Functional Data Analysis approach is proposed to solve the problem of testing the equality of the mean curves of a functional variable observed on several independent groups under different treatments or time periods. A novel approach for Functional Analysis of Variance (FANOVA) for repeated measures that takes into account the complete curves is introduced. By assuming a basis expansion for each sample curve, two-way FANOVA problem is reduced to Multivariate ANOVA for the multivariate response of basis coefficients. Then, two different approaches for MANOVA with repeated measures are considered. Besides, an extensive simulation study is developed to check their performance. Finally, two applications with gait data are developed.},
	language = {en},
	urldate = {2022-06-09},
	journal = {Advances in Data Analysis and Classification},
	author = {Acal, Christian and Aguilera, Ana M.},
	month = apr,
	year = {2022},
	keywords = {62J05, 62J10, Biomechanics, Functional data analysis, Multivariate analysis of variance, Repeated measures, Splines},
}

@misc{bolker_rpubs_2012,
	title = {{RPubs} - {Multivariate} analysis with mixed model tools in {R}},
	url = {https://rpubs.com/bbolker/3336},
	urldate = {2022-06-03},
	author = {Bolker, Ben},
	month = dec,
	year = {2012},
}

@article{reiss_methods_2017,
	title = {Methods for {Scalar}-on-{Function} {Regression}},
	volume = {85},
	issn = {1751-5823},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12163},
	doi = {10.1111/insr.12163},
	abstract = {Recent years have seen an explosion of activity in the field of functional data analysis (FDA), in which curves, spectra, images and so on are considered as basic functional data units. A central problem in FDA is how to fit regression models with scalar responses and functional data points as predictors. We review some of the main approaches to this problem, categorising the basic model types as linear, non-linear and non-parametric. We discuss publicly available software packages and illustrate some of the procedures by application to a functional magnetic resonance imaging data set.},
	language = {en},
	number = {2},
	urldate = {2022-06-03},
	journal = {International Statistical Review},
	author = {Reiss, Philip T. and Goldsmith, Jeff and Shang, Han Lin and Ogden, R. Todd},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12163},
	keywords = {Functional additive model, functional generalised linear model, functional linear model, functional polynomial regression, functional single-index model, non-parametric functional regression},
	pages = {228--249},
}

@article{li_fixed-effects_nodate,
	title = {Fixed-effects inference and tests of correlation for longitudinal functional data},
	volume = {n/a},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9421},
	doi = {10.1002/sim.9421},
	abstract = {We propose an inferential framework for fixed effects in longitudinal functional models and introduce tests for the correlation structures induced by the longitudinal sampling procedure. The framework provides a natural extension of standard longitudinal correlation models for scalar observations to functional observations. Using simulation studies, we compare fixed effects estimation under correctly and incorrectly specified correlation structures and also test the longitudinal correlation structure. Finally, we apply the proposed methods to a longitudinal functional dataset on physical activity. The computer code for the proposed method is available at https://github.com/rli20ST758/FILF.},
	language = {en},
	number = {n/a},
	urldate = {2022-05-31},
	journal = {Statistics in Medicine},
	author = {Li, Ruonan and Xiao, Luo and Smirnova, Ekaterina and Cui, Erjia and Leroux, Andrew and Crainiceanu, Ciprian M.},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9421},
	keywords = {accelerometry data, covariance function, hypothesis test, mixed effects model},
}

@article{cui_fast_2022,
	title = {Fast {Univariate} {Inference} for {Longitudinal} {Functional} {Models}},
	volume = {31},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2021.1950006},
	doi = {10.1080/10618600.2021.1950006},
	abstract = {We propose fast univariate inferential approaches for longitudinal Gaussian and non-Gaussian functional data. The approach consists of three steps: (i) fit massively univariate pointwise mixed-effects models; (ii) apply any smoother along the functional domain; and (iii) obtain joint confidence bands using analytic approaches for Gaussian data or a bootstrap of study participants for non-Gaussian data. Methods are motivated by two applications: (i) Diffusion tensor imaging measured at multiple visits along the corpus callosum of multiple sclerosis patients; and (ii) physical activity (PA) data measured by body-worn accelerometers for multiple days. An extensive simulation study indicates that model fitting and inference are accurate and much faster than existing approaches. Moreover, the proposed approach was the only one that was computationally feasible for the PA data application. Methods are accompanied by R software, though the method is “read-and-use,” as it can be implemented by any analyst who is familiar with mixed-effects model software. Supplementary files for this article are available online.},
	number = {1},
	urldate = {2022-05-31},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cui, Erjia and Leroux, Andrew and Smirnova, Ekaterina and Crainiceanu, Ciprian M.},
	month = jan,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2021.1950006},
	keywords = {DTI, Longitudinal functional data, Mixed model, Wearable devices},
	pages = {219--230},
}

@misc{shi_2dfpca_2021,
	title = {{2DFPCA} ({Two}-{Dimensional} {Functional} {Principal} {Component} {Analysis} for {Image} {Feature} {Extraction})},
	url = {https://github.com/haoluns/2DFPCA/blob/bac2aacad090591482ec13403b817a727244694a/Readme.md},
	urldate = {2022-05-23},
	author = {Shi, Haolun},
	month = aug,
	year = {2021},
	note = {original-date: 2019-06-04T23:51:56Z},
}

@misc{noauthor_2dfpcafpc_0and1xrdata_nodate,
	title = {{2DFPCA}/fpc\_0and1x.{RData} at master · haoluns/{2DFPCA}},
	url = {https://github.com/haoluns/2DFPCA},
	abstract = {Contribute to haoluns/2DFPCA development by creating an account on GitHub.},
	language = {en},
	urldate = {2022-05-23},
	journal = {GitHub},
}

@article{shi_two-dimensional_2022,
	title = {Two-{Dimensional} {Functional} {Principal} {Component} {Analysis} for {Image} {Feature} {Extraction}},
	volume = {0},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2022.2035738},
	doi = {10.1080/10618600.2022.2035738},
	abstract = {Methodologies for functional principal component analysis are well established in the one-dimensional setting. However, for two-dimensional surfaces, for example, images, conducting functional principal component analysis is complicated and challenging, because the conventional eigendecomposition approach would require the estimation of a four-dimensional covariance function, which may incur high cost in terms of time and machine memory. To circumvent such computational difficulties, we propose a novel two-dimensional functional principal component analysis for extracting functional principal components and achieving dimensionality reduction for images. Different from the conventional eigendecomposition approach, our proposed method is based on the direct estimation of the optimal two-dimensional functional principal components via tensor product B-spline, which opens up a new avenue for estimating functional principal components. We present theoretical results that prove the consistency of the proposed approach. Our method is illustrated by analyzing brain images of subjects with the Alzheimer’s Disease and the handwritten digits images. The finite sample performance of our method is further assessed with some simulation studies. Supplementary materials for this article are available online.},
	number = {0},
	urldate = {2022-05-16},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Shi, Haolun and Yang, Yuping and Wang, Liangliang and Ma, Da and Beg, Mirza Faisal and Pei, Jian and Cao, Jiguo},
	month = feb,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2022.2035738},
	keywords = {Eigendecomposition, Functional data analysis, Two-dimensional surfaces},
	pages = {1--14},
}

@article{li_fixed-effects_nodate-1,
	title = {Fixed-effects inference and tests of correlation for longitudinal functional data},
	volume = {n/a},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9421},
	doi = {10.1002/sim.9421},
	abstract = {We propose an inferential framework for fixed effects in longitudinal functional models and introduce tests for the correlation structures induced by the longitudinal sampling procedure. The framework provides a natural extension of standard longitudinal correlation models for scalar observations to functional observations. Using simulation studies, we compare fixed effects estimation under correctly and incorrectly specified correlation structures and also test the longitudinal correlation structure. Finally, we apply the proposed methods to a longitudinal functional dataset on physical activity. The computer code for the proposed method is available at https://github.com/rli20ST758/FILF.},
	language = {en},
	number = {n/a},
	urldate = {2022-05-12},
	journal = {Statistics in Medicine},
	author = {Li, Ruonan and Xiao, Luo and Smirnova, Ekaterina and Cui, Erjia and Leroux, Andrew and Crainiceanu, Ciprian M.},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9421},
	keywords = {accelerometry data, covariance function, hypothesis test, mixed effects model},
}

@misc{noauthor_tidy_nodate,
	title = {Tidy {Data} {\textbar} {Journal} of {Statistical} {Software}},
	url = {https://www.jstatsoft.org/article/view/v059i10},
	urldate = {2022-05-11},
}

@article{hadjipantelis_unifying_2015,
	title = {Unifying {Amplitude} and {Phase} {Analysis}: {A} {Compositional} {Data} {Approach} to {Functional} {Multivariate} {Mixed}-{Effects} {Modeling} of {Mandarin} {Chinese}},
	volume = {110},
	issn = {0162-1459},
	shorttitle = {Unifying {Amplitude} and {Phase} {Analysis}},
	url = {https://doi.org/10.1080/01621459.2015.1006729},
	doi = {10.1080/01621459.2015.1006729},
	abstract = {Mandarin Chinese is characterized by being a tonal language; the pitch (or F0) of its utterances carries considerable linguistic information. However, speech samples from different individuals are subject to changes in amplitude and phase, which must be accounted for in any analysis that attempts to provide a linguistically meaningful description of the language. A joint model for amplitude, phase, and duration is presented, which combines elements from functional data analysis, compositional data analysis, and linear mixed effects models. By decomposing functions via a functional principal component analysis, and connecting registration functions to compositional data analysis, a joint multivariate mixed effect model can be formulated, which gives insights into the relationship between the different modes of variation as well as their dependence on linguistic and nonlinguistic covariates. The model is applied to the COSPRO-1 dataset, a comprehensive database of spoken Taiwanese Mandarin, containing approximately 50,000 phonetically diverse sample F0 contours (syllables), and reveals that phonetic information is jointly carried by both amplitude and phase variation. Supplementary materials for this article are available online.},
	number = {510},
	urldate = {2022-05-08},
	journal = {Journal of the American Statistical Association},
	author = {Hadjipantelis, P. Z. and Aston, J. A. D. and Müller, H. G. and Evans, J. P.},
	month = apr,
	year = {2015},
	pmid = {26692591},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2015.1006729},
	keywords = {Functional data analysis, Linguistics, Multivariate linear mixed models, Phonetic analysis, Registration},
	pages = {545--559},
}

@article{wahba_bayesian_1983,
	title = {Bayesian "{Confidence} {Intervals}" for the {Cross}-{Validated} {Smoothing} {Spline}},
	volume = {45},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345632},
	abstract = {We consider the model Y(t$_{\textrm{i}}$) = g(t$_{\textrm{i}}$) = ε$_{\textrm{i}}$, i = 1, 2,..., n, where g(t), t ∈ [ 0, 1] is a smooth function and the \{ε$_{\textrm{i}}$\} are independent N(0, σ$^{\textrm{2}}$) errors with σ$^{\textrm{2}}$ unknown. The cross-validated smoothing spline can be used to estimate g non-parametrically from observations on Y(t$_{\textrm{i}}$), i = 1, 2,..., n, and the purpose of this paper is to study confidence intervals for this estimate. Properties of smoothing splines as Bayes estimates are used to derive confidence intervals based on the posterior covariance functiion of the estimate. A small Monte Carlo study with the cubic smoothing spline is carried out to suggest by example to what extent the resulting 95 per cent confidence intervals can be expected to cover about 95 per cent of the true (but in practice unknown) values of g(t$_{\textrm{i}}$), i = 1, 2,..., n. The method was also applied to one example of a two-dimensional thin plate smoothing spline. An asymptotic theoretical argument is presented to explain why the method can be expected to work on fixed smooth functions (like those tried), which are "smoother" than the sample functions from the prior distributions on which the confidence interval theory is based.},
	number = {1},
	urldate = {2022-05-06},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Wahba, Grace},
	year = {1983},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {133--150},
}

@article{lee_bayesian_2019,
	title = {Bayesian {Semiparametric} {Functional} {Mixed} {Models} for {Serially} {Correlated} {Functional} {Data}, {With} {Application} to {Glaucoma} {Data}},
	volume = {114},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2018.1476242},
	doi = {10.1080/01621459.2018.1476242},
	abstract = {Glaucoma, a leading cause of blindness, is characterized by optic nerve damage related to intraocular pressure (IOP), but its full etiology is unknown. Researchers at UAB have devised a custom device to measure scleral strain continuously around the eye under fixed levels of IOP, which here is used to assess how strain varies around the posterior pole, with IOP, and across glaucoma risk factors such as age. The hypothesis is that scleral strain decreases with age, which could alter biomechanics of the optic nerve head and cause damage that could eventually lead to glaucoma. To evaluate this hypothesis, we adapted Bayesian Functional Mixed Models to model these complex data consisting of correlated functions on spherical scleral surface, with nonparametric age effects allowed to vary in magnitude and smoothness across the scleral surface, multi-level random effect functions to capture within-subject correlation, and functional growth curve terms to capture serial correlation across IOPs that can vary around the scleral surface. Our method yields fully Bayesian inference on the scleral surface or any aggregation or transformation thereof, and reveals interesting insights into the biomechanical etiology of glaucoma. The general modeling framework described is very flexible and applicable to many complex, high-dimensional functional data. Supplementary materials for this article are available online.},
	number = {526},
	urldate = {2022-04-28},
	journal = {Journal of the American Statistical Association},
	author = {Lee, Wonyul and Miranda, Michelle F. and Rausch, Philip and Baladandayuthapani, Veerabhadran and Fazio, Massimo and Downs, J. Crawford and Morris, Jeffrey S.},
	month = apr,
	year = {2019},
	pmid = {31235987},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2018.1476242},
	keywords = {Functional data analysis, Functional mixed models, Functional regression, Longitudinal functional data, Nonparametric effects, Smoothing splines},
	pages = {495--513},
}

@article{van_emmerik_comparing_2016,
	title = {Comparing dynamical systems concepts and techniques for biomechanical analysis},
	volume = {5},
	issn = {2095-2546},
	url = {https://www.sciencedirect.com/science/article/pii/S2095254616000156},
	doi = {10.1016/j.jshs.2016.01.013},
	abstract = {Traditional biomechanical analyses of human movement are generally derived from linear mathematics. While these methods can be useful in many situations, they do not describe behaviors in human systems that are predominately nonlinear. For this reason, nonlinear analysis methods based on a dynamical systems approach have become more prevalent in recent literature. These analysis techniques have provided new insights into how systems (1) maintain pattern stability, (2) transition into new states, and (3) are governed by short- and long-term (fractal) correlational processes at different spatio-temporal scales. These different aspects of system dynamics are typically investigated using concepts related to variability, stability, complexity, and adaptability. The purpose of this paper is to compare and contrast these different concepts and demonstrate that, although related, these terms represent fundamentally different aspects of system dynamics. In particular, we argue that variability should not uniformly be equated with stability or complexity of movement. In addition, current dynamic stability measures based on nonlinear analysis methods (such as the finite maximal Lyapunov exponent) can reveal local instabilities in movement dynamics, but the degree to which these local instabilities relate to global postural and gait stability and the ability to resist external perturbations remains to be explored. Finally, systematic studies are needed to relate observed reductions in complexity with aging and disease to the adaptive capabilities of the movement system and how complexity changes as a function of different task constraints.},
	language = {en},
	number = {1},
	urldate = {2022-04-27},
	journal = {Journal of Sport and Health Science},
	author = {van Emmerik, Richard E. A. and Ducharme, Scott W. and Amado, Avelino C. and Hamill, Joseph},
	month = mar,
	year = {2016},
	keywords = {Adaptability, Complexity, Dynamical systems, Nonlinear dynamics, Stability, Variability},
	pages = {3--13},
}

@incollection{lamb_assessing_2017-1,
	title = {Assessing movement coordination},
	isbn = {978-0-203-09554-6},
	author = {Lamb, Peter and Bartlett, Roger},
	month = dec,
	year = {2017},
	doi = {10.4324/9780203095546-3},
}

@article{jin_principal_2013,
	title = {Principal {Differential} {Analysis} with a {Continuous} {Covariate}: {Low} {Dimensional} {Approximations} for {Functional} {Data}},
	volume = {83},
	issn = {0094-9655},
	shorttitle = {Principal {Differential} {Analysis} with a {Continuous} {Covariate}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3811972/},
	doi = {10.1080/00949655.2012.675575},
	abstract = {Given a collection of n curves that are independent realizations of a functional variable, we are interested in finding patterns in the curve data by exploring low dimensional approximations to the curves. It is assumed that the data curves are noisy samples from the vector space span\{f1, …, fm\}, where f1, …, fm are unknown functions on the real interval (0, T) with square-integrable derivatives of all orders m or less, and m {\textless} n.  first proposed the method of regularized principal differential analysis as an alternative to principal component analysis for finding low dimensional approximations to curves. Principal differential analysis (PDA) is based on the following theorem: there exists an annihilating linear differential operator L of order m such that Lfi=0, i = 1, …, m (, Theorem 6.2). Principal differential analysis specifies m, then uses the data to estimate an annihilating linear differential operator (LDO). Smooth estimates of the coefficients of the LDO are obtained by minimizing a penalized sum of the squared norm of the residuals. In this context, the residual is that part of the data curve that is not annihilated by the LDO. PDA obtains the smooth low dimensional approximation to the data curves by projecting onto the null space of the estimated annihilating LDO; PDA is thus useful for obtaining low dimensional approximations to the data curves whether or not the interpretation of the annihilating LDO is intuitive or obvious from the context of the data. This paper extends PDA to allow for the coefficients in the linear differential operator to smoothly depend upon a single continuous covariate. The estimating equations for the coefficients allowing for a continuous covariate are derived; the penalty of  is used to impose smoothness. The results of a small computer simulation study investigating the bias and variance properties of the estimator are reported.},
	number = {10},
	urldate = {2022-04-21},
	journal = {Journal of statistical computation and simulation},
	author = {Jin, Seoweon and Staniswalis, Joan G. and Mallawaarachchi, Indika},
	month = jan,
	year = {2013},
	pmid = {24187396},
	pmcid = {PMC3811972},
	pages = {10.1080/00949655.2012.675575},
}

@article{ramsay_principal_1996,
	title = {Principal {Differential} {Analysis}: {Data} {Reduction} by {Differential} {Operators}},
	volume = {58},
	issn = {0035-9246},
	shorttitle = {Principal {Differential} {Analysis}},
	url = {https://www.jstor.org/stable/2345889},
	abstract = {Functional data are observations that are either themselves functions or are naturally representable as functions. When these functions can be considered smooth, it is natural to use their derivatives in exploring their variation. Principal differential analysis (PDA) identifies a linear differential operator L = w$_{\textrm{0I}}$ + w$_{\textrm{1D}}$ + ... + w$_{\textrm{m-1}}$D$^{\textrm{m-1}}$ + D$^{\textrm{m}}$ that comes as close as possible to annihilating a sample of functions. Convenient procedures for estimating the m weighting functions w$_{\textrm{j}}$ are developed. The estimated differential operator L is analogous to the projection operator used as the data annihilator in principal components analysis and thus can be viewed as a type of data reduction or exploration tool. The corresponding linear differential equation may also have a useful substantive interpretation. Modelling and regularization features can also be incorporated into PDA.},
	number = {3},
	urldate = {2022-04-04},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Ramsay, James O.},
	year = {1996},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {495--508},
}

@article{dallarosa_principal_2014,
	title = {Principal differential analysis of the {Aneurisk65} data set},
	volume = {8},
	issn = {1862-5355},
	url = {https://doi.org/10.1007/s11634-014-0175-5},
	doi = {10.1007/s11634-014-0175-5},
	abstract = {We explore the use of principal differential analysis as a tool for performing dimensional reduction of functional data sets. In particular, we compare the results provided by principal differential analysis and by functional principal component analysis in the dimensional reduction of three synthetic data sets, and of a real data set concerning 65 three-dimensional cerebral geometries, the AneuRisk65 data set. The analyses show that principal differential analysis can provide an alternative and effective representation of functional data, easily interpretable in terms of exponential, sinusoidal, or damped-sinusoidal functions and providing a different insight to the functional data set under investigation. Moreover, in the analysis of the AneuRisk65 data set, principal differential analysis is able to detect interesting features of the data, such as the rippling effect of the vessel surface, that functional principal component analysis is not able to detect.},
	language = {en},
	number = {3},
	urldate = {2022-04-20},
	journal = {Advances in Data Analysis and Classification},
	author = {Dalla Rosa, Matilde and Sangalli, Laura M. and Vantini, Simone},
	month = sep,
	year = {2014},
	keywords = {62H25, 62H30, 62P10, Dimensional reduction, Functional data analysis, Functional principal component analysis, Principal differential analysis},
	pages = {287--302},
}

@phdthesis{barraza_estimating_2017,
	address = {United States -- Texas},
	type = {Ph.{D}.},
	title = {Estimating the {Coefficients} of a {Linear} {Differential} {Operator}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/2015586456/abstract/724842BFC517421CPQ/1},
	abstract = {Principal Differential Analysis (PDA; Ramsay, 1996) is used to obtain low dimensional representations of functional data, where each observation is represented as a curve. PDA seeks to identify a Linear Differential Operator (LDO) L = ω0I + ω 1D + ... + ωmDm, where I denotes the identity function and D j the jth derivative, that satisfies as closely as possible that Lx = 0 for each functional observation x. A theorem from analysis establishes that the coefficients of the LDO are in the Sobolev space, and thus can be approximated by B-splines. Current PDA software used to estimate the LDO assumes that the leading coefficient is 1, and approximates the LDO coefficients by B-splines, even though the Sobolev space is not closed under division. We present a method that eliminates the restriction on the leading coefficient of the LDO. The proposed resampling method is inspired by results in linear regression (Frees, 1991 and Wu, 1986) that show that the weighted average of all (n m) pairwise slopes between n data points is equivalent to the least squares estimator of the regression line slope. In analyzing data, least-squares estimates and robust estimates of the LDO coefficients are computed, and results based on each estimate are compared. The R language implementation of the proposed method is available at https://www.utep.edu/science/computational-science/research/resources.html.},
	language = {English},
	urldate = {2022-04-19},
	school = {The University of Texas at El Paso},
	author = {Barraza, María Ivette},
	year = {2017},
	note = {ISBN: 9780355603613},
	keywords = {Functional data, Principal differential analysis, Pure sciences, Robust estimator},
}

@mastersthesis{mallawaarachchi_principal_2011,
	address = {United States -- Texas},
	title = {Principal differential analysis with covariates: {A} simulation study on the effect of the smoothing parameters},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	shorttitle = {Principal differential analysis with covariates},
	url = {https://www.proquest.com/docview/892083785/abstract/80676693800F44A0PQ/1},
	abstract = {Principal Differential Analysis deals with functional data. The word functional data refers to a collection of curves that are independent and measured on a dense grid of time points in an interval. These time points can be equally or unequally spaced. A differential equation is believed capable of capturing the features of these n curves.
Ramsay(1996) first introduced Principal Differential Analysis (PDA) as an alternative to the Principal Component Analysis(PCA). PDA finds a linear differential equation that captures features of a collection of curves, in order to have a low dimensional approximation for functional data. PDA is based on the theorem: the span of the functions f 1 ,…, fm with m derivatives has an annihilating linear differential operator(LDO) of the form L = w0I + w 1D + ,…, w m−1Dm −1 + wmDm.
In PDA the coefficients w0 , … , wm of the LDO are estimated using data for a specified m. The sum of squared norms of the residuals with penalty is used as the fitting criterion. Here the residual is that part of the data curve that is not annihilated by the LDO. The penalty of Eilers and Marx(1996) is used to impose the smoothness. A low-dimensional approximation of the curve data can be obtained by a linear combination of the null space basis functions.
Jin(2006) developed the theory for PDA with covariates when functional data collected from experimental units are described by covariates. This thesis is a Monte-Carlo simulation study to identify the effect of the smoothing parameters for the bias and variance of the estimators in PDA with covariates. Implementations of Jin(2006) were translated from Splus to R and were made to run more efficiently. A hearing data set taken from Wood(2007) was analyzed using PDA with covariates.},
	language = {English},
	urldate = {2022-04-19},
	school = {The University of Texas at El Paso},
	author = {Mallawaarachchi, Indika Varuna},
	year = {2011},
	note = {ISBN: 9781124850573},
	keywords = {Curve data, Principal differential analysis, Pure sciences, Smoothing},
}

@article{sundstrom_runners_2021,
	title = {Runners {Adapt} {Different} {Lower}-{Limb} {Movement} {Patterns} {With} {Respect} to {Different} {Speeds} and {Downhill} {Slopes}},
	volume = {3},
	issn = {2624-9367},
	url = {https://www.frontiersin.org/article/10.3389/fspor.2021.682401},
	abstract = {The aim of this study was to investigate the influence of slope and speed on lower-limb kinematics and energy cost of running. Six well-trained runners (VO2max 72 ± 6 mL·kg−1·min−1) were recruited for the study and performed (1) VO2max and energy cost tests and (2) an experimental running protocol at two speeds, 12 km·h−1 and a speed corresponding to 80\% of VO2max (V80, 15.8 ± 1.3 km·h−1) on three different slopes (0°, −5°, and −10°), totaling six 5-min workload conditions. The workload conditions were randomly ordered and performed continuously. The tests lasted 30 min in total. All testing was performed on a large treadmill (3 × 5 m) that offered control over both speed and slope. Three-dimensional kinematic data of the right lower limb were captured during the experimental running protocol using eight infrared cameras with a sampling frequency of 150 Hz. Running kinematics were calculated using a lower body model and inverse kinematics approach. The generic model contained three, one, and two degrees of freedom at the hip, knee, and ankle joints, respectively. Oxygen uptake was measured throughout the experimental protocol. Maximum hip extension and flexion during the stance phase increased due to higher speed (p {\textless} 0.01 and p {\textless} 0.01, respectively). Knee extension at the touchdown and maximal knee flexion in the stance phase both increased on steeper downhill slopes (both p {\textless} 0.05). Ground contact time (GCT) decreased as the speed increased (p {\textless} 0.01) but was unaffected by slope (p = 0.73). Runners modified their hip movement pattern in the sagittal plane in response to changes in speed, whereas they altered their knee movement pattern during the touchdown and stance phases in response to changes in slope. While energy cost of running was unaffected by speed alone (p = 0.379), a shift in energy cost was observed for different speeds as the downhill gradient increased (p {\textless} 0.001). Energy cost was lower at V80 than 12 km·h−1 on a −5° slope but worse on a −10° slope. This indicates that higher speeds are more efficient on moderate downhill slopes (−5°), while lower speeds are more efficient on steeper downhill slopes (−10°).},
	urldate = {2022-04-02},
	journal = {Frontiers in Sports and Active Living},
	author = {Sundström, David and Kurz, Markus and Björklund, Glenn},
	year = {2021},
}

@misc{noauthor_frontiers_nodate,
	title = {Frontiers {\textbar} {Runners} {Adapt} {Different} {Lower}-{Limb} {Movement} {Patterns} {With} {Respect} to {Different} {Speeds} and {Downhill} {Slopes} {\textbar} {Sports} and {Active} {Living}},
	url = {https://www.frontiersin.org/articles/10.3389/fspor.2021.682401/full},
	urldate = {2022-04-02},
}

@article{tredennick_practical_2021,
	title = {A practical guide to selecting models for exploration, inference, and prediction in ecology},
	volume = {102},
	issn = {1939-9170},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ecy.3336},
	doi = {10.1002/ecy.3336},
	abstract = {Selecting among competing statistical models is a core challenge in science. However, the many possible approaches and techniques for model selection, and the conflicting recommendations for their use, can be confusing. We contend that much confusion surrounding statistical model selection results from failing to first clearly specify the purpose of the analysis. We argue that there are three distinct goals for statistical modeling in ecology: data exploration, inference, and prediction. Once the modeling goal is clearly articulated, an appropriate model selection procedure is easier to identify. We review model selection approaches and highlight their strengths and weaknesses relative to each of the three modeling goals. We then present examples of modeling for exploration, inference, and prediction using a time series of butterfly population counts. These show how a model selection approach flows naturally from the modeling goal, leading to different models selected for different purposes, even with exactly the same data set. This review illustrates best practices for ecologists and should serve as a reminder that statistical recipes cannot substitute for critical thinking or for the use of independent data to test hypotheses and validate predictions.},
	language = {en},
	number = {6},
	urldate = {2022-03-18},
	journal = {Ecology},
	author = {Tredennick, Andrew T. and Hooker, Giles and Ellner, Stephen P. and Adler, Peter B.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ecy.3336},
	keywords = {model selection, prediction, validation, variable selection},
	pages = {e03336},
}

@article{shmueli_explain_2010,
	title = {To {Explain} or to {Predict}?},
	volume = {25},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-25/issue-3/To-Explain-or-to-Predict/10.1214/10-STS330.full},
	doi = {10.1214/10-STS330},
	abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
	number = {3},
	urldate = {2022-03-18},
	journal = {Statistical Science},
	author = {Shmueli, Galit},
	month = aug,
	year = {2010},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Explanatory modeling, causality, data mining, predictive modeling, predictive power, scientific research, statistical strategy},
	pages = {289--310},
}

@article{efron_prediction_2020,
	title = {Prediction, {Estimation}, and {Attribution}},
	volume = {88},
	issn = {1751-5823},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12409},
	doi = {10.1111/insr.12409},
	abstract = {The scientific needs and computational limitations of the twentieth century fashioned classical statistical methodology. Both the needs and limitations have changed in the twenty-first, and so has the methodology. Large-scale prediction algorithms—neural nets, deep learning, boosting, support vector machines, random forests—have achieved star status in the popular press. They are recognizable as heirs to the regression tradition, but ones carried out at enormous scale and on titanic datasets. How do these algorithms compare with standard regression techniques such as ordinary least squares or logistic regression? Several key discrepancies will be examined, centering on the differences between prediction and estimation or prediction and attribution (significance testing). Most of the discussion is carried out through small numerical examples.},
	language = {en},
	number = {S1},
	urldate = {2022-03-18},
	journal = {International Statistical Review},
	author = {Efron, Bradley},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12409},
	keywords = {Black box, Ephemeral predictors, Random forests, Surface plus noise},
	pages = {S28--S59},
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures} (with comments and a rejoinder by the author)},
	volume = {16},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Statistical {Modeling}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	number = {3},
	urldate = {2022-03-18},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	month = aug,
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {199--231},
}

@article{wahba_bayesian_1983-1,
	title = {Bayesian "{Confidence} {Intervals}" for the {Cross}-{Validated} {Smoothing} {Spline}},
	volume = {45},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345632},
	abstract = {We consider the model Y(t$_{\textrm{i}}$) = g(t$_{\textrm{i}}$) = ε$_{\textrm{i}}$, i = 1, 2,..., n, where g(t), t ∈ [ 0, 1] is a smooth function and the \{ε$_{\textrm{i}}$\} are independent N(0, σ$^{\textrm{2}}$) errors with σ$^{\textrm{2}}$ unknown. The cross-validated smoothing spline can be used to estimate g non-parametrically from observations on Y(t$_{\textrm{i}}$), i = 1, 2,..., n, and the purpose of this paper is to study confidence intervals for this estimate. Properties of smoothing splines as Bayes estimates are used to derive confidence intervals based on the posterior covariance functiion of the estimate. A small Monte Carlo study with the cubic smoothing spline is carried out to suggest by example to what extent the resulting 95 per cent confidence intervals can be expected to cover about 95 per cent of the true (but in practice unknown) values of g(t$_{\textrm{i}}$), i = 1, 2,..., n. The method was also applied to one example of a two-dimensional thin plate smoothing spline. An asymptotic theoretical argument is presented to explain why the method can be expected to work on fixed smooth functions (like those tried), which are "smoother" than the sample functions from the prior distributions on which the confidence interval theory is based.},
	number = {1},
	urldate = {2022-03-17},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Wahba, Grace},
	year = {1983},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {133--150},
}

@misc{noauthor_bayesian_nodate,
	title = {Bayesian "{Confidence} {Intervals}" for the {Cross}-{Validated} {Smoothing} {Spline} on {JSTOR}},
	url = {https://www.jstor.org/stable/2345632},
	abstract = {Grace Wahba, Bayesian "Confidence Intervals" for the Cross-Validated Smoothing Spline, Journal of the Royal Statistical Society. Series B (Methodological), Vol. 45, No. 1 (1983), pp. 133-150},
	language = {en},
	urldate = {2022-03-17},
}

@article{park_longitudinal_2015,
	title = {Longitudinal {Functional} {Data} {Analysis}},
	volume = {4},
	issn = {2049-1573},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4652857/},
	doi = {10.1002/sta4.89},
	abstract = {We consider dependent functional data that are correlated because of a longitudinal-based design: each subject is observed at repeated times and at each time a functional observation (curve) is recorded. We propose a novel parsimonious modeling framework for repeatedly observed functional observations that allows to extract low dimensional features. The proposed methodology accounts for the longitudinal design, is designed to study the dynamic behavior of the underlying process, allows prediction of full future trajectory, and is computationally fast. Theoretical properties of this framework are studied and numerical investigations confirm excellent behavior in finite samples. The proposed method is motivated by and applied to a diffusion tensor imaging study of multiple sclerosis.},
	number = {1},
	urldate = {2022-03-11},
	journal = {Stat (International Statistical Institute)},
	author = {Park, So Young and Staicu, Ana-Maria},
	year = {2015},
	pmid = {26594358},
	pmcid = {PMC4652857},
	pages = {212--226},
}

@article{pataky_zero-_2015,
	title = {Zero- vs. one-dimensional, parametric vs. non-parametric, and confidence interval vs. hypothesis testing procedures in one-dimensional biomechanical trajectory analysis},
	volume = {48},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929015001438},
	doi = {10.1016/j.jbiomech.2015.02.051},
	abstract = {Biomechanical processes are often manifested as one-dimensional (1D) trajectories. It has been shown that 1D confidence intervals (CIs) are biased when based on 0D statistical procedures, and the non-parametric 1D bootstrap CI has emerged in the Biomechanics literature as a viable solution. The primary purpose of this paper was to clarify that, for 1D biomechanics datasets, the distinction between 0D and 1D methods is much more important than the distinction between parametric and non-parametric procedures. A secondary purpose was to demonstrate that a parametric equivalent to the 1D bootstrap exists in the form of a random field theory (RFT) correction for multiple comparisons. To emphasize these points we analyzed six datasets consisting of force and kinematic trajectories in one-sample, paired, two-sample and regression designs. Results showed, first, that the 1D bootstrap and other 1D non-parametric CIs were qualitatively identical to RFT CIs, and all were very different from 0D CIs. Second, 1D parametric and 1D non-parametric hypothesis testing results were qualitatively identical for all six datasets. Last, we highlight the limitations of 1D CIs by demonstrating that they are complex, design-dependent, and thus non-generalizable. These results suggest that (i) analyses of 1D data based on 0D models of randomness are generally biased unless one explicitly identifies 0D variables before the experiment, and (ii) parametric and non-parametric 1D hypothesis testing provide an unambiguous framework for analysis when one׳s hypothesis explicitly or implicitly pertains to whole 1D trajectories.},
	language = {en},
	number = {7},
	urldate = {2022-03-07},
	journal = {Journal of Biomechanics},
	author = {Pataky, Todd C. and Vanrenterghem, Jos and Robinson, Mark A.},
	month = may,
	year = {2015},
	keywords = {Bootstrap confidence interval, Ground reaction force, Kinematics, Random field theory, Statistical parametric mapping, Time series analysis},
	pages = {1277--1285},
}

@phdthesis{shou_statistical_2014,
	type = {Thesis},
	title = {Statistical {Methods} for {Structured} {Multilevel} {Functional} {Data}: {Estimation} and {Reliability}},
	shorttitle = {Statistical {Methods} for {Structured} {Multilevel} {Functional} {Data}},
	url = {https://jscholarship.library.jhu.edu/handle/1774.2/37867},
	abstract = {The thesis investigates a specific type of functional data with multilevel structures induced by complex experimental designs. Novel statistical methods based on principal component analysis that account for different layers of correlations in the data are introduced. A robust metric is proposed to evaluate the reproducibility of replicated functional and imaging studies. Shrinkage-based methods are extended to functional and imaging data with no or few replicates, and studies with low reliability. The proposed estimator is shown to correct for measurement error and improve prediction at the subject level by borrowing strength from the population average. Methods have been motivated by and applied to high-throughput physical activity measurements and several brain imaging studies based on different modalities including functional magnetic resonance imaging (fMRI), voxel-based morphometry, and diffusion tensor imaging (DTI). Fast algorithms are developed to expand the applicability of the methods proposed to ultra-high dimensional data.},
	language = {en},
	urldate = {2022-03-01},
	school = {Johns Hopkins University},
	author = {Shou, Haochang},
	month = jun,
	year = {2014},
	note = {Accepted: 2015-09-16T03:35:10Z},
}

@article{aston_linguistic_2010,
	title = {Linguistic {Pitch} {Analysis} using {Functional} {Principal} {Component} {Mixed} {Effect} {Models}},
	volume = {59},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/40541687},
	abstract = {Fundamental frequency (F0, broadly 'pitch') is an integral part of spoken human language; however, a comprehensive quantitative model for F0 can be a challenge to formulate owing to the large number of effects and interactions between effects that lie behind the human voice's production of F0, and the very nature of the data being a contour rather than a point. The paper presents a semiparametric functional response model for F0 by incorporating linear mixed effects models through the functional principal component scores. This model is applied to the problem of modelling F0 in the tone language Qiang, a language in which relative pitch information is part of each word's dictionary entry.},
	number = {2},
	urldate = {2022-03-01},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Aston, John A. D. and Chiou, Jeng-Min and Evans, Jonathan P.},
	year = {2010},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {297--317},
}

@article{morris_automated_2011,
	title = {Automated analysis of quantitative image data using isomorphic functional mixed models, with application to proteomics data},
	volume = {5},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-5/issue-2A/Automated-analysis-of-quantitative-image-data-using-isomorphic-functional-mixed/10.1214/10-AOAS407.full},
	doi = {10.1214/10-AOAS407},
	abstract = {Image data are increasingly encountered and are of growing importance in many areas of science. Much of these data are quantitative image data, which are characterized by intensities that represent some measurement of interest in the scanned images. The data typically consist of multiple images on the same domain and the goal of the research is to combine the quantitative information across images to make inference about populations or interventions. In this paper we present a unified analysis framework for the analysis of quantitative image data using a Bayesian functional mixed model approach. This framework is flexible enough to handle complex, irregular images with many local features, and can model the simultaneous effects of multiple factors on the image intensities and account for the correlation between images induced by the design. We introduce a general isomorphic modeling approach to fitting the functional mixed model, of which the wavelet-based functional mixed model is one special case. With suitable modeling choices, this approach leads to efficient calculations and can result in flexible modeling and adaptive smoothing of the salient features in the data. The proposed method has the following advantages: it can be run automatically, it produces inferential plots indicating which regions of the image are associated with each factor, it simultaneously considers the practical and statistical significance of findings, and it controls the false discovery rate. Although the method we present is general and can be applied to quantitative image data from any application, in this paper we focus on image-based proteomic data. We apply our method to an animal study investigating the effects of cocaine addiction on the brain proteome. Our image-based functional mixed model approach finds results that are missed with conventional spot-based analysis approaches. In particular, we find that the significant regions of the image identified by the proposed method frequently correspond to subregions of visible spots that may represent post-translational modifications or co-migrating proteins that cannot be visually resolved from adjacent, more abundant proteins on the gel image. Thus, it is possible that this image-based approach may actually improve the realized resolution of the gel, revealing differentially expressed proteins that would not have even been detected as spots by modern spot-based analyses.},
	number = {2A},
	urldate = {2022-03-01},
	journal = {The Annals of Applied Statistics},
	author = {Morris, Jeffrey S. and Baladandayuthapani, Veerabhadran and Herrick, Richard C. and Sanna, Pietro and Gutstein, Howard},
	month = jun,
	year = {2011},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {2D gel electrophoresis, Bayesian analysis, False discovery rate, Functional data analysis, Wavelets, functional MRI, functional mixed models, image analysis, isomorphic transformations, proteomics},
	pages = {894--923},
}

@article{morris_automated_2011-1,
	title = {Automated analysis of quantitative image data using isomorphic functional mixed models, with application to proteomics data},
	volume = {5},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/1108.3910},
	doi = {10.1214/10-AOAS407},
	abstract = {Image data are increasingly encountered and are of growing importance in many areas of science. Much of these data are quantitative image data, which are characterized by intensities that represent some measurement of interest in the scanned images. The data typically consist of multiple images on the same domain and the goal of the research is to combine the quantitative information across images to make inference about populations or interventions. In this paper we present a unified analysis framework for the analysis of quantitative image data using a Bayesian functional mixed model approach. This framework is flexible enough to handle complex, irregular images with many local features, and can model the simultaneous effects of multiple factors on the image intensities and account for the correlation between images induced by the design. We introduce a general isomorphic modeling approach to fitting the functional mixed model, of which the wavelet-based functional mixed model is one special case. With suitable modeling choices, this approach leads to efficient calculations and can result in flexible modeling and adaptive smoothing of the salient features in the data. The proposed method has the following advantages: it can be run automatically, it produces inferential plots indicating which regions of the image are associated with each factor, it simultaneously considers the practical and statistical significance of findings, and it controls the false discovery rate.},
	number = {2A},
	urldate = {2022-03-01},
	journal = {The Annals of Applied Statistics},
	author = {Morris, Jeffrey S. and Baladandayuthapani, Veerabhadran and Herrick, Richard C. and Sanna, Pietro and Gutstein, Howard},
	month = jun,
	year = {2011},
	note = {arXiv: 1108.3910},
	keywords = {Statistics - Applications},
}

@article{aston_linguistic_2010-1,
	title = {Linguistic {Pitch} {Analysis} using {Functional} {Principal} {Component} {Mixed} {Effect} {Models}},
	volume = {59},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/40541687},
	abstract = {Fundamental frequency (F0, broadly 'pitch') is an integral part of spoken human language; however, a comprehensive quantitative model for F0 can be a challenge to formulate owing to the large number of effects and interactions between effects that lie behind the human voice's production of F0, and the very nature of the data being a contour rather than a point. The paper presents a semiparametric functional response model for F0 by incorporating linear mixed effects models through the functional principal component scores. This model is applied to the problem of modelling F0 in the tone language Qiang, a language in which relative pitch information is part of each word's dictionary entry.},
	number = {2},
	urldate = {2022-03-01},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Aston, John A. D. and Chiou, Jeng-Min and Evans, Jonathan P.},
	year = {2010},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {297--317},
}

@book{winter_biomechanics_1979,
	title = {Biomechanics of {Human} {Movement}},
	isbn = {978-0-471-03476-6},
	language = {en},
	publisher = {Wiley},
	author = {Winter, David A.},
	year = {1979},
	keywords = {Medical / General},
}

@article{chen_quantifying_2017,
	title = {Quantifying {Infinite}-{Dimensional} {Data}: {Functional} {Data} {Analysis} in {Action}},
	volume = {9},
	issn = {1867-1772},
	shorttitle = {Quantifying {Infinite}-{Dimensional} {Data}},
	url = {https://doi.org/10.1007/s12561-015-9137-5},
	doi = {10.1007/s12561-015-9137-5},
	abstract = {Functional data analysis (FDA) is concerned with inherently infinite-dimensional data objects and therefore can be viewed as part of the methodology for big data. The size of functional data may vary from terabytes as encountered in functional magnetic resonance imaging (fMRI) and other applications in brain imaging to just a few kilobytes in longitudinal data with small or modest sample sizes. In this contribution, we highlight some applications of FDA methodology through various data illustrations. We briefly review some basic computational tools that can be used to accelerate implementations of FDA methodology. The analyses presented in this paper illustrate the principal analysis by conditional expectation (PACE) package for FDA, where our applications include both relatively simple and more complex functional data from the biomedical sciences. The data we discuss range from functional data that result from daily movement profile tracking and that are modeled as repeatedly observed functions per subject, to medfly longitudinal behavior profiles, where the goal is to predict remaining lifetime of individual flies. We also discuss the quantification of connectivity of fMRI signals that is of interest in brain imaging and the prediction of continuous traits from high-dimensional SNPs in genomics. The methods of FDA that we demonstrate for these analyses include functional principal component analysis, functional regression and correlation, the modeling of dependent functional data, and the stringing of high-dimensional data into functional data and can be implemented with the PACE package.},
	language = {en},
	number = {2},
	urldate = {2022-02-09},
	journal = {Statistics in Biosciences},
	author = {Chen, Kehui and Zhang, Xiaoke and Petersen, Alexander and Müller, Hans-Georg},
	month = dec,
	year = {2017},
	pages = {582--604},
}

@misc{volkmann_multifamm_2021,
	title = {multifamm: {Multivariate} {Functional} {Additive} {Mixed} {Models}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {multifamm},
	url = {https://CRAN.R-project.org/package=multifamm},
	abstract = {An implementation for multivariate functional additive mixed models (multiFAMM), see Volkmann et al. (2021, {\textless}arXiv:2103.06606{\textgreater}). It builds on developed methods for univariate sparse functional regression models and multivariate functional principal component analysis. This package contains the function to run a multiFAMM and some convenience functions useful when working with large models. An additional package on GitHub contains more convenience functions to reproduce the analyses of the corresponding paper ({\textless}https://github.com/alexvolkmann/multifammPaper{\textgreater}).},
	urldate = {2022-02-08},
	author = {Volkmann, Alexander},
	month = sep,
	year = {2021},
}

@incollection{hadjipantelis_functional_2018,
	title = {Functional data analysis for big data: {A} case study on california temperature trends},
	shorttitle = {Functional data analysis for big data},
	booktitle = {Handbook of {Big} {Data} {Analytics}},
	publisher = {Springer},
	author = {Hadjipantelis, Pantelis Zenon and Müller, Hans-Georg},
	year = {2018},
	pages = {457--483},
}

@article{zhu_multivariate_2017,
	title = {Multivariate functional response regression, with application to fluorescence spectroscopy in a cervical pre-cancer study},
	volume = {111},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947317300245},
	doi = {10.1016/j.csda.2017.02.004},
	abstract = {Many scientific studies measure different types of high-dimensional signals or images from the same subject, producing multivariate functional data. These functional measurements carry different types of information about the scientific process, and a joint analysis that integrates information across them may provide new insights into the underlying mechanism for the phenomenon under study. Motivated by fluorescence spectroscopy data in a cervical pre-cancer study, a multivariate functional response regression model is proposed, which treats multivariate functional observations as responses and a common set of covariates as predictors. This novel modeling framework simultaneously accounts for correlations between functional variables and potential multi-level structures in data that are induced by experimental design. The model is fitted by performing a two-stage linear transformation—a basis expansion to each functional variable followed by principal component analysis for the concatenated basis coefficients. This transformation effectively reduces the intra- and inter-function correlations and facilitates fast and convenient calculation. A fully Bayesian approach is adopted to sample the model parameters in the transformed space, and posterior inference is performed after inverse-transforming the regression coefficients back to the original data domain. The proposed approach produces functional tests that flag local regions on the functional effects, while controlling the overall experiment-wise error rate or false discovery rate. It also enables functional discriminant analysis through posterior predictive calculation. Analysis of the fluorescence spectroscopy data reveals local regions with differential expressions across the pre-cancer and normal samples. These regions may serve as biomarkers for prognosis and disease assessment.},
	language = {en},
	urldate = {2022-02-01},
	journal = {Computational Statistics \& Data Analysis},
	author = {Zhu, Hongxiao and Morris, Jeffrey S. and Wei, Fengrong and Cox, Dennis D.},
	month = jul,
	year = {2017},
	keywords = {Bayesian methods, Fluorescence spectroscopy, Functional data analysis, Mixed models, Multivariate functional regression, Principal component analysis, Wavelets},
	pages = {88--101},
}

@article{pini_interval_2016,
	title = {The interval testing procedure: {A} general framework for inference in functional data analysis},
	volume = {72},
	issn = {1541-0420},
	shorttitle = {The interval testing procedure},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12476},
	doi = {10.1111/biom.12476},
	abstract = {We introduce in this work the Interval Testing Procedure (ITP), a novel inferential technique for functional data. The procedure can be used to test different functional hypotheses, e.g., distributional equality between two or more functional populations, equality of mean function of a functional population to a reference. ITP involves three steps: (i) the representation of data on a (possibly high-dimensional) functional basis; (ii) the test of each possible set of consecutive basis coefficients; (iii) the computation of the adjusted p-values associated to each basis component, by means of a new strategy here proposed. We define a new type of error control, the interval-wise control of the family wise error rate, particularly suited for functional data. We show that ITP is provided with such a control. A simulation study comparing ITP with other testing procedures is reported. ITP is then applied to the analysis of hemodynamical features involved with cerebral aneurysm pathology. ITP is implemented in the fdatest R package.},
	language = {en},
	number = {3},
	urldate = {2022-01-16},
	journal = {Biometrics},
	author = {Pini, Alessia and Vantini, Simone},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12476},
	keywords = {Family wise error rate, Functional data analysis, Inference, Multiple comparison, Permutation method},
	pages = {835--845},
}

@incollection{zhang_anova_2013,
	title = {{ANOVA} for {Functional} {Data}},
	isbn = {978-0-429-07008-2},
	abstract = {At the end of Chapter 4, we studied the one-sample problem for functional
data where we described some basic hypothesis tests for functional data, including the pointwise, L2-norm-based, F -type, and bootstrap tests. In this
chapter, we show how to extend these tests to more complicated designs where
two or more functional samples are involved. We start with the two-sample
problem for functional data. It is the simplest multi-sample problem. It allows
us to understand hypothesis testing problems for functional data with more
insight. Studies about one-way ANOVA and two-way ANOVA are then described in Sections 5.3 through 5.4. Technical proofs of the main results are
outlined in Section 5.5. Some concluding remarks and bibliographical notes
are given in Section 5.6. Section 5.7 is devoted to some exercise problems
related to this chapter.},
	booktitle = {Analysis of {Variance} for {Functional} {Data}},
	publisher = {Chapman and Hall/CRC},
	author = {Zhang, Jin-Ting},
	year = {2013},
	note = {Num Pages: 68},
}

@article{shen_f_2004,
	title = {{AN} {F} {TEST} {FOR} {LINEAR} {MODELS} {WITH} {FUNCTIONAL} {RESPONSES}},
	volume = {14},
	issn = {1017-0405},
	url = {https://www.jstor.org/stable/24307230},
	abstract = {Linear models where the response is a function, but the predictors are vectors are considered. A functional F test for choosing among two nested functional linear models is developed. Its null distribution is derived and a convenient approximation is presented. A simple way to test individual predictors is presented. The test is applied to some data from Ergonomics and compared to some competing tests. The ability to detect certain types of differences between models is explored. A simulation study is conducted to assess the size and power of the tests.},
	number = {4},
	urldate = {2022-01-13},
	journal = {Statistica Sinica},
	author = {Shen, Qing and Faraway, Julian},
	year = {2004},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {1239--1257},
}

@article{pataky_rft1d_2016,
	title = {rft1d: {Smooth} {One}-{Dimensional} {Random} {Field} {Upcrossing} {Probabilities} in {Python}},
	volume = {71},
	copyright = {Copyright (c) 2016 Todd C. Pataky},
	issn = {1548-7660},
	shorttitle = {rft1d},
	url = {https://doi.org/10.18637/jss.v071.i07},
	doi = {10.18637/jss.v071.i07},
	abstract = {Through topological expectations regarding smooth, thresholded n-dimensional Gaussian continua, random field theory (RFT) describes probabilities associated with both the field-wide maximum and threshold-surviving upcrossing geometry. A key application of RFT is a correction for multiple comparisons which affords field-level hypothesis testing for both univariate and multivariate fields. For unbroken isotropic fields just one parameter in addition to the mean and variance is required: the ratio of a field's size to its smoothness. Ironically the simplest manifestation of RFT (1D unbroken fields) has rarely surfaced in the literature, even during its foundational development in the late 1970s. This Python package implements 1D RFT primarily for exploring and validating RFT expectations, but also describes how it can be applied to yield statistical inferences regarding sets of experimental 1D fields.},
	language = {en},
	urldate = {2022-01-12},
	journal = {Journal of Statistical Software},
	author = {Pataky, Todd C.},
	month = jul,
	year = {2016},
	keywords = {continuum analysis},
	pages = {1--22},
}

@article{faraway_regression_1997,
	title = {Regression {Analysis} for a {Functional} {Response}},
	volume = {39},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1271130},
	doi = {10.2307/1271130},
	abstract = {Functional responses are encountered when units are observed over time. Although the whole function itself is not observed, a sufficiently large number of evaluations, as is common with modern recording equipment, are assumed to be available. Functional regression analysis relates the smooth functional response, y(t), to known covariates, x, by a linear combination of parameter functions, β(t), which are to be estimated. The model takes the standard form, y(t)=x$^{\textrm{T}}$β (t)+ε (t). This approach provides an alternative to standard longitudinal data methods used in the biological sciences, where less and noisier data necessitate parametric modeling. The methodology is illustrated by an application in ergonomics.},
	number = {3},
	urldate = {2022-01-11},
	journal = {Technometrics},
	author = {Faraway, Julian J.},
	year = {1997},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
	pages = {254--261},
}

@article{faraway_regression_1997-1,
	title = {Regression {Analysis} for a {Functional} {Response}},
	volume = {39},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1271130},
	doi = {10.2307/1271130},
	abstract = {Functional responses are encountered when units are observed over time. Although the whole function itself is not observed, a sufficiently large number of evaluations, as is common with modern recording equipment, are assumed to be available. Functional regression analysis relates the smooth functional response, y(t), to known covariates, x, by a linear combination of parameter functions, β(t), which are to be estimated. The model takes the standard form, y(t)=x$^{\textrm{T}}$β (t)+ε (t). This approach provides an alternative to standard longitudinal data methods used in the biological sciences, where less and noisier data necessitate parametric modeling. The methodology is illustrated by an application in ergonomics.},
	number = {3},
	urldate = {2022-01-11},
	journal = {Technometrics},
	author = {Faraway, Julian J.},
	year = {1997},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
	pages = {254--261},
}

@article{da_silva_soares_functional_2021,
	title = {Functional data analysis reveals asymmetrical crank torque during cycling performed at different exercise intensities},
	volume = {122},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929021002591},
	doi = {10.1016/j.jbiomech.2021.110478},
	abstract = {Pedaling asymmetry is claimed as a factor of influence on injury and performance. However, the evidence is still controversial. Most previous studies determined peak torque asymmetries, which in our understanding does not consider the pattern of movement like torque profiles. Here we demonstrate that asymmetries in pedaling torque at different exercise intensities can be better described when the torque profiles are considered using functional analysis of variance than when only the peak values are analyzed. We compared peak torques and torque curves recorded while cyclists pedaled at submaximal intensities of 60\%, 80\%, and 95\% of the maximal power output and compared data between the preferred and non-preferred legs. ANOVA showed symmetry or rather no difference in the amount of peak torque between legs, regardless of pedaling intensity. FANOVA, on the other hand, revealed significant asymmetries between legs, regardless of cycling intensity, apparently for different sections of the cycle, however, not for peak torque, either. We conclude that pedaling asymmetry cannot be quantified solely by peak torques and considering the analysis of the entire movement cycle can more accurately reflect the biomechanical movement pattern. Therefore, FANOVA data analysis could be an alternative to identify asymmetries. A novel approach as described here might be useful when combining kinetics assessment with other approaches like EMG and kinematics and help to better understand the role of pedaling asymmetries for performance and injury risks.},
	language = {en},
	urldate = {2022-01-10},
	journal = {Journal of Biomechanics},
	author = {da Silva Soares, Jéssica and Carpes, Felipe P and de Fátima Geraldo, Gislaine and Bertú Medeiros, Fabíola and Roberto Kunzler, Marcos and Sosa Machado, Álvaro and Augusto Paolucci, Leopoldo and Gustavo Pereira de Andrade, André},
	month = jun,
	year = {2021},
	keywords = {Asymmetry, Bicycling, Kinetics, Lower extremity, Statistics},
	pages = {110478},
}

@article{ramos_dalla_bernardina_asymmetric_2021,
	title = {Asymmetric velocity profiles in {Paralympic} powerlifters performing at different exercise intensities are detected by functional data analysis},
	volume = {123},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929021003043},
	doi = {10.1016/j.jbiomech.2021.110523},
	abstract = {Asymmetries compromise performance in powerlifting and Paralympic powerlifting, but its quantification can be complex. Previous studies consider average or peak values to quantify asymmetries, however this approach does not consider the pattern of movement like velocity profiles. Here we demonstrate that conducting a functional analysis of variance (FANOVA) permits to quantify asymmetries in bench press performance by Paralympic powerlifting at different submaximal intensities. Kinematic data were collected from 10 Paralympic powerlifting athletes performing in bench press at submaximal intensities (50\% and 90\% of the one-repetition maximum). Linear velocity was quantified considering mean values and the entire waveform. Mean values were compared by analysis of variance (ANOVA) and the waveforms were compared by FANOVA. FANOVA identified asymmetry profiles that ANOVA did not recognize at the highest intensity, which is the closest to a competition. This way, FANOVA can bring advantages to the analysis of competitive performance. FANOVA data analysis identifies asymmetries at higher intensity of effort considering the whole pattern of movement. Therefore, we consider that the FANOVA’s approach may benefit the biomechanical assessment of the Paralympic powerlifting.},
	language = {en},
	urldate = {2022-01-10},
	journal = {Journal of Biomechanics},
	author = {Ramos Dalla Bernardina, Gustavo and Danillo Matos dos Santos, Marcelo and Alves Resende, Renan and Túlio de Mello, Marco and Rodrigues Albuquerque, Maicon and Augusto Paolucci, Leopoldo and P. Carpes, Felipe and Silva, Andressa and Gustavo Pereira de Andrade, André},
	month = jun,
	year = {2021},
	keywords = {Kinematics, Muscle strength, Paralympic athletes, Statistical data analyses},
	pages = {110523},
}

@article{noauthor_asymmetric_2021,
	title = {Asymmetric velocity profiles in {Paralympic} powerlifters performing at different exercise intensities are detected by functional data analysis},
	volume = {123},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929021003043},
	doi = {10.1016/j.jbiomech.2021.110523},
	abstract = {Asymmetries compromise performance in powerlifting and Paralympic powerlifting, but its quantification can be complex. Previous studies consider avera…},
	language = {en},
	urldate = {2022-01-09},
	journal = {Journal of Biomechanics},
	month = jun,
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {110523},
}

@article{ty_hopkins_alterations_2012,
	title = {Alterations in evertor/invertor muscle activation and center of pressure trajectory in participants with functional ankle instability},
	volume = {22},
	issn = {1050-6411},
	url = {https://www.sciencedirect.com/science/article/pii/S1050641111001908},
	doi = {10.1016/j.jelekin.2011.11.012},
	abstract = {Participants with ankle instability demonstrate more foot inversion during the stance phase of gait than able-bodied subjects. Invertor excitation, coupled with evertor inhibition may contribute to this potentially injurious position. The purpose of this experiment was to examine evertor/invertor muscle activation and foot COP trajectory during walking in participants with functional ankle instability (FI). Twelve subjects were identified with FI and matched to healthy controls. Tibialis anterior (TA) and peroneus longus (PL) electromyography (EMG), as well as COP, were recorded during walking. Functional analyses were used to detect differences between FI and control subjects with respect to normalized EMG and COP trajectory during walking. Relative to matched controls, COP trajectory was more laterally deviated in the FI group from 20\% to 90\% of the stance phase. TA activation was greater in the FI group from 15\% to 30\% and 45\% to 70\% of stance. PL activation was greater in the FI group at initial heel contact and toe off and trended lower from 20\% to 40\% of stance in the FI group. Altered motor strategies appear to contribute to COP deviations in FI participants and may increase the susceptibility to repeated ankle inversion injury.},
	language = {en},
	number = {2},
	urldate = {2022-01-09},
	journal = {Journal of Electromyography and Kinesiology},
	author = {Ty Hopkins, J. and Coglianese, Mark and Glasgow, Philip and Reese, Shane and Seeley, Matthew K.},
	month = apr,
	year = {2012},
	keywords = {Peroneus longus, Plantar pressure, Tibialis anterior},
	pages = {280--285},
}

@book{wood_generalized_2017,
	address = {Boca Raton},
	edition = {2},
	title = {Generalized {Additive} {Models}: {An} {Introduction} with {R}},
	isbn = {978-1-315-37027-9},
	shorttitle = {Generalized {Additive} {Models}},
	abstract = {The first edition of this book has established itself as one of the leading references on generalized additive models (GAMs), and the only book on the topic to be introductory in nature with a wealth of practical examples and software implementation. It is self-contained, providing the necessary background in linear models, linear mixed models, and generalized linear models (GLMs), before presenting a balanced treatment of the theory and applications of GAMs and related models. 

The author bases his approach on a framework of penalized regression splines, and while firmly focused on the practical aspects of GAMs, discussions include fairly full explanations of the theory underlying the methods. Use of R software helps explain the theory and illustrates the practical application of the methodology. Each chapter contains an extensive set of exercises, with solutions in an appendix or in the book’s R data package gamair, to enable use as a course text or for self-study.},
	publisher = {Chapman and Hall/CRC},
	author = {Wood, Simon N.},
	month = may,
	year = {2017},
	doi = {10.1201/9781315370279},
}

@article{fan_two-step_2000,
	title = {Two-{Step} {Estimation} of {Functional} {Linear} {Models} with {Applications} to {Longitudinal} {Data}},
	volume = {62},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/3088861},
	abstract = {Functional linear models are useful in longitudinal data analysis. They include many classical and recently proposed statistical models for longitudinal data and other functional data. Recently, smoothing spline and kernel methods have been proposed for estimating their coefficient functions nonparametrically but these methods are either intensive in computation or inefficient in performance. To overcome these drawbacks, in this paper, a simple and powerful two-step alternative is proposed. In particular, the implementation of the proposed approach via local polynomial smoothing is discussed. Methods for estimating standard deviations of estimated coefficient functions are also proposed. Some asymptotic results for the local polynomial estimators are established. Two longitudinal data sets, one of which involves time-dependent covariates, are used to demonstrate the approach proposed. Simulation studies show that our two-step approach improves the kernel method proposed by Hoover and co-workers in several aspects such as accuracy, computational time and visual appeal of the estimators.},
	number = {2},
	urldate = {2022-01-08},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Fan, Jianqing and Zhang, Jin-Ting},
	year = {2000},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {303--322},
}

@article{cederbaum_functional_2016,
	title = {Functional linear mixed models for irregularly or sparsely sampled data},
	volume = {16},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X15617594},
	doi = {10.1177/1471082X15617594},
	abstract = {We propose an estimation approach to analyse correlated functional data, which are observed on unequal grids or even sparsely. The model we use is a functional linear mixed model, a functional analogue of the linear mixed model. Estimation is based on dimension reduction via functional principal component analysis and on mixed model methodology. Our procedure allows the decomposition of the variability in the data as well as the estimation of mean effects of interest, and borrows strength across curves. Confidence bands for mean effects can be constructed conditionally on estimated principal components. We provide R-code implementing our approach in an online appendix. The method is motivated by and applied to data from speech production research.},
	language = {en},
	number = {1},
	urldate = {2022-01-07},
	journal = {Statistical Modelling},
	author = {Cederbaum, Jona and Pouplier, Marianne and Hoole, Phil and Greven, Sonja},
	month = feb,
	year = {2016},
	note = {Publisher: SAGE Publications India},
	keywords = {Dependent functional data, functional additive mixed models, functional principal component analysis, penalized splines, speech production},
	pages = {67--88},
}

@article{cederbaum_functional_2016-1,
	title = {Functional linear mixed models for irregularly or sparsely sampled data},
	volume = {16},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X15617594},
	doi = {10.1177/1471082X15617594},
	abstract = {We propose an estimation approach to analyse correlated functional data, which are observed on unequal grids or even sparsely. The model we use is a functional linear mixed model, a functional analogue of the linear mixed model. Estimation is based on dimension reduction via functional principal component analysis and on mixed model methodology. Our procedure allows the decomposition of the variability in the data as well as the estimation of mean effects of interest, and borrows strength across curves. Confidence bands for mean effects can be constructed conditionally on estimated principal components. We provide R-code implementing our approach in an online appendix. The method is motivated by and applied to data from speech production research.},
	language = {en},
	number = {1},
	urldate = {2022-01-07},
	journal = {Statistical Modelling},
	author = {Cederbaum, Jona and Pouplier, Marianne and Hoole, Phil and Greven, Sonja},
	month = feb,
	year = {2016},
	note = {Publisher: SAGE Publications India},
	keywords = {Dependent functional data, functional additive mixed models, functional principal component analysis, penalized splines, speech production},
	pages = {67--88},
}

@misc{noauthor_functional_nodate,
	title = {‪{Functional} linear mixed models for irregularly or sparsely sampled data‬},
	url = {https://scholar.google.de/citations?view_op=view_citation&hl=de&user=MneZY6cAAAAJ&sortby=pubdate&alert_preview_top_rm=2&citation_for_view=MneZY6cAAAAJ:UeHWp8X0CEIC},
	abstract = {‪J Cederbaum, M Pouplier, P Hoole, S Greven‬, ‪Statistical Modelling, 2016‬ - ‪28-mal zitiert‬},
	urldate = {2022-01-07},
}

@article{ecarnot_writing_2015,
	title = {Writing a scientific article: {A} step-by-step guide for beginners},
	volume = {6},
	issn = {1878-7649},
	shorttitle = {Writing a scientific article},
	url = {https://www.sciencedirect.com/science/article/pii/S1878764915001606},
	doi = {10.1016/j.eurger.2015.08.005},
	abstract = {Many young researchers find it extremely difficult to write scientific articles, and few receive specific training in the art of presenting their research work in written format. Yet, publication is often vital for career advancement, to obtain funding, to obtain academic qualifications, or for all these reasons. We describe here the basic steps to follow in writing a scientific article. We outline the main sections that an average article should contain; the elements that should appear in these sections, and some pointers for making the overall result attractive and acceptable for publication.},
	language = {en},
	number = {6},
	urldate = {2022-01-04},
	journal = {European Geriatric Medicine},
	author = {Ecarnot, F. and Seronde, M. -F. and Chopard, R. and Schiele, F. and Meneveau, N.},
	month = dec,
	year = {2015},
	keywords = {Article, Research, Scientific publications, Writing},
	pages = {573--579},
}

@misc{dowle_datatable_2021,
	title = {data.table: {Extension} of 'data.frame'},
	copyright = {MPL-2.0 {\textbar} file LICENSE},
	shorttitle = {data.table},
	url = {https://CRAN.R-project.org/package=data.table},
	abstract = {Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.},
	urldate = {2022-01-04},
	author = {Dowle, Matt and Srinivasan, Arun and Gorecki, Jan and Chirico, Michael and Stetsenko, Pasha and Short, Tom and Lianoglou, Steve and Antonyan, Eduard and Bonsch, Markus and Parsonage, Hugh and Ritchie, Scott and Ren, Kun and Tan, Xianying and Saporta, Rick and Seiskari, Otto and Dong, Xianghui and Lang, Michel and Iwasaki, Watal and Wenchel, Seth and Broman, Karl and Schmidt, Tobias and Arenburg, David and Smith, Ethan and Cocquemas, Francois and Gomez, Matthieu and Chataignon, Philippe and Blaser, Nello and Selivanov, Dmitry and Riabushenko, Andrey and Lee, Cheng and Groves, Declan and Possenriede, Daniel and Parages, Felipe and Toth, Denes and Yaramaz-David, Mus and Perumal, Ayappan and Sams, James and Morgan, Martin and Quinn, Michael and @javrucebo and @marc-outins and Storey, Roy and Saraswat, Manish and Jacob, Morgan and Schubmehl, Michael and Vaughan, Davis and Hocking, Toby and Silvestri, Leonardo and Barrett, Tyson and Hester, Jim and Damico, Anthony and Freundt, Sebastian and Simons, David and Andrade, Elliott Sales de and Miller, Cole and Meldgaard, Jens Peder and Tlapak, Vaclav and Ushey, Kevin and Eddelbuettel, Dirk and Schwen, Ben},
	month = sep,
	year = {2021},
	keywords = {Finance, HighPerformanceComputing, TimeSeries},
}

@article{zhu_robust_2012,
	title = {Robust {Classification} of {Functional} and {Quantitative} {Image} {Data} {Using} {Functional} {Mixed} {Models}},
	volume = {68},
	issn = {0006-341X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3443537/},
	doi = {10.1111/j.1541-0420.2012.01765.x},
	abstract = {This paper introduces new methods for performing classification of complex, high-dimensional functional data using the functional mixed model (FMM) framework. The FMM relates a functional response to a set of predictors through functional fixed and random effects, which allows it to account for various factors and between-function correlations. The methods include training and prediction steps. In the training steps we train the FMM model by treating class designation as one of the fixed effects, and in the prediction steps we classify the new objects using posterior predictive probabilities of class. Through a Bayesian scheme, we are able to adjust for factors affecting both the functions and the class designations. While the methods can be used in any FMM framework, we provide details for two specific Bayesian approaches: the Gaussian, wavelet-based FMM (G-WFMM) and the robust, wavelet-based FMM (R-WFMM). Both methods perform modeling in the wavelet space, which yields parsimonious representations for the functions, and can naturally adapt to local features and complex nonstationarities in the functions. The R-WFMM allows potentially heavier tails for features of the functions indexed by particular wavelet coefficients, leading to a down-weighting of outliers that makes the method robust to outlying functions or regions of functions. The models are applied to a pancreatic cancer mass spectroscopy data set and compared with other recently developed functional classification methods.},
	number = {4},
	urldate = {2021-12-09},
	journal = {Biometrics},
	author = {Zhu, Hongxiao and Brown, Philip J. and Morris, Jeffrey S.},
	month = dec,
	year = {2012},
	pmid = {22670567},
	pmcid = {PMC3443537},
	pages = {1260--1268},
}

@misc{noauthor_sage_2021,
	title = {The {SAGE} {Handbook} of {Multilevel} {Modeling}},
	url = {https://uk.sagepub.com/en-gb/eur/the-sage-handbook-of-multilevel-modeling/book235673},
	language = {en},
	urldate = {2021-12-09},
	journal = {SAGE Publications Ltd},
	month = nov,
	year = {2021},
}

@article{dillon_injury-resistant_2021,
	title = {Do {Injury}-{Resistant} {Runners} {Have} {Distinct} {Differences} in {Clinical} {Measures} {Compared} with {Recently} {Injured} {Runners}?},
	volume = {53},
	issn = {1530-0315},
	doi = {10.1249/MSS.0000000000002649},
	abstract = {INTRODUCTION: Although lower extremity muscle strength, joint motion, and functional foot alignment are commonly used, time-efficient clinical measures that have been proposed as risk factors for running-related injuries, it is unclear if these factors can distinguish injury resistance in runners.
PURPOSE: This study compares clinical measures, with consideration of sex, between recently injured runners (3 months to 1 yr prior), those with a high level of injury resistance who have been uninjured for at least 2 yr, and never-injured runners.
METHODS: Averaged bilateral values and between-limb symmetry angles of lower limb isometric muscle strength, joint motion, navicular drop, and foot posture index (FPI) were assessed in a cohort of recreational runners, and their injury history was recorded. Differences in clinical measures between injury groupings were examined, with consideration of sex.
RESULTS: Of the 223 runners tested, 116 had been recently injured, 61 had been injured {\textgreater}2 yr ago and were deemed to have acquired reinjury resistance, and 46 were never injured. Plantarflexion was greater in both recently injured (P = 0.001) and acquired reinjury resistance runners (P = 0.001) compared with never-injured runners. Recently injured runners displayed higher hip abduction strength compared with never-injured runners (P = 0.019, η2 = 0.038, small effect size). There were no statistically significant differences in the remaining measures between the injury groupings. With the exception of FPI, there was no interaction between sex and injury grouping for any of the measures.
CONCLUSION: Commonly used clinical measures of strength, joint motion, and functional foot alignment were not superior in injury-resistant runners compared with recently injured runners, questioning their relevance in identifying future injury resistance of runners.},
	language = {eng},
	number = {9},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Dillon, Sarah and Burke, Aoife and Whyte, Enda F. and O'Connor, Siobhán and Gore, Shane and Moran, Kieran A.},
	month = sep,
	year = {2021},
	pmid = {33899779},
	keywords = {Adult, Athletic Injuries, Female, Humans, Lower Extremity, Male, Middle Aged, Muscle Strength, Range of Motion, Articular, Risk Factors, Running, Sex Factors, Surveys and Questionnaires},
	pages = {1807--1817},
}

@article{berry_cross-validation_2021,
	title = {Cross-{Validation}, {Information} {Theory}, or {Maximum} {Likelihood}? {A} {Comparison} of {Tuning} {Methods} for {Penalized} {Splines}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Cross-{Validation}, {Information} {Theory}, or {Maximum} {Likelihood}?},
	url = {https://www.mdpi.com/2571-905X/4/3/42},
	doi = {10.3390/stats4030042},
	abstract = {Functional data analysis techniques, such as penalized splines, have become common tools used in a variety of applied research settings. Penalized spline estimators are frequently used in applied research to estimate unknown functions from noisy data. The success of these estimators depends on choosing a tuning parameter that provides the correct balance between fitting and smoothing the data. Several different smoothing parameter selection methods have been proposed for choosing a reasonable tuning parameter. The proposed methods generally fall into one of three categories: cross-validation methods, information theoretic methods, or maximum likelihood methods. Despite the well-known importance of selecting an ideal smoothing parameter, there is little agreement in the literature regarding which method(s) should be considered when analyzing real data. In this paper, we address this issue by exploring the practical performance of six popular tuning methods under a variety of simulated and real data situations. Our results reveal that maximum likelihood methods outperform the popular cross-validation methods in most situations—especially in the presence of correlated errors. Furthermore, our results reveal that the maximum likelihood methods perform well even when the errors are non-Gaussian and/or heteroscedastic. For real data applications, we recommend comparing results using cross-validation and maximum likelihood tuning methods, given that these methods tend to perform similarly (differently) when the model is correctly (incorrectly) specified.},
	language = {en},
	number = {3},
	urldate = {2021-12-08},
	journal = {Stats},
	author = {Berry, Lauren N. and Helwig, Nathaniel E.},
	month = sep,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {functional data analysis, nonparametric regression, regularization, smoothing},
	pages = {701--724},
}

@article{bauer_introduction_2018,
	title = {An introduction to semiparametric function-on-scalar regression},
	volume = {18},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X17748034},
	doi = {10.1177/1471082X17748034},
	abstract = {Abstract:, Function-on-scalar regression models feature a function over some domain as the response while the regressors are scalars. Collections of time series as well as 2D or 3D images can be considered as functional responses. We provide a hands-on introduction for a flexible semiparametric approach for function-on-scalar regression, using spatially referenced time series of ground velocity measurements from large-scale simulated earthquake data as a running example. We discuss important practical considerations and challenges in the modelling process and outline best practices. The outline of our approach is complemented by comprehensive R code, freely available in the online appendix. This text is aimed at analysts with a working knowledge of generalized regression models and penalized splines.},
	language = {en},
	number = {3-4},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Bauer, Alexander and Scheipl, Fabian and Küchenhoff, Helmut and Gabriel, Alice-Agnes},
	month = jun,
	year = {2018},
	note = {Publisher: SAGE Publications India},
	keywords = {Functional regression, Functional response, generalized additive model, geophysics, penalized splines, semiparametric regression},
	pages = {346--364},
}

@article{eilers_discussion_2017,
	title = {Discussion on the article ‘{A} general framework for functional regression modelling’},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X17691157},
	doi = {10.1177/1471082X17691157},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Eilers, Paul},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	pages = {86--93},
}

@article{morris_comparison_2017,
	title = {Comparison and contrast of two general functional regression modelling frameworks},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681875},
	doi = {10.1177/1471082X16681875},
	abstract = {Abstract:, In their article, Greven and Scheipl describe an impressively general framework for performing functional regression that builds upon the generalized additive modelling framework. Over the past number of years, my collaborators and I have also been developing a general framework for functional regression, functional mixed models, which shares many similarities with this framework, but has many differences as well. In this discussion, I compare and contrast these two frameworks, to hopefully illuminate characteristics of each, highlighting their respective strengths and weaknesses, and providing recommendations regarding the settings in which each approach might be preferable.},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Morris, Jeffrey S.},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Bayesian modeling, Functional data analysis, functional mixed models, functional regression, linear mixed models},
	pages = {59--85},
}

@article{durban_estimation_2017,
	title = {On the estimation of functional random effects},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681333},
	doi = {10.1177/1471082X16681333},
	abstract = {Functional regression modelling has become one of the most vibrant areas of research in the last years. This discussion provides some alternative approaches to one of the key issues of functional data analysis: the basis representation of curves, and in particular, of functional random effects. First, we propose the estimation of functional principal components by penalizing the norm, and as an alternative, we provide an efficient and unified approach based on B-spline basis and quadratic penalties.},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Durban, Maria and Aguilera-Morillo, M. Carmen},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Functional PCA, SOP algorithm, Subject-specific curves, identifiability},
	pages = {50--58},
}

@article{greven_rejoinder_2017,
	title = {Rejoinder},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16689188},
	doi = {10.1177/1471082X16689188},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Greven, Sonja and Scheipl, Fabian},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	pages = {100--115},
}

@article{greven_rejoinder_2017-1,
	title = {Rejoinder},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16689188},
	doi = {10.1177/1471082X16689188},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Greven, Sonja and Scheipl, Fabian},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	pages = {100--115},
}

@article{bai_discussion_2017,
	title = {Discussion of the paper ‘{A} general framework for functional regression modelling’},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681335},
	doi = {10.1177/1471082X16681335},
	abstract = {Abstract, This discussion provides our reaction to the article by Greven and Scheipl. It contains an overview of their article and a description of the many areas of research that remain open and could benefit from further methodological and computational development.},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Bai, Jiawei and Ivanescu, Andrada and Crainiceanu, Ciprian M.},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Functional regression, high-dimensional data, penalized},
	pages = {36--44},
}

@article{kokoszka_discussion_2017,
	title = {Discussion of ‘a general framework for functional regression modelling’ by {Greven} and {Scheipl}},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681331},
	doi = {10.1177/1471082X16681331},
	abstract = {Abstract, We discuss the challenge in properly assessing the uncertainty of the estimates produced by the R package pffr, especially as it pertains to constructing confidence bands and computing p-values in functional linear models. We also present an approach that partially addresses some of these issues. Simulations are provided to help articulate these ideas.},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Kokoszka, Piotr and Reimherr, Matthew},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Confidence bands, Functional data analysis, functional regression, hypothesis testing},
	pages = {45--49},
}

@article{greven_general_2017,
	title = {A general framework for functional regression modelling},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681317},
	doi = {10.1177/1471082X16681317},
	abstract = {Abstract, Researchers are increasingly interested in regression models for functional data. This article discusses a comprehensive framework for additive (mixed) models for functional responses and/or functional covariates based on the guiding principle of reframing functional regression in terms of corresponding models for scalar data, allowing the adaptation of a large body of existing methods for these novel tasks. The framework encompasses many existing as well as new models. It includes regression for ‘generalized’ functional data, mean regression, quantile regression as well as generalized additive models for location, shape and scale (GAMLSS) for functional data. It admits many flexible linear, smooth or interaction terms of scalar and functional covariates as well as (functional) random effects and allows flexible choices of bases—particularly splines and functional principal components—and corresponding penalties for each term. It covers functional data observed on common (dense) or curve-specific (sparse) grids. Penalized-likelihood-based and gradient-boosting-based inference for these models are implemented in R packages refund and FDboost, respectively. We also discuss identifiability and computational complexity for the functional regression models covered. A running example on a longitudinal multiple sclerosis imaging study serves to illustrate the flexibility and utility of the proposed model class. Reproducible code for this case study is made available online.},
	language = {en},
	number = {1-2},
	urldate = {2021-11-25},
	journal = {Statistical Modelling},
	author = {Greven, Sonja and Scheipl, Fabian},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Functional data, GAMLSS, functional additive mixed model, functional principal components, gradient boosting, penalized splines},
	pages = {1--35},
}

@article{davids_movement_2003,
	title = {Movement {Systems} as {Dynamical} {Systems}},
	volume = {33},
	issn = {1179-2035},
	url = {https://doi.org/10.2165/00007256-200333040-00001},
	doi = {10.2165/00007256-200333040-00001},
	abstract = {In recent years, concepts and tools from dynamical systems theory have been successfully applied to the study of movement systems, contradicting traditional views of variability as noise or error. From this perspective, it is apparent that variability in movement systems is omnipresent and unavoidable due to the distinct constraints that shape each individual’s behaviour. In this position paper, it is argued that trial-to-trial movement variations within individuals and performance differences observed between individuals may be best interpreted as attempts to exploit the variability that is inherent within and between biological systems. That is, variability in movement systems helps individuals adapt to the unique constraints (personal, task and environmental) impinging on them across different timescales. We examine the implications of these ideas for sports medicine, by: (i) focusing on intra-individual variability in postural control to exemplify within-individual real-time adaptations to changing informational constraints in the performance environment; and (ii) interpreting recent evidence on the role of the angiotensin-converting enzyme gene as a genetic (developmental) constraint on individual differences in physical performance.},
	language = {en},
	number = {4},
	urldate = {2021-11-17},
	journal = {Sports Medicine},
	author = {Davids, Keith and Glazier, Paul and Araújo, Duarte and Bartlett, Roger},
	month = apr,
	year = {2003},
	pages = {245--260},
}

@article{davids_movement_2003-1,
	title = {Movement {Systems} as {Dynamical} {Systems}},
	volume = {33},
	issn = {1179-2035},
	url = {https://doi.org/10.2165/00007256-200333040-00001},
	doi = {10.2165/00007256-200333040-00001},
	abstract = {In recent years, concepts and tools from dynamical systems theory have been successfully applied to the study of movement systems, contradicting traditional views of variability as noise or error. From this perspective, it is apparent that variability in movement systems is omnipresent and unavoidable due to the distinct constraints that shape each individual’s behaviour. In this position paper, it is argued that trial-to-trial movement variations within individuals and performance differences observed between individuals may be best interpreted as attempts to exploit the variability that is inherent within and between biological systems. That is, variability in movement systems helps individuals adapt to the unique constraints (personal, task and environmental) impinging on them across different timescales. We examine the implications of these ideas for sports medicine, by: (i) focusing on intra-individual variability in postural control to exemplify within-individual real-time adaptations to changing informational constraints in the performance environment; and (ii) interpreting recent evidence on the role of the angiotensin-converting enzyme gene as a genetic (developmental) constraint on individual differences in physical performance.},
	language = {en},
	number = {4},
	urldate = {2021-11-17},
	journal = {Sports Medicine},
	author = {Davids, Keith and Glazier, Paul and Araújo, Duarte and Bartlett, Roger},
	month = apr,
	year = {2003},
	pages = {245--260},
}

@article{duquesne_statistical_2021,
	title = {Statistical kinematic modelling: concepts and model validity},
	volume = {0},
	issn = {1025-5842},
	shorttitle = {Statistical kinematic modelling},
	url = {https://doi.org/10.1080/10255842.2021.1995722},
	doi = {10.1080/10255842.2021.1995722},
	abstract = {Data reduction techniques are applied to reduce the volume of data while maintaining its integrity. For cyclic motion data, a reliable overview comparing these methods is lacking. Therefore, this study aims to evaluate the features of the different data reduction techniques by applying them to large public data sets. The periodicity of cyclic motion can be exploited by either analysing a single cycle or studying a series of cycles. Analysing single cycles requires a pre-processing step to isolate the amplitude variability. Three different alignment techniques were evaluated, namely Linear length normalisation (LLN), piecewise LLN (PLLN) and continuous registration (CR). CR showed to remove the most phase variation. For the data reduction, three techniques were assessed (i.e., principal component analysis (PCA), principal polynomial analysis (PPA) and multivariate functional PCA (MFPCA)) based on the in- and out-of-sample error, the compactness and the computation time. The differences were found to be minimal. From our results, PPA appeared to be most useful for data compression. Further, we recommend PCA and MFPCA for classification and feature extraction purposes. We suggest the use of PCA when computation time is key and we advise the use of MFPCA when the inclusion of different data sources is desired. In contrast, the analysis of a series of cycles requires a pre-processing step to decompose the series. Further, a regression model was used to compensate for the difference in fundamental frequency. PCA on FC and MFPCA with splines were applied on the frequency compensated curves. Both methods performed as good.},
	number = {0},
	urldate = {2021-11-08},
	journal = {Computer Methods in Biomechanics and Biomedical Engineering},
	author = {Duquesne, Kate and Galibarov, Pavel and Salazar-Torres, Jose-de-Jesus and Audenaert, Emmanuel},
	month = oct,
	year = {2021},
	pmid = {34714697},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10255842.2021.1995722},
	keywords = {PCA, cyclic motion, human gait, statistics, variability},
	pages = {1--12},
}

@article{pataky_simultaneous_2021,
	title = {Simultaneous inference for functional data in sports biomechanics},
	issn = {1863-818X},
	url = {https://doi.org/10.1007/s10182-021-00418-4},
	doi = {10.1007/s10182-021-00418-4},
	abstract = {The recent sports science literature conveys a growing interest in robust statistical methods to analyze smooth, regularly-sampled functional data. This paper focuses on the inferential problem of identifying the parts of a functional domain where two population means differ. We considered four approaches recently used in sports science: interval-wise testing (IWT), statistical parametric mapping (SPM), statistical nonparametric mapping (SnPM) and the Benjamini-Hochberg (BH) procedure for false discovery control. We applied these procedures to both six representative sports science datasets, and also to systematically varied simulated datasets which replicated ten signal- and/or noise-relevant parameters that were identified in the experimental datasets. We observed generally higher IWT and BH sensitivity for five of the six experimental datasets. BH was the most sensitive procedure in simulation, but also had relatively high false positive rates (generally {\textgreater} 0.1) which increased sharply ({\textgreater} 0.3) in certain extreme simulation scenarios including highly rough data. SPM and SnPM were more sensitive than IWT in simulation except for (1) high roughness, (2) high nonstationarity, and (3) highly nonuniform smoothness. These results suggest that the optimum procedure is both signal and noise-dependent. We conclude that: (1) BH is most sensitive but also susceptible to high false positive rates, (2) IWT, SPM and SnPM appear to have relatively inconsequential differences in terms of domain identification sensitivity, except in cases of extreme signal/noise characteristics, where IWT appears to be superior at identifying a greater portion of the true signal.},
	language = {en},
	urldate = {2021-10-15},
	journal = {AStA Advances in Statistical Analysis},
	author = {Pataky, Todd Colin and Abramowicz, Konrad and Liebl, Dominik and Pini, Alessia and de Luna, Sara Sjöstedt and Schelin, Lina},
	month = oct,
	year = {2021},
}

@misc{noauthor_asta_nodate,
	title = {{AStA} {Advances} in {Statistical} {Analysis}},
	url = {https://www.springer.com/journal/10182},
	abstract = {AStA - Advances in Statistical Analysis, a journal of the German Statistical Society, is published quarterly and presents original contributions on ...},
	language = {en},
	urldate = {2021-10-15},
	journal = {Springer},
}

@article{morris_wavelet-based_2006,
	title = {Wavelet-based functional mixed models},
	volume = {68},
	issn = {1369-7412},
	doi = {10.1111/j.1467-9868.2006.00539.x},
	abstract = {Increasingly, scientific studies yield functional data, in which the ideal units of observation are curves and the observed data consist of sets of curves that are sampled on a fine grid. We present new methodology that generalizes the linear mixed model to the functional mixed model framework, with model fitting done by using a Bayesian wavelet-based approach. This method is flexible, allowing functions of arbitrary form and the full range of fixed effects structures and between-curve covariance structures that are available in the mixed model framework. It yields nonparametric estimates of the fixed and random-effects functions as well as the various between-curve and within-curve covariance matrices. The functional fixed effects are adaptively regularized as a result of the non-linear shrinkage prior that is imposed on the fixed effects' wavelet coefficients, and the random-effect functions experience a form of adaptive regularization because of the separately estimated variance components for each wavelet coefficient. Because we have posterior samples for all model quantities, we can perform pointwise or joint Bayesian inference or prediction on the quantities of the model. The adaptiveness of the method makes it especially appropriate for modelling irregular functional data that are characterized by numerous local features like peaks.},
	language = {eng},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series B, Statistical Methodology},
	author = {Morris, Jeffrey S. and Carroll, Raymond J.},
	month = apr,
	year = {2006},
	pmid = {19759841},
	pmcid = {PMC2744105},
	pages = {179--199},
}

@article{lopez-pintado_concept_2009,
	title = {On the {Concept} of {Depth} for {Functional} {Data}},
	volume = {104},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/40592217},
	abstract = {The statistical analysis of functional data is a growing need in many research areas. In particular, a robust methodology is important to study curves, which are the output of many experiments in applied statistics. As a starting point for this robust analysis, we propose, analyze, and apply a new definition of depth for functional observations based on the graphic representation of the curves. Given a collection of functions, it establishes the "centrality" of an observation and provides a natural center-outward ordering of the sample curves. Robust statistics, such as the median function or a trimmed mean function, can be defined from this depth definition. Its finite-dimensional version provides a new depth for multivariate data that is computationally feasible and useful for studying high-dimensional observations. Thus, this new depth is also suitable for complex observations such as microarray data, images, and those arising in some recent marketing and financial studies. Natural properties of these new concepts are established and the uniform consistency of the sample depth is proved. Simulation results show that the corresponding depth based trimmed mean presents better performance than other possible location estimators proposed in the literature for some contaminated models. Data depth can be also used to screen for outliers. The ability of the new notions of depth to detect "shape" outliers is presented. Several real datasets are considered to illustrate this new concept of depth, including applications to microarray observations, weather data, and growth curves. Finally, through this depth, we generalize to functions the Wilcoxon rank sum test. It allows testing whether two groups of curves come from the same population. This functional rank test when applied to children growth curves shows different growth patterns for boys and girls.},
	number = {486},
	urldate = {2021-10-13},
	journal = {Journal of the American Statistical Association},
	author = {López-Pintado, Sara and Romo, Juan},
	year = {2009},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {718--734},
}

@article{sun_functional_2011,
	title = {Functional {Boxplots}},
	volume = {20},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/jcgs.2011.09224},
	doi = {10.1198/jcgs.2011.09224},
	abstract = {This article proposes an informative exploratory tool, the functional boxplot, for visualizing functional data, as well as its generalization, the enhanced functional boxplot. Based on the center outward ordering induced by band depth for functional data, the descriptive statistics of a functional boxplot are: the envelope of the 50\% central region, the median curve, and the maximum non-outlying envelope. In addition, outliers can be detected in a functional boxplot by the 1.5 times the 50\% central region empirical rule, analogous to the rule for classical boxplots. The construction of a functional boxplot is illustrated on a series of sea surface temperatures related to the El Niño phenomenon and its outlier detection performance is explored by simulations. As applications, the functional boxplot and enhanced functional boxplot are demonstrated on children growth data and spatio-temporal U.S. precipitation data for nine climatic regions, respectively. This article has supplementary material online.},
	number = {2},
	urldate = {2021-10-08},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Sun, Ying and Genton, Marc G.},
	month = jan,
	year = {2011},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jcgs.2011.09224},
	keywords = {Depth, Functional data, Growth data, Precipitation data, Space–time data, Visualization},
	pages = {316--334},
}

@techreport{wickham_40_2021,
	type = {Technical {Report}},
	title = {40 years of boxplots},
	abstract = {The boxplot plot has been around for over 40 years. This paper summarises the improvements, extensions and variations since Tukey first introduced his 'schematic plot in 1970. We focus particularly on richer displays of density and extensions to 2d.},
	institution = {had.co.nz},
	author = {Wickham, Hadley and Stryjewski, Lisa},
	year = {2021},
}

@book{tukey_exploratory_1977,
	address = {Reading, Mass},
	edition = {1st edition},
	title = {Exploratory {Data} {Analysis}},
	isbn = {978-0-201-07616-5},
	abstract = {The approach in this introductory book is that of informal study of the data. Methods range from plotting picture-drawing techniques to rather elaborate numerical summaries. Several of the methods are the original creations of the author, and all can be carried out either with pencil or aided by hand-held calculator.},
	language = {English},
	publisher = {Pearson},
	author = {Tukey, John},
	month = jan,
	year = {1977},
}

@incollection{genton_functional_2020,
	title = {Functional {Data} {Visualization}},
	isbn = {978-1-118-44511-2},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat08290},
	abstract = {This article reviews tools to visualize functional data, that is, curves, surfaces/images, and trajectories. These tools are based on ranking functional data by means of notions of depth/outlyingness and make use of methods for functional outlier detections. For univariate functional data, the functional boxplot and surface boxplot are emphasized. For multivariate functional data, the magnitude–shape plot, the two-stage functional boxplot, and the trajectory functional boxplot are described. A bivariate functional dataset of the angles formed by the hip and knee of 39 children over their gait cycles is used throughout for illustration of the various visualization tools.},
	language = {en},
	urldate = {2021-09-22},
	booktitle = {Wiley {StatsRef}: {Statistics} {Reference} {Online}},
	publisher = {American Cancer Society},
	author = {Genton, Marc G. and Sun, Ying},
	year = {2020},
	doi = {10.1002/9781118445112.stat08290},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118445112.stat08290},
	keywords = {functional boxplot, functional data, functional depth, functional outlyingness, image data, magnitude-shape plot, multivariate functional data, surface boxplot, surface data, trajectory functional boxplot, two-stage functional boxplot, visualization},
	pages = {1--11},
}

@article{sangalli_case_2009,
	title = {A {Case} {Study} in {Exploratory} {Functional} {Data} {Analysis}: {Geometrical} {Features} of the {Internal} {Carotid} {Artery}},
	volume = {104},
	issn = {0162-1459},
	shorttitle = {A {Case} {Study} in {Exploratory} {Functional} {Data} {Analysis}},
	url = {https://doi.org/10.1198/jasa.2009.0002},
	doi = {10.1198/jasa.2009.0002},
	abstract = {This pilot study is a product of the AneuRisk Project, a scientific program that aims at evaluating the role of vascular geometry and hemodynamics in the pathogenesis of cerebral aneurysms. By means of functional data analyses, we explore the AneuRisk dataset to highlight the relations between the geometric features of the internal carotid artery, expressed by its radius profile and centerline curvature, and the aneurysm location. After introducing a new similarity index for functional data, we eliminate ancillary variability of vessel radius and curvature profiles through an iterative registration procedure. We then reduce data dimension by means of functional principal components analysis. Last, a quadratic discriminant analysis of functional principal components scores allows us to discriminate patients with aneurysms in different districts.},
	number = {485},
	urldate = {2021-08-09},
	journal = {Journal of the American Statistical Association},
	author = {Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone and Veneziani, Alessandro},
	month = mar,
	year = {2009},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jasa.2009.0002},
	keywords = {Aneurysm classification, Curve registration, Functional principal component analysis, Hemodynamics},
	pages = {37--48},
}

@article{baida_does_2018,
	title = {Does the amount of lower extremity movement variability differ between injured and uninjured populations? {A} systematic review},
	volume = {28},
	issn = {1600-0838},
	shorttitle = {Does the amount of lower extremity movement variability differ between injured and uninjured populations?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.13036},
	doi = {10.1111/sms.13036},
	abstract = {Movement variability during repetitive performance of a dynamic activity (eg, running, jumping, kicking) is considered an integral characteristic of optimal movement execution; however, its relationship with musculo-skeletal injury is not known. The primary aim of this study was to review published comparison trials to determine whether movement variability differs between uninjured controls and subjects with a lower limb musculo-skeletal injury. A systematic search of online databases; MEDLINE, Sports Discus, Scopus, and Web of Science was conducted from July to November 2016. Studies were selected if they (a) included participants with a lower limb injury, (b) compared injured participants to uninjured controls, (c) examined movement variability for at least one dependent variable, and (d) provided a statistical between-group comparison when comparing measures of movement variability. Studies were excluded if they (a) investigated neurological disorders, (b) examined musculo-skeletal injury in the upper extremity or spine, and (c) used nonlinear measures to examine variability (ie, complexity). A significant difference between injured and uninjured populations was reported in 73\% of the included studies, and of these, 64\% reported greater movement variability in the injured group. This is the first systematic review with a best-evidence synthesis investigating the association between movement variability and musculo-skeletal injury. Findings suggest that movement variability in those with a musculo-skeletal injury differs from uninjured individuals. Interestingly, there was an overall trend toward greater movement variability being associated with the injured groups, although it should be noted that this trend was not consistent across all subcategories (eg, injury type). For a clearer insight into the clinical application of variability, greater methodological homogeneity is required and prospective research is recommended.},
	language = {en},
	number = {4},
	urldate = {2021-07-06},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Baida, S. R. and Gore, S. J. and Franklyn-Miller, A. D. and Moran, K. A.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.13036},
	keywords = {biomechanics, control, coordination, injury},
	pages = {1320--1338},
}

@article{baida_does_2018-1,
	title = {Does the amount of lower extremity movement variability differ between injured and uninjured populations? {A} systematic review},
	volume = {28},
	issn = {1600-0838},
	shorttitle = {Does the amount of lower extremity movement variability differ between injured and uninjured populations?},
	doi = {10.1111/sms.13036},
	abstract = {Movement variability during repetitive performance of a dynamic activity (eg, running, jumping, kicking) is considered an integral characteristic of optimal movement execution; however, its relationship with musculo-skeletal injury is not known. The primary aim of this study was to review published comparison trials to determine whether movement variability differs between uninjured controls and subjects with a lower limb musculo-skeletal injury. A systematic search of online databases; MEDLINE, Sports Discus, Scopus, and Web of Science was conducted from July to November 2016. Studies were selected if they (a) included participants with a lower limb injury, (b) compared injured participants to uninjured controls, (c) examined movement variability for at least one dependent variable, and (d) provided a statistical between-group comparison when comparing measures of movement variability. Studies were excluded if they (a) investigated neurological disorders, (b) examined musculo-skeletal injury in the upper extremity or spine, and (c) used nonlinear measures to examine variability (ie, complexity). A significant difference between injured and uninjured populations was reported in 73\% of the included studies, and of these, 64\% reported greater movement variability in the injured group. This is the first systematic review with a best-evidence synthesis investigating the association between movement variability and musculo-skeletal injury. Findings suggest that movement variability in those with a musculo-skeletal injury differs from uninjured individuals. Interestingly, there was an overall trend toward greater movement variability being associated with the injured groups, although it should be noted that this trend was not consistent across all subcategories (eg, injury type). For a clearer insight into the clinical application of variability, greater methodological homogeneity is required and prospective research is recommended.},
	language = {eng},
	number = {4},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Baida, S. R. and Gore, S. J. and Franklyn-Miller, A. D. and Moran, K. A.},
	month = apr,
	year = {2018},
	pmid = {29239047},
	keywords = {Biomechanical Phenomena, Case-Control Studies, Humans, Leg Injuries, Movement, Musculoskeletal System, Range of Motion, Articular, biomechanics, control, coordination, injury},
	pages = {1320--1338},
}

@article{lee_conditional_2004,
	title = {Conditional and {Marginal} {Models}: {Another} {View}},
	volume = {19},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Conditional and {Marginal} {Models}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-19/issue-2/Conditional-and-Marginal-Models-Another-View/10.1214/088342304000000305.full},
	doi = {10.1214/088342304000000305},
	abstract = {There has existed controversy about the use of marginal and conditional models, particularly in the analysis of data from longitudinal studies. We show that alleged differences in the behavior of parameters in so-called marginal and conditional models are based on a failure to compare like with like. In particular, these seemingly apparent differences are meaningless because they are mainly caused by preimposed unidentifiable constraints on the random effects in models. We discuss the advantages of conditional models over marginal models. We regard the conditional model as fundamental, from which marginal predictions can be made.},
	number = {2},
	urldate = {2021-07-06},
	journal = {Statistical Science},
	author = {Lee, Youngjo and Nelder, John A.},
	month = may,
	year = {2004},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {generalized linear model, hierarchical generalized linear model, joint modeling of mean and dispersion, spatial correlation, temporal correlation},
	pages = {219--238},
}

@article{backenroth_modeling_2018,
	title = {Modeling {Motor} {Learning} {Using} {Heteroscedastic} {Functional} {Principal} {Components} {Analysis}},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2017.1379403},
	doi = {10.1080/01621459.2017.1379403},
	abstract = {We propose a novel method for estimating population-level and subject-specific effects of covariates on the variability of functional data. We extend the functional principal components analysis framework by modeling the variance of principal component scores as a function of covariates and subject-specific random effects. In a setting where principal components are largely invariant across subjects and covariate values, modeling the variance of these scores provides a flexible and interpretable way to explore factors that affect the variability of functional data. Our work is motivated by a novel dataset from an experiment assessing upper extremity motor control, and quantifies the reduction in movement variability associated with skill learning. The proposed methods can be applied broadly to understand movement variability, in settings that include motor learning, impairment due to injury or disease, and recovery. Supplementary materials for this article are available online.},
	number = {523},
	urldate = {2021-07-06},
	journal = {Journal of the American Statistical Association},
	author = {Backenroth, Daniel and Goldsmith, Jeff and Harran, Michelle D. and Cortes, Juan C. and Krakauer, John W. and Kitago, Tomoko},
	month = jul,
	year = {2018},
	pmid = {30416231},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2017.1379403},
	keywords = {Functional data, Kinematic data, Motor control, Probabilistic PCA, Variance modeling, Variational Bayes},
	pages = {1003--1015},
}

@article{zhou_joint_2008,
	title = {Joint modelling of paired sparse functional data using principal components},
	volume = {95},
	issn = {0006-3444},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2672432/},
	doi = {10.1093/biomet/asn035},
	abstract = {We propose a modelling framework to study the relationship between two paired longitudinally observed variables. The data for each variable are viewed as smooth curves measured at discrete time-points plus random errors. While the curves for each variable are summarized using a few important principal components, the association of the two longitudinal variables is modelled through the association of the principal component scores. We use penalized splines to model the mean curves and the principal component curves, and cast the proposed model into a mixed-effects model framework for model fitting, prediction and inference. The proposed method can be applied in the difficult case in which the measurement times are irregular and sparse and may differ widely across individuals. Use of functional principal components enhances model interpretation and improves statistical and numerical stability of the parameter estimates.},
	number = {3},
	urldate = {2021-06-03},
	journal = {Biometrika},
	author = {ZHOU, LAN and HUANG, JIANHUA Z. and CARROLL, RAYMOND J.},
	year = {2008},
	pmid = {19396364},
	pmcid = {PMC2672432},
	pages = {601--619},
}

@article{zhang_interpretable_2019,
	title = {Interpretable {Principal} {Components} {Analysis} for {Multilevel} {Multivariate} {Functional} {Data}, with {Application} to {EEG} {Experiments}},
	url = {http://arxiv.org/abs/1909.08024},
	abstract = {Many studies collect functional data from multiple subjects that have both multilevel and multivariate structures. An example of such data comes from popular neuroscience experiments where participants' brain activity is recorded using modalities such as EEG and summarized as power within multiple time-varying frequency bands within multiple electrodes, or brain regions. Summarizing the joint variation across multiple frequency bands for both whole-brain variability between subjects, as well as location-variation within subjects, can help to explain neural reactions to stimuli. This article introduces a novel approach to conducting interpretable principal components analysis on multilevel multivariate functional data that decomposes total variation into subject-level and replicate-within-subject-level (i.e. electrode-level) variation, and provides interpretable components that can be both sparse among variates (e.g. frequency bands) and have localized support over time within each frequency band. The sparsity and localization of components is achieved by solving an innovative rank-one based convex optimization problem with block Frobenius and matrix \$L\_1\$-norm based penalties. The method is used to analyze data from a study to better understand reactions to emotional information in individuals with histories of trauma and the symptom of dissociation, revealing new neurophysiological insights into how subject- and electrode-level brain activity are associated with these phenomena.},
	urldate = {2021-05-31},
	journal = {arXiv:1909.08024 [stat]},
	author = {Zhang, Jun and Siegle, Greg J. and D'Andrea, Wendy and Krafty, Robert T.},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.08024},
	keywords = {Statistics - Applications, Statistics - Methodology},
}

@misc{noauthor_doug_nodate,
	title = {Doug {Altman}: {Driving} critical appraisal and improvements in the quality of methodological and medical research - {Sauerbrei} - 2021 - {Biometrical} {Journal} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/bimj.202000053},
	urldate = {2021-05-18},
}

@article{heisig_why_2019,
	title = {Why {You} {Should} {Always} {Include} a {Random} {Slope} for the {Lower}-{Level} {Variable} {Involved} in a {Cross}-{Level} {Interaction}},
	volume = {35},
	issn = {0266-7215},
	url = {https://doi.org/10.1093/esr/jcy053},
	doi = {10.1093/esr/jcy053},
	abstract = {Mixed-effects multilevel models are often used to investigate cross-level interactions, a specific type of context effect that may be understood as an upper-level variable moderating the association between a lower-level predictor and the outcome. We argue that multilevel models involving cross-level interactions should always include random slopes on the lower-level components of those interactions. Failure to do so will usually result in severely anti-conservative statistical inference. We illustrate the problem with extensive Monte Carlo simulations and examine its practical relevance by studying 30 prototypical cross-level interactions with European Social Survey data for 28 countries. In these empirical applications, introducing a random slope term reduces the absolute t-ratio of the cross-level interaction term by 31 per cent or more in three quarters of cases, with an average reduction of 42 per cent. Many practitioners seem to be unaware of these issues. Roughly half of the cross-level interaction estimates published in the European Sociological Review between 2011 and 2016 are based on models that omit the crucial random slope term. Detailed analysis of the associated test statistics suggests that many of the estimates would not reach conventional thresholds for statistical significance in correctly specified models that include the random slope. This raises the question how much robust evidence of cross-level interactions sociology has actually produced over the past decades.},
	number = {2},
	urldate = {2021-05-18},
	journal = {European Sociological Review},
	author = {Heisig, Jan Paul and Schaeffer, Merlin},
	month = apr,
	year = {2019},
	pages = {258--279},
}

@article{sangalli_efficient_2009,
	title = {Efficient estimation of three-dimensional curves and their derivatives by free-knot regression splines, applied to the analysis of inner carotid artery centrelines},
	volume = {58},
	copyright = {© 2009 Royal Statistical Society},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2008.00653.x},
	doi = {https://doi.org/10.1111/j.1467-9876.2008.00653.x},
	abstract = {Summary. We deal with the problem of efficiently estimating a three-dimensional curve and its derivatives, starting from a discrete and noisy observation of the curve. This problem is now arising in many applicative contexts, thanks to the advent of devices that provide three-dimensional images and measures, such as three-dimensional scanners in medical diagnostics. Our research, in particular, stems from the need for accurate estimation of the curvature of an artery, from image reconstructions of three-dimensional angiographies. This need has emerged within the AneuRisk project, a scientific endeavour which aims to investigate the role of vessel morphology, blood fluid dynamics and biomechanical properties of the vascular wall, on the pathogenesis of cerebral aneurysms. We develop a regression technique that exploits free-knot splines in a novel setting, to estimate three-dimensional curves and their derivatives. We thoroughly compare this technique with a classical regression method, local polynomial smoothing, showing that three-dimensional free-knot regression splines yield more accurate and efficient estimates.},
	language = {en},
	number = {3},
	urldate = {2021-05-18},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone and Veneziani, Alessandro},
	year = {2009},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9876.2008.00653.x},
	keywords = {Free-knot regression splines, Functional data analysis, Local polynomial smoothing, Smooth curve fitting},
	pages = {285--306},
}

@article{happ-kurz_object-oriented_2020,
	title = {Object-{Oriented} {Software} for {Functional} {Data}},
	volume = {93},
	copyright = {Copyright (c) 2020 Clara Happ-Kurz},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v093i05},
	doi = {10.18637/jss.v093.i05},
	language = {en},
	number = {1},
	urldate = {2021-05-18},
	journal = {Journal of Statistical Software},
	author = {Happ-Kurz, Clara},
	month = apr,
	year = {2020},
	note = {Number: 1},
	keywords = {functional data analysis, functional principal component analysis, multivariate functional data, object orientation, simulation},
	pages = {1--38},
}

@article{chiou_multivariate_2016,
	series = {Special {Issue} on {Statistical} {Models} and {Methods} for {High} or {Infinite} {Dimensional} {Spaces}},
	title = {Multivariate functional linear regression and prediction},
	volume = {146},
	issn = {0047-259X},
	url = {https://www.sciencedirect.com/science/article/pii/S0047259X15002535},
	doi = {10.1016/j.jmva.2015.10.003},
	abstract = {We propose a multivariate functional linear regression (mFLR) approach to analysis and prediction of multivariate functional data in cases in which both the response and predictor variables contain multivariate random functions. The mFLR model, coupled with the multivariate functional principal component analysis approach, takes the advantage of cross-correlation between component functions within the multivariate response and predictor variables, respectively. The estimate of the matrix of bivariate regression functions is consistent in the sense of the multi-dimensional Gram–Schmidt norm and is asymptotically normally distributed. The prediction intervals of the multivariate random trajectories are available for predictive inference. We show the finite sample performance of mFLR by a simulation study and illustrate the method through predicting multivariate traffic flow trajectories for up-to-date and partially observed traffic streams.},
	language = {en},
	urldate = {2021-05-17},
	journal = {Journal of Multivariate Analysis},
	author = {Chiou, Jeng-Min and Yang, Ya-Fang and Chen, Yu-Ting},
	month = apr,
	year = {2016},
	keywords = {Functional prediction, Functional principal component analysis, Functional regression, Multivariate functional data, Stochastic processes},
	pages = {301--312},
}

@article{rosen_bayesian_2009,
	title = {A {Bayesian} regression model for multivariate functional data},
	volume = {53},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947309001352},
	doi = {10.1016/j.csda.2009.03.026},
	abstract = {In this paper we present a model for the analysis of multivariate functional data with unequally spaced observation times that may differ among subjects. Our method is formulated as a Bayesian mixed-effects model in which the fixed part corresponds to the mean functions, and the random part corresponds to individual deviations from these mean functions. Covariates can be incorporated into both the fixed and the random effects. The random error term of the model is assumed to follow a multivariate Ornstein–Uhlenbeck process. For each of the response variables, both the mean and the subject-specific deviations are estimated via low-rank cubic splines using radial basis functions. Inference is performed via Markov chain Monte Carlo methods.},
	language = {en},
	number = {11},
	urldate = {2021-05-17},
	journal = {Computational Statistics \& Data Analysis},
	author = {Rosen, Ori and Thompson, Wesley K.},
	month = sep,
	year = {2009},
	pages = {3773--3786},
}

@phdthesis{wenbo_sun_uncertainty_2019,
	type = {Doctoral {Thesis}},
	title = {Uncertainty {Quantification} {Methodologies} for {Functional} {Data} in {Biomechanical} {Applications}},
	abstract = {Massive data are feasibly collected or generated with the rapid development of sensing,
high computing and computer simulation technologies. Among various types of
data, functional data plays an important role in tracking system behaviors in various
applications. However, functional data often shows complex data uncertainty
caused by multiple factors such as experimental conditions, subject characteristics
or computer simulation settings. To better understand the system behaviors for
decision-making, new methodologies are expected to systematically quantify the uncertainty
of functional data. Specifically, three major research issues are studied in
the dissertation. First, the problem of constructing confidence bands (also known as
corridors in biomechanical applications) of univariate functional signals is discussed.
An effective method is developed for confidence bands generation that applies principal
component analysis (PCA). Rather than using existing empirical models to
account for the effects of subject variables on functional responses, linear regression
models are further built to model the relationship between extracted PC features and
subject variables, which makes the effects of subject variables interpretable. The advantage
of the resultant confidence bands is reflected by the narrower bands than
those generated by existing techniques while keeping a high coverage rate of sampled
experimental functional data. Second, a generic method is developed to construct
confidence bands for bivariate functional data. The effect of subject variables is
quantified by non-parametric B-spline fitting and a polynomial regression model,
which is capable of capturing non-linear dependencies between the subject variables
vii
and functional responses. Moreover, a Gaussian process model is developed to model
the complicated covariance structure, which can fully consider between-subject and
within-subject variability, auto-correlation between time points and cross-correlation
between bivariate functional responses. Therefore, the constructed confidence bands
can effectively capture the bivariate functional profile shape and functional variation
patterns. As a byproduct, the developed model is effectively used for testing
outliers of abnormal functional responses based on the property of the developed
Gaussian process model. Third, a method to search for the optimal system design
using an inexact computer simulation model with uncertainty quantification is developed.
The uncertainty is quantified by specifying feasible regions instead of building
a full probabilistic model, which makes the proposed method to be applicable when
an emulator is not available. The use of feasible regions also narrows the potential
simulation parameter set and reduces the computation load in generating simulation
runs. An robust optimization problem is formulated and integrated with the model
calibration. The proposed point and interval estimators of the optimal design are
mathematically proved to have consistency and coverage properties.},
	school = {University of Michigan},
	author = {{Wenbo Sun}},
	year = {2019},
}

@misc{noauthor_landmark-based_nodate,
	title = {Landmark-{Based} {Registration} of {Curves} via the {Continuous} {Wavelet} {Transform}: {Journal} of {Computational} and {Graphical} {Statistics}: {Vol} 15, {No} 3},
	url = {https://www.tandfonline.com/doi/abs/10.1198/106186006X133023},
	urldate = {2021-05-17},
}

@article{shang_ftsa_2013,
	title = {ftsa: {An} {R} package for analyzing functional time series},
	volume = {5},
	shorttitle = {ftsa},
	url = {https://researchers.mq.edu.au/en/publications/ftsa-an-r-package-for-analyzing-functional-time-series},
	language = {English},
	number = {1},
	urldate = {2021-05-17},
	journal = {R Journal},
	author = {Shang, Han Lin},
	month = jun,
	year = {2013},
	note = {Publisher: R Foundation for Statistical Computing},
	pages = {64--72},
}

@inproceedings{shang_exploratory_2010,
	title = {Exploratory graphics for functional data},
	abstract = {We survey some graphical tools for visualizing large sets of functional data represented by smooth curves. These graphical tools include the phase-plane plot, singular value decomposition plot, rainbow plot, functional variants of the bagplot and the highest density region boxplot. The latter two techniques utilize the first two robust principal component scores, Tukey’s halfspace location depth and highest density regions.

The computer code and datasets are collected in the rainbow package for R, which is available at the Comprehensive R Archive Network (CRAN).

Keywords: Highest density regions, Kernel density estimation, Robust principal component analysis, Singular value decomposition, Tukey’s halfspace location depth.},
	author = {Shang, Han Lin and Hyndman, Rob J.},
	month = jun,
	year = {2010},
}

@misc{noauthor_pdf_nodate,
	title = {[{PDF}] {Exploratory} {Graphics} for {Functional} {Actigraphy} {Data} {\textbar} {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/Exploratory-Graphics-for-Functional-Actigraphy-Data-Symanzik-Shannon/f503df50b9b7c6efd87361bee264f6779e51dc41},
	urldate = {2021-05-17},
}

@misc{noauthor_flexible_nodate,
	title = {Flexible smoothing with {P}-splines: a unified approach - {I} {D} {Currie}, {M} {Durban}, 2002},
	url = {https://journals.sagepub.com/doi/abs/10.1191/1471082x02st039ob?journalCode=smja},
	urldate = {2021-05-17},
}

@article{coffey_analyzing_2011,
	title = {Analyzing time-course microarray data using functional data analysis - a review},
	issn = {1544-6115},
	url = {https://aran.library.nuigalway.ie/handle/10379/1903},
	abstract = {Gene expression over time can be viewed as a continuous process and therefore represented as 
a continuous curve or function. Functional data analysis (FDA) is a statistical methodology used 
to analyze functional data that has become increasingly popular in the analysis of time-course 
gene expression data. Several FDA techniques have been applied to gene expression profiles 
including functional regression analysis (to describe the relationship between expression profiles 
and other covariate(s)), functional discriminant analysis (to discriminate and classify groups of 
genes) and functional principal components analysis (for dimension reduction and clustering). 
This paper reviews the use of FDA and it¿s associated methods to analyze time-course microarray 
gene expression data.},
	language = {en\_US},
	urldate = {2021-03-01},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {Coffey, Norma and Hinde, John},
	month = may,
	year = {2011},
	note = {Accepted: 2011-05-16T15:11:00Z
Publisher: Statistical Applications in Genetics and Molecular Biology},
}

@article{davis_sagittal_2019,
	title = {Sagittal plane walking biomechanics in individuals with knee osteoarthritis after quadriceps strengthening},
	volume = {27},
	issn = {1522-9653},
	doi = {10.1016/j.joca.2018.12.026},
	abstract = {OBJECTIVE: To compare sagittal walking gait biomechanics between participants with knee osteoarthritis (KOA) who increased quadriceps strength following a lower-extremity strengthening intervention (responders) and those who did not increase strength following the same strengthening protocol (non-responders) both at baseline and following the lower extremity strengthening protocol.
DESIGN: Fifty-three participants with radiographic KOA (47\% female, 62.3 ± 7.1 years, BMI = 28.5 ± 3.9 kg/m2) were enrolled in 10 sessions of lower extremity strengthening over a 28-day period. Maximum isometric quadriceps strength and walking gait biomechanics were collected on the involved limb at baseline and 4-weeks following the strengthening intervention. Responders were classified as individuals who increased quadriceps strength greater than the upper limit of the 95\% confidence interval (CI) for the minimal detectable change (MDC) in quadriceps strength (29 Nm) determined in a previous study. 2 × 2 functional analyses of variance were used to evaluate the effects of group (responders and non-responders) and time (baseline and 4-weeks) on time-normalized waveforms for knee flexion angle (KFA), vertical ground reaction force (vGRF), and internal knee extension moment (KEM).
RESULTS: A significant group x time interaction for KFA demonstrated greater KFA in the first half of stance at baseline and greater knee extension in the second half of stance at 4-weeks in responders compared to non-responders. There was no significant group x time interaction for vGRF or internal KEM.
CONCLUSIONS: Quadriceps strengthening may be used to stimulate small changes in KFA in individuals with KOA.},
	language = {eng},
	number = {5},
	journal = {Osteoarthritis and Cartilage},
	author = {Davis, H. C. and Luc-Harkey, B. A. and Seeley, M. K. and Blackburn, J. Troy and Pietrosimone, B.},
	year = {2019},
	pmid = {30660722},
	pmcid = {PMC6475608},
	keywords = {Adult, Aged, Biomechanical Phenomena, Disability Evaluation, Female, Functional data analysis, Gait, Humans, Internal knee extension moment, Knee Joint, Knee flexion angle, Male, Middle Aged, Muscle Strength, Osteoarthritis, Knee, Pain Measurement, Quadriceps Muscle, Range of Motion, Articular, Resistance Training, Vertical ground reaction force, Waveform analysis, Weight-Bearing},
	pages = {771--780},
}

@article{levitin_introduction_2007,
	title = {Introduction to functional data analysis},
	volume = {48},
	issn = {1878-7304(Electronic),0708-5591(Print)},
	doi = {10.1037/cp2007014},
	abstract = {Psychologists and behavioural scientists are increasingly collecting data that are drawn from continuous underlying processes. We describe a set of quantitative methods, Functional Data Analysis (FDA), which can answer a number of questions that traditional statistical approaches cannot. These methods are applicable for analyzing many datasets that are common in experimental psychology, including time series data, repeated measures, and data distributed over time or space as in neuroimaging experiments. The primary advantage of FDA is that it allows the researcher to ask questions about when in a time series differences may exist between two or more sets of observations. We discuss functional correlations, principal components, the derivatives of functional curves, and analysis of variances models. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Canadian Psychology/Psychologie canadienne},
	author = {Levitin, Daniel J. and Nuzzo, Regina L. and Vines, Bradley W. and Ramsay, J. O.},
	year = {2007},
	note = {Place: Canada
Publisher: Canadian Psychological Association},
	keywords = {Analysis of Variance, Behavioral Sciences, Methodology, Psychology, Quantitative Methods, Statistical Analysis},
	pages = {135--155},
}

@article{kenneally-dabrowski_late_2019,
	title = {Late swing running mechanics influence hamstring injury susceptibility in elite rugby athletes: {A} prospective exploratory analysis},
	volume = {92},
	issn = {0021-9290},
	shorttitle = {Late swing running mechanics influence hamstring injury susceptibility in elite rugby athletes},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929019303811},
	doi = {10.1016/j.jbiomech.2019.05.037},
	abstract = {Hamstring injuries are one of the most prevalent injuries in rugby union and many other running-based sports, such as track sprinting and soccer. The majority of these injuries occur during running; however, the relationship between running mechanics and hamstring injury is unclear. Obtaining large samples of prospective injury data to examine this relationship is difficult, and therefore exploratory analysis frameworks may assist in deriving valuable information from studies with small but novel samples. The aim of this study was to undertake a prospective exploratory analysis of the relationship between running mechanics and hamstring injury. Kinematic and kinetic data of the trunk, pelvis and lower limbs were collected during maximal overground running efforts for ten elite rugby union athletes. Subsequently, hamstring injury occurrence was recorded for the following Super Rugby season, during which three athletes sustained a running-based hamstring injury. Functional principal component analysis was used to visualise patterns of variability in running mechanics during the late swing phase between athletes. Results indicated that subsequently injured athletes demonstrated a tendency for greater thoracic lateral flexion, greater hip extension moments and greater knee power absorption, compared to uninjured athletes. All variables demonstrated an ability to descriptively differentiate between injured and uninjured athletes at approximately 60\% of the late swing phase. Therefore, we hypothesize that greater thoracic lateral flexion, a greater hip extension moment and greater knee power absorption between peak hip flexion and peak knee extension during the late swing phase may put rugby athletes at greater risk of running-based hamstring injury.},
	language = {en},
	urldate = {2021-05-14},
	journal = {Journal of Biomechanics},
	author = {Kenneally-Dabrowski, Claire and Brown, Nicholas A. T. and Warmenhoven, John and Serpell, Benjamin G. and Perriman, Diana and Lai, Adrian K. M. and Spratford, Wayne},
	month = jul,
	year = {2019},
	keywords = {Biomechanics, Muscle injuries, PCA, Rugby},
	pages = {112--119},
}

@article{lees_biomechanics_2010,
	title = {The biomechanics of kicking in soccer: {A} review},
	volume = {28},
	issn = {0264-0414},
	shorttitle = {The biomechanics of kicking in soccer},
	url = {https://doi.org/10.1080/02640414.2010.481305},
	doi = {10.1080/02640414.2010.481305},
	abstract = {Kicking is the defining action of soccer, so it is appropriate to review the scientific work that provides a basis of our understanding of this skill. The focus of this review is biomechanical in nature and builds on and extends previous reviews and overviews. While much is known about the biomechanics of the kicking leg, there are several other aspects of the kick that have been the subject of recent exploration. Researchers have widened their interest to consider the kick beginning from the way a player approaches the ball to the end of ball flight, the point that determines the success of the kick. This interest has encapsulated characteristics of overall technique and the influences of the upper body, support leg and pelvis on the kicking action, foot–ball impact and the influences of footwear and soccer balls, ball launch characteristics and corresponding flight of the ball. This review evaluates these and attempts to provide direction for future research.},
	number = {8},
	urldate = {2021-05-14},
	journal = {Journal of Sports Sciences},
	author = {Lees, A. and Asai, T. and Andersen, T. B. and Nunome, H. and Sterzing, T.},
	month = jun,
	year = {2010},
	pmid = {20509089},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02640414.2010.481305},
	keywords = {Kicking, biomechanics, soccer, technique},
	pages = {805--817},
}

@techreport{grith_functional_2016,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Functional {Principal} {Component} {Analysis} for {Derivatives} of {Multivariate} {Curves}},
	url = {https://papers.ssrn.com/abstract=2835954},
	abstract = {We present two methods based on functional principal component analysis (FPCA) for the estimation of smooth derivatives of a sample of random functions, which are observed in a more than one-dimensional domain.We apply eigenvalue decomposition to a) the dual covariance matrix of the derivatives, and b) the dual covariance matrix of the observed curves. To handle noisy data from discrete observations, we rely on local polynomial regressions. If curves are contained in a finite-dimensional function space, the secondmethod performs better asymptotically. We apply our methodology in a simulation and empirical study, inwhichwe estimate state price density (SPD) surfaces from call option prices.We identify three main components, which can be interpreted as volatility, skewness and tail factors.We also find evidence for term structure variation.},
	language = {en},
	number = {ID 2835954},
	urldate = {2021-05-14},
	institution = {Social Science Research Network},
	author = {Grith, Maria and Härdle, Wolfgang K. and Kneip, Alois and Wagner, Heiko},
	month = sep,
	year = {2016},
	doi = {10.2139/ssrn.2835954},
	keywords = {derivatives, dual method, functional principal component, multivariate functions, state price densities},
}

@article{wang_linear_2014,
	title = {Linear mixed function-on-function regression models},
	volume = {70},
	copyright = {© 2014, The International Biometric Society},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12207},
	doi = {https://doi.org/10.1111/biom.12207},
	abstract = {We develop a linear mixed regression model where both the response and the predictor are functions. Model parameters are estimated by maximizing the log likelihood via the ECME algorithm. The estimated variance parameters or covariance matrices are shown to be positive or positive definite at each iteration. In simulation studies, the approach outperforms in terms of the fitting error and the MSE of estimating the “regression coefficients.”},
	language = {en},
	number = {4},
	urldate = {2021-05-14},
	journal = {Biometrics},
	author = {Wang, Wei},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12207},
	keywords = {ECME algorithm, Functional data analysis, Linear mixed effects models, Principal component analysis},
	pages = {794--801},
}

@article{andrieu_functional_2014,
	title = {A functional analysis of speed profiles: smoothing using derivative information, curve registration, and functional boxplot},
	shorttitle = {A functional analysis of speed profiles},
	url = {http://arxiv.org/abs/1312.2252},
	abstract = {In this paper, we propose a functional analysis of a set of individual space-speed profiles corresponding to speed as function of the distance traveled by the vehicle from an initial point. This functional analysis begins with a functional modeling of space-speed profiles and the study of mathematical properties of these functions. Then, in a first step, a smoothing procedure based on spline smoothing is developed in order to convert the raw data into functional objets and to filter out the measurement noise as efficiently as possible. It is shown that this smoothing step leads to a complex nonparametric regression problem that needs to take into account two constraints: the use of the derivative information, and a monotonicity constraint. The performance of the proposed two-step estimator (smooth, and then monotonize) is illustrated on simulation studies and a real data example. In a second step, we use a curve registration method based on landmarks alignment in order to construct an average speed profile representative of a set of individual speed profiles. Finally, the variability of such a set is explored by the use of functional boxplots.},
	urldate = {2021-05-14},
	journal = {arXiv:1312.2252 [stat]},
	author = {Andrieu, Cindie and Pierre, Guillaume Saint and Bressaud, Xavier},
	month = jan,
	year = {2014},
	note = {arXiv: 1312.2252},
	keywords = {Statistics - Applications},
}

@article{james_statistics_2018,
	series = {The role of {Statistics} in the era of big data},
	title = {Statistics within business in the era of big data},
	volume = {136},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S0167715218300798},
	doi = {10.1016/j.spl.2018.02.034},
	abstract = {The last decade has seen a dramatic increase in the availability of business data. Here I discuss some of the corresponding opportunities and challenges for business related statistical applications and the role that statisticians can play within a business school.},
	language = {en},
	urldate = {2021-05-14},
	journal = {Statistics \& Probability Letters},
	author = {James, Gareth M.},
	month = may,
	year = {2018},
	keywords = {BRANDS, Business schools, Business statistics},
	pages = {155--159},
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures} (with comments and a rejoinder by the author)},
	volume = {16},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Statistical {Modeling}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	number = {3},
	urldate = {2021-05-14},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	month = aug,
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {199--231},
}

@article{ramsay_functional_2002,
	series = {Information and {Entropy} {Econometrics}},
	title = {Functional data analysis of the dynamics of the monthly index of nondurable goods production},
	volume = {107},
	issn = {0304-4076},
	url = {https://www.sciencedirect.com/science/article/pii/S0304407601001270},
	doi = {10.1016/S0304-4076(01)00127-0},
	abstract = {Functional data analysis techniques pioneered by Ramsay and Bernard Silverman are used to analyze the dynamics of a monthly nonseasonally adjusted index of production. After determining the order (three) of the ordinary differential equation that describes the data and estimating its coefficients; the time variation of each vector of coefficients is examined in detail to determine the evolutionary dynamics of each series over a 70-year span. The dynamical properties of the solution paths are also analyzed for their qualitative dynamics. The resulting models are used to examine the interaction between seasonal dynamics, dynamics at business cycle frequencies, and long-term growth.},
	language = {en},
	number = {1},
	urldate = {2021-05-14},
	journal = {Journal of Econometrics},
	author = {Ramsay, James O. and Ramsey, James B.},
	month = mar,
	year = {2002},
	keywords = {Continuous time dynamics, Differential equations, Functional data analysis, Seasonality},
	pages = {327--344},
}

@inproceedings{jorge_c_lucero_principal_2001,
	title = {Principal {Differential} {Analysis} of {Lip} {Motion} {Signals}},
	abstract = {Principal differential analysis is applied to lip motion recorded from a subject during the repeated production of the sentence “Buy Bobby a puppy” at fast, normal, and slow rates. In this technique, a second order differential equation of the form D2xi(t) + w1(t)Dxi(t) + w0(t)xi(t) = 0 is fitted to the lip trajectories xi(t). The objective is to characterize lip trajectories at different speaking rates in terms of biomechanical parameters as stiffness, damping, and applied external forces. The results show that, in the case of fast rate, the lip system is substantially underdamped and behaves like a simple mass-spring oscillator. In the case of slow rate, on the other hand, the lips are under a stronger external control to conform to the required trajectory. The case of normal rate falls between the fast and slow rate cases. Further, the variability computed at the forcing level increases with decreasing speaking rate. These results suggest that, at fast speaking rates, the lips are left to move at their natural frequency and so their motion presents low variability across repetitions. At slow rates, on the other hand, a stronger external control is exerted, whose associated variability results in increased variability of the lip motion.},
	author = {Jorge C. Lucero},
	year = {2001},
}

@inproceedings{yu_liu_injury_2007,
	address = {Ouro Preto, Brazil},
	title = {Injury {Mechanism} of {Bi}-articular {Muscle} {Hamstring} during {Sprint} {Running}},
	abstract = {Many mechanisms and risk factors of hamstring injury were implicated. In sprinting, the
greatest length of the hamstring muscle occurs during later swing phase. However,
maximal muscle torque at knee joint and consequent stress on muscle occurs during
stance phase. In present paper, we apply the intersegmental dynamics and the
optimization model combined with kinematics, ground reaction force (GRF) and
Electromyography （EMG）measurement to study the injury mechanisms of hamstring
muscle. The findings of intersegmental dynamics analysis revealed that the GRF
produced a large extension torque at knee joint during the initial stage of stance phase,
meanwhile, the hamstring muscle was required to generate a flexion torque in order to
counteract the effect of GRF, this may contribute to the occurrence of hamstring injury.
This kind of analysis provides a new approach for understanding the mechanisms of
hamstring injury.},
	author = {{Yu Liu}},
	year = {2007},
}

@article{bates_cross-validation_2021,
	title = {Cross-validation: what does it estimate and how well does it do it?},
	shorttitle = {Cross-validation},
	url = {http://arxiv.org/abs/2104.00673},
	abstract = {Cross-validation is a widely-used technique to estimate prediction error, but its behavior is complex and not fully understood. Ideally, one would like to think that cross-validation estimates the prediction error for the model at hand, fit to the training data. We prove that this is not the case for the linear model fit by ordinary least squares; rather it estimates the average prediction error of models fit on other unseen training sets drawn from the same population. We further show that this phenomenon occurs for most popular estimates of prediction error, including data splitting, bootstrapping, and Mallow's Cp. Next, the standard confidence intervals for prediction error derived from cross-validation may have coverage far below the desired level. Because each data point is used for both training and testing, there are correlations among the measured accuracies for each fold, and so the usual estimate of variance is too small. We introduce a nested cross-validation scheme to estimate this variance more accurately, and show empirically that this modification leads to intervals with approximately correct coverage in many examples where traditional cross-validation intervals fail. Lastly, our analysis also shows that when producing confidence intervals for prediction accuracy with simple data splitting, one should not re-fit the model on the combined data, since this invalidates the confidence intervals.},
	urldate = {2021-05-14},
	journal = {arXiv:2104.00673 [math, stat]},
	author = {Bates, Stephen and Hastie, Trevor and Tibshirani, Robert},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.00673},
	keywords = {Mathematics - Statistics Theory, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
}

@article{liu_relationship_2015,
	title = {{THE} {RELATIONSHIP} {BETWEEN} {OPTIMAL} {KNEE} {FLEXION} {ANGLE} {AND} {HAMST} {RING} {FLEXIBILITY}: {INDICATION} {FOR} {HAMSTRING} {STRAIN} {INJURY}},
	copyright = {Copyright (c) 2016 ISBS - Conference Proceedings Archive},
	issn = {1999-4168},
	shorttitle = {{THE} {RELATIONSHIP} {BETWEEN} {OPTIMAL} {KNEE} {FLEXION} {ANGLE} {AND} {HAMST} {RING} {FLEXIBILITY}},
	url = {https://ojs.ub.uni-konstanz.de/cpa/article/view/6416},
	abstract = {The purpose of this study was to determine the relationships among hamstring flexibility,  optimal knee flexion angle for maximal knee flexion moment, maximal knee flexion moment.  Ten male and 10 female reactional athletes were tested for hamstring flexibility and  isokinetic strength. The maximal knee flexion moment and the knee flexion angle  corresponding to the maximal knee flexion moment were determined for each participant.  Optimal knee flexion angle was a function of hamstring flexibility score and gender, but not  of the hamstring strength. Optimal knee flexion angle and hamstring strength were not  correlated. These results indicate that hamstring muscle optimal length is correlated to its  flexibility, but not to its strength. Increased hamstring flexibility is correlated with increased  muscle optimal length. Hamstring flexibility may be a risk factor for hamstring strain injury.},
	language = {en},
	urldate = {2021-05-14},
	journal = {ISBS - Conference Proceedings Archive},
	author = {Liu, Hui and Wan, Xianglin and Garrett, William E. and Yu, Bing},
	year = {2015},
	keywords = {Hamstring strain injury, flexibility, muscle optimal length},
}

@phdthesis{zuzana_rostakova_probabilistic_2018,
	type = {Dissertation thesis},
	title = {Probabilistic modelling and functional data analysis of sleep structure},
	abstract = {Sleep deprivation, whether from disorder or lifestyle, whether acute or chronic, poses a significant risk in
day-time cognitive performance, excessive somnolence, fatigue, or impaired vigilance. The aim of the
dissertation is to use new probability models of the sleep process, functional data analysis and machine
learning methodologies to objectify the quality of sleep. An important element of this goal is the definition and
search of significant sleep biomarkers correlated with the daily cognitive, physiological and psychological
status and performance of observed subjects. In addition to a healthy population, it is intended to study patients
with specific brain lesions as it is known that such patients are susceptible to sleep disorders that often lead to
disorders in daytime performance and attention.},
	school = {Institute of Measurement Science of the Slovak Academy of Science},
	author = {{Zuzana Rošťáková}},
	month = may,
	year = {2018},
}

@article{gonzalez_effect_2019,
	title = {Effect of {Smoothing} on {Impact} {Variables} in {Soccer} {Kicking}},
	url = {https://digital.library.txstate.edu/handle/10877/8840},
	abstract = {This technical note examined the effect of smoothing on calculation on several impact effectiveness variables in soccer kicking. A skilled male soccer player performed 10 maximum effort place kicks with a regulation soccer ball. Two-dimensional foot and ball motion were recorded by high-speed (210 Hz) for the 0.4 seconds around impact. Kinematic data were smoothed either through impact or using a separation and five-point linear interpolation technique (Knudson, 2005). Smoothing protocol had a significant effect on three of five impact effectiveness variables (e, foot-to-ball speed ratio, VFpre). Smoothing protocol did not affect VBpost and effective striking mass. The results supported previous studies reporting distortions of velocities near impact in striking objects, however these distortions inconsistently affected more complex impact parameters. More research is needed on smoothing techniques for impact kinematic variables, particularly parameters utilizing both pre- and post-impact velocity values.},
	language = {en\_US},
	urldate = {2021-05-14},
	journal = {Proceedings of the International Society of Biomechanics in Sports, 2019, Oxford, Ohio, United States.},
	author = {Gonzalez, Andrew and Knudson, Duane V.},
	month = jul,
	year = {2019},
	note = {Accepted: 2019-11-20T13:52:32Z
Artwork Medium: 1 file (.pdf)
Interview Medium: 1 file (.pdf)
Publisher: Northern Michigan University},
}

@article{febrero-bande_statistical_2012,
	title = {Statistical {Computing} in {Functional} {Data} {Analysis}: {The} {R} {Package} fda.usc},
	volume = {51},
	copyright = {Copyright (c) 2011 Manuel Febrero-Bande, Manuel Oviedo de la Fuente},
	issn = {1548-7660},
	shorttitle = {Statistical {Computing} in {Functional} {Data} {Analysis}},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v051i04},
	doi = {10.18637/jss.v051.i04},
	language = {en},
	number = {1},
	urldate = {2021-05-14},
	journal = {Journal of Statistical Software},
	author = {Febrero-Bande, Manuel and Fuente, Manuel Oviedo de la},
	month = oct,
	year = {2012},
	note = {Number: 1},
	pages = {1--28},
}

@article{xiao_asymptotic_2020,
	title = {Asymptotic properties of penalized splines for functional data},
	volume = {26},
	issn = {1350-7265},
	url = {https://projecteuclid.org/journals/bernoulli/volume-26/issue-4/Asymptotic-properties-of-penalized-splines-for-functional-data/10.3150/20-BEJ1209.full},
	doi = {10.3150/20-BEJ1209},
	abstract = {Penalized spline methods are popular for functional data analysis but their asymptotic properties have not been established. We present a theoretic study of the \$L\_\{2\}\$ and uniform convergence of penalized splines for estimating the mean and covariance functions of functional data under general settings. The established convergence rates for the mean function estimation are mini-max rate optimal and the rates for the covariance function estimation are comparable to those using other smoothing methods.},
	number = {4},
	urldate = {2021-05-14},
	journal = {Bernoulli},
	author = {Xiao, Luo},
	month = nov,
	year = {2020},
	note = {Publisher: Bernoulli Society for Mathematical Statistics and Probability},
	keywords = {\$L\_\{2\}\$ convergence, Functional data analysis, Nonparametric regression, Uniform convergence, penalized splines},
	pages = {2847--2875},
}

@article{shang_survey_2014,
	title = {A survey of functional principal component analysis},
	volume = {98},
	issn = {1863-818X},
	url = {https://doi.org/10.1007/s10182-013-0213-1},
	doi = {10.1007/s10182-013-0213-1},
	abstract = {Advances in data collection and storage have tremendously increased the presence of functional data, whose graphical representations are curves, images or shapes. As a new area of statistics, functional data analysis extends existing methodologies and theories from the realms of functional analysis, generalized linear model, multivariate data analysis, nonparametric statistics, regression models and many others. From both methodological and practical viewpoints, this paper provides a review of functional principal component analysis, and its use in explanatory analysis, modeling and forecasting, and classification of functional data.},
	language = {en},
	number = {2},
	urldate = {2021-05-14},
	journal = {AStA Advances in Statistical Analysis},
	author = {Shang, Han Lin},
	month = apr,
	year = {2014},
	pages = {121--142},
}

@article{eilers_splines_2010,
	title = {Splines, knots, and penalties},
	volume = {2},
	copyright = {Copyright © 2010 John Wiley \& Sons, Inc.},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.125},
	doi = {https://doi.org/10.1002/wics.125},
	abstract = {Penalized splines have gained much popularity as a flexible tool for smoothing and semi-parametric models. Two approaches have been advocated: (1) use a B-spline basis, equally spaced knots, and difference penalties [Eilers PHC, Marx BD. Flexible smoothing using B-splines and penalized likelihood (with Comments and Rejoinder). Stat Sci 1996, 11:89–121.] and (2) use truncated power functions, knots based on quantiles of the independent variable and a ridge penalty [Ruppert D, Wand MP, Carroll RJ. Semiparametric Regression. New York: Cambridge University Press; 2003]. We compare the two approaches on many aspects: numerical stability, quality of the fit, interpolation/extrapolation, derivative estimation, visual presentation and extension to multidimensional smoothing. We discuss mixed model and Bayesian parallels to penalized regression. We conclude that B-splines with difference penalties are clearly to be preferred. WIREs Comp Stat 2010 2 637–653 DOI: 10.1002/wics.125 This article is categorized under: Statistical and Graphical Methods of Data Analysis {\textgreater} Density Estimation},
	language = {en},
	number = {6},
	urldate = {2021-05-14},
	journal = {WIREs Computational Statistics},
	author = {Eilers, Paul H. C. and Marx, Brian D.},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.125},
	keywords = {P-splines, difference penalty, interpolation, smoothing, truncated power functions},
	pages = {637--653},
}

@inproceedings{zuzana_rostakova_multilevel_2017,
	title = {Multilevel {Functional} {Principal} {Component} {Analysis} for {Unbalanced} {Data}},
	abstract = {Functional principal component analysis (FPCA) is the key technique for dimensionality reduction and detection of main directions of variability present in functional data. However, it is not the most suitable tool for the situation when analysed dataset contains repeated or multiple observations, because information about repeatability of measurements is not taken into account. Multilevel functional principal component analysis (MFPCA) is the modified version of FPCA developed for data observed at multiple visits. The original MFPCA method was designed for balanced data only, where for each subject the same number of measurements is available. In this article we propose the modified MFPCA algorithm which can be applied for unbalanced functional data. The modified algorithm is validated and tested on real–world sleep data.},
	author = {{Zuzana Rošťáková} and {Roman Rosipal}},
	month = sep,
	year = {2017},
}

@article{matabuena_are_2021,
	title = {Are {Multilevel} functional models the next step in sports biomechanics and wearable technology? {A} case study of {Knee} {Biomechanics} patterns in typical training sessions of recreational runners},
	shorttitle = {Are {Multilevel} functional models the next step in sports biomechanics and wearable technology?},
	url = {http://arxiv.org/abs/2103.15704},
	abstract = {This paper illustrates how multilevel functional models can detect and characterize biomechanical changes along different sport training sessions. Our analysis focuses on the relevant cases to identify differences in knee biomechanics in recreational runners during low and high-intensity exercise sessions with the same energy expenditure by recording \$20\$ steps. To do so, we review the existing literature of multilevel models, and then, we propose a new hypothesis test to look at the changes between different levels of the multilevel model as low and high-intensity training sessions. We also evaluate the reliability of measures recorded in three-dimension knee angles from the functional intra-class correlation coefficient (ICC) obtained from the decomposition performed with the multilevel funcional model taking into account \$20\$ measures recorded in each test. The results show that there are no statistically significant differences between the two modes of exercise. However, we have to be careful with the conclusions since, as we have shown, human gait-patterns are very individual and heterogeneous between groups of athletes, and other alternatives to the p-value may be more appropriate to detect statistical differences in biomechanical changes in this context.},
	urldate = {2021-05-14},
	journal = {arXiv:2103.15704 [stat]},
	author = {Matabuena, Marcos and Riazati, Sherveen and Caplan, Nick and Hayes, Phil},
	month = apr,
	year = {2021},
	note = {arXiv: 2103.15704},
	keywords = {Statistics - Applications, Statistics - Methodology, Statistics - Other Statistics},
}

@article{chen_modeling_2012,
	title = {Modeling {Repeated} {Functional} {Observations}},
	volume = {107},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/23427358},
	abstract = {We introduce a new methodological framework for repeatedly observed and thus dependent functional data, aiming at situations where curves are recorded repeatedly for each subject in a sample. Our methodology covers the case where the recordings of the curves are scheduled on a regular and dense grid and also situations more typical for longitudinal studies, where the timing of recordings is often sparse and random. The proposed models lead to an interpretable and straightforward decomposition of the inherent variation in repeatedly observed functional data and are implemented through a straightforward two-step functional principal component analysis. We provide consistency results and asymptotic convergence rates for the estimated model components. We compare the proposed model with an alternative approach via a two-dimensional Karhunen-Loève expansion and illustrate it through the analysis of longitudinal mortality data from period lifetables that are repeatedly observed for a sample of countries over many years, and also through simulation studies. This article has online supplementary materials.},
	number = {500},
	urldate = {2021-05-14},
	journal = {Journal of the American Statistical Association},
	author = {Chen, Kehui and Müller, Hans-Georg},
	year = {2012},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1599--1609},
}

@article{ruppert_trimmed_1980,
	title = {Trimmed {Least} {Squares} {Estimation} in the {Linear} {Model}},
	volume = {75},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1980.10477560},
	doi = {10.1080/01621459.1980.10477560},
	abstract = {We consider two methods of defining a regression analog to a trimmed mean. The first was suggested by Koenker and Bassett and uses their concept of regression quantiles. Its asymptotic behavior is completely analogous to that of a trimmed mean. The second method uses residuals from a preliminary estimator. Its asymptotic behavior depends heavily on the preliminary estimate; it behaves, in general, quite differently than the estimator proposed by Koenker and Bassett, and it can be inefficient at the normal model even if the percentage of trimming is small. However, if the preliminary estimator is the average of the two regression quantiles used with Koenker and Bassett's estimator, then the first and second methods are asymptotically equivalent for symmetric error distributions.},
	number = {372},
	urldate = {2021-05-14},
	journal = {Journal of the American Statistical Association},
	author = {Ruppert, David and Carroll, Raymond J.},
	month = dec,
	year = {1980},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1980.10477560},
	keywords = {Linear model, Preliminary estimator, Regression analog, Regression quantile, Trimmed least squares, Trimmed mean},
	pages = {828--838},
}

@article{lee_conditional_2004-1,
	title = {Conditional and {Marginal} {Models}: {Another} {View}},
	volume = {19},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Conditional and {Marginal} {Models}},
	url = {https://projecteuclid.org/journals/statistical-science/volume-19/issue-2/Conditional-and-Marginal-Models-Another-View/10.1214/088342304000000305.full},
	doi = {10.1214/088342304000000305},
	abstract = {There has existed controversy about the use of marginal and conditional models, particularly in the analysis of data from longitudinal studies. We show that alleged differences in the behavior of parameters in so-called marginal and conditional models are based on a failure to compare like with like. In particular, these seemingly apparent differences are meaningless because they are mainly caused by preimposed unidentifiable constraints on the random effects in models. We discuss the advantages of conditional models over marginal models. We regard the conditional model as fundamental, from which marginal predictions can be made.},
	number = {2},
	urldate = {2021-05-14},
	journal = {Statistical Science},
	author = {Lee, Youngjo and Nelder, John A.},
	month = may,
	year = {2004},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {generalized linear model, hierarchical generalized linear model, joint modeling of mean and dispersion, spatial correlation, temporal correlation},
	pages = {219--238},
}

@article{morris_blups_2002,
	title = {The {BLUPs} are not “best” when it comes to bootstrapping},
	volume = {56},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S016771520200041X},
	doi = {10.1016/S0167-7152(02)00041-X},
	abstract = {In the setting of mixed models, some researchers may construct a semiparametric bootstrap by sampling from the best linear unbiased predictor residuals. This paper demonstrates both mathematically and by simulation that such a bootstrap will consistently underestimate the variation in the data in finite samples.},
	language = {en},
	number = {4},
	urldate = {2021-05-14},
	journal = {Statistics \& Probability Letters},
	author = {Morris, Jeffrey S},
	month = feb,
	year = {2002},
	keywords = {Bootstrap, Correlated data, Mixed models, Nested models},
	pages = {425--430},
}

@book{hodges_random_2011,
	title = {Random {Effects} {Old} and {New}},
	abstract = {The term “random effect ” is now used much more broadly than it was, say, 50 years ago. At that time, a random effect was an effect having (in analysis-of-variance jargon) levels that were draws from a population, and the draws were not of interest in themselves but only as samples from the larger population (e.g., Scheffé 1959, p. 238). By contrast, new-style random effects have levels that are not draws from any population, or that are the entire population, or that may be a sample but a new draw from the random effect could not conceivably be drawn; and the levels themselves are usually of interest. All such new-style random effects can be understood as formal devices to facilitate smoothing or shrinkage, interpreting those terms broadly. The distinction between oldand new-style random effects is not a mere nicety but has practical consequences for inference and prediction, simulation experiments for evaluating statistical methods, and interpretation of analytical artifacts. Therefore, this distinction should be developed beyond the catalog of examples and consequences given here and incorporated into statistical theory and practice.},
	author = {Hodges, James S. and Clayton, Murray K.},
	year = {2011},
}

@article{greven_behaviour_2010,
	title = {On the behaviour of marginal and conditional {AIC} in linear mixed models},
	volume = {97},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/asq042},
	doi = {10.1093/biomet/asq042},
	abstract = {In linear mixed models, model selection frequently includes the selection of random effects. Two versions of the Akaike information criterion, aic, have been used, based either on the marginal or on the conditional distribution. We show that the marginal aic is not an asymptotically unbiased estimator of the Akaike information, and favours smaller models without random effects. For the conditional aic, we show that ignoring estimation uncertainty in the random effects covariance matrix, as is common practice, induces a bias that can lead to the selection of any random effect not predicted to be exactly zero. We derive an analytic representation of a corrected version of the conditional aic, which avoids the high computational cost and imprecision of available numerical approximations. An implementation in an R package (R Development Core Team, 2010) is provided. All theoretical results are illustrated in simulation studies, and their impact in practice is investigated in an analysis of childhood malnutrition in Zambia.},
	number = {4},
	urldate = {2021-05-14},
	journal = {Biometrika},
	author = {Greven, Sonja and Kneib, Thomas},
	month = dec,
	year = {2010},
	pages = {773--789},
}

@article{wand_penalized_2011,
	title = {Penalized wavelets: {Embedding} wavelets into semiparametric regression},
	volume = {5},
	issn = {1935-7524, 1935-7524},
	shorttitle = {Penalized wavelets},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-5/issue-none/Penalized-wavelets-Embedding-wavelets-into-semiparametric-regression/10.1214/11-EJS652.full},
	doi = {10.1214/11-EJS652},
	abstract = {We introduce the concept of penalized wavelets to facilitate seamless embedding of wavelets into semiparametric regression models. In particular, we show that penalized wavelets are analogous to penalized splines; the latter being the established approach to function estimation in semiparametric regression. They differ only in the type of penalization that is appropriate. This fact is not borne out by the existing wavelet literature, where the regression modelling and fitting issues are overshadowed by computational issues such as efficiency gains afforded by the Discrete Wavelet Transform and partially obscured by a tendency to work in the wavelet coefficient space. With penalized wavelet structure in place, we then show that fitting and inference can be achieved via the same general approaches used for penalized splines: penalized least squares, maximum likelihood and best prediction within a frequentist mixed model framework, and Markov chain Monte Carlo and mean field variational Bayes within a Bayesian framework. Penalized wavelets are also shown have a close relationship with wide data (“p≫n”) regression and benefit from ongoing research on that topic.},
	number = {none},
	urldate = {2021-05-14},
	journal = {Electronic Journal of Statistics},
	author = {Wand, M. P. and Ormerod, J. T.},
	month = jan,
	year = {2011},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {Bayesian inference, Gibbs sampling, Markov chain Monte Carlo, Mean field variational Bayes, best prediction, generalized additive models, maximum likelihood estimation, sparseness-inducing penalty, wide data regression},
	pages = {1654--1717},
}

@article{leroy_functional_2018,
	title = {Functional {Data} {Analysis} in {Sport} {Science}: {Example} of {Swimmers}’ {Progression} {Curves} {Clustering}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Functional {Data} {Analysis} in {Sport} {Science}},
	url = {https://www.mdpi.com/2076-3417/8/10/1766},
	doi = {10.3390/app8101766},
	abstract = {Many data collected in sport science come from time dependent phenomenon. This article focuses on Functional Data Analysis (FDA), which study longitudinal data by modelling them as continuous functions. After a brief review of several FDA methods, some useful practical tools such as Functional Principal Component Analysis (FPCA) or functional clustering algorithms are presented and compared on simulated data. Finally, the problem of the detection of promising young swimmers is addressed through a curve clustering procedure on a real data set of performance progression curves. This study reveals that the fastest improvement of young swimmers generally appears before 16 years old. Moreover, several patterns of improvement are identified and the functional clustering procedure provides a useful detection tool.},
	language = {en},
	number = {10},
	urldate = {2021-05-14},
	journal = {Applied Sciences},
	author = {Leroy, Arthur and Marc, Andy and Dupas, Olivier and Rey, Jean Lionel and Gey, Servane},
	month = oct,
	year = {2018},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {curve clustering, detection, functional data analysis, sport, swimming},
	pages = {1766},
}

@article{laird_random-effects_1982,
	title = {Random-{Effects} {Models} for {Longitudinal} {Data}},
	volume = {38},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2529876},
	doi = {10.2307/2529876},
	abstract = {Models for the analysis of longitudinal data must recognize the relationship between serial observations on the same unit. Multivariate models with general covariance structure are often difficult to apply to highly unbalanced data, whereas two-stage random-effects models can be used easily. In two-stage models, the probability distributions for the response vectors of different individuals belong to a single family, but some random-effects parameters vary across individuals, with a distribution specified at the second stage. A general family of models is discussed, which includes both growth models and repeated-measures models as special cases. A unified approach to fitting these models, based on a combination of empirical Bayes and maximum likelihood estimation of model parameters and using the EM algorithm, is discussed. Two examples are taken from a current epidemiological study of the health effects of air pollution.},
	number = {4},
	urldate = {2021-05-14},
	journal = {Biometrics},
	author = {Laird, Nan M. and Ware, James H.},
	year = {1982},
	note = {Publisher: [Wiley, International Biometric Society]},
	pages = {963--974},
}

@article{wood_generalized_2015,
	title = {Generalized additive models for large data sets},
	volume = {64},
	copyright = {© 2014 The Authors. Journal of the Royal Statistical Society: Series C Applied Statistics Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12068},
	doi = {https://doi.org/10.1111/rssc.12068},
	abstract = {We consider an application in electricity grid load prediction, where generalized additive models are appropriate, but where the data set's size can make their use practically intractable with existing methods. We therefore develop practical generalized additive model fitting methods for large data sets in the case in which the smooth terms in the model are represented by using penalized regression splines. The methods use iterative update schemes to obtain factors of the model matrix while requiring only subblocks of the model matrix to be computed at any one time. We show that efficient smoothing parameter estimation can be carried out in a well-justified manner. The grid load prediction problem requires updates of the model fit, as new data become available, and some means for dealing with residual auto-correlation in grid load. Methods are provided for these problems and parallel implementation is covered. The methods allow estimation of generalized additive models for large data sets by using modest computer hardware, and the grid load prediction problem illustrates the utility of reduced rank spline smoothing methods for dealing with complex modelling problems.},
	language = {en},
	number = {1},
	urldate = {2021-05-14},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Wood, Simon N. and Goude, Yannig and Shaw, Simon},
	year = {2015},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssc.12068},
	keywords = {Correlated additive model, Electricity load prediction, Generalized additive model estimation},
	pages = {139--155},
}

@article{crainiceanu_generalized_2009,
	title = {Generalized {Multilevel} {Functional} {Regression}},
	volume = {104},
	issn = {0162-1459},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2897156/},
	doi = {10.1198/jasa.2009.tm08564},
	abstract = {We introduce Generalized Multilevel Functional Linear Models (GMFLMs), a novel statistical framework for regression models where exposure has a multilevel functional structure. We show that GMFLMs are, in fact, generalized multilevel mixed models (GLMMs). Thus, GMFLMs can be analyzed using the mixed effects inferential machinery and can be generalized within a well researched statistical framework. We propose and compare two methods for inference: 1) a two-stage frequentist approach; and 2) a joint Bayesian analysis. Our methods are motivated by and applied to the Sleep Heart Health Study (SHHS), the largest community cohort study of sleep. However, our methods are general and easy to apply to a wide spectrum of emerging biological and medical data sets. Supplemental materials for this article are available online.},
	number = {488},
	urldate = {2021-05-14},
	journal = {Journal of the American Statistical Association},
	author = {Crainiceanu, Ciprian M. and Staicu, Ana-Maria and Di, Chong-Zhi},
	month = dec,
	year = {2009},
	pmid = {20625442},
	pmcid = {PMC2897156},
	pages = {1550--1561},
}

@article{prosser_trunk_2010,
	title = {Trunk and hip muscle activity in early walkers with and without cerebral palsy – {A} frequency analysis},
	volume = {20},
	issn = {1050-6411},
	url = {https://www.sciencedirect.com/science/article/pii/S1050641110000647},
	doi = {10.1016/j.jelekin.2010.04.005},
	abstract = {Poor control of postural muscles is a primary impairment in cerebral palsy (CP), yet core trunk and hip muscle activity has not been thoroughly investigated. Frequency analysis of electromyographic (EMG) signals provides insight about the intensity and pattern of muscle activation, correlates with functional measures in CP, and is sensitive to change after intervention. The objective of this study was to investigate differences in trunk and hip muscle activation frequency in children with CP compared to children with similar amounts of walking experience and typical development (TD). EMG data from 31 children (15 with CP, 16 with TD) were recorded from 16 trunk and hip muscles bilaterally. A time–frequency pattern was generated using the continuous wavelet transform and instantaneous mean frequency (IMNF) was calculated at each interval of the gait cycle. Functional principal component analysis (PCA) revealed that IMNF was significantly higher in the CP group throughout the gait cycle for all muscles. Additionally, stride-to-stride variability was higher in the CP group. This evidence demonstrated altered patterns of trunk and hip muscle activation in CP, including increased rates of motor unit firing, increased number of recruited motor units, and/or decreased synchrony of motor units. These altered muscle activation patterns likely contribute to muscle fatigue and decreased biomechanical efficiency in children with CP.},
	language = {en},
	number = {5},
	urldate = {2021-05-14},
	journal = {Journal of Electromyography and Kinesiology},
	author = {Prosser, Laura A. and Lee, Samuel C. K. and Barbe, Mary F. and VanSant, Ann F. and Lauer, Richard T.},
	month = oct,
	year = {2010},
	keywords = {Cerebral palsy, Frequency, Gait, Muscle, Trunk},
	pages = {851--859},
}

@article{volkmann_multivariate_2021,
	title = {Multivariate {Functional} {Additive} {Mixed} {Models}},
	url = {http://arxiv.org/abs/2103.06606},
	abstract = {Multivariate functional data can be intrinsically multivariate like movement trajectories in 2D or complementary like precipitation, temperature, and wind speeds over time at a given weather station. We propose a multivariate functional additive mixed model (multiFAMM) and show its application to both data situations using examples from sports science (movement trajectories of snooker players) and phonetic science (acoustic signals and articulation of consonants). The approach includes linear and nonlinear covariate effects and models the dependency structure between the dimensions of the responses using multivariate functional principal component analysis. Multivariate functional random intercepts capture both the auto-correlation within a given function and cross-correlations between the multivariate functional dimensions. They also allow us to model between-function correlations as induced by e.g.{\textbackslash} repeated measurements or crossed study designs. Modeling the dependency structure between the dimensions can generate additional insight into the properties of the multivariate functional process, improves the estimation of random effects, and yields corrected confidence bands for covariate effects. Extensive simulation studies indicate that a multivariate modeling approach is more parsimonious than fitting independent univariate models to the data while maintaining or improving model fit.},
	urldate = {2021-05-12},
	journal = {arXiv:2103.06606 [stat]},
	author = {Volkmann, Alexander and Stöcker, Almond and Scheipl, Fabian and Greven, Sonja},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.06606},
	keywords = {Statistics - Methodology},
}

@misc{parodi_fdakma_2015,
	title = {fdakma: {Functional} {Data} {Analysis}: {K}-{Mean} {Alignment}},
	copyright = {GPL (≥ 3)},
	shorttitle = {fdakma},
	url = {https://CRAN.R-project.org/package=fdakma},
	abstract = {It performs simultaneously clustering and alignment of a multidimensional or unidimensional functional dataset by means of k-mean alignment.},
	urldate = {2020-11-10},
	author = {Parodi, Alice and Patriarca, Mirco and Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone and Vitelli, Valeria},
	month = may,
	year = {2015},
	keywords = {FunctionalData},
}

@article{sangalli_analysis_2014,
	title = {Analysis of {AneuRisk65} data: \$k\$-mean alignment},
	shorttitle = {Analysis of {AneuRisk65} data},
	doi = {10.1214/14-EJS938A},
	abstract = {We describe the k-mean alignment procedure, for the joint alignment and clustering of functional data and we apply it to the analysis of AneuRisk65 data. Thanks to the efficient separation of the variability in phase variability and within/between clusters amplitude variability, we are able to discriminate subjects having aneurysms in different cerebral districts and identifying different morphological shapes of Inner Carotid Arteries, unveiling a strong association between arteries morphologies and the aneurysmal pathology. 1 K-mean alignment We here summarize the k-mean alignment procedure that we shall use in Section 2 to analyze the AneuRisk65 data. This procedure, introduced in Sangalli, Secchi, Vantini, and Vitelli (2010), is able to efficiently align and cluster in k groups a set of curves. The procedure can be seen as a continuous alignment with k ≥ 1 templates, or equivalently as a k-mean clustering of curves with warping allowed. In fact, if the number of clusters k is set equal to 1, the algorithm implements the Procrustes aligning procedure described in Sangalli et al. (2009), whereas, if no alignment is allowed, it implements a functional k-mean clustering of curves (see, e.g., Tarpey and Kinateder (2003)). The described procedure merges the goal of alignment, i.e., decoupling phase and amplitude variability, with the goal of k-mean clustering, i.e., decoupling within and between-cluster amplitude variability. The k-mean alignment is also able to disclose clustering structures in the phase even though this is not one of the stated goals of the procedure. Overall, the},
	author = {Sangalli, Laura M. and Secchi, P. and Vantini, S.},
	year = {2014},
}

@book{james_introduction_2013,
	address = {New York},
	edition = {2013th edition},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R} ({Springer} {Texts} in {Statistics}): 103},
	isbn = {978-1-4614-7137-0},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
	language = {English},
	publisher = {Springer},
	author = {James, Gareth M. and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	month = aug,
	year = {2013},
}

@article{crane_functional_2011,
	title = {Functional {Data} {Analysis} for {Biomechanics}},
	url = {https://www.intechopen.com/books/theoretical-biomechanics/functional-data-analysis-for-biomechanics},
	doi = {10.5772/22382},
	abstract = {Open access peer-reviewed chapter},
	language = {en},
	urldate = {2020-09-16},
	journal = {Theoretical Biomechanics},
	author = {Crane, Elizabeth A. and Childers, David and Gerstner, Geoffrey and Rothman, Edward},
	month = nov,
	year = {2011},
	note = {Publisher: IntechOpen},
}

@article{ramsay_tools_1991,
	title = {Some {Tools} for {Functional} {Data} {Analysis}},
	volume = {53},
	copyright = {© 1991 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1991.tb01844.x},
	doi = {10.1111/j.2517-6161.1991.tb01844.x},
	abstract = {Multivariate data analysis permits the study of observations which are finite sets of numbers, but modern data collection situations can involve data, or the processes giving rise to them, which are functions. Functional data analysis involves infinite dimensional processes and/or data. The paper shows how the theory of L-splines can support generalizations of linear modelling and principal components analysis to samples drawn from random functions. Spline smoothing rests on a partition of a function space into two orthogonal subspaces, one of which contains the obvious or structural components of variation among a set of observed functions, and the other of which contains residual components. This partitioning is achieved through the use of a linear differential operator, and we show how the theory of polynomial splines can be applied more generally with an arbitrary operator and associated boundary constraints. These data analysis tools are illustrated by a study of variation in temperature–precipitation patterns among some Canadian weather-stations.},
	language = {en},
	number = {3},
	urldate = {2020-08-12},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Ramsay, James O. and Dalzell, C. J.},
	year = {1991},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1991.tb01844.x},
	keywords = {differential operator, functional linear model, functional principal components, l-splines, nonparametric regression, smoothing},
	pages = {539--561},
}

@article{ramsay_tools_1991-1,
	title = {Some {Tools} for {Functional} {Data} {Analysis}},
	volume = {53},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345586},
	abstract = {Multivariate data analysis permits the study of observations which are finite sets of numbers, but modern data collection situations can involve data, or the processes giving rise to them, which are functions. Functional data analysis involves infinite dimensional processes and/or data. The paper shows how the theory of L-splines can support generalizations of linear modelling and principal components analysis to samples drawn from random functions. Spline smoothing rests on a partition of a function space into two orthogonal subspaces, one of which contains the obvious or structural components of variation among a set of observed functions, and the other of which contains residual components. This partitioning is achieved through the use of a linear differential operator, and we show how the theory of polynomial splines can be applied more generally with an arbitrary operator and associated boundary constraints. These data analysis tools are illustrated by a study of variation in temperature-precipitation patterns among some Canadian weather-stations.},
	number = {3},
	urldate = {2020-08-12},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Ramsay, James O. and Dalzell, C. J.},
	year = {1991},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {539--572},
}

@article{sadeghi_reduction_2000,
	title = {Reduction of gait data variability using curve registration},
	volume = {12},
	issn = {0966-6362},
	doi = {10.1016/s0966-6362(00)00085-0},
	abstract = {Timing in peak gait values shifts slightly between gait trials. When averaged, the standard deviation (S.D.) in gait data may increase due to this inter-trial variability unless normalization is carried out beforehand. The objective of this study was to determine how curve registration, an alignment technique, can reduce inter-subject variability in gait data without perturbing the curve characteristics. Twenty young, healthy men participated in this study each providing a single gait trial. Gait was assessed by means of a four-camera high-speed video system synchronized to a force plate. A rigid body three-segment model was used in an inverse dynamic approach to calculate three-dimensional muscle powers at the hip, knee and ankle. Curve registration was applied to each of the 20 gait trials to align the peak powers. The mean registered peak powers increased by an average of 0.10 +/- 0.13 W/kg with the highest increases in the sagittal plane at push-off. After performing curve registration, the RMS values decreased by 13.6\% and the greatest reduction occurred at the hip and knee, both in the sagittal plane. No important discontinuities were reported in the first and second derivatives of the unregistered and registered curves. Curve registration did not have much effect on the harmonic content. This would be an appropriate technique for application prior to any statistical analysis using able-bodied gait patterns.},
	language = {eng},
	number = {3},
	journal = {Gait \& Posture},
	author = {Sadeghi, H. and Allard, P. and Shafie, K. and Mathieu, P. A. and Sadeghi, S. and Prince, F. and Ramsay, James O.},
	month = dec,
	year = {2000},
	pmid = {11154937},
	keywords = {Adult, Ankle Joint, Biomechanical Phenomena, Gait, Hip Joint, Humans, Joints, Knee Joint, Male, Muscle, Skeletal, Reproducibility of Results, Signal Processing, Computer-Assisted},
	pages = {257--264},
}

@misc{ramsay_functional_nodate,
	title = {Functional {Data} {Analysis} in {Action}},
	url = {/paper/Functional-Data-Analysis-in-Action-Ramsay-Gribble/19aa403d49c288f87e0763724addd0e28028991f},
	abstract = {These notes describe our analyses of data collected from Michael Newton, Department of Biostatistics, University of Wisconsin, in November 1998. We recording him juggling 3, 4, and 5 balls as well as bowling pins. Our goal was to model the movement of his hands during juggling by a relatively simple second order di erential equation. This study was a follow-up on our earlier work on handwriting (Ramsay, 1999), where a second order linear di erential equation was able to account well for pen movement during the writing a complex piece of Chinese script. The larger aim of these studies is to shed light on the way in which the brain controls movement during complex task. A di erential equation permits the study of the dynamics of this process, and ts simultaneously a number of derivatives as well as the position data. Since neural control, leading to muscle contraction, must, by the laws of mechanics, have a direct impact on acceleration, di erential equations seems to be a natural modeling framework. The analyses in this report use the techniques for functional data analysis described in Ramsay and Silverman (1997), and the software in Matlab and S-PLUS available at the Internet site ego.psych.mcgill.ca/pub/ramsay/FDAfuns.},
	language = {en},
	urldate = {2021-03-31},
	author = {Ramsay, James O. and Gribble, P.},
}

@book{ramsay_functional_2005,
	address = {New York},
	edition = {2},
	series = {Springer {Series} in {Statistics}},
	title = {Functional {Data} {Analysis}},
	isbn = {978-0-387-40080-8},
	url = {https://www.springer.com/gp/book/9780387400808},
	abstract = {Scientists and others today often collect samples of curves and other functional observations. This monograph presents many ideas and techniques for such data. Included are expressions in the functional domain of such classics as linear regression, principal components analysis, linear modeling, and canonical correlation analysis, as well as specifically functional techniques such as curve registration and principal differential analysis. Data arising in real applications are used throughout for both motivation and illustration, showing how functional approaches allow us to see new things, especially by exploiting the smoothness of the processes generating the data. The data sets exemplify the wide scope of functional data analysis; they are drawn from growth analysis, meteorology, biomechanics, equine science, economics, and medicine. The book presents novel statistical technology, much of it based on the authors’ own research work, while keeping the mathematical level widely accessible. It is designed to appeal to students, to applied data analysts, and to experienced researchers; it will have value both within statistics and across a broad spectrum of other fields. This second edition is aimed at a wider range of readers, and especially those who would like to apply these techniques to their research problems. It complements the authors' other recent volume Applied Functional Data Analysis: Methods and Case Studies. In particular, there is an extended coverage of data smoothing and other matters arising in the preliminaries to a functional data analysis. The chapters on the functional linear model and modeling of the dynamics of systems through the use of differential equations and principal differential analysis have been completely rewritten and extended to include new developments. Other chapters have been revised substantially, often to give more weight to examples and practical considerations. Jim Ramsay is Professor of Psychology at McGill University and is an international authority on many aspects of multivariate analysis. He was President of the Statistical Society of Canada in 2002-3 and holds the Society’s Gold Medal for his work in functional data analysis. Bernard Silverman is Master of St Peter’s College and Professor of Statistics at Oxford University. He was President of the Institute of Mathematical Statistics in 2000–1. He is a Fellow of the Royal Society. His main specialty is in computational statistics, and he is the author or editor of several highly regarded books in this area.},
	language = {en},
	urldate = {2020-08-12},
	publisher = {Springer-Verlag},
	author = {Ramsay, James O. and Silverman, B. W.},
	year = {2005},
	doi = {10.1007/b98888},
}

@article{ramsay_functional_2000,
	title = {Functional {Components} of {Variation} in {Handwriting}},
	volume = {95},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10473894},
	doi = {10.1080/01621459.2000.10473894},
	abstract = {Functional data analysis techniques are used to analyze a sample of handwriting in Chinese. The goals are (a) to identify a differential equation that satisfactorily models the data's dynamics, and (b) to use the model to classify handwriting samples taken from differential individuals. After preliminary smoothing and registration steps, a second-order linear differential equation, for which the forcing function is small, is found to provide a good reconstruction of the original script records. The equation is also able to capture a substantial amount of the variation in the scripts across replication. The cross-validated classification process is 100\% effective for the samples analyzed.},
	number = {449},
	urldate = {2021-03-31},
	journal = {Journal of the American Statistical Association},
	author = {Ramsay, James O.},
	month = mar,
	year = {2000},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.2000.10473894},
	keywords = {Classification, Differential equations, Dynamic model, Functional data analysis, Longitudinal data, Penalized nonparametric regression, Principal differential analysis, Registration, Smoothing spline, Time warping.},
	pages = {9--15},
}

@book{ramsay_applied_2002,
	address = {New York},
	series = {Springer {Series} in {Statistics}},
	title = {Applied {Functional} {Data} {Analysis}: {Methods} and {Case} {Studies}},
	isbn = {978-0-387-95414-1},
	shorttitle = {Applied {Functional} {Data} {Analysis}},
	url = {https://www.springer.com/gp/book/9780387954141},
	abstract = {Almost as soon as we had completed our previous book Functional Data Analysis in 1997, it became clear that potential interest in the ?eld was far wider than the audience for the thematic presentation we had given there. At the same time, both of us rapidly became involved in relevant new research involving many colleagues in ?elds outside statistics. This book treats the ?eld in a di?erent way, by considering case st- ies arising from our own collaborative research to illustrate how functional data analysis ideas work out in practice in a diverse range of subject areas. These include criminology, economics, archaeology, rheumatology, psych- ogy, neurophysiology, auxology (the study of human growth), meteorology, biomechanics, and education—and also a study of a juggling statistician. Obviously such an approach will not cover the ?eld exhaustively, and in any case functional data analysis is not a hard-edged closed system of thought. Nevertheless we have tried to give a ?avor of the range of meth- ology we ourselves have considered. We hope that our personal experience, including the fun we had working on these projects, will inspire others to extend “functional” thinking to many other statistical contexts. Of course, manyofourcasestudiesrequireddevelopmentofexistingmethodology,and readersshouldgaintheabilitytoadaptmethodstotheirownproblemstoo.},
	language = {en},
	urldate = {2020-08-12},
	publisher = {Springer-Verlag},
	author = {Ramsay, James O. and Silverman, B. W.},
	year = {2002},
	doi = {10.1007/b98886},
}

@article{ramsay_functional_1995,
	title = {A {Functional} {Data} {Analysis} of the {Pinch} {Force} of {Human} {Fingers}},
	volume = {44},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2986192},
	doi = {10.2307/2986192},
	abstract = {The ability of the human thumb and forefinger to adapt the pinch force to the static and dynamic characteristics of the object being grasped is one of the marvels of human physiology. We analyse a sample of records of the force applied during a brief squeeze by functional data analysis techniques in which familiar statistical concepts are adapted to observations that are functional in character. Except for scale, a graph of these force impulses closely resembles a log-normal density function, and this has a plausible physiological rationale. Specially adapted smoothing spline approximations along with a functional version of principal components analysis reveal that the residual variation is essentially one dimensional in structure, and that the force functions can be described by a simple linear differential equation incorporating the effects of drag or viscosity in the joints and muscles involved.},
	number = {1},
	urldate = {2020-09-15},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Ramsay, James O. and Wang, X. and Flanagan, R.},
	year = {1995},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {17--30},
}

@article{ramsay_functional_1995-1,
	title = {A {Functional} {Data} {Analysis} of the {Pinch} {Force} of {Human} {Fingers}},
	volume = {44},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2986192},
	doi = {10.2307/2986192},
	abstract = {The ability of the human thumb and forefinger to adapt the pinch force to the static and dynamic characteristics of the object being grasped is one of the marvels of human physiology. We analyse a sample of records of the force applied during a brief squeeze by functional data analysis techniques in which familiar statistical concepts are adapted to observations that are functional in character. Except for scale, a graph of these force impulses closely resembles a log-normal density function, and this has a plausible physiological rationale. Specially adapted smoothing spline approximations along with a functional version of principal components analysis reveal that the residual variation is essentially one dimensional in structure, and that the force functions can be described by a simple linear differential equation incorporating the effects of drag or viscosity in the joints and muscles involved.},
	number = {1},
	urldate = {2020-09-15},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Ramsay, James O. and Wang, X. and Flanagan, R.},
	year = {1995},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {17--30},
}

@article{ramsay_functional_1995-2,
	title = {A {Functional} {Data} {Analysis} of the {Pinch} {Force} of {Human} {Fingers}},
	volume = {44},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2986192},
	doi = {10.2307/2986192},
	abstract = {The ability of the human thumb and forefinger to adapt the pinch force to the static and dynamic characteristics of the object being grasped is one of the marvels of human physiology. We analyse a sample of records of the force applied during a brief squeeze by functional data analysis techniques in which familiar statistical concepts are adapted to observations that are functional in character. Except for scale, a graph of these force impulses closely resembles a log-normal density function, and this has a plausible physiological rationale. Specially adapted smoothing spline approximations along with a functional version of principal components analysis reveal that the residual variation is essentially one dimensional in structure, and that the force functions can be described by a simple linear differential equation incorporating the effects of drag or viscosity in the joints and muscles involved.},
	number = {1},
	urldate = {2020-09-21},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Ramsay, James O. and Wang, X. and Flanagan, R.},
	year = {1995},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {17--30},
}

@article{guo_functional_2002,
	title = {Functional mixed effects models},
	volume = {58},
	issn = {0006-341X},
	doi = {10.1111/j.0006-341x.2002.00121.x},
	abstract = {In this article, a new class of functional models in which smoothing splines are used to model fixed effects as well as random effects is introduced. The linear mixed effects models are extended to nonparametric mixed effects models by introducing functional random effects, which are modeled as realizations of zero-mean stochastic processes. The fixed functional effects and the random functional effects are modeled in the same functional space, which guarantee the population-average and subject-specific curves have the same smoothness property. These models inherit the flexibility of the linear mixed effects models in handling complex designs and correlation structures, can include continuous covariates as well as dummy factors in both the fixed or random design matrices, and include the nested curves models as special cases. Two estimation procedures are proposed. The first estimation procedure exploits the connection between linear mixed effects models and smoothing splines and can be fitted using existing software. The second procedure is a sequential estimation procedure using Kalman filtering. This algorithm avoids inversion of large dimensional matrices and therefore can be applied to large data sets. A generalized maximum likelihood (GML) ratio test is proposed for inference and model selection. An application to comparison of cortisol profiles is used as an illustration.},
	language = {eng},
	number = {1},
	journal = {Biometrics},
	author = {Guo, Wensheng},
	month = mar,
	year = {2002},
	pmid = {11890306},
	keywords = {Bayes Theorem, Circadian Rhythm, Fibromyalgia, Humans, Hydrocortisone, Likelihood Functions, Models, Statistical, Stochastic Processes},
	pages = {121--128},
}

@inproceedings{ramsay_functional_1999,
	title = {Functional {Data} {Analysis} in {Action}},
	abstract = {These notes describe our analyses of data collected from Michael Newton, Department of Biostatistics, University of Wisconsin, in November 1998. We recording him juggling 3, 4, and 5 balls as well as bowling pins. Our goal was to model the movement of his hands during juggling by a relatively simple second order di erential equation. This study was a follow-up on our earlier work on handwriting (Ramsay, 1999), where a second order linear di erential equation was able to account well for pen movement during the writing a complex piece of Chinese script. The larger aim of these studies is to shed light on the way in which the brain controls movement during complex task. A di erential equation permits the study of the dynamics of this process, and ts simultaneously a number of derivatives as well as the position data. Since neural control, leading to muscle contraction, must, by the laws of mechanics, have a direct impact on acceleration, di erential equations seems to be a natural modeling framework. The analyses in this report use the techniques for functional data analysis described in Ramsay and Silverman (1997), and the software in Matlab and S-PLUS available at the Internet site ego.psych.mcgill.ca/pub/ramsay/FDAfuns.},
	booktitle = {Proceedings of the {American} {Statistical} {Association}},
	author = {Ramsay, James O. and Gribble, Paul},
	year = {1999},
	pages = {30--36},
}

@article{hurmuzlu_presenting_1994,
	title = {Presenting joint kinematics of human locomotion using phase plane portraits and {Poincaré} maps},
	volume = {27},
	issn = {0021-9290},
	doi = {10.1016/0021-9290(94)90199-6},
	abstract = {Additional graphical tools are needed to better visualize the joint kinematics of human locomotion. Standard plots in which the joint displacements are plotted against time or percent gait cycle do not provide sufficient information about the dynamics of the system. In this article, a study based on the two graphical tools of nonlinear dynamics to visualize the steady-state kinematics of human gait is presented. An experimental setup was developed to acquire the necessary data for application of the techniques. Twenty young adults, whose medical histories are free of gait pathology, were tested. Computerized electrogoniometers and foot switches were used to measure the kinematic data of the lower extremities and capture four instants of the gait cycle: heel strike, foot flat, heel off, and toe off. Phase plane portraits of each joint were constructed for the sagittal plane by plotting angular velocity against angular displacement. Poincaré maps were obtained by periodically sampling the joint profiles at toe off and plotting the ith iterate against the (i + 1)th one. Phase plane portraits are useful in monitoring the variations of joint velocity and position on the same graph in a more compact form. Poincaré maps are effective in differentiating steady gait from transient locomotion.},
	language = {eng},
	number = {12},
	journal = {Journal of Biomechanics},
	author = {Hurmuzlu, Y. and Basdogan, C. and Carollo, J. J.},
	month = dec,
	year = {1994},
	pmid = {7528748},
	keywords = {Adult, Algorithms, Ankle Joint, Audiovisual Aids, Computer Graphics, Electronics, Medical, Female, Foot, Gait, Heel, Hip Joint, Humans, Knee Joint, Locomotion, Male, Middle Aged, Models, Biological, Range of Motion, Articular, Time Factors, Toes, Walking},
	pages = {1495--1499},
}

@article{lamb_use_2014,
	title = {On the use of continuous relative phase: {Review} of current approaches and outline for a new standard},
	volume = {29},
	issn = {0268-0033},
	shorttitle = {On the use of continuous relative phase},
	url = {https://www.sciencedirect.com/science/article/pii/S0268003314000618},
	doi = {10.1016/j.clinbiomech.2014.03.008},
	abstract = {Background
In this paper we review applications of continuous relative phase and commonly reported methods for calculating the phase angle. Signals with known properties as well as empirical data were used to compare methods for calculating the phase angle.
Findings
Our results suggest that the most valid, robust and intuitive results are obtained from the following steps: 1) centering the amplitude of the original signals around zero, 2) creating analytic signals from the original signals using the Hilbert transform, 3) calculating the phase angle using the analytic signal and 4) calculating the continuous relative phase.
Interpretations
The resulting continuous relative phase values are free of frequency artifacts, a problem associated with most normalization techniques, and the interpretation remains intuitive. We propose these methods for future research using continuous relative phase in studies and analyses of human movement coordination.},
	language = {en},
	number = {5},
	urldate = {2021-03-31},
	journal = {Clinical Biomechanics},
	author = {Lamb, Peter F. and Stöckl, Michael},
	month = may,
	year = {2014},
	keywords = {Continuous relative phase, Coordination, Gait data, Movement variability, Normalization, Phase angle},
	pages = {484--493},
}

@article{brockhaus_boosting_2020,
	title = {Boosting {Functional} {Regression} {Models} with {FDboost}},
	volume = {94},
	copyright = {Copyright (c) 2020 Sarah Brockhaus, David Rügamer, Sonja Greven},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v094i10},
	doi = {10.18637/jss.v094.i10},
	language = {en},
	number = {1},
	urldate = {2021-03-24},
	journal = {Journal of Statistical Software},
	author = {Brockhaus, Sarah and Rügamer, David and Greven, Sonja},
	month = sep,
	year = {2020},
	note = {Number: 1},
	keywords = {function-on-function regression, function-on-scalar regression, functional data analysis, gradient boosting, model-based boosting, scalar-on-function regression},
	pages = {1--50},
}

@article{liew_interpretable_2020,
	title = {Interpretable machine learning models for classifying low back pain status using functional physiological variables},
	volume = {29},
	issn = {1432-0932},
	url = {https://doi.org/10.1007/s00586-020-06356-0},
	doi = {10.1007/s00586-020-06356-0},
	abstract = {To evaluate the predictive performance of statistical models which distinguishes different low back pain (LBP) sub-types and healthy controls, using as input predictors the time-varying signals of electromyographic and kinematic variables, collected during low-load lifting.},
	language = {en},
	number = {8},
	urldate = {2021-03-24},
	journal = {European Spine Journal},
	author = {Liew, Bernard X. W. and Rugamer, David and De Nunzio, Alessandro Marco and Falla, Deborah},
	month = aug,
	year = {2020},
	pages = {1845--1859},
}

@article{liew_classifying_2020,
	title = {Classifying neck pain status using scalar and functional biomechanical variables – development of a method using functional data boosting},
	volume = {76},
	issn = {0966-6362},
	url = {https://www.sciencedirect.com/science/article/pii/S0966636219317734},
	doi = {10.1016/j.gaitpost.2019.12.008},
	abstract = {Background
Individuals with neck pain have different movement and muscular activation (collectively termed as biomechanical variables) patterns compared to healthy individuals. Incorporating biomechanical variables as covariates into prognostic models is challenging due to the high dimensionality of the data.
Research question
What is the classification performance of neck pain status of a statistical model which uses both scalar and functional biomechanical covariates?
Methods
Motion capture with electromyography assessment on the sternocleidomastoid, splenius cervicis, erector spinae, was performed on 21 healthy and 26 individuals with neck pain during walking over three gait conditions (rectilinear, curvilinear clockwise (CW) and counterclockwise (CCW)). After removing highly collinear variables, 94 covariates across the three conditions were used to classify neck pain status using functional data boosting (FDboost).
Results
Two functional covariates trunk lateral flexion angle during CCW gait, and trunk flexion angle during CW gait; and a scalar covariate, hip jerk index during CCW gait were selected. The model achieved an estimated AUC of 80.8 \%. For hip jerk index, an increase in hip jerk index by one unit increased the log odds of being in the neck pain group by 0.37. A 1° increase in trunk lateral flexion angle throughout gait alone reduced the probability of being in the neck pain group from 0.5 to 0.15. A 1° increase in trunk flexion angle throughout gait alone increased the probability of being in the neck pain group from 0.5 to 0.9.
Significance
Interpreting the physiological significance of the extracted covariates, with other biomechanical variables, suggests that individuals with neck pain performed curvilinear walking using a stiffer strategy, compared to controls; and this increased the risk of being in the neck pain group. FDboost can produce clinically interpretable models with complex high dimensional data and could be used in future prognostic modelling studies in neck pain research.},
	language = {en},
	urldate = {2021-03-24},
	journal = {Gait \& Posture},
	author = {Liew, Bernard X. W. and Rugamer, David and Stocker, Almond and De Nunzio, Alessandro Marco},
	month = feb,
	year = {2020},
	keywords = {Biomechanics, Functional regression, Machine learning, Neck pain, Walking},
	pages = {146--150},
}

@article{james_functional_2009,
	title = {Functional linear regression that’s interpretable},
	volume = {37},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-37/issue-5A/Functional-linear-regression-thats-interpretable/10.1214/08-AOS641.full},
	doi = {10.1214/08-AOS641},
	abstract = {Regression models to relate a scalar Y to a functional predictor X(t) are becoming increasingly common. Work in this area has concentrated on estimating a coefficient function, β(t), with Y related to X(t) through ∫β(t)X(t) dt. Regions where β(t)≠0 correspond to places where there is a relationship between X(t) and Y. Alternatively, points where β(t)=0 indicate no relationship. Hence, for interpretation purposes, it is desirable for a regression procedure to be capable of producing estimates of β(t) that are exactly zero over regions with no apparent relationship and have simple structures over the remaining regions. Unfortunately, most fitting procedures result in an estimate for β(t) that is rarely exactly zero and has unnatural wiggles making the curve hard to interpret. In this article we introduce a new approach which uses variable selection ideas, applied to various derivatives of β(t), to produce estimates that are both interpretable, flexible and accurate. We call our method “Functional Linear Regression That’s Interpretable” (FLiRTI) and demonstrate it on simulated and real-world data sets. In addition, non-asymptotic theoretical bounds on the estimation error are presented. The bounds provide strong theoretical motivation for our approach.},
	number = {5A},
	urldate = {2021-03-24},
	journal = {The Annals of Statistics},
	author = {James, Gareth M. and Wang, Jing and Zhu, Ji},
	month = oct,
	year = {2009},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62J99, Dantzig selector, Functional linear regression, Interpretable regression, Lasso},
	pages = {2083--2108},
}

@article{liew_classifying_2020-1,
	title = {Classifying individuals with and without patellofemoral pain syndrome using ground force profiles – {Development} of a method using functional data boosting},
	volume = {80},
	issn = {0966-6362},
	url = {https://www.sciencedirect.com/science/article/pii/S0966636220301843},
	doi = {10.1016/j.gaitpost.2020.05.034},
	abstract = {Background
Predictors of recovery in patellofemoral pain syndrome (PFPS) currently used in prognostic models are scalar in nature, despite many physiological measures originally lying on the functional scale. Traditional modelling techniques cannot harness the potential predictive value of functional physiological variables.
Research question
What is the classification performance of PFPS status of a statistical model when using functional ground reaction force (GRF) time-series?
Methods
Thirty-one individuals (control = 17, PFPS = 14) performed maximal countermovement jumps, on two force plates. The three-dimensional components of the GRF profiles were time-normalized between the start of the eccentric phase and take-off, and used as functional predictors. A statistical model was developed using functional data boosting (FDboost), for binary classification of PFPS statuses (control vs PFPS). The area under the Receiver Operating Characteristic curve (AUC) was used to quantify the model’s ability to discriminate the two groups.
Results
The three predictors of GRF waveform achieved an average out-of-bag AUC of 93.7 \%. A 1 \% increase in applied medial force reduced the log odds of being in the PFPS group by 0.68 at 87 \% of jump cycle. In the AP direction, a 1 \% reduction in applied posterior force increased the log odds of being classified as PFPS by 1.10 at 70 \% jump cycle. For the vertical GRF, a 1 \% increase in applied force reduced the log odds of being classified in the PFPS group by 0.12 at 44 \% of the jump cycle.
Significance
Using simple functional GRF variables collected during functionally relevant task, in conjunction with FDboost, produced clinically interpretable models that retain excellent classification performance in individuals with PFPS. FDboost may be an invaluable tool to be used in longitudinal cohort prognostic studies, especially when scalar and functional predictors are collected.},
	language = {en},
	urldate = {2021-03-23},
	journal = {Gait \& Posture},
	author = {Liew, Bernard X. W. and Rugamer, David and Abichandani, Deepa and De Nunzio, Alessandro Marco},
	month = jul,
	year = {2020},
	keywords = {Biomechanics, Functional regression, Jumping, Machine learning, Patellofemoral pain syndrome},
	pages = {90--95},
}

@article{liew_classifying_2020-2,
	title = {Classifying neck pain status using scalar and functional biomechanical variables – development of a method using functional data boosting},
	volume = {76},
	issn = {0966-6362},
	url = {https://www.sciencedirect.com/science/article/pii/S0966636219317734},
	doi = {10.1016/j.gaitpost.2019.12.008},
	abstract = {Background
Individuals with neck pain have different movement and muscular activation (collectively termed as biomechanical variables) patterns compared to healthy individuals. Incorporating biomechanical variables as covariates into prognostic models is challenging due to the high dimensionality of the data.
Research question
What is the classification performance of neck pain status of a statistical model which uses both scalar and functional biomechanical covariates?
Methods
Motion capture with electromyography assessment on the sternocleidomastoid, splenius cervicis, erector spinae, was performed on 21 healthy and 26 individuals with neck pain during walking over three gait conditions (rectilinear, curvilinear clockwise (CW) and counterclockwise (CCW)). After removing highly collinear variables, 94 covariates across the three conditions were used to classify neck pain status using functional data boosting (FDboost).
Results
Two functional covariates trunk lateral flexion angle during CCW gait, and trunk flexion angle during CW gait; and a scalar covariate, hip jerk index during CCW gait were selected. The model achieved an estimated AUC of 80.8 \%. For hip jerk index, an increase in hip jerk index by one unit increased the log odds of being in the neck pain group by 0.37. A 1° increase in trunk lateral flexion angle throughout gait alone reduced the probability of being in the neck pain group from 0.5 to 0.15. A 1° increase in trunk flexion angle throughout gait alone increased the probability of being in the neck pain group from 0.5 to 0.9.
Significance
Interpreting the physiological significance of the extracted covariates, with other biomechanical variables, suggests that individuals with neck pain performed curvilinear walking using a stiffer strategy, compared to controls; and this increased the risk of being in the neck pain group. FDboost can produce clinically interpretable models with complex high dimensional data and could be used in future prognostic modelling studies in neck pain research.},
	language = {en},
	urldate = {2021-03-23},
	journal = {Gait \& Posture},
	author = {Liew, Bernard X. W. and Rugamer, David and Stocker, Almond and De Nunzio, Alessandro Marco},
	month = feb,
	year = {2020},
	keywords = {Biomechanics, Functional regression, Machine learning, Neck pain, Walking},
	pages = {146--150},
}

@article{trounson_effects_2020,
	title = {Effects of acute wearable resistance loading on overground running lower body kinematics},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0244361},
	doi = {10.1371/journal.pone.0244361},
	abstract = {Field-based sports require athletes to run sub-maximally over significant distances, often while contending with dynamic perturbations to preferred coordination patterns. The ability to adapt movement to maintain performance under such perturbations appears to be trainable through exposure to task variability, which encourages movement variability. The aim of the present study was to investigate the extent to which various wearable resistance loading magnitudes alter coordination and induce movement variability during running. To investigate this, 14 participants (three female and 11 male) performed 10 sub-maximal velocity shuttle runs with either no weight, 1\%, 3\%, or 5\% of body weight attached to the lower limbs. Sagittal plane lower limb joint kinematics from one complete stride cycle in each run were assessed using functional data analysis techniques, both across the participant group and within-individuals. At the group-level, decreases in ankle plantarflexion following toe-off were evident in the 3\% and 5\% conditions, while increased knee flexion occurred during weight acceptance in the 5\% condition compared with unloaded running. At the individual-level, between-run joint angle profiles varied, with six participants exhibiting increased joint angle variability in one or more loading conditions compared with unloaded running. Loading of 5\% decreased between-run ankle joint variability among two individuals, likely in accordance with the need to manage increased system load or the novelty of the task. In terms of joint coordination, the most considerable alterations to coordination occurred in the 5\% loading condition at the hip-knee joint pair, however, only a minority of participants exhibited this tendency. Coaches should prescribe wearable resistance individually to perturb preferred coordination patterns and encourage movement variability without loading to the extent that movement options become limited.},
	language = {en},
	number = {12},
	urldate = {2021-03-16},
	journal = {PLOS ONE},
	author = {Trounson, Karl M. and Busch, Aglaja and Collier, Neil French and Robertson, Sam},
	month = dec,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Ankles, Hip, Kinematics, Knee joints, Knees, Musculoskeletal mechanics, Running, Skeletal joints},
	pages = {e0244361},
}

@article{goldsmith_assessing_2016,
	title = {Assessing systematic effects of stroke on motorcontrol by using hierarchical function-on-scalar regression},
	volume = {65},
	issn = {0035-9254},
	doi = {10.1111/rssc.12115},
	abstract = {This work is concerned with understanding common population-level effects of stroke on motor control while accounting for possible subject-level idiosyncratic effects. Upper extremity motor control for each subject is assessed through repeated planar reaching motions from a central point to eight pre-specified targets arranged on a circle. We observe the kinematic data for hand position as a bivariate function of time for each reach. Our goal is to estimate the bivariate function-on-scalar regression with subject-level random functional effects while accounting for potential correlation in residual curves; covariates of interest are severity of motor impairment and target number. We express fixed effects and random effects using penalized splines, and allow for residual correlation using a Wishart prior distribution. Parameters are jointly estimated in a Bayesian framework, and we implement a computationally efficient approximation algorithm using variational Bayes. Simulations indicate that the proposed method yields accurate estimation and inference, and application results suggest that the effect of stroke on motor control has a systematic component observed across subjects.},
	language = {eng},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series C, Applied Statistics},
	author = {Goldsmith, Jeff and Kitago, Tomoko},
	month = feb,
	year = {2016},
	pmid = {27546913},
	pmcid = {PMC4988692},
	keywords = {Bayesian Regression, Bivariate Data, Gibbs Sampler, Penalized Splines, Variational Bayes},
	pages = {215--236},
}

@article{morris_functional_2015,
	title = {Functional {Regression}},
	volume = {2},
	abstract = {Functional data analysis (FDA) involves the analysis of data whose ideal units of observation are functions defined on some continuous domain, and the observed data consist of a sample of functions taken from some population, sampled on a discrete grid. Ramsay \& Silverman's (1997) textbook sparked the development of this field, which has accelerated in the past 10 years to become one of the fastest growing areas of statistics, fueled by the growing number of applications yielding this type of data. One unique characteristic of FDA is the need to combine information both across and within functions, which Ramsay and Silverman called replication and regularization, respectively. This article focuses on functional regression, the area of FDA that has received the most attention in applications and methodological development. First, there is an introduction to basis functions, key building blocks for regularization in functional regression methods, followed by an overview of functional regression methods, split into three types: (a) functional predictor regression (scalar-on-function), (b) functional response regression (function-on-scalar), and (c) function-on-function regression. For each, the role of replication and regularization is discussed and the methodological development described in a roughly chronological manner, at times deviating from the historical timeline to group together similar methods. The primary focus is on modeling and methodology, highlighting the modeling structures that have been developed and the various regularization approaches employed. The review concludes with a brief discussion describing potential areas of future development in this field.},
	journal = {Annual Review of Statistics and Its Application},
	author = {Morris, Jeffrey S.},
	month = mar,
	year = {2015},
	pages = {321--359},
}

@article{greven_comments_2020,
	title = {Comments on: {Inference} and computation with {Generalized} {Additive} {Models} and their extensions},
	volume = {29},
	issn = {1863-8260},
	shorttitle = {Comments on},
	url = {https://doi.org/10.1007/s11749-020-00714-2},
	doi = {10.1007/s11749-020-00714-2},
	language = {en},
	number = {2},
	urldate = {2021-03-09},
	journal = {TEST},
	author = {Greven, Sonja and Scheipl, Fabian},
	month = jun,
	year = {2020},
	pages = {343--350},
}

@article{morris_comparison_2017,
	title = {Comparison and contrast of two general functional regression modelling frameworks},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681875},
	doi = {10.1177/1471082X16681875},
	abstract = {Abstract:, In their article, Greven and Scheipl describe an impressively general framework for performing functional regression that builds upon the generalized additive modelling framework. Over the past number of years, my collaborators and I have also been developing a general framework for functional regression, functional mixed models, which shares many similarities with this framework, but has many differences as well. In this discussion, I compare and contrast these two frameworks, to hopefully illuminate characteristics of each, highlighting their respective strengths and weaknesses, and providing recommendations regarding the settings in which each approach might be preferable.},
	language = {en},
	number = {1-2},
	urldate = {2021-03-09},
	journal = {Statistical Modelling},
	author = {Morris, Jeffrey S.},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Bayesian modeling, Functional data analysis, functional mixed models, functional regression, linear mixed models},
	pages = {59--85},
}

@article{fan_two-step_2000,
	title = {Two-step estimation of functional linear models with applications to longitudinal data},
	volume = {62},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00233},
	doi = {https://doi.org/10.1111/1467-9868.00233},
	abstract = {Functional linear models are useful in longitudinal data analysis. They include many classical and recently proposed statistical models for longitudinal data and other functional data. Recently, smoothing spline and kernel methods have been proposed for estimating their coefficient functions nonparametrically but these methods are either intensive in computation or inefficient in performance. To overcome these drawbacks, in this paper, a simple and powerful two-step alternative is proposed. In particular, the implementation of the proposed approach via local polynomial smoothing is discussed. Methods for estimating standard deviations of estimated coefficient functions are also proposed. Some asymptotic results for the local polynomial estimators are established. Two longitudinal data sets, one of which involves time-dependent covariates, are used to demonstrate the approach proposed. Simulation studies show that our two-step approach improves the kernel method proposed by Hoover and co-workers in several aspects such as accuracy, computational time and visual appeal of the estimators.},
	language = {en},
	number = {2},
	urldate = {2021-03-05},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Fan, J. and Zhang, J.-T.},
	year = {2000},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00233},
	keywords = {Functional analysis of variance, Functional linear models, Local polynomial smoothing, Longitudinal data analysis},
	pages = {303--322},
}

@article{reiss_fast_2010,
	title = {Fast {Function}-on-{Scalar} {Regression} with {Penalized} {Basis} {Expansions}},
	volume = {6},
	issn = {1557-4679},
	url = {https://www.degruyter.com/document/doi/10.2202/1557-4679.1246/html},
	doi = {10.2202/1557-4679.1246},
	abstract = {Regression models for functional responses and scalar predictors are often fitted by means of basis functions, with quadratic roughness penalties applied to avoid overfitting. The fitting approach described by Ramsay and Silverman in the 1990s amounts to a penalized ordinary least squares (P-OLS) estimator of the coefficient functions. We recast this estimator as a generalized ridge regression estimator, and present a penalized generalized least squares (P-GLS) alternative. We describe algorithms by which both estimators can be implemented, with automatic selection of optimal smoothing parameters, in a more computationally efficient manner than has heretofore been available. We discuss pointwise confidence intervals for the coefficient functions, simultaneous inference by permutation tests, and model selection, including a novel notion of pointwise model selection. P-OLS and P-GLS are compared in a simulation study. Our methods are illustrated with an analysis of age effects in a functional magnetic resonance imaging data set, as well as a reanalysis of a now-classic Canadian weather data set. An R package implementing the methods is publicly available.},
	language = {en},
	number = {1},
	urldate = {2021-03-04},
	journal = {The International Journal of Biostatistics},
	author = {Reiss, Philip T. and Huang, Lei and Mennes, Maarten},
	month = aug,
	year = {2010},
	note = {Publisher: De Gruyter
Section: The International Journal of Biostatistics},
}

@article{greven_general_2017,
	title = {A general framework for functional regression modelling},
	volume = {17},
	issn = {1471-082X},
	url = {https://doi.org/10.1177/1471082X16681317},
	doi = {10.1177/1471082X16681317},
	abstract = {Abstract, Researchers are increasingly interested in regression models for functional data. This article discusses a comprehensive framework for additive (mixed) models for functional responses and/or functional covariates based on the guiding principle of reframing functional regression in terms of corresponding models for scalar data, allowing the adaptation of a large body of existing methods for these novel tasks. The framework encompasses many existing as well as new models. It includes regression for ‘generalized’ functional data, mean regression, quantile regression as well as generalized additive models for location, shape and scale (GAMLSS) for functional data. It admits many flexible linear, smooth or interaction terms of scalar and functional covariates as well as (functional) random effects and allows flexible choices of bases—particularly splines and functional principal components—and corresponding penalties for each term. It covers functional data observed on common (dense) or curve-specific (sparse) grids. Penalized-likelihood-based and gradient-boosting-based inference for these models are implemented in R packages refund and FDboost, respectively. We also discuss identifiability and computational complexity for the functional regression models covered. A running example on a longitudinal multiple sclerosis imaging study serves to illustrate the flexibility and utility of the proposed model class. Reproducible code for this case study is made available online.},
	language = {en},
	number = {1-2},
	urldate = {2021-03-04},
	journal = {Statistical Modelling},
	author = {Greven, Sonja and Scheipl, Fabian},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications India},
	keywords = {Functional data, GAMLSS, functional additive mixed model, functional principal components, gradient boosting, penalized splines},
	pages = {1--35},
}

@article{sorensen_introduction_2013,
	title = {An introduction with medical applications to functional data analysis},
	volume = {32},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5989},
	doi = {https://doi.org/10.1002/sim.5989},
	abstract = {Functional data are data that can be represented by suitable functions, such as curves (potentially multi-dimensional) or surfaces. This paper gives an introduction to some basic but important techniques for the analysis of such data, and we apply the techniques to two datasets from biomedicine. One dataset is about white matter structures in the brain in multiple sclerosis patients; the other dataset is about three-dimensional vascular geometries collected for the study of cerebral aneurysms. The techniques described are smoothing, alignment, principal component analysis, and regression. Copyright © 2013 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {30},
	urldate = {2021-03-04},
	journal = {Statistics in Medicine},
	author = {Sørensen, Helle and Goldsmith, Jeff and Sangalli, Laura M.},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.5989},
	keywords = {curve alignment, functional principal component analysis, functional regression, smoothing},
	pages = {5222--5240},
}

@article{lee_functional_2019,
	title = {Functional {Data} {Analyses} of {Gait} {Data} {Measured} {Using} {In}-{Shoe} {Sensors}},
	volume = {11},
	issn = {1867-1772},
	url = {https://doi.org/10.1007/s12561-018-9226-3},
	doi = {10.1007/s12561-018-9226-3},
	abstract = {In studies of gait, continuous measurement of force exerted by the ground on a body, or ground reaction force (GRF), provides valuable insights into biomechanics, locomotion, and the possible presence of pathology. However, gold-standard measurement of GRF requires a costly in-lab observation obtained with sophisticated equipment and computer systems. Recently, in-shoe sensors have been pursued as a relatively inexpensive alternative to in-lab measurement. In this study, we explore the properties of continuous in-shoe sensor recordings using a functional data analysis approach. Our case study is based on measurements of three healthy subjects, with more than 300 stances (defined as the period between the foot striking and lifting from the ground) per subject. The sensor data show both phase and amplitude variabilities; we separate these sources via curve registration. We examine the correlation of phase shifts across sensors within a stance to evaluate the pattern of phase variability shared across sensors. Using the registered curves, we explore possible associations between in-shoe sensor recordings and GRF measurements to evaluate the in-shoe sensor recordings as a possible surrogate for in-lab GRF measurements.},
	language = {en},
	number = {2},
	urldate = {2021-03-03},
	journal = {Statistics in Biosciences},
	author = {Lee, Jihui and Li, Gen and Christensen, William F. and Collins, Gavin and Seeley, Matthew and Bowden, Anton E. and Fullwood, David T. and Goldsmith, Jeff},
	month = jul,
	year = {2019},
	pages = {288--313},
}

@article{ferber_gait_2016,
	title = {Gait biomechanics in the era of data science},
	volume = {49},
	issn = {1873-2380},
	doi = {10.1016/j.jbiomech.2016.10.033},
	abstract = {Data science has transformed fields such as computer vision and economics. The ability of modern data science methods to extract insights from large, complex, heterogeneous, and noisy datasets is beginning to provide a powerful complement to the traditional approaches of experimental motion capture and biomechanical modeling. The purpose of this article is to provide a perspective on how data science methods can be incorporated into our field to advance our understanding of gait biomechanics and improve treatment planning procedures. We provide examples of how data science approaches have been applied to biomechanical data. We then discuss the challenges that remain for effectively using data science approaches in clinical gait analysis and gait biomechanics research, including the need for new tools, better infrastructure and incentives for sharing data, and education across the disciplines of biomechanics and data science. By addressing these challenges, we can revolutionize treatment planning and biomechanics research by capitalizing on the wealth of knowledge gained by gait researchers over the past decades and the vast, but often siloed, data that are collected in clinical and research laboratories around the world.},
	language = {eng},
	number = {16},
	journal = {Journal of Biomechanics},
	author = {Ferber, Reed and Osis, Sean T. and Hicks, Jennifer L. and Delp, Scott L.},
	month = dec,
	year = {2016},
	pmid = {27814971},
	pmcid = {PMC5407492},
	keywords = {Biomechanical Phenomena, Biomechanics, Data science, Gait, Humans, Informatics, Machine learning, Research},
	pages = {3759--3761},
}

@article{phinyomark_analysis_2018,
	title = {Analysis of {Big} {Data} in {Gait} {Biomechanics}: {Current} {Trends} and {Future} {Directions}},
	volume = {38},
	issn = {1609-0985},
	shorttitle = {Analysis of {Big} {Data} in {Gait} {Biomechanics}},
	doi = {10.1007/s40846-017-0297-2},
	abstract = {The increasing amount of data in biomechanics research has greatly increased the importance of developing advanced multivariate analysis and machine learning techniques, which are better able to handle "big data". Consequently, advances in data science methods will expand the knowledge for testing new hypotheses about biomechanical risk factors associated with walking and running gait-related musculoskeletal injury. This paper begins with a brief introduction to an automated three-dimensional (3D) biomechanical gait data collection system: 3D GAIT, followed by how the studies in the field of gait biomechanics fit the quantities in the 5 V's definition of big data: volume, velocity, variety, veracity, and value. Next, we provide a review of recent research and development in multivariate and machine learning methods-based gait analysis that can be applied to big data analytics. These modern biomechanical gait analysis methods include several main modules such as initial input features, dimensionality reduction (feature selection and extraction), and learning algorithms (classification and clustering). Finally, a promising big data exploration tool called "topological data analysis" and directions for future research are outlined and discussed.},
	language = {eng},
	number = {2},
	journal = {Journal of Medical and Biological Engineering},
	author = {Phinyomark, Angkoon and Petri, Giovanni and Ibáñez-Marcelo, Esther and Osis, Sean T. and Ferber, Reed},
	year = {2018},
	pmid = {29670502},
	pmcid = {PMC5897457},
	keywords = {Biomechanics, Data science, Gait, Kinematics, Principal component analysis, Support vector machine, Topological data analysis},
	pages = {244--260},
}

@article{honert_timing_2021,
	title = {Timing of gait events affects whole trajectory analyses: {A} statistical parametric mapping sensitivity analysis of lower limb biomechanics},
	volume = {119},
	issn = {0021-9290},
	shorttitle = {Timing of gait events affects whole trajectory analyses},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929021001093},
	doi = {10.1016/j.jbiomech.2021.110329},
	abstract = {Time continuous analyses, such as statistical parametric mapping (SPM), have been increasingly used in biomechanics research to determine differences between populations, interventions and methodologies. Currently, it is not known how sensitive time-continuous analyses are to timing variability that occur in gait data. We evaluated this sensitivity by examining the frequency of significant SPM outcomes between two walking speeds when lower limb kinematics and kinetics were segmented and aligned based on 40 repeatable gait events. These events, defined in the supplementary material, include a commonly used event like foot contact and other events that have been previously demonstrated to be repeatable. Repeatable gait events were determined from joint and segment kinematics, joint kinetics as well as ground reaction forces. We examined the frequency of statistical outcomes for a single subject with different numbers of strides analyzed and for a cohort of 10 subjects. Our findings demonstrate that gait interventions, such as changes in walking speed, can induce temporal shifts that affect time-continuous outcomes for both cohort- and subject-level analyses. As both timing and magnitude are important in gait data, researchers are encouraged to perform additional analyses to understand how both of these variables affect time-continuous analysis outcomes. Finally, we demonstrate that multiple SPM tests can be performed to determine if statistical outcomes are due to temporal shifting or differences in magnitude. It is important to understand how both timing and magnitude of biomechanical data influences time continuous analyses as these analyses inform injury prevention, device development and basic understanding of biomechanics.},
	language = {en},
	urldate = {2021-03-03},
	journal = {Journal of Biomechanics},
	author = {Honert, Eric C. and Pataky, Todd C.},
	month = apr,
	year = {2021},
	keywords = {Curve registration, Gait analysis, Principal component analysis, Time continuous analysis},
	pages = {110329},
}

@article{zeppelzauer_gaitrec_2020,
	title = {{GaitRec}: {A} large-scale ground reaction force dataset of healthy and impaired gait},
	shorttitle = {{GaitRec}},
	url = {/collections/GaitRec_A_large-scale_ground_reaction_force_dataset_of_healthy_and_impaired_gait/4788012},
	doi = {10.6084/m9.figshare.c.4788012.v1},
	abstract = {The quantification of ground reaction forces (GRF) is a standard tool for clinicians to quantify and analyze human locomotion. Such recordings produce a vast amount of complex data and variables which are difficult to comprehend. This makes data interpretation challenging. Machine learning approaches seem to be promising tools to support clinicians in identifying and categorizing specific gait patterns. However, the quality of such approaches strongly depends on the amount of available annotated data to train the underlying models. Therefore, we present GAITREC, a comprehensive and completely annotated large-scale dataset containing bi-lateral GRF walking trials of 2,084 patients with various musculo-skeletal impairments and data from 211 healthy controls. The gait dataset comprises data of patients after joint replacement, fractures, ligament ruptures, and related disorders at the hip, knee, ankle or calcaneus during their entire stay(s) at a rehabilitation center. The data sum up to a total of 75,732 bi-lateral walking trials and enable researchers to classify gait patterns at a large-scale as well as to analyze the entire recovery process of patients.},
	language = {en},
	urldate = {2021-02-28},
	author = {Zeppelzauer, Matthias},
	month = apr,
	year = {2020},
	note = {Publisher: figshare},
}

@article{horsak_gaitrec_2020,
	title = {{GaitRec}, a large-scale ground reaction force dataset of healthy and impaired gait},
	volume = {7},
	copyright = {2020 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-020-0481-z},
	doi = {10.1038/s41597-020-0481-z},
	abstract = {The quantification of ground reaction forces (GRF) is a standard tool for clinicians to quantify and analyze human locomotion. Such recordings produce a vast amount of complex data and variables which are difficult to comprehend. This makes data interpretation challenging. Machine learning approaches seem to be promising tools to support clinicians in identifying and categorizing specific gait patterns. However, the quality of such approaches strongly depends on the amount of available annotated data to train the underlying models. Therefore, we present GaitRec, a comprehensive and completely annotated large-scale dataset containing bi-lateral GRF walking trials of 2,084 patients with various musculoskeletal impairments and data from 211 healthy controls. The dataset comprises data of patients after joint replacement, fractures, ligament ruptures, and related disorders at the hip, knee, ankle or calcaneus during their entire stay(s) at a rehabilitation center. The data sum up to a total of 75,732 bi-lateral walking trials and enable researchers to classify gait patterns at a large-scale as well as to analyze the entire recovery process of patients.},
	language = {en},
	number = {1},
	urldate = {2021-02-28},
	journal = {Scientific Data},
	author = {Horsak, Brian and Slijepcevic, Djordje and Raberger, Anna-Maria and Schwab, Caterine and Worisch, Marianne and Zeppelzauer, Matthias},
	month = may,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {143},
}

@article{dossantos_average_2020,
	title = {Average of trial peaks versus peak of average profile: impact on change of direction biomechanics},
	volume = {19},
	issn = {1476-3141},
	shorttitle = {Average of trial peaks versus peak of average profile},
	url = {https://doi.org/10.1080/14763141.2018.1497197},
	doi = {10.1080/14763141.2018.1497197},
	abstract = {The aims of this study were twofold: firstly, to compare lower limb kinematic and kinetic variables during a sprint and 90° cutting task between two averaging methods of obtaining discrete data (peak of average profile vs. average of individual trial peaks); secondly, to determine the effect of averaging methods on participant ranking of each variable within a group. Twenty-two participants, from multiple sports, performed a 90° cut, whereby lower limb kinematics and kinetics were assessed via 3D motion and ground reaction force (GRF) analysis. Six of the eight dependent variables (vertical and horizontal GRF; hip flexor, knee flexor, and knee abduction moments, and knee abduction angle) were significantly greater (p ≤ 0.001, g = 0.10–0.37, 2.74–10.40\%) when expressed as an average of trial peaks compared to peak of average profiles. Trivial (g ≤ 0.04) and minimal differences (≤ 0.94\%) were observed in peak hip and knee flexion angle between averaging methods. Very strong correlations (ρ ≥ 0.901, p {\textless} 0.001) were observed for rankings of participants between averaging methods for all variables. Practitioners and researchers should obtain discrete data based on the average of trial peaks because it is not influenced by misalignments and variations in trial peak locations, in contrast to the peak from average profile.},
	number = {4},
	urldate = {2021-02-26},
	journal = {Sports Biomechanics},
	author = {Dos’Santos, Thomas and Comfort, Paul and Jones, Paul A.},
	month = jul,
	year = {2020},
	pmid = {30124388},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2018.1497197},
	keywords = {Cutting, discrete data, kinematics, kinetics, statistical design},
	pages = {483--492},
}

@article{hyndman_rainbow_2010,
	title = {Rainbow {Plots}, {Bagplots}, and {Boxplots} for {Functional} {Data}},
	volume = {19},
	issn = {1061-8600},
	url = {https://www.jstor.org/stable/25651298},
	abstract = {We propose new tools for visualizing large amounts of functional data in the form of smooth curves. The proposed tools include functional versions of the bagplot and boxplot, which make use of the first two robust principal component scores, Tukey's data depth and highest density regions. By-products of our graphical displays are outlier detection methods for functional data. We compare these new outlier detection methods with existing methods for detecting outliers in functional data, and show that our methods are better able to identify outliers. An R-package containing computer code and datasets is available in the online supplements.},
	number = {1},
	urldate = {2021-02-26},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Hyndman, Rob J. and Shang, Han Lin},
	year = {2010},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
	pages = {29--45},
}

@phdthesis{coffey_functional_2008,
	title = {Functional principal components analysis in a linear mixed effects model framework},
	language = {eng},
	school = {University of Limerick},
	author = {Coffey, Norma},
	year = {2008},
}

@incollection{horvath_tests_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Tests for error correlation in the functional linear model},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_11},
	abstract = {In this chapter, we consider two tests for error correlation in the fully functional linear model, which we call Methods I and II They complement the tools described in Section 8.6 and the graphical goodness of fit checks used in Chapter 9. To construct the test statistics, finite dimensional residuals are computed in two different ways, and then their autocorrelations are suitably defined. From these autocorrelation matrices, two quadratic forms are constructed whose limiting distribution are chi–squared with known numbers of degrees of freedom (different for the two forms). The test statistics can be relatively easily computed using the R package fda.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_11},
	keywords = {Brownian Bridge, Brownian Motion, Error Correlation, Functional Principal Component, Magnetometer Data},
	pages = {191--224},
}

@incollection{horvath_determining_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Determining the order of the functional autoregressive model},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_15},
	abstract = {This chapter is concerned with determining the order p in the FAR(p) model \$\$Z\_\{i\} = {\textbackslash}sum{\textbackslash}limits\_\{j = 1\}{\textasciicircum}\{p\}{\textbackslash}phi\_j(Z\_\{i - j\}) + {\textbackslash}varepsilon\_i.\$\$ We describe a testing procedure proposed by Kokoszka and Reimherr (2011). At its core is the representation of the FAR(p) process as a fully functional linear model with dependent regressors.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_15},
	keywords = {Empirical Size, Finite Sample Performance, Functional Observation, Functional Principal Component, Random Subspace},
	pages = {277--288},
}

@incollection{horvath_change_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Change point detection in the functional autoregressive process},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_14},
	abstract = {In this chapter, we develop a change point test for the FAR(1) model introduced in Chapter 13. The importance of change point testing was discussed in Chapter 6. Failure to take change points into account leads to spurious inference. This chapter is based on the work of Horváth et al. (2010). Zhang et al. (2011) proposed a self–normalized statistic to solve the problem discussed in this chapter. Self–normalized statistics are discussed in Section 16.6.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_14},
	keywords = {Brownian Bridge, Change Point, Change Point Detection, Ergodic Sequence, Zero Innovation},
	pages = {253--276},
}

@incollection{horvath_detection_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Detection of changes in the mean function},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_6},
	abstract = {In this chapter, we present a methodology for the detection of changes in the mean of functional observations. At its core is a significance test for testing the null hypothesis of a constant functional mean against the alternative of a changing mean. We also show how to locate the change points if the null hypothesis is rejected. Our methodology is readily implemented using the R package fda. The null distribution of the test statistic is asymptotically pivotal with a well-known asymptotic distribution going back to the work of Kiefer (1959).},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_6},
	keywords = {Brownian Bridge, Brownian Motion, Change Point, Change Point Detection, Empirical Size},
	pages = {79--104},
}

@incollection{horvath_consistency_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Consistency of the simple mean and the empirical functional principal components for spatially distributed curves},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_18},
	abstract = {In this chapter, we continue to study functional data that consist of curves {\textbackslash}(X({\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{k\} ; t), t {\textbackslash}in [0, 1]{\textbackslash}) observed at spatial points {\textbackslash}({\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{1\}, {\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{2\}, {\textbackslash}ldots, {\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{N\}{\textbackslash}). In Chapter 17, we have seen that in this context the simple sample average and the EFPC’s are not the optimal estimators of their population counterparts, and that better estimators can be constructed by using weighted averages.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_18},
	keywords = {Consistent Estimation, Covariance Operator, Functional Principal Component, Functional Time Series, Random Sampling Design},
	pages = {375--403},
}

@incollection{horvath_spatially_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Spatially distributed functional data},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_17},
	abstract = {Chapters 13, 14 and 16 focused on functional time series. The present chapter and Chapter 18 deal with curves observed at spatial locations. The data consist of curves {\textbackslash}(X({\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{k\} ; t) {\textbackslash}in [0, 1]{\textbackslash}) observed at spatial locations {\textbackslash}({\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{1\}, {\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{2\}, {\textbackslash}ldots, {\textbackslash}mathbf\{{\textbackslash}mathrm\{S\}\}\_\{N\}{\textbackslash}). We propose methods for the estimation of the mean function and the FPC’s for such data. We also develop a significance test for the correlation of two such functional spatial fields.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_17},
	keywords = {Covariance Tensor, Empirical Variogram, Finite Sample Performance, Functional Data, Spatial Statistic},
	pages = {343--374},
}

@incollection{horvath_portmanteau_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Portmanteau test of independence},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_7},
	abstract = {Most inferential tools of functional data analysis rely on the assumption of iid functional observations. In designed experiments this assumption can be ensured, but for observational data, especially derived from time series, it requires a verification. In this chapter, based on the paper of Gabrys and Kokoszka (2007), we describe a simple portmanteau test of independence for functional observations whose idea is as follows.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_7},
	keywords = {Asymptotic Distribution, Brownian Bridge, Fourth Moment, Functional Data Analysis, Random Element},
	pages = {105--124},
}

@incollection{horvath_two_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Two sample inference for the mean and covariance functions},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_5},
	abstract = {Due to possibly different FPC’s structures, working with two functional samples may be difficult. An important contribution has been made by Benko et al. (2009) who developed bootstrap procedures for testing the equality of mean functions, the FPC’s, and the eigenspaces spanned by them. In this chapter, we present asymptotic procedures for testing the equality of the means and the covariance operators in two independent samples. Section 5.1 focuses on testing the equality of mean functions. It shows that instead of statistics which have chi–square limits, those that converge to weighted sums of squares of independent standard normals can also be used. In other chapters we focus on statistics converging to chi–square distributions, but analogous versions converging to weighted sums of normals can be readily constructed.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_5},
	keywords = {Brownian Bridge, Covariance Function, Covariance Operator, Nominal Size, Schmidt Operator},
	pages = {65--77},
}

@incollection{horvath_functional_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional principal components},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_3},
	abstract = {This chapter introduces one of the most fundamental concepts of FDA, that of the functional principal components (FPC’s). FPC’s allow us to reduce the dimension of infinitely dimensional functional data to a small finite dimension in an optimal way. In Sections 3.1 and 3.2, we introduce the FPC’s from two angles, as coordinates maximizing variability, and as an optimal orthonormal basis. In Section 3.3, we identify the FPC’s with the eigenfunctions of the covariance operator, and show how its eigenvalues decompose the variance of the functional data. We conclude with Section 3.4 which explains how to compute the FPC’s in the R package fda.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_3},
	keywords = {Covariance Operator, Functional Data, Functional Data Analysis, Functional Object, Schmidt Operator},
	pages = {37--43},
}

@incollection{horvath_two_2012-1,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Two sample inference for regression kernels},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_10},
	abstract = {In Chapter 5, we studied two sample procedures for the mean function and the covariance operator. This chapter is devoted to testing the equality of the regression operators in two functional linear models.We are concerned with the following problem: We observe two samples: sample 1: {\textbackslash}((X\_i, Y\_i), 1 {\textbackslash}leq i {\textbackslash}leq N{\textbackslash}) and sample 2: {\textbackslash}((X\_\{i\}{\textasciicircum}\{{\textbackslash}ast\}, Y\_\{i\}{\textasciicircum}\{{\textbackslash}ast\}), 1 {\textbackslash}leq j {\textbackslash}leq M{\textbackslash}).},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_10},
	keywords = {Covariance Operator, Functional Response, Magnetometer Data, Regression Kernel, Standard Brownian Motion},
	pages = {169--190},
}

@incollection{horvath_canonical_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Canonical correlation analysis},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_4},
	abstract = {Canonical correlation analysis (CCA) is one of the most important tools of multivariate statistical analysis. Its extension to the functional context is not trivial, and in many ways illustrates the differences between multivariate and functional data. One of the most influential contributions has been made by Leurgans et al. (1993) who showed that smoothing is necessary in order to define the functional canonical correlations meaningfully.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_4},
	keywords = {Canonical Correlation, Canonical Correlation Analysis, Covariance Operator, Global Index, Magnetic Storm},
	pages = {45--63},
}

@incollection{horvath_functional_2012-1,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional time series},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_16},
	abstract = {Functional data often arise from measurements obtained by separating an almost continuous time record into natural consecutive intervals, for example days. The functions thus obtained form a functional time series, and the central issue in the analysis of such data is to take into account the temporal dependence of these functional observations. In the previous chapters we have seen many examples, which include daily curves of financial transaction data and daily patterns of geophysical and environmental data.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_16},
	keywords = {Adjusted Power, Brownian Bridge, Change Point, Change Point Detection, Kernel Estimator},
	pages = {289--341},
}

@incollection{horvath_functional_2012-2,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional autoregressive model},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_13},
	abstract = {This chapter studies the functional autoregressive (FAR) process which has found many applications. The theory of autoregressive and more general linear processes in Hilbert and Banach spaces is developed in the monograph of Bosq (2000), on which Sections 13.1 and 13.2 are based. We present only a few selected results which provide an introduction to the central ideas, and are needed in the sequel. Section 13.3 is devoted to prediction by means of the FAR process; some theoretical background is given in Section 13.5.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_13},
	keywords = {Brownian Bridge, Estimate Kernel, Partial Isometry, Trace Class, Trace Class Operator},
	pages = {235--252},
}

@incollection{horvath_test_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Test for lack of effect in the functional linear model},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_9},
	abstract = {In this chapter, we study the fully functional linear model (8.1) and test the nullity of the operator {\textbackslash}({\textbackslash}Psi{\textbackslash}), i.e. \$\$H\_\{0\} : {\textbackslash}Psi = 0{\textbackslash} \{{\textbackslash}rm versus\}{\textbackslash} H\_\{4\} : {\textbackslash}Psi {\textbackslash}neq 0.\$\$},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_9},
	keywords = {Brownian Bridge, Empirical Size, Geomagnetic Observatory, Magnetometer Data, Straight Line Regression},
	pages = {147--167},
}

@incollection{horvath_functional_2012-3,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional data structures},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_1},
	abstract = {Statistics is concerned with obtaining information from observations X 1, X 2, …, X N . The X n can be scalars, vectors or other objects. For example, each X n can be a satellite image, in some spectral bandwidth, of a particular region of the Earth taken at time n. Functional Data Analysis (FDA) is concerned with observations which are viewed as functions defined over some set T. A satellite image processed to show surface temperature can be viewed as a function X defined on a subset T of a sphere, X(t) being the temperature at location t. The value X n (t) is then the temperature at location t at time n. Clearly, due to finite resolution, the values of X n are available only at a finite grid of points, but the temperature does exist at every location, so it is natural to view X n as a function defined over the whole set T.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_1},
	keywords = {Fourier Basis, Functional Data, Functional Data Analysis, Functional Object, Universal Time},
	pages = {1--17},
}

@incollection{horvath_test_2012-1,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {A test of significance in functional quadratic regression},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_12},
	abstract = {The functional quadratic model in which a scalar response, Y n , is paired with a functional predictor, Y n (t), is defined as \$\$Y\_n = {\textbackslash}mu + {\textbackslash}int k(t)X{\textasciicircum}\{c\}\_\{n\}(t)dt + {\textbackslash}iint h(s,t)X{\textasciicircum}\{c\}\_\{n\}(S)X{\textasciicircum}\{c\}\_\{n\}(t)dt ds + {\textbackslash}varepsilon\_\{n\},\$\$},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_12},
	pages = {225--232},
}

@incollection{horvath_hilbert_2012,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Hilbert space model for functional data},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_2},
	abstract = {In this Chapter we introduce some fundamental concepts of the theory of operators in a Hilbert space, and then focus of the properties of random samples in the space L 2 of square integrable functions. The space L 2 is sufficient to handle most procedures considered in this book. We also present a few technical results that fit into the framework considered in this chapter, and are used in subsequent chapters.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_2},
	keywords = {Compact Operator, Covariance Operator, Functional Data, Hilbert Space, Random Function},
	pages = {21--36},
}

@incollection{horvath_functional_2012-4,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Functional linear models},
	isbn = {978-1-4614-3655-3},
	url = {https://doi.org/10.1007/978-1-4614-3655-3_8},
	abstract = {In this chapter we review some important ideas related to the functional linear model. Like its multivariate counterpart, this model has been developed in various directions, and has been found to be extremely useful in a broad range of applications. The relevant research is very rich and multifaceted, and we do not aim at a full review of the very extensive literature on this subject. Our objective in this chapter is to explain briefly the general ideas and point to some recent advances. Some additional references are given in Section 8.7. Our choice of topics is partially motivated by the the methodology presented in Chapters 9, 11 and 10. Practically all inferential tool for the functional linear model have been developed under the assumption that the regressor/response pairs, (X i , Y i ), are independent. They must therefore be applied with care to functional data obtained over time or space.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {Inference for {Functional} {Data} with {Applications}},
	publisher = {Springer},
	author = {Horváth, Lajos and Kokoszka, Piotr},
	editor = {Horváth, Lajos and Kokoszka, Piotr},
	year = {2012},
	doi = {10.1007/978-1-4614-3655-3_8},
	keywords = {Approximate Identity, Bibliographical Note, Functional Model, Reproduce Kernel Hilbert Space, Standard Linear Model},
	pages = {127--145},
}

@inproceedings{geler_dynamic_2019,
	title = {Dynamic {Time} {Warping}: {Itakura} vs {Sakoe}-{Chiba}},
	shorttitle = {Dynamic {Time} {Warping}},
	doi = {10.1109/INISTA.2019.8778300},
	abstract = {In the domain of time-series classification, one simple but persistently successful method is the 1-nearest neighbour (1NN) classifier coupled with an elastic distance measure such as Dynamic Time Warping (DTW). In this paper we evaluate the performance of DTW when constrained using the Itakura parallelogram, and compare it with the more commonly used Sakoe-Chiba band, as well as with the unconstrained DTW. Results show that although the Itakura parallelogram is generally inferior to the Sakoe-Chiba band, it is still superior to unconstrained DTW. Furthermore, on individual data sets the Itakura parallelogram can produce superior results, warranting further investigation into the merits of its use with DTW and other elastic distance measures for time-series classification.},
	booktitle = {2019 {IEEE} {International} {Symposium} on {INnovations} in {Intelligent} {SysTems} and {Applications} ({INISTA})},
	author = {Geler, Z. and Kurbalija, V. and Ivanović, M. and Radovanović, M. and Dai, W.},
	month = jul,
	year = {2019},
	keywords = {1NN classifier, Classification algorithms, DTW, Heuristic algorithms, Itakura parallelogram, Microsoft Windows, Prediction algorithms, Sakoe-Chiba band, Task analysis, Time measurement, Time series analysis, constraints, distances, dynamic programming, dynamic time warping, elastic distance measure, pattern classification, time series, time-series classification, unconstrained DTW},
	pages = {1--6},
}

@article{marron_functional_2015,
	title = {Functional {Data} {Analysis} of {Amplitude} and {Phase} {Variation}},
	volume = {30},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/24780816},
	abstract = {The abundance of functional observations in scientific endeavors has led to a significant development in tools for functional data analysis (FDA). This kind of data comes with several challenges: infinite-dimensionality of function spaces, observation noise, and so on. However, there is another interesting phenomena that creates problems in FDA. The functional data often comes with lateral displacements/deformations in curves, a phenomenon which is different from the height or amplitude variability and is termed phase variation. The presence of phase variability artificially often inflates data variance, blurs underlying data structures, and distorts principal components. While the separation and/or removal of phase from amplitude data is desirable, this is a difficult problem. In particular, a commonly used alignment procedure, based on minimizing the 핃2 norm between functions, does not provide satisfactory results. In this paper we motivate the importance of dealing with the phase variability and summarize several current ideas for separating phase and amplitude components. These approaches differ in the following: (1) the definition and mathematical representation of phase variability, (2) the objective functions that are used in functional data alignment, and (3) the algorithmic tools for solving estimation/optimization problems. We use simple examples to illustrate various approaches and to provide useful contrast between them.},
	number = {4},
	urldate = {2021-02-21},
	journal = {Statistical Science},
	author = {Marron, J. S. and Ramsay, James O. and Sangalli, Laura M. and Srivastava, Anuj},
	year = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {468--484},
}

@article{helwig_methods_2011,
	title = {Methods to temporally align gait cycle data},
	volume = {44},
	issn = {1873-2380},
	doi = {10.1016/j.jbiomech.2010.09.015},
	abstract = {The need for the temporal alignment of gait cycle data is well known; however, there is little consensus concerning which alignment method to use. In this paper, we discuss the pros and cons of some methods commonly applied to temporally align gait cycle data (normalization to percent gait cycle, dynamic time warping, derivative dynamic time warping, and piecewise alignment methods). In addition, we empirically evaluate these different methods' abilities to produce successful temporal alignment when mapping a test gait cycle trajectory to a target trajectory. We demonstrate that piecewise temporal alignment techniques outperform other commonly used alignment methods (normalization to percent gait cycle, dynamic time warping, and derivative dynamic time warping) in typical biomechanical and clinical alignment tasks. Lastly, we present an example of how these piecewise alignment techniques make it possible to separately examine intensity and temporal differences between gait cycle data throughout the entire gait cycle, which can provide greater insight into the complexities of movement patterns.},
	language = {eng},
	number = {3},
	journal = {Journal of Biomechanics},
	author = {Helwig, Nathaniel E. and Hong, Sungjin and Hsiao-Wecksler, Elizabeth T. and Polk, John D.},
	month = feb,
	year = {2011},
	pmid = {20887992},
	keywords = {Algorithms, Gait, Motor Activity},
	pages = {561--566},
}

@article{kneip_statistical_1992,
	title = {Statistical {Tools} to {Analyze} {Data} {Representing} a {Sample} of {Curves}},
	volume = {20},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2242012},
	abstract = {The paper is concerned with data representing a sample of smooth curves which can be considered as independent realizations of an underlying biological (chemical, ...) process. Such samples of curves often possess the following features: There is a typical structural pattern common to all curves of the sample. On the other hand, individual realizations of the typical shape show different dynamics and intensity. In particular, typical peaks are shifted from individual to individual. Differences in dynamics complicate the analysis of samples of curves. For example, the cross-sectional average usually does not reflect an average pattern. Due to shifts, structure is smeared or might even disappear. Our approach consists in synchronizing the individual curves before determining the average or any further statistics. Pointwise averaging of the synchronized curves then leads to an average curve which represents the common structure with average dynamics and average intensity. The method requires the introduction of new statistical objects. They are defined mathematically, their properties are discussed, and possible estimators are proposed. The asymptotic bias and variance of the estimators are derived. An application to visually evoked brain potentials illustrates the approach.},
	number = {3},
	urldate = {2021-02-21},
	journal = {The Annals of Statistics},
	author = {Kneip, Alois and Gasser, Theo},
	year = {1992},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1266--1305},
}

@article{gasser_searching_1995,
	title = {Searching for {Structure} in {Curve} {Sample}},
	volume = {90},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2291510},
	doi = {10.2307/2291510},
	abstract = {The shape of a regression curve can to a large extent be characterized by the succession of structural features like extrema, inflection points, and so on. When analyzing a sample of regression curves, it is often important to know at an early stage of data analysis which structural features are occurring consistently in each curve of the sample. Such a definition is usually not easy due to substantial interindividual variation both in the x and the y axis and due to the influence of noise. A method is proposed for identifying typical features without relying on an a priori specified functional model for the curves. The approach is based on the frequencies of occurrence of structural features, as, for example, maxima in the curve sample along the x axis. Important tools are nonparametric regression and differentiation and kernel density estimation. Apart from a theoretical foundation, the usefulness of the method is documented by application to two interesting biomedical areas: growth and development, and neurophysiology.},
	number = {432},
	urldate = {2021-02-21},
	journal = {Journal of the American Statistical Association},
	author = {Gasser, Theo and Kneip, Alois},
	year = {1995},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1179--1188},
}

@article{wagner_nonparametric_2019,
	title = {Nonparametric registration to low-dimensional function spaces},
	volume = {138},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947319300714},
	doi = {10.1016/j.csda.2019.03.004},
	abstract = {Registration aims to decompose amplitude and phase variation of samples of curves. Phase variation is captured by warping functions which monotonically transform the domains. Resulting registered curves should then only exhibit amplitude variation. Most existing methods assume that all sample functions exhibit a typical sequence of shape features like peaks or valleys, and registration focuses on aligning these features. A more general perspective is adopted which goes beyond feature alignment. A registration method is introduced where warping functions are defined in such a way that the resulting registered curves span a low dimensional linear function space. The approach may be used as a tool for analyzing any type of functional data satisfying a structural regularity condition called bounded shape variation. Problems of identifiability are discussed in detail, and connections to established registration procedures are analyzed. The method is applied to real and simulated data.},
	language = {en},
	urldate = {2021-02-21},
	journal = {Computational Statistics \& Data Analysis},
	author = {Wagner, Heiko and Kneip, Alois},
	month = oct,
	year = {2019},
	keywords = {Amplitude variation, Dimension reduction, Functional data analysis, Functional principal components, Genes, Low dimensional linear function spaces, Phase variation, Registration, Time warping},
	pages = {49--63},
}

@article{zin_effectiveness_2020,
	title = {Effectiveness of {Landmark} and {Continuous} {Registrations} in {Reducing} {Inter}- and {Intrasubject} {Phase} {Variability}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3038494},
	abstract = {This study aimed to compare the effectiveness of applying landmark and continuous registrations in functional data analysis in reducing inter- and intrasubject phase variability of kinematic data, particularly lower extremity joint angles during the American kettlebell swing (AKS). Twenty healthy male subjects volunteered to perform the AKS test. Three different registration approaches; landmark registration, continuous registration used as an additional method to landmark registration, and continuous registration used as an alternative method to landmark registration were applied, and their effectiveness in aligning the curves was analyzed using functional permutation t-tests. All registration methods showed an improved mean curve than that of the method without registration. The root mean square error (RMSE) values between the mean unregistered curves and the individual unregistered curves were significantly higher than those of the landmark-registered curves (p {\textless}; 0.001) and the continuously registered curves (p {\textless}; 0.001). Continuous registration (as additional method) is the best registration method than landmark and continuous registrations (as alternative method), as it produced the highest mean percent decrease in the RMSE difference between the unregistered and continuously registered (as additional method) curves. Continuous registration (as additional method) appears to be the best method in reducing inter- and intrasubject phase variability than landmark and continuous registrations (as alternative method). Thus, it is recommended to implement continuous registration as an additional method to landmark registration prior to any AKS analysis. Both landmark and continuous registrations (as additional and alternative methods) enhance the likelihood of identifying significant differences between the right and left joint angles.},
	journal = {IEEE Access},
	author = {Zin, M. A. M. and Rambely, A. S. and Ariff, N. M.},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {AKS test, American kettlebell swing, Data analysis, Extremities, Kinematics, RMSE, Root mean square, biomechanics, continuous registration, data analysis, data reduction, functional data analysis, functional permutation t-tests, intersubject phase variability, intrasubject phase variability, kinematic data, kinematics, landmark registration, landmark-registered curves, mean square error methods, registration method, root mean square error, time-warping function},
	pages = {216003--216017},
}

@misc{tucker_fdasrvf_2020,
	title = {fdasrvf: {Elastic} {Functional} {Data} {Analysis}},
	copyright = {GPL-3},
	shorttitle = {fdasrvf},
	url = {https://CRAN.R-project.org/package=fdasrvf},
	abstract = {Performs alignment, PCA, and modeling of multidimensional and unidimensional functions using the square-root velocity framework (Srivastava et al., 2011 {\textless}arXiv:1103.3817{\textgreater} and Tucker et al., 2014 {\textless}doi:10.1016/j.csda.2012.12.001{\textgreater}). This framework allows for elastic analysis of functional data through phase and amplitude separation.},
	urldate = {2021-02-19},
	author = {Tucker, J. Derek},
	month = oct,
	year = {2020},
	keywords = {FunctionalData},
}

@article{craven_smoothing_1978,
	title = {Smoothing noisy data with spline functions},
	volume = {31},
	issn = {0945-3245},
	url = {https://doi.org/10.1007/BF01404567},
	doi = {10.1007/BF01404567},
	abstract = {Smoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline.},
	language = {en},
	number = {4},
	urldate = {2021-02-17},
	journal = {Numerische Mathematik},
	author = {Craven, Peter and Wahba, Grace},
	month = dec,
	year = {1978},
	pages = {377--403},
}

@article{hotelling_relations_1936,
	title = {{RELATIONS} {BETWEEN} {TWO} {SETS} {OF} {VARIATES}*},
	volume = {28},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/28.3-4.321},
	doi = {10.1093/biomet/28.3-4.321},
	number = {3-4},
	urldate = {2021-02-15},
	journal = {Biometrika},
	author = {HOTELLING, HAROLD},
	month = dec,
	year = {1936},
	pages = {321--377},
}

@book{morettin_wavelets_2017,
	series = {{SpringerBriefs} in {Mathematics}},
	title = {Wavelets in {Functional} {Data} {Analysis}},
	isbn = {978-3-319-59622-8},
	url = {https://www.springer.com/gp/book/9783319596228},
	abstract = {Wavelet-based procedures are key in many areas of statistics, applied mathematics, engineering, and science. This book presents wavelets in functional data analysis, offering a glimpse of problems in which they can be applied, including tumor analysis, functional magnetic resonance and meteorological data. Starting with the Haar wavelet, the authors explore myriad families of wavelets and how they can be used. High-dimensional data visualization (using Andrews' plots), wavelet shrinkage (a simple, yet powerful, procedure for nonparametric models) and a selection of estimation and testing techniques (including a discussion on Stein’s Paradox) make this a highly valuable resource for graduate students and experienced researchers alike.},
	language = {en},
	urldate = {2021-02-14},
	publisher = {Springer International Publishing},
	author = {Morettin, Pedro A. and Pinheiro, Aluísio and Vidakovic, Brani},
	year = {2017},
	doi = {10.1007/978-3-319-59623-5},
}

@article{pigoli_wavelets_2012,
	title = {Wavelets in functional data analysis: {Estimation} of multidimensional curves and their derivatives},
	volume = {56},
	issn = {0167-9473},
	shorttitle = {Wavelets in functional data analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947311004518},
	doi = {10.1016/j.csda.2011.12.016},
	abstract = {A wavelet-based method is proposed to obtain accurate estimates of curves in more than one dimension and of their derivatives. By means of simulation studies, this novel method is compared to another locally-adaptive estimation technique for multidimensional functional data, based on free-knot regression splines. This comparison shows that the proposed method is particularly attractive when the curves to be estimated present strongly localized features. The multidimensional wavelet estimation method is thus applied to multi-lead electrocardiogram records, where strongly localized features are indeed expected.},
	language = {en},
	number = {6},
	urldate = {2021-02-14},
	journal = {Computational Statistics \& Data Analysis},
	author = {Pigoli, Davide and Sangalli, Laura M.},
	month = jun,
	year = {2012},
	keywords = {Derivative estimation, Electrocardiograms, Multidimensional curve fitting},
	pages = {1482--1498},
}

@article{mckay_statistically_2012,
	title = {Statistically significant contrasts between {EMG} waveforms revealed using wavelet-based functional {ANOVA}},
	volume = {109},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.00447.2012},
	doi = {10.1152/jn.00447.2012},
	abstract = {We developed wavelet-based functional ANOVA (wfANOVA) as a novel approach for comparing neurophysiological signals that are functions of time. Temporal resolution is often sacrificed by analyzing such data in large time bins, increasing statistical power by reducing the number of comparisons. We performed ANOVA in the wavelet domain because differences between curves tend to be represented by a few temporally localized wavelets, which we transformed back to the time domain for visualization. We compared wfANOVA and ANOVA performed in the time domain (tANOVA) on both experimental electromyographic (EMG) signals from responses to perturbation during standing balance across changes in peak perturbation acceleration (3 levels) and velocity (4 levels) and on simulated data with known contrasts. In experimental EMG data, wfANOVA revealed the continuous shape and magnitude of significant differences over time without a priori selection of time bins. However, tANOVA revealed only the largest differences at discontinuous time points, resulting in features with later onsets and shorter durations than those identified using wfANOVA (P {\textless} 0.02). Furthermore, wfANOVA required significantly fewer (∼¼×; P {\textless} 0.015) significant F tests than tANOVA, resulting in post hoc tests with increased power. In simulated EMG data, wfANOVA identified known contrast curves with a high level of precision (r2 = 0.94 ± 0.08) and performed better than tANOVA across noise levels (P {\textless} {\textless}0.01). Therefore, wfANOVA may be useful for revealing differences in the shape and magnitude of neurophysiological signals (e.g., EMG, firing rates) across multiple conditions with both high temporal resolution and high statistical power.},
	number = {2},
	urldate = {2021-02-14},
	journal = {Journal of Neurophysiology},
	author = {McKay, J. Lucas and Welch, Torrence D. J. and Vidakovic, Brani and Ting, Lena H.},
	month = oct,
	year = {2012},
	note = {Publisher: American Physiological Society},
	pages = {591--602},
}

@book{ruppert_semiparametric_2003,
	address = {Cambridge},
	series = {Cambridge {Series} in {Statistical} and {Probabilistic} {Mathematics}},
	title = {Semiparametric {Regression}},
	isbn = {978-0-521-78050-6},
	url = {https://www.cambridge.org/core/books/semiparametric-regression/02FC9A9435232CA67532B4D31874412C},
	abstract = {Semiparametric regression is concerned with the flexible incorporation of non-linear functional relationships in regression analyses. Any application area that benefits from regression analysis can also benefit from semiparametric regression. Assuming only a basic familiarity with ordinary parametric regression, this user-friendly book explains the techniques and benefits of semiparametric regression in a concise and modular fashion. The authors make liberal use of graphics and examples plus case studies taken from environmental, financial, and other applications. They include practical advice on implementation and pointers to relevant software. The 2003 book is suitable as a textbook for students with little background in regression as well as a reference book for statistically oriented scientists such as biostatisticians, econometricians, quantitative social scientists, epidemiologists, with a good working knowledge of regression and the desire to begin using more flexible semiparametric models. Even experts on semiparametric regression should find something new here.},
	urldate = {2021-02-12},
	publisher = {Cambridge University Press},
	author = {Ruppert, David and Wand, M. P. and Carroll, R. J.},
	year = {2003},
	doi = {10.1017/CBO9780511755453},
}

@article{osullivan_statistical_1986,
	title = {A {Statistical} {Perspective} on {Ill}-{Posed} {Inverse} {Problems}},
	volume = {1},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/euclid.ss/1177013525},
	doi = {10.1214/ss/1177013525},
	abstract = {Ill-posed inverse problems arise in many branches of science and engineering. In the typical situation one is interested in recovering a whole function given a finite number of noisy measurements on functionals. Performance characteristics of an inversion algorithm are studied via the mean square error which is decomposed into bias and variability. Variability calculations are often straightforward, but useful bias measures are more difficult to obtain. An appropriate definition of what geophysicists call the Backus-Gilbert averaging kernel leads to a natural way of measuring bias characteristics. Moreover, the ideas give rise to some important experimental design criteria. It can be shown that the optimal inversion algorithms are methods of regularization procedures, but to completely specify these algorithms the signal to noise ratio must be supplied. Statistical approaches to the empirical determination of the signal to noise ratio are discussed; cross-validation and unbiased risk methods are reviewed; and some extensions, which seem particularly appropriate in the inverse problem context, are indicated. Linear and nonlinear examples from medicine, meteorology, and geophysics are used for illustration.},
	language = {EN},
	number = {4},
	urldate = {2021-02-12},
	journal = {Statistical Science},
	author = {O'Sullivan, Finbarr},
	month = nov,
	year = {1986},
	mrnumber = {MR874480},
	zmnumber = {0625.62110},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Averaging kernel, B-splines, cross-validation, experimental design, mean square error, reservoir engineering, satellite meteorology, stereology},
	pages = {502--518},
}

@article{eilers_flexible_1996,
	title = {Flexible smoothing with {B}-splines and penalties},
	volume = {11},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/euclid.ss/1038425655},
	doi = {10.1214/ss/1038425655},
	abstract = {B-splines are attractive for nonparametric modelling, but choosing the optimal number and positions of knots is a complex task. Equidistant knots can be used, but their small and discrete number allows only limited control over smoothness and fit. We propose to use a relatively large number of knots and a difference penalty on coefficients of adjacent B-splines. We show connections to the familiar spline penalty on the integral of the squared second derivative. A short overview of B-splines, of their construction and of penalized likelihood is presented. We discuss properties of penalized B-splines and propose various criteria for the choice of an optimal penalty parameter. Nonparametric logistic regression, density estimation and scatterplot smoothing are used as examples. Some details of the computations are presented.},
	language = {en},
	number = {2},
	urldate = {2021-02-11},
	journal = {Statistical Science},
	author = {Eilers, Paul H. C. and Marx, Brian D.},
	month = may,
	year = {1996},
	mrnumber = {MR1435485},
	zmnumber = {0955.62562},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Generalized linear models, density estimation, nonparametric models, smoothing, splines},
	pages = {89--121},
}

@book{hastie_elements_2009,
	address = {New York, NY},
	edition = {2nd ed. 2009, Corr. 9th printing 2017 edition},
	title = {The {Elements} of {Statistical} {Learning}},
	isbn = {978-0-387-84857-0},
	abstract = {This book describes the important ideas in a variety of fields such as medicine, biology, finance, and marketing in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of colour graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorisation, and spectral clustering. There is also a chapter on methods for "wide'' data (p bigger than n), including multiple testing and false discovery rates.},
	language = {English},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	month = oct,
	year = {2009},
}

@article{tucker_generative_2013,
	title = {Generative models for functional data using phase and amplitude separation},
	volume = {61},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947312004227},
	doi = {10.1016/j.csda.2012.12.001},
	abstract = {Constructing generative models for functional observations is an important task in statistical functional analysis. In general, functional data contains both phase (or x or horizontal) and amplitude (or y or vertical) variability. Traditional methods often ignore the phase variability and focus solely on the amplitude variation, using cross-sectional techniques such as fPCA for dimensional reduction and data modeling. Ignoring phase variability leads to a loss of structure in the data and inefficiency in data models. This paper presents an approach that relies on separating the phase (x-axis) and amplitude (y-axis), then modeling these components using joint distributions. This separation, in turn, is performed using a technique called elastic shape analysis of curves that involves a new mathematical representation of functional data. Then, using individual fPCAs, one each for phase and amplitude components, it imposes joint probability models on principal coefficients of these components while respecting the nonlinear geometry of the phase representation space. These ideas are demonstrated using random sampling, for models estimated from simulated and real datasets, and show their superiority over models that ignore phase-amplitude separation. Furthermore, the generative models are applied to classification of functional data and achieve high performance in applications involving SONAR signals of underwater objects, handwritten signatures, and periodic body movements recorded by smart phones.},
	language = {en},
	urldate = {2021-02-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {Tucker, J. Derek and Wu, Wei and Srivastava, Anuj},
	month = may,
	year = {2013},
	keywords = {Amplitude variability, Function alignment, Function principal component analysis, Functional data analysis, Generative model, Phase variability},
	pages = {50--66},
}

@article{ieva_multivariate_2013,
	title = {Multivariate functional clustering for the morphological analysis of electrocardiograph curves},
	volume = {62},
	copyright = {© 2012 Royal Statistical Society},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2012.01062.x},
	doi = {https://doi.org/10.1111/j.1467-9876.2012.01062.x},
	abstract = {Summary. Cardiovascular ischaemic diseases are one of the main causes of death all over the world. In this class of pathologies, a quick diagnosis is essential for a good prognosis in reperfusive treatment. In particular, an automatic classification procedure based on statistical analysis of teletransmitted electrocardiograph (‘ECG’) traces would be very helpful for an early diagnosis. This work presents an analysis of ECG traces, either physiological or pathological, of patients whose 12-lead prehospital ECG has been sent to the 118 Dispatch Center in Milan by life-support personnel. The statistical analysis starts with a preprocessing step, where functional data are reconstructed from noisy observations and biological variability is removed by a non-linear registration procedure. Then, a multivariate functional k-means clustering procedure is carried out on reconstructed and registered ECGs and their first derivatives. Hence, a new semi-automatic diagnostic procedure, based solely on the ECG morphology, is proposed to classify ECG traces; finally, the performance of this classification method is evaluated.},
	language = {en},
	number = {3},
	urldate = {2021-02-10},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Ieva, Francesca and Paganoni, Anna M. and Pigoli, Davide and Vitelli, Valeria},
	year = {2013},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9876.2012.01062.x},
	keywords = {Electrocardiograph signal, Functional k-means clustering, Functional registration, Wavelets smoothing},
	pages = {401--418},
}

@article{chiou_multivariate_2014,
	title = {{MULTIVARIATE} {FUNCTIONAL} {PRINCIPAL} {COMPONENT} {ANALYSIS}: {A} {NORMALIZATION} {APPROACH}},
	volume = {24},
	issn = {1017-0405},
	shorttitle = {{MULTIVARIATE} {FUNCTIONAL} {PRINCIPAL} {COMPONENT} {ANALYSIS}},
	url = {https://www.jstor.org/stable/24310959},
	abstract = {We propose an extended version of the classical Karhunen-Loève expansion of a multivariate random process, termed a normalized multivariate functional principal component (mFPCn) representation. This takes variations between the components of the process into account and takes advantage of component dependencies through the pairwise cross-covariance functions. This approach leads to a single set of multivariate functional principal component scores, which serve well as a proxy for multivariate functional data. We derive the consistency properties for the estimates of the mFPCn, and the asymptotic distributions for statistical inferences. We illustrate the finite sample performance of this approach through the analysis of a traffic flow data set, including an application to clustering and a simulation study. The mFPCn approach serves as a basic and useful statistical tool for multivariate functional data analysis.},
	number = {4},
	urldate = {2021-02-10},
	journal = {Statistica Sinica},
	author = {Chiou, Jeng-Min and Chen, Yu-Ting and Yang, Ya-Fang},
	year = {2014},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {1571--1596},
}

@article{gorecki_selected_2018,
	title = {Selected statistical methods of data analysis for multivariate functional data},
	volume = {59},
	issn = {1613-9798},
	url = {https://doi.org/10.1007/s00362-016-0757-8},
	doi = {10.1007/s00362-016-0757-8},
	abstract = {Data in the form of a continuous vector function on a given interval are referred to as multivariate functional data. These data are treated as realizations of multivariate random processes. The paper is devoted to three statistical dimension reduction techniques for multivariate data. For the first one, principal components analysis, the authors present a review of a recent paper (Jacques and Preda in, Comput Stat Data Anal, 71:92–106, 2014). For two others one, canonical variables and discriminant coordinates, the authors extend existing works for univariate functional data to multivariate. These methods for multivariate functional data are presented, illustrated and discussed in the context of analyzing real data sets. Each of these techniques is applied on real data set.},
	language = {en},
	number = {1},
	urldate = {2021-02-10},
	journal = {Statistical Papers},
	author = {Górecki, Tomasz and Krzyśko, Mirosław and Waszak, Łukasz and Wołyński, Waldemar},
	month = mar,
	year = {2018},
	pages = {153--182},
}

@article{happ_multivariate_2018,
	title = {Multivariate {Functional} {Principal} {Component} {Analysis} for {Data} {Observed} on {Different} ({Dimensional}) {Domains}},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2016.1273115},
	doi = {10.1080/01621459.2016.1273115},
	abstract = {Existing approaches for multivariate functional principal component analysis are restricted to data on the same one-dimensional interval. The presented approach focuses on multivariate functional data on different domains that may differ in dimension, such as functions and images. The theoretical basis for multivariate functional principal component analysis is given in terms of a Karhunen–Loève Theorem. For the practically relevant case of a finite Karhunen–Loève representation, a relationship between univariate and multivariate functional principal component analysis is established. This offers an estimation strategy to calculate multivariate functional principal components and scores based on their univariate counterparts. For the resulting estimators, asymptotic results are derived. The approach can be extended to finite univariate expansions in general, not necessarily orthonormal bases. It is also applicable for sparse functional data or data with measurement error. A flexible R implementation is available on CRAN. The new method is shown to be competitive to existing approaches for data observed on a common one-dimensional domain. The motivating application is a neuroimaging study, where the goal is to explore how longitudinal trajectories of a neuropsychological test score covary with FDG-PET brain scans at baseline. Supplementary material, including detailed proofs, additional simulation results, and software is available online.},
	number = {522},
	urldate = {2021-02-10},
	journal = {Journal of the American Statistical Association},
	author = {Happ, Clara and Greven, Sonja},
	month = apr,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2016.1273115},
	keywords = {Dimension reduction, Functional data analysis, Image analysis, Multivariate functional data},
	pages = {649--659},
}

@article{crainiceanu_bayesian_2010,
	title = {Bayesian {Functional} {Data} {Analysis} {Using} {WinBUGS}},
	volume = {32},
	copyright = {Copyright (c) 2009 Ciprian M. Crainiceanu, A. Jeffrey Goldsmith},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v032i11},
	doi = {10.18637/jss.v032.i11},
	language = {en},
	number = {1},
	urldate = {2021-02-10},
	journal = {Journal of Statistical Software},
	author = {Crainiceanu, Ciprian M. and Goldsmith, A. Jeffrey},
	month = jan,
	year = {2010},
	note = {Number: 1},
	pages = {1--33},
}

@article{harrison_applications_2014,
	title = {{APPLICATIONS} {OF} {FUNCTIONAL} {DATA} {ANALYSIS} {IN} {SPORT} {BIOMECHANICS}},
	copyright = {Copyright (c) 2015 ISBS - Conference Proceedings Archive},
	issn = {1999-4168},
	url = {https://ojs.ub.uni-konstanz.de/cpa/article/view/5905},
	abstract = {This paper reconsiders the challenge of analysing coordination in human movement with  particular emphasis on the application of Functional Data Analysis and Functional  Principal Component Analysis. The process of Functional Data Analysis is outlined using  examples from biomechanics of sports injuries and coordination in race-walking, jumping  and running. The evolution of the spring mass model used to describe jumping and  hopping behaviour is examined and it is proposed that this model represents a  coordination structure in human movement which may be appropriately analysed using  Functional Data Analysis methods.},
	language = {en},
	urldate = {2021-02-10},
	journal = {ISBS - Conference Proceedings Archive},
	author = {Harrison, Andrew J.},
	month = sep,
	year = {2014},
	keywords = {coordination variability, functional data analysis, functional principal components analysis, leg spring stiffness},
}

@misc{noauthor_nba_nodate,
	title = {{NBA} {Player} {Shooting} {Motions}: {A} {Data} {Dump}},
	shorttitle = {{NBA} {Player} {Shooting} {Motions}},
	url = {https://www.inpredictable.com/2021/01/nba-player-shooting-motions-data-dump.html},
	abstract = {Over 5 years ago, I published my first research on NBA motion tracking data . Where most analysis and research at that time (and still today...},
	urldate = {2021-02-09},
	journal = {inpredictable},
}

@misc{noauthor_biostatistics_nodate,
	title = {Biostatistics {Software} {Downloadable} or {Online}},
	url = {https://biostatistics.mdanderson.org/SoftwareDownload/SingleSoftware/Index/70},
	urldate = {2021-02-09},
}

@misc{noauthor_biostatistics_nodate-1,
	title = {Biostatistics {Software} {Downloadable} or {Online}},
	url = {https://biostatistics.mdanderson.org/SoftwareDownload/SingleSoftware/Index/70},
	urldate = {2021-02-09},
}

@misc{xie_xieyj17fdajl_2020,
	title = {xieyj17/{FDA}.jl},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/xieyj17/FDA.jl},
	abstract = {Julia implementation for functional data analysis. Contribute to xieyj17/FDA.jl development by creating an account on GitHub.},
	urldate = {2021-02-09},
	author = {Xie, Yijun},
	month = sep,
	year = {2020},
	note = {original-date: 2020-09-15T06:45:06Z},
}

@misc{tucker_jdtuckelasticfdajl_2020,
	title = {jdtuck/{ElasticFDA}.jl},
	copyright = {View license         ,                 View license},
	url = {https://github.com/jdtuck/ElasticFDA.jl},
	abstract = {Functional Data Analysis using Square-Root Slope Framework},
	urldate = {2021-02-09},
	author = {Tucker, Derek},
	month = oct,
	year = {2020},
	note = {original-date: 2015-02-09T03:30:32Z},
}

@misc{hein_lewisheinfdajl_2016,
	title = {{LewisHein}/{FDA}.jl},
	copyright = {View license         ,                 View license},
	url = {https://github.com/LewisHein/FDA.jl},
	abstract = {A package for functional data analysis in julia. Contribute to LewisHein/FDA.jl development by creating an account on GitHub.},
	urldate = {2021-02-09},
	author = {Hein, Lewis},
	month = feb,
	year = {2016},
	note = {original-date: 2016-02-14T19:26:12Z},
}

@article{perkel_julia_2019,
	title = {Julia: come for the syntax, stay for the speed},
	volume = {572},
	copyright = {2020 Nature},
	shorttitle = {Julia},
	url = {https://www.nature.com/articles/d41586-019-02310-3},
	doi = {10.1038/d41586-019-02310-3},
	abstract = {Researchers often find themselves coding algorithms in one programming language, only to have to rewrite them in a faster one. An up-and-coming language could be the answer.},
	language = {en},
	number = {7767},
	urldate = {2021-02-09},
	journal = {Nature},
	author = {Perkel, Jeffrey M.},
	month = jul,
	year = {2019},
	note = {Number: 7767
Publisher: Nature Publishing Group},
	pages = {141--142},
}

@misc{noauthor_scikit-fda_nodate,
	title = {scikit-fda: {Functional} {Data} {Analysis} {Python} package.},
	copyright = {BSD License},
	shorttitle = {scikit-fda},
	url = {https://fda.readthedocs.io},
	urldate = {2021-02-09},
	keywords = {Scientific/Engineering - Mathematics, Software Development - Libraries - Python Modules},
}

@misc{noauthor_gaa-uamscikit-fda_2021,
	title = {{GAA}-{UAM}/scikit-fda},
	copyright = {BSD-3-Clause License         ,                 BSD-3-Clause License},
	url = {https://github.com/GAA-UAM/scikit-fda},
	abstract = {Functional Data Analysis Python package. Contribute to GAA-UAM/scikit-fda development by creating an account on GitHub.},
	urldate = {2021-02-09},
	publisher = {Grupo de Aprendizaje Automático - Universidad Autónoma de Madrid},
	month = feb,
	year = {2021},
	note = {original-date: 2017-07-03T17:06:56Z},
	keywords = {functional-data-analysis, python, python3, statistics},
}

@misc{noauthor_representation_nodate,
	title = {Representation of functional {Data} — scikit-fda 0.5 documentation},
	url = {https://fda.readthedocs.io/en/latest/modules/representation.html},
	urldate = {2021-02-09},
}

@misc{wrobel_refundersrefundshiny_2020,
	title = {refunders/refund.shiny},
	url = {https://github.com/refunders/refund.shiny},
	abstract = {Interactive graphics for functional data analyses. Contribute to refunders/refund.shiny development by creating an account on GitHub.},
	urldate = {2021-02-08},
	publisher = {refund: regression for functional data in R},
	author = {Wrobel, Julia},
	month = dec,
	year = {2020},
	note = {original-date: 2015-08-10T21:35:03Z},
}

@article{bland_statistical_1986,
	title = {Statistical methods for assessing agreement between two methods of clinical measurement},
	volume = {1},
	issn = {0140-6736},
	abstract = {In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old. Such investigations are often analysed inappropriately, notably by using correlation coefficients. The use of correlation is misleading. An alternative approach, based on graphical techniques and simple calculations, is described, together with the relation between this analysis and the assessment of repeatability.},
	language = {eng},
	number = {8476},
	journal = {Lancet (London, England)},
	author = {Bland, J. M. and Altman, D. G.},
	month = feb,
	year = {1986},
	pmid = {2868172},
	keywords = {Diagnosis, Humans, Peak Expiratory Flow Rate, Statistics as Topic},
	pages = {307--310},
}

@misc{greven_denseflmm_2018,
	title = {{denseFLMM}: {Functional} {Linear} {Mixed} {Models} for {Densely} {Sampled} {Data}},
	copyright = {GPL-2},
	shorttitle = {{denseFLMM}},
	url = {https://CRAN.R-project.org/package=denseFLMM},
	abstract = {Estimation of functional linear mixed models for densely sampled data based on functional principal component analysis.},
	urldate = {2021-02-09},
	author = {Greven, Sonja and Cederbaum, Jona},
	month = apr,
	year = {2018},
	keywords = {FunctionalData},
}

@misc{cederbaum_sparseflmm_2021,
	title = {{sparseFLMM}: {Functional} {Linear} {Mixed} {Models} for {Irregularly} or {Sparsely} {Sampled} {Data}},
	copyright = {GPL-2},
	shorttitle = {{sparseFLMM}},
	url = {https://CRAN.R-project.org/package=sparseFLMM},
	abstract = {Estimation of functional linear mixed models for irregularly or sparsely sampled data based on functional principal component analysis.},
	urldate = {2021-02-09},
	author = {Cederbaum, Jona and Volkmann, Alexander and Stöcker, Almond},
	month = jan,
	year = {2021},
	keywords = {FunctionalData},
}

@article{pini_testretest_2019,
	title = {Test–retest reliability measures for curve data: an overview with recommendations and supplementary code},
	volume = {0},
	issn = {1476-3141},
	shorttitle = {Test–retest reliability measures for curve data},
	url = {https://doi.org/10.1080/14763141.2019.1655089},
	doi = {10.1080/14763141.2019.1655089},
	abstract = {The purpose of this paper is to provide an overview of available methods for reliability investigations when the outcome of interest is a curve. Curve data, or functional data, is commonly collected in biomechanical research in order to better understand different aspects of human movement. Using recent statistical developments, curve data can be analysed in its most detailed form, as functions. However, an overview of appropriate statistical methods for assessing reliability of curve data is lacking. A review of contemporary literature of reliability measures for curve data within the fields of biomechanics and statistics identified the following methods: coefficient of multiple correlation, functional limits of agreement, measures of distance and similarity, and integrated pointwise indices (an extension of univariate reliability measures to curve data, inclusive of Pearson correlation, intraclass correlation, and standard error of measurement). These methods are briefly presented, implemented (R-code available as supplementary material) and evaluated on simulated data to highlight advantages and disadvantages of the methods. Among the identified methods, the integrated intraclass correlation and standard error of measurement are recommended. These methods are straightforward to implement, enable results over the domain, and consider variation between individuals, which the other methods partly neglect.},
	number = {0},
	urldate = {2021-02-09},
	journal = {Sports Biomechanics},
	author = {Pini, Alessia and Markström, Jonas L. and Schelin, Lina},
	month = oct,
	year = {2019},
	pmid = {31578129},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2019.1655089},
	keywords = {Agreement, functional data, kinematics, similarity},
	pages = {1--22},
}

@book{jolliffe_principal_1986,
	address = {New York},
	series = {Springer {Series} in {Statistics}},
	title = {Principal {Component} {Analysis}},
	isbn = {978-1-4757-1904-8},
	url = {https://www.springer.com/gp/book/9781475719048},
	abstract = {Principal component analysis is probably the oldest and best known of the It was first introduced by Pearson (1901), techniques ofmultivariate analysis. and developed independently by Hotelling (1933). Like many multivariate methods, it was not widely used until the advent of electronic computers, but it is now weIl entrenched in virtually every statistical computer package. The central idea of principal component analysis is to reduce the dimen­ sionality of a data set in which there are a large number of interrelated variables, while retaining as much as possible of the variation present in the data set. This reduction is achieved by transforming to a new set of variables, the principal components, which are uncorrelated, and which are ordered so that the first few retain most of the variation present in all of the original variables. Computation of the principal components reduces to the solution of an eigenvalue-eigenvector problem for a positive-semidefinite symmetrie matrix. Thus, the definition and computation of principal components are straightforward but, as will be seen, this apparently simple technique has a wide variety of different applications, as weIl as a number of different deri­ vations. Any feelings that principal component analysis is a narrow subject should soon be dispelled by the present book; indeed some quite broad topics which are related to principal component analysis receive no more than a brief mention in the final two chapters.},
	language = {en},
	urldate = {2021-02-08},
	publisher = {Springer-Verlag},
	author = {Jolliffe, I. T.},
	year = {1986},
	doi = {10.1007/978-1-4757-1904-8},
}

@article{halilaj_machine_2018,
	title = {Machine learning in human movement biomechanics: {Best} practices, common pitfalls, and new opportunities},
	volume = {81},
	issn = {0021-9290},
	shorttitle = {Machine learning in human movement biomechanics},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929018307309},
	doi = {10.1016/j.jbiomech.2018.09.009},
	abstract = {Traditional laboratory experiments, rehabilitation clinics, and wearable sensors offer biomechanists a wealth of data on healthy and pathological movement. To harness the power of these data and make research more efficient, modern machine learning techniques are starting to complement traditional statistical tools. This survey summarizes the current usage of machine learning methods in human movement biomechanics and highlights best practices that will enable critical evaluation of the literature. We carried out a PubMed/Medline database search for original research articles that used machine learning to study movement biomechanics in patients with musculoskeletal and neuromuscular diseases. Most studies that met our inclusion criteria focused on classifying pathological movement, predicting risk of developing a disease, estimating the effect of an intervention, or automatically recognizing activities to facilitate out-of-clinic patient monitoring. We found that research studies build and evaluate models inconsistently, which motivated our discussion of best practices. We provide recommendations for training and evaluating machine learning models and discuss the potential of several underutilized approaches, such as deep learning, to generate new knowledge about human movement. We believe that cross-training biomechanists in data science and a cultural shift toward sharing of data and tools are essential to maximize the impact of biomechanics research.},
	language = {en},
	urldate = {2021-02-08},
	journal = {Journal of Biomechanics},
	author = {Halilaj, Eni and Rajagopal, Apoorva and Fiterau, Madalina and Hicks, Jennifer L. and Hastie, Trevor J. and Delp, Scott L.},
	month = nov,
	year = {2018},
	keywords = {Data science, Machine learning, Musculoskeletal, Neuromuscular},
	pages = {1--11},
}

@article{wrobel_interactive_2016,
	title = {Interactive graphics for functional data analyses},
	url = {http://arxiv.org/abs/1602.04091},
	abstract = {Although there are established graphics that accompany the most common functional data analyses, generating these graphics for each dataset and analysis can be cumbersome and time consuming. Often, the barriers to visualization inhibit useful exploratory data analyses and prevent the development of intuition for a method and its application to a particular dataset. The refund.shiny package was developed to address these issues for several of the most common functional data analyses. After conducting an analysis, the plot\_shiny() function is used to generate an interactive visualization environment that contains several distinct graphics, many of which are updated in response to user input. These visualizations reduce the burden of exploratory analyses and can serve as a useful tool for the communication of results to non-statisticians.},
	urldate = {2021-02-08},
	journal = {arXiv:1602.04091 [stat]},
	author = {Wrobel, Julia and Park, So Young and Staicu, Ana Maria and Goldsmith, Jeff},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.04091},
	keywords = {Statistics - Other Statistics},
}

@misc{noauthor_cran_nodate,
	title = {{CRAN} - {Package} refund.shiny},
	url = {https://cran.r-project.org/web/packages/refund.shiny/index.html},
	urldate = {2021-02-08},
}

@misc{pini_fdatest_2015,
	title = {fdatest: {Interval} {Testing} {Procedure} for {Functional} {Data}},
	copyright = {GPL-2},
	shorttitle = {fdatest},
	url = {https://CRAN.R-project.org/package=fdatest},
	abstract = {Implementation of the Interval Testing Procedure for functional data in different frameworks (i.e., one or two-population frameworks, functional linear models) by means of different basis expansions (i.e., B-spline, Fourier, and phase-amplitude Fourier). The current version of the package requires functional data evaluated on a uniform grid; it automatically projects each function on a chosen functional basis; it performs the entire family of multivariate tests; and, finally, it provides the matrix of the p-values of the previous tests and the vector of the corrected p-values. The functional basis, the coupled or uncoupled scenario, and the kind of test can be chosen by the user. The package provides also a plotting function creating a graphical output of the procedure: the p-value heat-map, the plot of the corrected p-values, and the plot of the functional data.},
	urldate = {2021-02-08},
	author = {Pini, Alessia and Vantini, Simone},
	month = feb,
	year = {2015},
	keywords = {FunctionalData},
}

@article{scheipl_cran_2020,
	title = {{CRAN} {Task} {View}: {Functional} {Data} {Analysis}},
	shorttitle = {{CRAN} {Task} {View}},
	url = {https://CRAN.R-project.org/view=FunctionalData},
	urldate = {2021-02-08},
	author = {Scheipl, Fabian},
	month = sep,
	year = {2020},
}

@article{zhang_hamstring_2020,
	title = {Hamstring muscle-tendon unit lengthening and activation in instep and cut-off kicking},
	volume = {99},
	issn = {1873-2380},
	doi = {10.1016/j.jbiomech.2019.109482},
	abstract = {Hamstring muscle strain injury is one of the most common injuries in sports involving sprinting and kicking. Studies examining hamstring kinematics and activations are rich for sprinting but lacking for kicking. The purpose of this study was to examine kinematics and activations of hamstring muscles in instep and cut-off kicking tasks frequently performed in soccer. Videographic and electromyographic (EMG) data were collected for 11 male soccer-majored college students performing the two kicking tasks. Peak hamstring muscle-tendon unit lengths, elongation velocities, and maximum linear envelop EMG data were identified and compared among hamstring muscles and between kicking tasks. Hamstring muscles exhibited activated elongations before and after the contact of the kicking foot with the ball. The muscle-tendon unit lengths peaked in the follow-through phase. The peak elongation velocity of the semimembranosus was significantly greater than that of the semitendinosus and biceps femoris (p = 0.001). The maximum linear envelop EMG of the biceps femoris was significantly greater than that of the semimembranosus (p = 0.026). The potential for hamstring injury exists in the follow-through phase of each kicking task. The increased hamstring muscle-tendon unit elongation velocities in kicking tasks may explain the more severe hamstring injuries in kicking compared to sprinting.},
	language = {eng},
	journal = {Journal of Biomechanics},
	author = {Zhang, Liwen and Li, Hanjun and Garrett, William E. and Liu, Hui and Yu, Bing},
	month = jan,
	year = {2020},
	pmid = {31733820},
	keywords = {Adult, Biomechanical Phenomena, Hamstring Muscles, Hamstring Tendons, Hamstring injury, Humans, Injury mechanism, Kicking, Male, Mechanical Phenomena, Movement, Muscle strain injury, Risk factors, Soccer, Young Adult},
	pages = {109482},
}

@article{yu_hamstring_2008,
	title = {Hamstring muscle kinematics and activation during overground sprinting},
	volume = {41},
	issn = {0021-9290},
	doi = {10.1016/j.jbiomech.2008.09.005},
	abstract = {Hamstring muscle strain injury is one of the most commonly seen injuries in sports such as track and field, soccer, football, and rugby. The purpose of this study was to advance our understanding of the mechanisms of hamstring muscle strain injuries during over ground sprinting by investigating hamstring muscle-tendon kinematics and muscle activation. Three-dimensional videographic and electromyographic (EMG) data were collected for 20 male runners, soccer or lacrosse players performing overground sprinting at their maximum effort. Hamstring muscle-tendon lengths, elongation velocities, and linear envelop EMG data were analyzed for a running gait cycle of the dominant leg. Hamstring muscles exhibited eccentric contractions during the late stance phase as well as during the late swing phase of overground sprinting. The peak eccentric contraction speeds of the hamstring muscles were significantly greater during the late swing phase than during the late stance phase (p=0.001) while the hamstring muscle-tendon lengths at the peak eccentric contraction speeds were significantly greater during the late stance phase than during the late swing phase (p=0.001). No significant differences existed in the maximum hamstring muscle-tendon lengths between the two eccentric contractions. The potential for hamstring muscle strain injury exists during the late stance phase as well as during the late swing phases of overground sprinting.},
	language = {eng},
	number = {15},
	journal = {Journal of Biomechanics},
	author = {Yu, Bing and Queen, Robin M. and Abbey, Alicia N. and Liu, Yu and Moorman, Claude T. and Garrett, William E.},
	month = nov,
	year = {2008},
	pmid = {18848700},
	keywords = {Humans, Knee Joint, Male, Muscle Contraction, Muscle, Skeletal, Range of Motion, Articular, Running, Sports, Stress, Mechanical, Young Adult},
	pages = {3121--3126},
}

@article{wu_isb_2002,
	title = {{ISB} recommendation on definitions of joint coordinate system of various joints for the reporting of human joint motion--part {I}: ankle, hip, and spine. {International} {Society} of {Biomechanics}},
	volume = {35},
	issn = {0021-9290},
	shorttitle = {{ISB} recommendation on definitions of joint coordinate system of various joints for the reporting of human joint motion--part {I}},
	doi = {10.1016/s0021-9290(01)00222-6},
	abstract = {The Standardization and Terminology Committee (STC) of the International Society of Biomechanics (ISB) proposes a general reporting standard for joint kinematics based on the Joint Coordinate System (JCS), first proposed by Grood and Suntay for the knee joint in 1983 (J. Biomech. Eng. 105 (1983) 136). There is currently a lack of standard for reporting joint motion in the field of biomechanics for human movement, and the JCS as proposed by Grood and Suntay has the advantage of reporting joint motions in clinically relevant terms. In this communication, the STC proposes definitions of JCS for the ankle, hip, and spine. Definitions for other joints (such as shoulder, elbow, hand and wrist, temporomandibular joint (TMJ), and whole body) will be reported in later parts of the series. The STC is publishing these recommendations so as to encourage their use, to stimulate feedback and discussion, and to facilitate further revisions. For each joint, a standard for the local axis system in each articulating bone is generated. These axes then standardize the JCS. Adopting these standards will lead to better communication among researchers and clinicians.},
	language = {eng},
	number = {4},
	journal = {Journal of Biomechanics},
	author = {Wu, Ge and Siegler, Sorin and Allard, Paul and Kirtley, Chris and Leardini, Alberto and Rosenbaum, Dieter and Whittle, Mike and D'Lima, Darryl D. and Cristofolini, Luca and Witte, Hartmut and Schmid, Oskar and Stokes, Ian and {Standardization and Terminology Committee of the International Society of Biomechanics}},
	month = apr,
	year = {2002},
	pmid = {11934426},
	keywords = {Biomechanical Phenomena, Humans, International Cooperation, Joints, Movement, Reference Standards},
	pages = {543--548},
}

@article{woods_football_2004,
	title = {The {Football} {Association} {Medical} {Research} {Programme}: an audit of injuries in professional football—analysis of hamstring injuries},
	volume = {38},
	copyright = {Copyright 2004 British Journal of Sports Medicine},
	issn = {0306-3674, 1473-0480},
	shorttitle = {The {Football} {Association} {Medical} {Research} {Programme}},
	url = {https://bjsm.bmj.com/content/38/1/36},
	doi = {10.1136/bjsm.2002.002352},
	abstract = {Objective: To conduct a detailed analysis of hamstring injuries sustained in English professional football over two competitive seasons.
Methods: Club medical staff at 91 professional football clubs annotated player injuries over two seasons. A specific injury audit questionnaire was used together with a weekly form that documented each clubs’ current injury status.
Results: Completed injury records for the two competitive seasons were obtained from 87\% and 76\% of the participating clubs respectively. Hamstring strains accounted for 12\% of the total injuries over the two seasons with nearly half (53\%) involving the biceps femoris. An average of five hamstring strains per club per season was observed. A total of 13 116 days and 2029 matches were missed because of hamstring strains, giving an average of 90 days and 15 matches missed per club per season. In 57\% of cases, the injury occurred during running. Hamstring strains were most often observed during matches (62\%) with an increase at the end of each half (p{\textless}0.01). Groups of players sustaining higher than expected rates of hamstring injury were Premiership (p{\textless}0.01) and outfield players (p{\textless}0.01), players of black ethnic origin (p{\textless}0.05), and players in the older age groups (p{\textless}0.01). Only 5\% of hamstring strains underwent some form of diagnostic investigation. The reinjury rate for hamstring injury was 12\%.
Conclusion: Hamstring strains are common in football. In trying to reduce the number of initial and recurrent hamstring strains in football, prevention of initial injury is paramount. If injury does occur, the importance of differential diagnosis followed by the management of all causes of posterior thigh pain is emphasised. Clinical reasoning with treatment based on best available evidence is recommended.},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {British Journal of Sports Medicine},
	author = {Woods, C. and Hawkins, R. D. and Maltby, S. and Hulse, M. and Thomas, A. and Hodson, A.},
	month = feb,
	year = {2004},
	pmid = {14751943},
	note = {Publisher: British Association of Sport and Excercise Medicine
Section: Original article},
	keywords = {CT, computed tomography, MRI, magnetic resonance imaging, football, hamstring, injury},
	pages = {36--41},
}

@article{wilson_coordination_2008,
	title = {Coordination variability and skill development in expert triple jumpers},
	volume = {7},
	issn = {1476-3141},
	doi = {10.1080/14763140701682983},
	abstract = {The aim of this study was to examine the influence of skill of expert triple jumpers on the coordination variability of lower extremity intra-limb couplings. In contrast to the traditional motor learning perspective, we hypothesized that as skill and thus performance increases, movement coordination variability will also increase. Three-dimensional kinematic and ground reaction force data were collected during the hop-step transition phase of the triple jump. Relative motion plots and a modified vector coding technique were used to quantify the coordination variability across the trials. The results were consistent with a U-shaped curve, representing coordination variability, as skill increases. The high coordination variability in less skilled athletes is present while the appropriate characteristics defining the movement coordination patterns are acquired. This coordination variability may not be beneficial to performance. As the refinement of these characteristics is achieved, coordination variability decreases, resulting in a more consistent or regulated performance. In the final stages of developing a skilled performance, a functional variability is accessed that brings flexibility to the system allowing it to cope with perturbations. This study highlights the need to address the learning effect when analysing coordination variability from a dynamical systems perspective.},
	language = {eng},
	number = {1},
	journal = {Sports Biomechanics},
	author = {Wilson, Cassie and Simpson, Scott E. and van Emmerik, Richard E. A. and Hamill, Joseph},
	month = jan,
	year = {2008},
	pmid = {18341132},
	keywords = {Adult, Ankle Joint, Biomechanical Phenomena, Cohort Studies, Female, Humans, Image Processing, Computer-Assisted, Knee Joint, Male, Motor Skills, Pilot Projects, Postural Balance, Range of Motion, Articular, Task Performance and Analysis, Track and Field, Video Recording},
	pages = {2--9},
}

@book{wickham_ggplot2_2009,
	address = {New York},
	series = {Use {R}!},
	title = {ggplot2: {Elegant} {Graphics} for {Data} {Analysis}},
	isbn = {978-0-387-98141-3},
	shorttitle = {ggplot2},
	url = {https://www.springer.com/gp/book/9780387981413},
	abstract = {This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkison's Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, it's easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and you'll learn everything you need in the book. After reading this book you'll be able to produce graphics customized precisely for your problems, and you'll find it easy to get graphics out of your head and on to the screen or page. Hadley Wickham is an Assistant Professor of Statistics at Rice University, and is interested in developing computational and cognitive tools for making data preparation, visualization, and analysis easier. He has developed 15 R packages and in 2006 he won the John Chambers Award for Statistical Computing for his work on the ggplot and reshape R packages.},
	language = {en},
	urldate = {2020-12-21},
	publisher = {Springer-Verlag},
	author = {Wickham, Hadley},
	year = {2009},
	doi = {10.1007/978-0-387-98141-3},
}

@article{thelen_hamstring_2005,
	title = {Hamstring muscle kinematics during treadmill sprinting},
	volume = {37},
	issn = {0195-9131},
	doi = {10.1249/01.mss.0000150078.79120.c8},
	abstract = {INTRODUCTION/PURPOSE: The objective of this study was to characterize hamstring muscle kinematics during sprinting, so as to provide scientific data to better understand injury mechanisms and differences in injury rates between muscles.
METHODS: We conducted three-dimensional motion analyses of 14 athletes performing treadmill sprinting at speeds ranging from 80 to 100\% of maximum. Scaled musculoskeletal models were used to estimate hamstring muscle-tendon lengths throughout the sprinting gait cycle for each speed. We tested the hypothesis that the biceps femoris (BF) long head would be stretched a greater amount, relative to its length in an upright posture, than the semitendinosus (ST) and semimembranosus (SM). We also tested the hypothesis that increasing from submaximal to maximal sprinting speed would both increase the magnitude and delay the occurrence of peak muscle-tendon length in the gait cycle.
RESULTS: Maximum hamstring lengths occurred during the late swing phase of sprinting and were an average of 7.4\% (SM), 8.1\% (ST), and 9.5\% (BF) greater than the respective muscle-tendon lengths in an upright configuration. Peak lengths were significantly larger in the BF than the ST and SM (P {\textless} 0.01), occurred significantly later in the gait cycle at the maximal speed (P {\textless} 0.01), but did not increase significantly with speed. Differences in the hip extension and knee flexion moment arms between the biarticular hamstrings account for the intermuscle variations in the peak lengths that were estimated.
CONCLUSIONS: We conclude that intermuscle differences in hamstring moment arms about the hip and knee may be a factor contributing to the greater propensity for hamstring strain injuries to occur in the BF muscle.},
	language = {eng},
	number = {1},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Thelen, Darryl G. and Chumanov, Elizabeth S. and Hoerth, Dina M. and Best, Thomas M. and Swanson, Stephen C. and Li, Li and Young, Michael and Heiderscheit, Bryan C.},
	month = jan,
	year = {2005},
	pmid = {15632676},
	keywords = {Adolescent, Adult, Athletic Injuries, Biomechanical Phenomena, Exercise Test, Female, Humans, Knee, Lower Extremity, Male, Models, Biological, Motion, Muscle, Skeletal, Risk Factors},
	pages = {108--114},
}

@article{sugi_contribution_2019,
	title = {Contribution of lower body segment rotations in various height soccer volley kicking},
	issn = {1752-6116},
	doi = {10.1080/14763141.2019.1667422},
	abstract = {We aimed to quantify the contribution of lower body segment rotations in producing foot velocity during the soccer volley kick. Fifteen male experienced university players kicked a soccer ball placed at four height conditions (0, 25, 50 and 75 cm). Their kicking motion was captured at 500 Hz. The effectiveness of lower body segment rotations in producing forward (Ffv) and upward (Fuv) foot velocity were computed and time integrated. Major contributors for Ffv were a) left hip linear velocity, b) knee extension and c) pelvis retroflexion (the pitch rotation). The contribution of a) become smaller as the ball height increased while those of b) and c) did not change significantly. Moreover, the pelvis clockwise rotation (the yaw rotation) showed apparent contribution only for volley kicking (except 0 cm height). Major contributors for Fuv were 1) knee flexion, 2) hip internal rotation, 3) pelvis clockwise rotation (the roll rotation) and 4) hip flexion. The contributions of 1) and 4) become consistently smaller as the ball height increased, while those of 2) and 3) become larger systematically. Soccer volley kicking was found to have unique adaptations of segmental contributions to achieve higher foot position while maintain foot forward velocity.},
	language = {eng},
	journal = {Sports Biomechanics},
	author = {Sugi, Shusei and Nunome, Hiroyuki and Tamura, Yuji and Iga, Takahito and Lake, Mark},
	month = nov,
	year = {2019},
	pmid = {31762385},
	keywords = {Word, coaching cues, foot centre of mass velocity, joint angular motion, kicking leg},
	pages = {1--16},
}

@article{sterzing_influence_2008,
	title = {The {Influence} of {Soccer} {Shoes} on {Kicking} {Velocity} in {Full}-{Instep} {Kicks}},
	volume = {36},
	issn = {0091-6331},
	url = {https://journals.lww.com/acsm-essr/fulltext/2008/04000/The_Influence_of_Soccer_Shoes_on_Kicking_Velocity.8.aspx},
	doi = {10.1097/JES.0b013e318168ece7},
	abstract = {Soccer shoes enhance the traction required by the stance leg but decrease the quality of the ball contact during full-instep kicking. Shoe features that influence ball velocity include traction, foot protection, foot rigidity, and toe box height. Upper material and general comfort potentially affect ball velocity. In contrast, shoe weight and outsole stiffness do not influence ball velocity.},
	language = {en-US},
	number = {2},
	urldate = {2020-12-21},
	journal = {Exercise and Sport Sciences Reviews},
	author = {Sterzing, Thorsten and Hennig, Ewald M.},
	month = apr,
	year = {2008},
	pages = {91--97},
}

@article{seifert_inter-individual_2011,
	title = {Inter-individual variability in the upper-lower limb breaststroke coordination},
	volume = {30},
	issn = {1872-7646},
	doi = {10.1016/j.humov.2010.12.003},
	abstract = {The aim of the present study was to examine inter-individual variability in upper-lower limb breaststroke coordination. First, inter-individual variability was compared between recreational and comparative swimmers. Second, as recreational swimmers revealed more variable inter-limb coordination than competitive swimmers, inter-individual variability was assessed among recreational swimmers to identify coordination profiles. The elbow-knee continuous relative phase (CRP) was used to analyze upper-lower limbs coupling during a breaststroke cycle. Twenty-four recreational and twenty-four competitive swimmers swam 25 m at 80\% of their maximal speed. Underwater and aerial side views were mixed and genlocked. Angular position, velocity and CRP were calculated for the knee and elbow joints by digitizing body markers from the side view. The kinematics of three cycles were filtered, averaged and normalized in terms of percentage of total cycle duration. The topography of the mean CRP curve of the recreational swimmers resembled a 'W-shape', whereas an 'inverse U-shape' was seen in the competitive swimmers. However, higher inter-individual variability was observed among the recreational swimmers than among the competitive swimmers (38.1° vs. 19.4°; p{\textless}.05), suggesting that several profiles of inter-limb coordination may exist in recreational swimmers. Coordination profiling showed that three clusters could classify the recreational swimmers.},
	language = {eng},
	number = {3},
	journal = {Human Movement Science},
	author = {Seifert, L. and Leblanc, H. and Herault, R. and Komar, J. and Button, C. and Chollet, D.},
	month = jun,
	year = {2011},
	pmid = {21439666},
	keywords = {Adolescent, Athletic Performance, Competitive Behavior, Female, Humans, Individuality, Male, Psychomotor Performance, Reaction Time, Recreation, Swimming},
	pages = {550--565},
}

@article{seifert_coordination_2014,
	title = {Coordination pattern variability provides functional adaptations to constraints in swimming performance},
	volume = {44},
	issn = {1179-2035},
	doi = {10.1007/s40279-014-0210-x},
	abstract = {In a biophysical approach to the study of swimming performance (blending biomechanics and bioenergetics), inter-limb coordination is typically considered and analysed to improve propulsion and propelling efficiency. In this approach, 'opposition' or 'continuous' patterns of inter-limb coordination, where continuity between propulsive actions occurs, are promoted in the acquisition of expertise. Indeed a 'continuous' pattern theoretically minimizes intra-cyclic speed variations of the centre of mass. Consequently, it may also minimize the energy cost of locomotion. However, in skilled swimming performance there is a need to strike a delicate balance between inter-limb coordination pattern stability and variability, suggesting the absence of an 'ideal' pattern of coordination toward which all swimmers must converge or seek to imitate. Instead, an ecological dynamics framework advocates that there is an intertwined relationship between the specific intentions, perceptions and actions of individual swimmers, which constrains this relationship between coordination pattern stability and variability. This perspective explains how behaviours emerge from a set of interacting constraints, which each swimmer has to satisfy in order to achieve specific task performance goals and produce particular task outcomes. This overview updates understanding on inter-limb coordination in swimming to analyse the relationship between coordination variability and stability in relation to interacting constraints (related to task, environment and organism) that swimmers may encounter during training and performance.},
	language = {eng},
	number = {10},
	journal = {Sports Medicine (Auckland, N.Z.)},
	author = {Seifert, Ludovic and Komar, John and Barbosa, Tiago and Toussaint, Huub and Millet, Grégoire and Davids, Keith},
	month = oct,
	year = {2014},
	pmid = {24895244},
	keywords = {Arm, Athletic Performance, Biomechanical Phenomena, Humans, Leg, Motor Skills, Physical Education and Training, Swimming},
	pages = {1333--1345},
}

@book{allard_three-dimensional_1995,
	address = {Champaign, IL},
	title = {Three-dimensional analysis of human movement},
	isbn = {978-0-87322-623-3},
	abstract = {Researchers, graduate students, and practitioners alike will benefit from this state-of-the-art reference. It's the first book to explain in a single volume the essential components of three-dimensional analysis of human movement. Readers will gain a fundamental understanding of methods and technology used to capture, reconstruct, and process 3-D data; concepts and techniques of mechanical and neuromuscular modeling, including robotics; and the application of 3-D analysis. The editors have brought together contributions from international experts to create a technical manual that demonstrates the possibilities and potential pitfalls of 3-D analysis of human movement. More than 140 tables, diagrams, and photos throughout the book illustrate essential content.},
	language = {English},
	publisher = {Human Kinetics},
	editor = {Allard, Paul and Stokes, Ian A. F and Blanchi, Jean-Pierre},
	year = {1995},
	note = {OCLC: 28928515},
}

@incollection{newell_coordination_1985,
	series = {Differing {Perspectives} {In} {Motor} {Learning}, {Memory}, {And} {Control}},
	title = {Coordination, {Control} and {Skill}},
	volume = {27},
	url = {http://www.sciencedirect.com/science/article/pii/S0166411508625418},
	abstract = {In this chapter, I develop the interpretation of coordination, control and skill sketched by Kugler, Kelso and Turvey (1980, 1982). The orientation promoted here is primarily descriptive with the focus being the development of a framework for a useful operational distinction between the three terms. 1 believe one can draw on the interpretation of coordination, control and skill outlined by Kugler and colleagues without necessarily invoking the theoretical position advanced by this group, although it will become clear as this chapter unfolds, that I am sympathetic to this theoretical position.},
	language = {en},
	urldate = {2020-12-21},
	booktitle = {Advances in {Psychology}},
	publisher = {North-Holland},
	author = {Newell, K. M.},
	editor = {Goodman, David and Wilberg, Robert B. and Franks, Ian M.},
	month = jan,
	year = {1985},
	doi = {10.1016/S0166-4115(08)62541-8},
	pages = {295--317},
}

@article{mazurek_differences_2020,
	title = {Differences in inter-segment coordination between high- and low-calibre ice hockey players during forward skating},
	volume = {0},
	issn = {1476-3141},
	url = {https://doi.org/10.1080/14763141.2020.1797151},
	doi = {10.1080/14763141.2020.1797151},
	abstract = {The objective was to compare lower extremity inter-segment coordination between high-calibre and low-calibre ice hockey players during forward full stride skating. A 10-camera Vicon motion capture system collected kinematic data on male high-calibre (n = 8) and low-calibre (n = 8) participants. Continuous relative phase (CRP) was calculated for shank-sagittal/thigh-sagittal, shank-sagittal/thigh-frontal and foot-sagittal/shank-sagittal segment pairs. Principal component analysis (PCA) was used to extract features of greatest variability of the CRP and hierarchical linear model investigated relationships between principal components and skill level. High-calibre players demonstrated more out-of-phase coordination (higher CRP) of shank-sagittal/thigh-sagittal throughout glide/push-off (p = 0.011) as well as a delay in the transition to more in-phase coordination during early recovery phase (p = 0.014). For shank-sagittal/thigh-frontal (p = 0.013), high-calibre players had more out-of-phase coordination throughout the entire stride. High-calibre players were also associated with an earlier transition to more out-of-phase coordination of the foot-sagittal/shank-sagittal during push-off (p = 0.007) and a smaller difference in CRP between mid-glide/early recovery (p = 0.016). Utilising more out-of-phase modes of coordination may allow players to more easily adjust to optimal modes of coordination throughout skating strides. Skating drills incorporating varying speed, directionality and external stimuli may encourage the development of more optimal coordination during skating.},
	number = {0},
	urldate = {2020-12-21},
	journal = {Sports Biomechanics},
	author = {Mazurek, Caitlin M. and Pearsall, David J. and Renaud, Philippe J. and Robbins, Shawn M.},
	month = aug,
	year = {2020},
	pmid = {32862791},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2020.1797151},
	keywords = {Motion capture, kinematics, skates},
	pages = {1--16},
}

@article{li_quantifying_2016,
	title = {Quantifying {Inter}-{Segmental} {Coordination} during the {Instep} {Soccer} {Kicks}},
	volume = {9},
	issn = {1939-795X},
	abstract = {In order to generate a high ball speed in soccer, the inter-segmental coordination of the kicking leg is critical. The purpose of this study was to quantify the coordination between the thigh and shank movement in the sagittal plane during instep kicks. Eleven female soccer players were video recorded using a high-speed (80 Hz) video camera during penalty kicks. Hip, knee and ankle joint centers of the right leg were digitized, and the movement was analyzed using Dartfish TeamPro (6.0). The thigh and shank segment angles were generated, and the coordination was quantified using the cross-correlation and the vector coding method. Four coordination patterns were defined based on coupling angles: in-phase, anti-phase, thigh-phase and shank-phase. The time spent in each coordination pattern was analyzed. The cross-correlation coefficient was positive for all the participants, indicating that the two segments rotated with similar patterns. Based on the vector coding method, we observed dominant coordination patterns of shank-phase and in-phase during the backswing and forward swing phase, respectively. We hope the outcomes of our study could provide a better understanding of soccer kicking coordination and benefit training young soccer players. Future studies may use the methodology and outcomes in the present study to investigate the coordination of different levels of players to better understand the process of skill acquisition.},
	language = {eng},
	number = {5},
	journal = {International Journal of Exercise Science},
	author = {Li, Yumeng and Alexander, Marion and Glazebrook, Cheryl and Leiter, Jeff},
	year = {2016},
	pmid = {27990225},
	pmcid = {PMC5154722},
	keywords = {Kinematics, kicking performance, soccer training, vector coding},
	pages = {646--656},
}

@article{levanon_comparison_1998,
	title = {Comparison of the kinematics of the full-instep and pass kicks in soccer},
	volume = {30},
	issn = {0195-9131},
	doi = {10.1097/00005768-199806000-00022},
	abstract = {PURPOSE: The goal of this study was to gain a better understanding of the mechanics of the inside-of-the-foot passing shot used in soccer ("pass kick").
METHODS: The motions of the pass kick were compared with those of the full-instep kick ("full kick"). The study followed an inverse dynamics approach, using three-dimensional cinematographic techniques.
RESULTS: At impact, the pelvis and the thigh-shank plane pointed more toward the right in the pass kick; the shank-foot plane also pointed further outward relative to the thigh-shank plane. Knee extension accounted for most of the speed of the foot in both kicks (86\% in the full kick; 67\% in the pass kick). In the pass kick, pelvis tilt toward the right and hip adduction contributed to a medial component of foot velocity (8.4 m.s-1) normal to the thigh-shank plane, which made the resultant foot velocity vector more oblique to the plane than in the full kick. This facilitated ball impact with the medial aspect of the foot. The slower ball speed in the pass kick was because of a slower foot speed (18.3 m.s-1 vs 21.6 m.s-1). Limitations in the maximum medial velocity that can be generated may force players to restrain the within-plane (and therefore also the resultant) velocity of the foot to be able to impact the ball squarely with the medial aspect of the foot.
CONCLUSIONS: To impact the ball with the medial aspect of the foot in the pass kick, the player orients the pelvis, the right leg, and the foot more toward the right and introduces a medial component of foot velocity. However, most of the speed of the foot is still generated through knee extension.},
	language = {eng},
	number = {6},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Levanon, J. and Dapena, J.},
	month = jun,
	year = {1998},
	pmid = {9624652},
	keywords = {Adult, Biomechanical Phenomena, Humans, Knee Joint, Male, Motor Activity, Posture, Soccer, Video Recording},
	pages = {917--927},
}

@article{lees_biomechanics_2010,
	title = {The biomechanics of kicking in soccer: a review},
	volume = {28},
	issn = {1466-447X},
	shorttitle = {The biomechanics of kicking in soccer},
	doi = {10.1080/02640414.2010.481305},
	abstract = {Kicking is the defining action of soccer, so it is appropriate to review the scientific work that provides a basis of our understanding of this skill. The focus of this review is biomechanical in nature and builds on and extends previous reviews and overviews. While much is known about the biomechanics of the kicking leg, there are several other aspects of the kick that have been the subject of recent exploration. Researchers have widened their interest to consider the kick beginning from the way a player approaches the ball to the end of ball flight, the point that determines the success of the kick. This interest has encapsulated characteristics of overall technique and the influences of the upper body, support leg and pelvis on the kicking action, foot-ball impact and the influences of footwear and soccer balls, ball launch characteristics and corresponding flight of the ball. This review evaluates these and attempts to provide direction for future research.},
	language = {eng},
	number = {8},
	journal = {Journal of Sports Sciences},
	author = {Lees, A. and Asai, T. and Andersen, T. B. and Nunome, H. and Sterzing, T.},
	month = jun,
	year = {2010},
	pmid = {20509089},
	keywords = {Biomechanical Phenomena, Humans, Joints, Lower Extremity, Movement, Soccer, Task Performance and Analysis},
	pages = {805--817},
}

@book{kelso_dynamic_1997,
	address = {Cambridge, Mass.},
	edition = {New Ed edition},
	title = {Dynamic {Patterns}: {The} {Self}-{Organization} of {Brain} and {Behavior}},
	isbn = {978-0-262-61131-2},
	shorttitle = {Dynamic {Patterns}},
	abstract = {foreword by Hermann Haken For the past twenty years Scott Kelso's research has focused on extending the physical concepts of self- organization and the mathematical tools of nonlinear dynamics to understand how human beings (and human brains) perceive, intend, learn, control, and coordinate complex behaviors. In this book Kelso proposes a new, general framework within which to connect brain, mind, and behavior.Kelso's prescription for mental life breaks dramatically with the classical computational approach that is still the operative framework for many newer psychological and neurophysiological studies. His core thesis is that the creation and evolution of patterned behavior at all levels-from neurons to mind-is governed by the generic processes of self-organization. Both human brain and behavior are shown to exhibit features of pattern-forming dynamical systems, including multistability, abrupt phase transitions, crises, and intermittency. Dynamic Patterns brings together different aspects of this approach to the study of human behavior, using simple experimental examples and illustrations to convey essential concepts, strategies, and methods, with a minimum of mathematics. Kelso begins with a general account of dynamic pattern formation. He then takes up behavior, focusing initially on identifying pattern-forming instabilities in human sensorimotor coordination. Moving back and forth between theory and experiment, he establishes the notion that the same pattern-forming mechanisms apply regardless of the component parts involved (parts of the body, parts of the nervous system, parts of society) and the medium through which the parts are coupled. Finally, employing the latest techniques to observe spatiotemporal patterns of brain activity, Kelso shows that the human brain is fundamentally a pattern forming dynamical system, poised on the brink of instability. Self-organization thus underlies the cooperative action of neurons that produces human behavior in all its forms.},
	language = {English},
	publisher = {MIT Press},
	author = {Kelso, Scott},
	month = mar,
	year = {1997},
}

@article{kellis_biomechanical_2007,
	title = {Biomechanical {Characteristics} and {Determinants} of {Instep} {Soccer} {Kick}},
	volume = {6},
	issn = {1303-2968},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3786235/},
	abstract = {Good kicking technique is an important aspect of a soccer player. Therefore, understanding the biomechanics of soccer kicking is particularly important for guiding and monitoring the training process. The purpose of this review was to examine latest research findings on biomechanics of soccer kick performance and identify weaknesses of present research which deserve further attention in the future. Being a multiarticular movement, soccer kick is characterised by a proximal-to-distal motion of the lower limb segments of the kicking leg. Angular velocity is maximized first by the thigh, then by the shank and finally by the foot. This is accomplished by segmental and joint movements in multiple planes. During backswing, the thigh decelerates mainly due to a motion-dependent moment from the shank and, to a lesser extent, by activation of hip muscles. In turn, forward acceleration of the shank is accomplished through knee extensor moment as well as a motion-dependent moment from the thigh. The final speed, path and spin of the ball largely depend on the quality of foot-ball contact. Powerful kicks are achieved through a high foot velocity and coefficient of restitution. Preliminary data indicate that accurate kicks are achieved through slower kicking motion and ball speed values., Key pointsSoccer kick is achieved through segmental and joint rotations in multiple planes and via the proximal-to-distal sequence of segmental angular velocities until ball impact. The quality of ball - foot impact and the mechanical behavior of the foot are also important determinants of the final speed, path and spin of the ball.Ball speed values during the maximum instep kick range from 18 to 35 msec-1 depending on various factors, such as skill level, age, approach angle and limb dominance.The main bulk of biomechanics research examined the biomechanics of powerful kicks, mostly under laboratory conditions. A powerful kick is characterized by the achievement of maximal ball speed. However, maximal ball speed does not guarantee a successful kick: in each case, the ball must reach the target. As already explained, when the player is instructed to hit the ball accurately, joint and segment velocities are lower as opposed to a fast and powerful kick performance. It is therefore apparent that future research should focus on biomechanics of fast but accurate kicking.},
	number = {2},
	urldate = {2020-12-21},
	journal = {Journal of Sports Science \& Medicine},
	author = {Kellis, Eleftherios and Katis, Athanasios},
	month = jun,
	year = {2007},
	pmid = {24149324},
	pmcid = {PMC3786235},
	pages = {154--165},
}

@article{kadaba_measurement_1990,
	title = {Measurement of lower extremity kinematics during level walking},
	volume = {8},
	issn = {0736-0266},
	doi = {10.1002/jor.1100080310},
	abstract = {A simple external marker system and algorithms for computing lower extremity joint angle motion during level walking were developed and implemented on a computer-aided video motion analysis system (VICON). The concept of embedded axes and Euler rotation angles was used to define the three-dimensional joint angle motion based on a set of body surface markers. Gait analysis was performed on 40 normal young adults three times on three different test days at least 1 week apart using the marker system. Angular motion of the hip, knee, and ankle joints and of the pelvis were obtained throughout a gait cycle utilizing the three-dimensional trajectories of markers. The effect of uncertainties in defining the embedded axis on joint angles was demonstrated using sensitivity analysis. The errors in the estimation of joint angle motion were quantified with respect to the degree of error in the construction of embedded axes. The limitations of the model and the marker system in evaluating pathologic gait are discussed. The relatively small number of body surface markers used in the system render it easy to implement for use in routine clinical gait evaluations. Additionally, data presented in this paper should be a useful reference for describing and comparing pathologic gait patterns.},
	language = {eng},
	number = {3},
	journal = {Journal of Orthopaedic Research: Official Publication of the Orthopaedic Research Society},
	author = {Kadaba, M. P. and Ramakrishnan, H. K. and Wootten, M. E.},
	month = may,
	year = {1990},
	pmid = {2324857},
	keywords = {Adolescent, Adult, Algorithms, Biomechanical Phenomena, Female, Gait, Humans, Image Processing, Computer-Assisted, Leg, Male},
	pages = {383--392},
}

@book{faraway_extending_2016,
	title = {Extending the {Linear} {Model} with {R} : {Generalized} {Linear}, {Mixed} {Effects} and {Nonparametric} {Regression} {Models}, {Second} {Edition}},
	isbn = {978-1-315-38272-2},
	shorttitle = {Extending the {Linear} {Model} with {R}},
	url = {https://www.taylorfrancis.com/books/extending-linear-model-julian-faraway/10.1201/9781315382722},
	abstract = {Start Analyzing a Wide Range of Problems 
Since the publication of the bestselling, highly recommended first edition, R has considerably},
	language = {en},
	urldate = {2020-12-21},
	publisher = {Chapman and Hall/CRC},
	author = {Faraway, Julian J.},
	month = mar,
	year = {2016},
	doi = {10.1201/9781315382722},
}

@article{ekstrand_epidemiology_2011,
	title = {Epidemiology of muscle injuries in professional football (soccer)},
	volume = {39},
	issn = {1552-3365},
	doi = {10.1177/0363546510395879},
	abstract = {BACKGROUND: Muscle injuries constitute a large percentage of all injuries in football.
PURPOSE: To investigate the incidence and nature of muscle injuries in male professional footballers.
STUDY DESIGN: Cohort study; Level of evidence, 2.
METHODS: Fifty-one football teams, comprising 2299 players, were followed prospectively during the years 2001 to 2009. Team medical staff recorded individual player exposure and time-loss injuries. The first-team squads of 24 clubs selected by the Union of European Football Associations as belonging to the best European teams, 15 teams of the Swedish First League, and another 15 European teams playing their home matches on artificial turf pitches were included. A muscle injury was defined as "a traumatic distraction or overuse injury to the muscle leading to a player being unable to fully participate in training or match play."
RESULTS: In total, 2908 muscle injuries were registered. On average, a player sustained 0.6 muscle injuries per season. A squad of 25 players can thus expect about 15 muscle injuries per season. Muscle injuries constituted 31\% of all injuries and caused 27\% of the total injury absence. Ninety-two percent of all muscle injuries affected the 4 major muscle groups of the lower limbs: hamstrings (37\%), adductors (23\%), quadriceps (19\%), and calf muscles (13\%). Sixteen percent of the muscle injuries were reinjuries. These reinjuries caused significantly longer absences than did index injuries. The incidence of muscle injury increased with age. When separated into different muscle groups, however, an increased incidence with age was found only for calf muscle injuries and not for hamstring, quadriceps, or hip/groin strains.
CONCLUSION: Muscle injuries are a substantial problem for players and their clubs. They constitute almost one third of all time-loss injuries in men's professional football, and 92\% of all injuries affect the 4 big muscle groups in the lower limbs.},
	language = {eng},
	number = {6},
	journal = {The American Journal of Sports Medicine},
	author = {Ekstrand, Jan and Hägglund, Martin and Waldén, Markus},
	month = jun,
	year = {2011},
	pmid = {21335353},
	keywords = {Adult, Athletic Injuries, Cohort Studies, Europe, Humans, Incidence, Leg Injuries, Male, Muscle, Skeletal, Prevalence, Recurrence, Soccer, Young Adult},
	pages = {1226--1232},
}

@article{egan_effects_2007,
	title = {Effects of experience on the coordination of internally and externally timed soccer kicks},
	volume = {39},
	issn = {0022-2895},
	doi = {10.3200/JMBR.39.5.423-432},
	abstract = {The authors investigated differences in the soccer kick between 8 experienced and 10 less experienced participants in 2 different task conditions (kicking a stationary ball or a moving ball at a target). The experienced participants were more accurate than their less experienced counterparts, whereas there were no differences in maximum foot velocity between groups or between conditions. When compared with their performance in the stationary condition, participants kicked the moving ball with a smaller range of movement at the knee of the kicking leg, maintaining a proximodistal coordination pattern. Because of their significantly shorter knee-flexion phase, the participants in the experienced group displayed a significantly shorter time between initiation of the forward swing of the kick and ball contact than that of those in the less experienced group. The rapid knee flexion may have been a strategy of exploiting passive dynamics to increase accuracy rather than velocity. Members of both groups showed a proximodistal initiation sequence in the kicking leg, which suggests that players can acquire that coordination pattern with relatively little structured practice and that further practice leads to improvement possibly through the increased exploitation of passive dynamics.},
	language = {eng},
	number = {5},
	journal = {Journal of Motor Behavior},
	author = {Egan, Christopher D. and Verheul, Martine H. G. and Savelsbergh, Geert J. P.},
	month = sep,
	year = {2007},
	pmid = {17827118},
	keywords = {Adult, Biomechanical Phenomena, Data Interpretation, Statistical, Foot, Humans, Joints, Male, Motor Skills, Psychomotor Performance, Soccer},
	pages = {423--432},
}

@article{chow_variation_2007,
	title = {Variation in coordination of a discrete multiarticular action as a function of skill level},
	volume = {39},
	issn = {0022-2895},
	doi = {10.3200/JMBR.39.6.463-480},
	abstract = {The authors investigated coordination modes that emerged as a function of the interaction between skill level and task constraints in a multiarticular kicking action. Five skilled, 5 intermediate, and 5 novice participants attempted to satisfy specific height and accuracy constraints in kicking a ball over a barrier. Skilled and intermediate groups demonstrated a functional coordination mode involving less joint involvement at the proximal joints and greater joint involvement at distal joints, mimicking a chip-like action in soccer. Conversely, the novice group tended to produce larger ranges of motion throughout the kicking limb in a driving-like kicking action. Key differences were also found for task outcome scores, joint angle-angle relations, and ball-trajectory plots between the skilled and intermediate groups and the novice group. Findings from this study demonstrated that joint involvement during this discrete multiarticular action is a function of skill level and task constraints rather than a consequence of a global freezing-freeing strategy suggested in some previous research. The authors also highlight the merit of using a model of the acquisition of coordination in examining how coordination modes for multiarticular actions differ as a function of skill.},
	language = {eng},
	number = {6},
	journal = {Journal of Motor Behavior},
	author = {Chow, Jia Yi and Davids, Keith and Button, Chris and Koh, Michael},
	month = nov,
	year = {2007},
	pmid = {18055353},
	keywords = {Adult, Analysis of Variance, Athletic Performance, Biomechanical Phenomena, Humans, Joints, Kinesthesis, Lower Extremity, Male, Movement, Practice, Psychological, Psychomotor Performance, Range of Motion, Articular, Reference Values, Soccer},
	pages = {463--479},
}

@article{brooks_incidence_2006,
	title = {Incidence, risk, and prevention of hamstring muscle injuries in professional rugby union},
	volume = {34},
	issn = {0363-5465},
	doi = {10.1177/0363546505286022},
	abstract = {BACKGROUND: The incidence of hamstring muscle injuries in professional rugby union is high, but evidence-based information on risk factors and injury-prevention strategies in this sport is limited.
PURPOSE: To define the incidence, severity, and risk factors associated with hamstring muscle injuries in professional rugby union and to determine whether the use of hamstring strengthening and stretching exercises reduces the incidence and severity of these injuries.
STUDY DESIGN: Cohort study (prevention); Level of evidence, 3.
METHODS: Team clinicians reported all hamstring muscle injuries on a weekly basis and provided details of the location, diagnosis, severity, and mechanism of each injury; loss of time from training and match play was used as the definition of an injury. Players' match and training exposures were recorded on a weekly basis.
RESULTS: The incidence of hamstring muscle injuries was 0.27 per 1000 player training hours and 5.6 per 1000 player match hours. Injuries, on average, resulted in 17 days of lost time, with recurrent injuries (23\%) significantly more severe (25 days lost) than new injuries (14 days lost). Second-row forwards sustained the fewest (2.4 injuries/1000 player hours) and the least severe (7 days lost) match injuries. Running activities accounted for 68\% of hamstring muscle injuries, but injuries resulting from kicking were the most severe (36 days lost). Players undertaking Nordic hamstring exercises in addition to conventional stretching and strengthening exercises had lower incidences and severities of injury during training and competition.
CONCLUSION: The Nordic hamstring strengthening exercise may reduce the incidence and severity of hamstring muscle injuries sustained during training and competition.},
	language = {eng},
	number = {8},
	journal = {The American Journal of Sports Medicine},
	author = {Brooks, John H. M. and Fuller, Colin W. and Kemp, Simon P. T. and Reddin, Dave B.},
	month = aug,
	year = {2006},
	pmid = {16493170},
	keywords = {Adult, Athletic Injuries, Cohort Studies, England, Football, Humans, Incidence, Injury Severity Score, Muscle Strength, Muscle Stretching Exercises, Muscle, Skeletal, Muscular Diseases, Physical Education and Training, Physical Endurance, Recurrence, Risk Factors, Sprains and Strains, Time Factors},
	pages = {1297--1306},
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} lme4},
	volume = {67},
	copyright = {Copyright (c) 2015 Douglas Bates, Martin Mächler, Ben Bolker, Steve Walker},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v067i01},
	doi = {10.18637/jss.v067.i01},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	month = oct,
	year = {2015},
	note = {Number: 1},
	keywords = {Cholesky decomposition, linear mixed models, penalized least squares, sparse matrix methods},
	pages = {1--48},
}

@article{bartlett_is_2007,
	title = {Is movement variability important for sports biomechanists?},
	volume = {6},
	issn = {1476-3141},
	doi = {10.1080/14763140701322994},
	abstract = {This paper overviews the importance for sports biomechanics of movement variability, which has been studied for some time by cognitive and ecological motor skills specialists but, until quite recently, had somewhat been overlooked by sports biomechanists. The paper considers biomechanics research reporting inter- and intra-individual movement variability in javelin and discus throwing, basketball shooting, and locomotion. The overview does not claim to be comprehensive and we exclude such issues as the theoretical background to movement and coordination variability and their measurement. We overview evidence, both theoretical and empirical, of inter-individual movement variability in seeking to achieve the same task goal, in contrast to the concept of "optimal" movement patterns. Furthermore, even elite athletes cannot reproduce identical movement patterns after many years of training, contradicting the ideas of motor invariance and "representative" trials. We contend that movement variability, far from being solely due to neuromuscular system or measurement "noise"--as sports biomechanists may have previously supposed--is, or could be, functional. Such functionality could allow environmental adaptations, reduce injury risk, and facilitate changes in coordination patterns. We conclude by recommending that sports biomechanists should focus more of their research on movement variability and on important related topics, such as control and coordination of movement, and implications for practice and skill learning.},
	language = {eng},
	number = {2},
	journal = {Sports Biomechanics},
	author = {Bartlett, Roger and Wheat, Jon and Robins, Matthew},
	month = may,
	year = {2007},
	pmid = {17892098},
	keywords = {Basketball, Biomechanical Phenomena, Computer Simulation, Humans, Models, Biological, Models, Theoretical, Motion, Movement, Physical Education and Training, Running, Sports},
	pages = {224--243},
}

@article{barfield_biomechanics_1998,
	title = {The biomechanics of kicking in soccer},
	volume = {17},
	issn = {0278-5919},
	doi = {10.1016/s0278-5919(05)70113-7},
	abstract = {This article discusses the basics of kicking skill from development stages through mechanical characteristics of upper level players. Specific areas that are addressed include developmental levels, kicking components, approach angle, forces on the support foot, loading of the swing limb and subsequent movement toward ball contact, and the mechanics of ball contact and follow-through.},
	language = {eng},
	number = {4},
	journal = {Clinics in Sports Medicine},
	author = {Barfield, W. R.},
	month = oct,
	year = {1998},
	pmid = {9922896},
	keywords = {Biomechanical Phenomena, Foot, Hip Joint, Humans, Knee Joint, Leg, Muscle, Skeletal, Soccer},
	pages = {711--728, vi},
}

@book{robertson_research_2013,
	title = {Research {Methods} in {Biomechanics}},
	isbn = {978-1-4925-8185-7},
	abstract = {Research Methods in Biomechanics, Second Edition, demonstrates the range of available research techniques and how to best apply this knowledge to ensure valid data collection. In the highly technical field of biomechanics, research methods are frequently upgraded as the speed and sophistication of software and hardware technologies increase. With this in mind, the second edition includes up-to-date research methods and presents new information detailing advanced analytical tools for investigating human movement.  Expanded into 14 chapters and reorganized into four parts, the improved second edition features more than 100 new pieces of art and illustrations and new chapters introducing the latest techniques and up-and-coming areas of research. Also included is access to biomechanics research software designed by C-Motion, Visual3D Educational Edition, which allows users to explore the full range of modeling capabilities of the professional Visual3D software in sample data files as well as display visualizations for other data sets. Additional enhancements in this edition include the following:  • Special features called From the Scientific Literature highlight the ways in which biomechanical research techniques have been used in both classic and cutting-edge studies.  • An overview, summary, and list of suggested readings in each chapter guide students and researchers through the content and on to further study.  • Sample problems appear in select chapters, and answers are provided at the end of the text.  • Appendixes contain mathematical and technical references and additional examples.  • A glossary provides a reference for terminology associated with human movement studies. Research Methods in Biomechanics, Second Edition, assists readers in developing a comprehensive understanding of methods for quantifying human movement. Parts I and II of the text examine planar and three-dimensional kinematics and kinetics in research, issues of body segment parameters and forces, and energy, work, and power as they relate to analysis of two- and three-dimensional inverse dynamics. Two of the chapters have been extensively revised to reflect current research practices in biomechanics, in particular the widespread use of Visual3D software. Calculations from these two chapters are now located online with the supplemental software resource, making it easier for readers to grasp the progression of steps in the analysis.  In part III, readers can explore the use of musculoskeletal models in analyzing human movement. This part also discusses electromyography, computer simulation, muscle modeling, and musculoskeletal modeling; it presents new information on MRI and ultrasound use in calculating muscle parameters. Part IV offers a revised chapter on additional analytical procedures, including signal processing techniques. Also included is a new chapter on movement analysis and dynamical systems, which focuses on how to assess and measure coordination and stability in changing movement patterns and the role of movement variability in health and disease. In addition, readers will find discussion of statistical tools useful for identifying the essential characteristics of any human movement.  The second edition of Research Methods in Biomechanics explains the mathematics and data collection systems behind both simple and sophisticated biomechanics. Integrating software and text, Research Methods in Biomechanics, Second Edition, assists both beginning and experienced researchers in developing their methods for analyzing and quantifying human movement.},
	language = {en},
	publisher = {Human Kinetics},
	author = {Robertson, D. Gordon E. and Caldwell, Graham E. and Hamill, Joseph and Kamen, Gary and Whittlesey, Saunders},
	month = nov,
	year = {2013},
	note = {Google-Books-ID: \_u56DwAAQBAJ},
	keywords = {Medical / Physiology, Science / Life Sciences / Human Anatomy \& Physiology},
}

@article{wilson_coordination_2008-1,
	title = {Coordination variability and skill development in expert triple jumpers},
	volume = {7},
	issn = {1476-3141},
	doi = {10.1080/14763140701682983},
	abstract = {The aim of this study was to examine the influence of skill of expert triple jumpers on the coordination variability of lower extremity intra-limb couplings. In contrast to the traditional motor learning perspective, we hypothesized that as skill and thus performance increases, movement coordination variability will also increase. Three-dimensional kinematic and ground reaction force data were collected during the hop-step transition phase of the triple jump. Relative motion plots and a modified vector coding technique were used to quantify the coordination variability across the trials. The results were consistent with a U-shaped curve, representing coordination variability, as skill increases. The high coordination variability in less skilled athletes is present while the appropriate characteristics defining the movement coordination patterns are acquired. This coordination variability may not be beneficial to performance. As the refinement of these characteristics is achieved, coordination variability decreases, resulting in a more consistent or regulated performance. In the final stages of developing a skilled performance, a functional variability is accessed that brings flexibility to the system allowing it to cope with perturbations. This study highlights the need to address the learning effect when analysing coordination variability from a dynamical systems perspective.},
	language = {eng},
	number = {1},
	journal = {Sports Biomechanics},
	author = {Wilson, Cassie and Simpson, Scott E. and van Emmerik, Richard E. A. and Hamill, Joseph},
	month = jan,
	year = {2008},
	pmid = {18341132},
	keywords = {Adult, Ankle Joint, Biomechanical Phenomena, Cohort Studies, Female, Humans, Image Processing, Computer-Assisted, Knee Joint, Male, Motor Skills, Pilot Projects, Postural Balance, Range of Motion, Articular, Task Performance and Analysis, Track and Field, Video Recording},
	pages = {2--9},
}

@article{hamill_coordinative_2012,
	title = {Coordinative variability and overuse injury},
	volume = {4},
	issn = {1758-2555},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3536567/},
	doi = {10.1186/1758-2555-4-45},
	abstract = {Overuse injuries are generally defined as a repetitive micro-trauma to tissue. Many researchers have associated particular biomechanical parameters as an indicator of such injuries. However, while these parameters have been reported in single studies, in many instances, it has been difficult to verify these parameters as causative to the injury. We have investigated overuse injuries, such as patella-femoral pain syndrome, using a dynamical systems approach. Using such methods, the importance of the structure of coordinative variability (i.e. the variability of the interaction between segments or joints) becomes apparent. We view coordinative variability as functionally important to the movement and different from end-point or goal variability. Using concepts derived from the work of Bernstein, we conducted studies using a continuous relative phase and/or modified vector coding approaches to investigate the coordinative variability of overuse injuries. Consistently, we have found that the higher variability state of a coordinative structure is the healthy state while the lower variability state is the unhealthy or pathological state. It is clear that very high coordinative variability could also result in injury and that there must be a window of ‘higher variability’ in which non-injured athletes function. While this finding that coordinative variability is functional has been shown in several studies, it is still not clear if reduced variability contributes to or results from the injury. Studies are currently underway to determine the potential reasons for the reduced variability in injured athletes. Nevertheless, our laboratory believes that this understanding of how joints interact can be important in understanding overuse injuries.},
	urldate = {2020-12-21},
	journal = {Sports Medicine, Arthroscopy, Rehabilitation, Therapy \& Technology: SMARTT},
	author = {Hamill, Joseph and Palmer, Christopher and Van Emmerik, Richard E A},
	month = nov,
	year = {2012},
	pmid = {23186012},
	pmcid = {PMC3536567},
	pages = {45},
}

@article{cazzola_can_2016,
	title = {Can coordination variability identify performance factors and skill level in competitive sport? {The} case of race walking},
	volume = {5},
	issn = {2095-2546},
	shorttitle = {Can coordination variability identify performance factors and skill level in competitive sport?},
	url = {http://www.sciencedirect.com/science/article/pii/S2095254616000144},
	doi = {10.1016/j.jshs.2015.11.005},
	abstract = {Background
Marginal changes in the execution of competitive sports movements can represent a significant change for performance success. However, such differences may emerge only at certain execution intensities and are not easily detectable through conventional biomechanical techniques. This study aimed to investigate if and how competition standard and progression speed affect race walking kinematics from both a conventional and a coordination variability perspective.
Methods
Fifteen experienced athletes divided into three groups (elite, international, and national) were studied while race walking on a treadmill at two different speeds (12.0 and 15.5 km/h). Basic gait parameters, the angular displacement of the pelvis and lower limbs, and the variability in continuous relative phase between six different joint couplings were analyzed.
Results
Most of the spatio-temporal, kinematic, and coordination variability measures proved sensitive to the change in speed. Conversely, non-linear dynamics measures highlighted differences between athletes of different competition standard when conventional analytical tools were not able to discriminate between different skill levels. Continuous relative phase variability was higher for national level athletes than international and elite in two couplings (pelvis obliquity—hip flex/extension and pelvis rotation—ankle dorsi/plantarflexion) and gait phases (early stance for the first coupling, propulsive phase for the second) that are deemed fundamental for correct technique and performance.
Conclusion
Measures of coordination variability showed to be a more sensitive tool for the fine detection of skill-dependent factors in competitive race walking, and showed good potential for being integrated in the assessment and monitoring of sports motor abilities.},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {Journal of Sport and Health Science},
	author = {Cazzola, Dario and Pavei, Gaspare and Preatoni, Ezio},
	month = mar,
	year = {2016},
	keywords = {Biomechanics, Gait, Joint coupling, Motor control, Sports technique, Training},
	pages = {35--43},
}

@incollection{newell_coordination_1985-1,
	series = {Differing {Perspectives} {In} {Motor} {Learning}, {Memory}, {And} {Control}},
	title = {Coordination, {Control} and {Skill}},
	volume = {27},
	url = {http://www.sciencedirect.com/science/article/pii/S0166411508625418},
	abstract = {In this chapter, I develop the interpretation of coordination, control and skill sketched by Kugler, Kelso and Turvey (1980, 1982). The orientation promoted here is primarily descriptive with the focus being the development of a framework for a useful operational distinction between the three terms. 1 believe one can draw on the interpretation of coordination, control and skill outlined by Kugler and colleagues without necessarily invoking the theoretical position advanced by this group, although it will become clear as this chapter unfolds, that I am sympathetic to this theoretical position.},
	language = {en},
	urldate = {2020-12-21},
	booktitle = {Advances in {Psychology}},
	publisher = {North-Holland},
	author = {Newell, K. M.},
	editor = {Goodman, David and Wilberg, Robert B. and Franks, Ian M.},
	month = jan,
	year = {1985},
	doi = {10.1016/S0166-4115(08)62541-8},
	pages = {295--317},
}

@article{tolver_analysis_2014,
	title = {Analysis of juggling data: {Registration} subject to biomechanical constraints},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588173},
	doi = {10.1214/14-EJS937F},
	abstract = {We illustrate how physical constraints of a biomechanical system can be taken into account when registering functional data from juggling trials. We define an idealized model of juggling, based on a periodic joint movement in a low-dimensional space and a periodic position vector (from an undefined joint to the finger tip) of approximately constant length along the observed trajectory. Our registration procedure first warps the cycles in the trial to each other and computes a periodic average, and then estimates the joint movement and the position vector of the abovementioned model.},
	language = {EN},
	number = {2},
	urldate = {2020-12-15},
	journal = {Electronic Journal of Statistics},
	author = {Tolver, Anders and Sørensen, Helle and Muller, Martha and Mousavi, Seyed Nourollah},
	year = {2014},
	mrnumber = {MR3273605},
	zmnumber = {1305.62021},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Biomechanical constraints, decomposition, functional data analysis, juggling trajectories, periodic average, registration, warping},
	pages = {1856--1864},
}

@article{gervini_warped_2014,
	title = {Warped functional analysis of variance},
	volume = {70},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12171},
	doi = {https://doi.org/10.1111/biom.12171},
	abstract = {This article presents an Analysis of Variance model for functional data that explicitly incorporates phase variability through a time-warping component, allowing for a unified approach to estimation and inference in presence of amplitude and time variability. The focus is on single-random-factor models but the approach can be easily generalized to more complex ANOVA models. The behavior of the estimators is studied by simulation, and an application to the analysis of growth curves of flour beetles is presented. Although the model assumes a smooth latent process behind the observed trajectories, smootheness of the observed data is not required; the method can be applied to irregular time grids, which are common in longitudinal studies.},
	language = {en},
	number = {3},
	urldate = {2020-12-09},
	journal = {Biometrics},
	author = {Gervini, Daniel and Carter, Patrick A.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12171},
	keywords = {Karhunen–Loève decomposition, Longitudinal data, Phase variability, Quantitative genetics, Random-effect models},
	pages = {526--535},
}

@article{raket_nonlinear_2014,
	title = {A nonlinear mixed-effects model for simultaneous smoothing and registration of functional data},
	volume = {38},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865513004108},
	doi = {10.1016/j.patrec.2013.10.018},
	abstract = {We consider misaligned functional data, where data registration is necessary for proper statistical analysis. This paper proposes to treat misalignment as a nonlinear random effect, which makes simultaneous likelihood inference for horizontal and vertical effects possible. By simultaneously fitting the model and registering data, the proposed method estimates parameters and predicts random effects more precisely than conventional methods that register data in preprocessing. The ability of the model to estimate both hyperparameters and predict horizontal and vertical effects are illustrated on both simulated and real data.},
	language = {en},
	urldate = {2020-12-09},
	journal = {Pattern Recognition Letters},
	author = {Rakêt, Lars Lau and Sommer, Stefan and Markussen, Bo},
	month = mar,
	year = {2014},
	keywords = {Amplitude variation, Data alignment, Functional mixed-effects model, Nonlinear mixed-effects model, Phase variation, Smoothing},
	pages = {1--7},
}

@article{vantini_definition_2012,
	title = {On the definition of phase and amplitude variability in functional data analysis},
	volume = {21},
	issn = {1863-8260},
	url = {https://doi.org/10.1007/s11749-011-0268-9},
	doi = {10.1007/s11749-011-0268-9},
	abstract = {We introduce a modeling and mathematical framework in which the problem of registering a functional data set can be consistently set. In detail, we show that the introduction, in a functional data analysis, of a metric/semi-metric and of a group of warping functions, with respect to which the metric/semi-metric is invariant, enables a sound and not ambiguous definition of phase and amplitude variability. Indeed, in this framework, we prove that the analysis of a registered functional data set can be re-interpreted as the analysis of a set of suitable equivalence classes associated to original functions and induced by the group of the warping functions. Moreover, an amplitude-to-total variability index is proposed. This index turns out to be useful in practical situations for measuring to what extent phase variability affects the data and for comparing the effectiveness of different registration methods.},
	language = {en},
	number = {4},
	urldate = {2020-12-09},
	journal = {TEST},
	author = {Vantini, Simone},
	month = dec,
	year = {2012},
	pages = {676--696},
}

@article{poss_analysis_2014,
	title = {Analysis of juggling data: {Registering} data to principal components to explain amplitude variation},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588169},
	doi = {10.1214/14-EJS937B},
	abstract = {The paper considers an analysis of the juggling dataset based on registration. An elementary landmark registration is used to extract the juggling cycles from the data. The resulting cycles are then registered to functional principal components. After the registration step the paper then lays its focus on a functional principal component analysis to explain the amplitude variation of the cycles. More results about the behavior of the juggler’s movements of the hand during the juggling trials are obtained by a further investigation of the principal scores.},
	language = {EN},
	number = {2},
	urldate = {2020-12-08},
	journal = {Electronic Journal of Statistics},
	author = {Poss, Dominik and Wagner, Heiko},
	year = {2014},
	mrnumber = {MR3273601},
	zmnumber = {1305.62016},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Continuous registration, functional principal components analysis, landmark registration, phase variation, time warping, warping function},
	pages = {1825--1834},
}

@article{kneip_combining_2008,
	title = {Combining {Registration} and {Fitting} for {Functional} {Models}},
	volume = {103},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214508000000517},
	doi = {10.1198/016214508000000517},
	abstract = {A registration method can be defined as a process of aligning features of a sample of curves by monotone transformations of their domain. The aligned curves exhibit only amplitude variation, and the domain transformations, called warping functions, capture the phase variation in the original curves. In this article we precisely define a new type of registration process, in which the warping functions optimize the fit of a principal components decomposition to the aligned curves. The principal components are effectively the features that this process aligns. We discuss the relationship of registration to closure of a function space under convex operations, and define consistency for registration methods. We define an explicit decomposition of functional variation into amplitude and phase partitions, and develop an algorithm for combining registration with principal components analysis, and apply it to simulated and real data.},
	number = {483},
	urldate = {2020-12-08},
	journal = {Journal of the American Statistical Association},
	author = {Kneip, Alois and Ramsay, James O.},
	month = sep,
	year = {2008},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214508000000517},
	keywords = {Continuous registration, Functional principal components analysis, Landmark registration, Phase variation, Time warping, Warping function},
	pages = {1155--1165},
}

@inproceedings{brunel_frenet-serret_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Frenet}-{Serret} {Framework} for {Aligning} {Geometric} {Curves}},
	isbn = {978-3-030-26980-7},
	doi = {10.1007/978-3-030-26980-7_63},
	abstract = {Variations of the curves and trajectories in 1D can be analysed efficiently with functional data analysis tools. The main sources of variations in 1D curves have been identified as amplitude and phase variations. Dealing with the latter gives rise to the problem of curve alignment and registration problems. It has been recognised that it is important to incorporate geometric features of the curves in developing statistical approaches to address such problems. Extending these techniques to multidimensional curves is not obvious, as the notion of multidimensional amplitude can be defined in multiple ways. We propose a framework to deal with the curve alignment in multidimensional curves as 3D objects. In particular, we propose a new distance between the curves that utilises the geometric information of the curves through the Frenet-Serret representation of the curves. This can be viewed as a generalisation of the elastic shape analysis based on the square root velocity framework. We develop an efficient computational algorithm to find an optimal alignment based on the proposed distance using dynamic programming.},
	language = {en},
	booktitle = {Geometric {Science} of {Information}},
	publisher = {Springer International Publishing},
	author = {Brunel, Nicolas J.-B. and Park, Juhyun},
	editor = {Nielsen, Frank and Barbaresco, Frédéric},
	year = {2019},
	keywords = {Curve registration, Frenet-Serret frames, Functional data analysis},
	pages = {608--617},
}

@article{brunel_removing_2014,
	title = {Removing phase variability to extract a mean shape for juggling trajectories},
	volume = {8},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1414588172},
	doi = {10.1214/14-EJS937E},
	abstract = {One of the purposes of the curve alignment has been to recover a structural mean of the curves by taking into account the common structural information or shape. Borrowing ideas from shape analysis, we introduce the Frenet-Serret framework to remove phase variation and to define a mean shape for three dimensional curves. Our method effectively regularizes the estimation of the geometry through curvature and torsion, and does not require curve alignment to define a mean. The method is demonstrated with the juggling data set.},
	language = {EN},
	number = {2},
	urldate = {2020-12-03},
	journal = {Electronic Journal of Statistics},
	author = {Brunel, Nicolas J.-B. and Park, Juhyun},
	year = {2014},
	mrnumber = {MR3273604},
	zmnumber = {1302.62073},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Curve alignment, Frenet-Serret frame, Fréchet mean, multi-dimensional curves},
	pages = {1848--1855},
}

@article{gelman_what_2020,
	title = {What are the most important statistical ideas of the past 50 years?},
	url = {http://arxiv.org/abs/2012.00174},
	abstract = {We argue that the most important statistical ideas of the past half century are: counterfactual causal inference, bootstrapping and simulation-based inference, overparameterized models and regularization, multilevel models, generic computation algorithms, adaptive decision analysis, robust inference, and exploratory data analysis. We discuss common features of these ideas, how they relate to modern computing and big data, and how they might be developed and extended in future decades. The goal of this article is to provoke thought and discussion regarding the larger themes of research in statistics and data science.},
	urldate = {2020-12-03},
	journal = {arXiv:2012.00174 [stat]},
	author = {Gelman, Andrew and Vehtari, Aki},
	month = nov,
	year = {2020},
	note = {arXiv: 2012.00174},
	keywords = {Statistics - Methodology},
}

@article{park_mean_2019,
	title = {Mean curvature and mean shape for multivariate functional data under {Frenet}-{Serret} framework},
	url = {http://arxiv.org/abs/1910.12049},
	abstract = {The analysis of curves has been routinely dealt with using tools from functional data analysis. However its extension to multi-dimensional curves poses a new challenge due to its inherent geometric features that are difficult to capture with the classical approaches that rely on linear approximations. We propose a new framework for functional data as multidimensional curves that allows us to extract geometrical features from noisy data. We define a mean through measuring shape variation of the curves. The notion of shape has been used in functional data analysis somewhat intuitively to find a common pattern in one dimensional curves. As a generalization, we directly utilize a geometric representation of the curves through the Frenet-Serret ordinary differential equations and introduce a new definition of mean curvature and mean shape through the mean ordinary differential equation. We formulate the estimation problem in a penalized regression and develop an efficient algorithm. We demonstrate our approach with both simulated data and a real data example.},
	urldate = {2020-12-02},
	journal = {arXiv:1910.12049 [stat]},
	author = {Park, Juhyun and Brunel, Nicolas J.-B.},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.12049},
	keywords = {Statistics - Methodology},
}

@article{taylor_statistical_2015,
	title = {Statistical learning and selective inference},
	volume = {112},
	issn = {1091-6490},
	doi = {10.1073/pnas.1507583112},
	abstract = {We describe the problem of "selective inference." This addresses the following challenge: Having mined a set of data to find potential associations, how do we properly assess the strength of these associations? The fact that we have "cherry-picked"--searched for the strongest associations--means that we must set a higher bar for declaring significant the associations that we see. This challenge becomes more important in the era of big data and complex statistical modeling. The cherry tree (dataset) can be very large and the tools for cherry picking (statistical learning methods) are now very sophisticated. We describe some recent new developments in selective inference and illustrate their use in forward stepwise regression, the lasso, and principal components analysis.},
	language = {eng},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Taylor, Jonathan and Tibshirani, Robert J.},
	month = jun,
	year = {2015},
	pmid = {26100887},
	pmcid = {PMC4485109},
	keywords = {Datasets as Topic, Learning, Models, Statistical, P values, inference, lasso},
	pages = {7629--7634},
}

@article{preatoni_movement_2013,
	title = {Movement variability and skills monitoring in sports},
	volume = {12},
	issn = {1476-3141},
	url = {https://doi.org/10.1080/14763141.2012.738700},
	doi = {10.1080/14763141.2012.738700},
	abstract = {The aim of this paper was to present a review on the role that movement variability (MV) plays in the analysis of sports movement and in the monitoring of the athlete's skills. MV has been traditionally considered an unwanted noise to be reduced, but recent studies have re-evaluated its role and have tried to understand whether it may contain important information about the neuro-musculo-skeletal organisation. Issues concerning both views of MV, different approaches for analysing it and future perspectives are discussed. Information regarding the nature of the MV is vital in the analysis of sports movements/motor skills, and the way in which these movements are analysed and the MV subsequently quantified is dependent on the movement in question and the issues the researcher is trying to address. In dealing with a number of issues regarding MV, this paper has also raised a number of questions which are still to be addressed.},
	number = {2},
	urldate = {2020-11-25},
	journal = {Sports Biomechanics},
	author = {Preatoni, Ezio and Hamill, Joseph and Harrison, Andrew J. and Hayes, Kevin and Emmerik, Richard E. A. Van and Wilson, Cassie and Rodano, Renato},
	month = jun,
	year = {2013},
	pmid = {23898682},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2012.738700},
	keywords = {Biomechanics, experimental methods, injury, performance, reliability},
	pages = {69--92},
}

@article{kurtek_segmentation_2013,
	title = {Segmentation, alignment and statistical analysis of biosignals with application to disease classification},
	volume = {40},
	issn = {0266-4763},
	url = {https://doi.org/10.1080/02664763.2013.785492},
	doi = {10.1080/02664763.2013.785492},
	abstract = {We present a novel methodology for a comprehensive statistical analysis of approximately periodic biosignal data. There are two main challenges in such analysis: (1) the automatic extraction (segmentation) of cycles from long, cyclostationary biosignals and (2) the subsequent statistical analysis, which in many cases involves the separation of temporal and amplitude variabilities. The proposed framework provides a principled approach for statistical analysis of such signals, which in turn allows for an efficient cycle segmentation algorithm. This is achieved using a convenient representation of functions called the square-root velocity function (SRVF). The segmented cycles, represented by SRVFs, are temporally aligned using the notion of the Karcher mean, which in turn allows for more efficient statistical summaries of signals. We show the strengths of this method through various disease classification experiments. In the case of myocardial infarction detection and localization, we show that our method compares favorably to methods described in the current literature.},
	number = {6},
	urldate = {2020-11-25},
	journal = {Journal of Applied Statistics},
	author = {Kurtek, Sebastian and Wu, Wei and Christensen, Gary E. and Srivastava, Anuj},
	month = jun,
	year = {2013},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/02664763.2013.785492},
	keywords = {cyclostationary biosignal segmentation, disease classification, functional data analysis, gait, myocardial infarction},
	pages = {1270--1288},
}

@article{wu_predicting_2019,
	title = {Predicting fatigue using countermovement jump force-time signatures: {PCA} can distinguish neuromuscular versus metabolic fatigue},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Predicting fatigue using countermovement jump force-time signatures},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0219295},
	doi = {10.1371/journal.pone.0219295},
	abstract = {Purpose This study investigated the relationship between the ground reaction force-time profile of a countermovement jump (CMJ) and fatigue, specifically focusing on predicting the onset of neuromuscular versus metabolic fatigue using the CMJ. Method Ten recreational athletes performed 5 CMJs at time points prior to, immediately following, and at 0.5, 1, 3, 6, 24 and 48 h after training, which comprised repeated sprint sessions of low, moderate, or high workloads. Features of the concentric portion of the CMJ force-time signature at the measurement time points were analysed using Principal Components Analysis (PCA) and functional PCA (fPCA) to better understand fatigue onset given training workload. In addition, Linear Mixed Effects (LME) models were developed to predict the onset of fatigue. Results The first two Principal Components (PCs) using PCA explained 68\% of the variation in CMJ features, capturing variation between athletes through weighted combinations of force, concentric time and power. The next two PCs explained 9.9\% of the variation and revealed fatigue effects between 6 to 48 h after training for PC3, and contrasting neuromuscular and metabolic fatigue effects in PC4. fPCA supported these findings and further revealed contrasts between metabolic and neuromuscular fatigue effects in the first and second half of the force-time curve in PC3, and a double peak effect in PC4. Subsequently, CMJ measurements up to 0.5 h after training were used to predict relative peak CMJ force, with mean squared errors of 0.013 and 0.015 at 6 and 48 h corresponding to metabolic and neuromuscular fatigue. Conclusion The CMJ was found to provide a strong predictor of neuromuscular and metabolic fatigue, after accounting for force, concentric time and power. This method can be used to assist coaches to individualise future training based on CMJ response to the immediate session.},
	language = {en},
	number = {7},
	urldate = {2020-11-25},
	journal = {PLOS ONE},
	author = {Wu, Paul Pao-Yen and Sterkenburg, Nicholas and Everett, Kirsten and Chapman, Dale W. and White, Nicole and Mengersen, Kerrie},
	month = jul,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Fatigue, Forecasting, Human performance, Material fatigue, Principal component analysis, Running, Sports, Time measurement},
	pages = {e0219295},
}

@article{srivastava_shape_2011,
	title = {Shape {Analysis} of {Elastic} {Curves} in {Euclidean} {Spaces}},
	volume = {33},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2010.184},
	abstract = {This paper introduces a square-root velocity (SRV) representation for analyzing shapes of curves in euclidean spaces under an elastic metric. In this SRV representation, the elastic metric simplifies to the IL(2) metric, the reparameterization group acts by isometries, and the space of unit length curves becomes the unit sphere. The shape space of closed curves is the quotient space of (a submanifold of) the unit sphere, modulo rotation, and reparameterization groups, and we find geodesics in that space using a path straightening approach. These geodesics and geodesic distances provide a framework for optimally matching, deforming, and comparing shapes. These ideas are demonstrated using: 1) shape analysis of cylindrical helices for studying protein structure, 2) shape analysis of facial curves for recognizing faces, 3) a wrapped probability distribution for capturing shapes of planar closed curves, and 4) parallel transport of deformations for predicting shapes from novel poses.},
	language = {eng},
	number = {7},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Srivastava, Anuj and Klassen, Eric and Joshi, Shantanu H. and Jermyn, Ian H.},
	month = jul,
	year = {2011},
	pmid = {20921581},
	pages = {1415--1428},
}

@article{wei_direction-projection-permutation_2016,
	title = {Direction-{Projection}-{Permutation} for {High}-{Dimensional} {Hypothesis} {Tests}},
	volume = {25},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2015.1027773},
	doi = {10.1080/10618600.2015.1027773},
	abstract = {High-dimensional low sample size (HDLSS) data are becoming increasingly common in statistical applications. When the data can be partitioned into two classes, a basic task is to construct a classifier that can assign objects to the correct class. Binary linear classifiers have been shown to be especially useful in HDLSS settings and preferable to more complicated classifiers because of their ease of interpretability. We propose a computational tool called direction-projection-permutation (DiProPerm), which rigorously assesses whether a binary linear classifier is detecting statistically significant differences between two high-dimensional distributions. The basic idea behind DiProPerm involves working directly with the one-dimensional projections of the data induced by binary linear classifier. Theoretical properties of DiProPerm are studied under the HDLSS asymptotic regime whereby dimension diverges to infinity while sample size remains fixed. We show that certain variations of DiProPerm are consistent and that consistency is a nontrivial property of tests in the HDLSS asymptotic regime. The practical utility of DiProPerm is demonstrated on HDLSS gene expression microarray datasets. Finally, an empirical power study is conducted comparing DiProPerm to several alternative two-sample HDLSS tests to understand the advantages and disadvantages of each method.},
	number = {2},
	urldate = {2020-11-25},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Wei, Susan and Lee, Chihoon and Wichers, Lindsay and Marron, J. S.},
	month = apr,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2015.1027773},
	keywords = {Distance weighted discrimination; High-dimensional hypothesis test; High-dimensional low sample size; Linear binary classification; Permutation test; Two-sample problem},
	pages = {549--569},
}

@article{cabanski_swiss_2010,
	title = {{SWISS} {MADE}: {Standardized} {WithIn} {Class} {Sum} of {Squares} to {Evaluate} {Methodologies} and {Dataset} {Elements}},
	volume = {5},
	issn = {1932-6203},
	shorttitle = {{SWISS} {MADE}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009905},
	doi = {10.1371/journal.pone.0009905},
	abstract = {Contemporary high dimensional biological assays, such as mRNA expression microarrays, regularly involve multiple data processing steps, such as experimental processing, computational processing, sample selection, or feature selection (i.e. gene selection), prior to deriving any biological conclusions. These steps can dramatically change the interpretation of an experiment. Evaluation of processing steps has received limited attention in the literature. It is not straightforward to evaluate different processing methods and investigators are often unsure of the best method. We present a simple statistical tool, Standardized WithIn class Sum of Squares (SWISS), that allows investigators to compare alternate data processing methods, such as different experimental methods, normalizations, or technologies, on a dataset in terms of how well they cluster a priori biological classes. SWISS uses Euclidean distance to determine which method does a better job of clustering the data elements based on a priori classifications. We apply SWISS to three different gene expression applications. The first application uses four different datasets to compare different experimental methods, normalizations, and gene sets. The second application, using data from the MicroArray Quality Control (MAQC) project, compares different microarray platforms. The third application compares different technologies: a single Agilent two-color microarray versus one lane of RNA-Seq. These applications give an indication of the variety of problems that SWISS can be helpful in solving. The SWISS analysis of one-color versus two-color microarrays provides investigators who use two-color arrays the opportunity to review their results in light of a single-channel analysis, with all of the associated benefits offered by this design. Analysis of the MACQ data shows differential intersite reproducibility by array platform. SWISS also shows that one lane of RNA-Seq clusters data by biological phenotypes as well as a single Agilent two-color microarray.},
	language = {en},
	number = {3},
	urldate = {2020-11-25},
	journal = {PLOS ONE},
	author = {Cabanski, Christopher R. and Qi, Yuan and Yin, Xiaoying and Bair, Eric and Hayward, Michele C. and Fan, Cheng and Li, Jianying and Wilkerson, Matthew D. and Marron, J. S. and Perou, Charles M. and Hayes, D. Neil},
	month = mar,
	year = {2010},
	note = {Publisher: Public Library of Science},
	keywords = {Breast cancer, Data processing, Gene expression, Microarrays, Oligonucleotides, Permutation, Regression analysis, Reproducibility},
	pages = {e9905},
}

@article{yu_principal_2017,
	title = {Principal {Nested} {Spheres} for {Time}-{Warped} {Functional} {Data} {Analysis}},
	volume = {26},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2015.1115359},
	doi = {10.1080/10618600.2015.1115359},
	abstract = {There are often two important types of variation in functional data: the horizontal (or phase) variation and the vertical (or amplitude) variation. These two types of variation have been appropriately separated and modeled through a domain warping method (or curve registration) based on the Fisher–Rao metric. This article focuses on the analysis of the horizontal variation, captured by the domain warping functions. The square-root velocity function representation transforms the manifold of the warping functions to a Hilbert sphere. Motivated by recent results on manifold analogs of principal component analysis, we propose to analyze the horizontal variation via a principal nested spheres approach. Compared with earlier approaches, such as approximating tangent plane principal component analysis, this is seen to be an efficient and interpretable approach to decompose the horizontal variation in both simulated and real data examples.},
	number = {1},
	urldate = {2020-11-24},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Yu, Qunqun and Lu, Xiaosun and Marron, J. S.},
	month = jan,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2015.1115359},
	keywords = {Functional data variability, Principal nested spheres, Time warping},
	pages = {144--151},
}

@article{fletcher_principal_2004,
	title = {Principal geodesic analysis for the study of nonlinear statistics of shape},
	volume = {23},
	issn = {1558-254X},
	doi = {10.1109/TMI.2004.831793},
	abstract = {A primary goal of statistical shape analysis is to describe the variability of a population of geometric objects. A standard technique for computing such descriptions is principal component analysis. However, principal component analysis is limited in that it only works for data lying in a Euclidean vector space. While this is certainly sufficient for geometric models that are parameterized by a set of landmarks or a dense collection of boundary points, it does not handle more complex representations of shape. We have been developing representations of geometry based on the medial axis description or m-rep. While the medial representation provides a rich language for variability in terms of bending, twisting, and widening, the medial parameters are not elements of a Euclidean vector space. They are in fact elements of a nonlinear Riemannian symmetric space. In this paper, we develop the method of principal geodesic analysis, a generalization of principal component analysis to the manifold setting. We demonstrate its use in describing the variability of medially-defined anatomical objects. Results of applying this framework on a population of hippocampi in a schizophrenia study are presented.},
	number = {8},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Fletcher, P. T. and {Conglin Lu} and Pizer, S. M. and {Sarang Joshi}},
	month = aug,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Algorithms, Anatomical structure, Anatomy, Artificial Intelligence, Biomedical imaging, Cluster Analysis, Computer Graphics, Computer Simulation, Geometry, Hippocampus, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Image analysis, Imaging, Three-Dimensional, Information Storage and Retrieval, Models, Biological, Models, Statistical, Nonlinear Dynamics, Numerical Analysis, Computer-Assisted, Pattern Recognition, Automated, Principal Component Analysis, Principal component analysis, Reproducibility of Results, Schizophrenia, Sensitivity and Specificity, Shape, Signal Processing, Computer-Assisted, Solid modeling, Statistical analysis, Subtraction Technique, Vectors, complex shape representations, computerised tomography, hippocampus, medial axis description, medially-defined anatomical objects, medical image processing, nonlinear Riemannian symmetric space, nonlinear statistical shape analysis, principal component analysis, principal geodesic analysis, schizophrenia},
	pages = {995--1005},
}

@article{lu_analysis_2014,
	title = {Analysis of juggling data: {Object} oriented data analysis of clustering in acceleration functions},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588171},
	doi = {10.1214/14-EJS937D},
	abstract = {This paper describes an analysis of acceleration variability among the juggling cycles. The Fisher Rao curve registration is used for curve alignment. Five different choices of data objects are considered in this paper. We show that one of these choices of data objects leads to a much better clustering into two distinct types of juggling cycles than the other choices.},
	language = {EN},
	number = {2},
	urldate = {2020-11-24},
	journal = {Electronic Journal of Statistics},
	author = {Lu, Xiaosun and Marron, J. S.},
	year = {2014},
	mrnumber = {MR3273603},
	zmnumber = {1305.62014},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Curve registration, clustering, distance weighted discrimination, functional data analysis},
	pages = {1842--1847},
}

@phdthesis{lu_object_2013,
	address = {Chapel Hill},
	type = {Doctor of {Philosophy}},
	title = {Object {Oriented} {Data} {Analysis} of {Cell} {Images} and {Analysis} of {Elastic} {Functions}},
	url = {https://cdr.lib.unc.edu/concern/dissertations/k643b1852},
	abstract = {This thesis consists of two parts: object oriented data analysis of cell images, and analysis of elastic functions. Both topics are motivated by studies in cell culture biology. The first part discusses object oriented data analysis (OODA) of cell images, which highlights a common critical issue - choice of data objects. OODA is a useful method for analyzing populations of complicated objects, such as images, trees, etc. Instead of naively choosing either the individual cells or the wells (a container in which the cells are grown) as data objects, a new type of data object is proposed, that is the union of a well with its corresponding set of cells. This research suggests that OODA is not simply a framework for understanding the structure of the data analysis. It leads to useful interdisciplinary discussion that gives better results through more appropriate choice of data objects, especially for complex data analyses. The second part discusses functional data analysis motivated by analyzing data variability among cell growth curves. There are two important types of variation: the horizontal (or phase) variation and the vertical (or amplitude) variation. They can be separated and modeled through a novel domain warping (or curve registration) approach based on the Fisher Rao metric. A convenient square-root velocity function (SRVF) representation is used to computationally simplify the Fisher Rao framework. In this thesis, both separate and joint analyses of these two types of variation are discussed. Compared with conventional approaches such as functional principal component analysis, the SRVF approaches proposed in this thesis can be more efficient and interpretable in understanding the variability of functions.},
	language = {English},
	school = {University of North Carolina},
	author = {Lu, Xiaosun},
	month = may,
	year = {2013},
}

@misc{noauthor_object_nodate,
	title = {Object {Oriented} {Data} {Analysis} of {Cell} {Images} and {Analysis} of {Elastic} {Functions}},
	language = {http://id.loc.gov/vocabulary/iso639-2/eng},
	note = {Context Object: url\_ver=Z39.88-2004\&ctx\_ver=Z39.88-2004\&rft\_val\_fmt=info\%3Aofi\%2Ffmt\%3Akev\%3Amtx\%3Adc\&rfr\_id=info\%3Asid\%2Fblacklight.rubyforge.org\%3Agenerator\&rft.title=Object+Oriented+Data+Analysis+of+Cell+Images+and+Analysis+of+Elastic+Functions\&rft.publisher=University+of+North+Carolina+at+Chapel+Hill\&rft.format=Dissertation\&rft.language=http\%3A\%2F\%2Fid.loc.gov\%2Fvocabulary\%2Fiso639-2\%2Feng
Publisher: University of North Carolina at Chapel Hill},
}

@article{srivastava_registration_2011,
	title = {Registration of {Functional} {Data} {Using} {Fisher}-{Rao} {Metric}},
	url = {http://arxiv.org/abs/1103.3817},
	abstract = {We introduce a novel geometric framework for separating the phase and the amplitude variability in functional data of the type frequently studied in growth curve analysis. This framework uses the Fisher-Rao Riemannian metric to derive a proper distance on the quotient space of functions modulo the time-warping group. A convenient square-root velocity function (SRVF) representation transforms the Fisher-Rao metric into the standard \${\textbackslash}ltwo\$ metric, simplifying the computations. This distance is then used to define a Karcher mean template and warp the individual functions to align them with the Karcher mean template. The strength of this framework is demonstrated by deriving a consistent estimator of a signal observed under random warping, scaling, and vertical translation. These ideas are demonstrated using both simulated and real data from different application domains: the Berkeley growth study, handwritten signature curves, neuroscience spike trains, and gene expression signals. The proposed method is empirically shown to be be superior in performance to several recently published methods for functional alignment.},
	urldate = {2020-11-24},
	journal = {arXiv:1103.3817 [math, stat]},
	author = {Srivastava, Anuj and Wu, Wei and Kurtek, Sebastian and Klassen, Eric and Marron, J. S.},
	month = may,
	year = {2011},
	note = {arXiv: 1103.3817},
	keywords = {Mathematics - Statistics Theory, Statistics - Applications, Statistics - Methodology},
}

@article{ullah_applications_2013,
	title = {Applications of functional data analysis: {A} systematic review},
	volume = {13},
	issn = {1471-2288},
	shorttitle = {Applications of functional data analysis},
	url = {https://doi.org/10.1186/1471-2288-13-43},
	doi = {10.1186/1471-2288-13-43},
	abstract = {Functional data analysis (FDA) is increasingly being used to better analyze, model and predict time series data. Key aspects of FDA include the choice of smoothing technique, data reduction, adjustment for clustering, functional linear modeling and forecasting methods.},
	language = {en},
	number = {1},
	urldate = {2020-11-20},
	journal = {BMC Medical Research Methodology},
	author = {Ullah, Shahid and Finch, Caroline F.},
	month = mar,
	year = {2013},
	pages = {43},
}

@article{kurtek_analysis_2014,
	title = {Analysis of juggling data: {Alignment}, extraction, and modeling of juggling cycles},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588174},
	doi = {10.1214/14-EJS937G},
	abstract = {In this paper we present results from alignment, extraction, and statistical analysis of juggling trajectories using an elastic functional data analysis framework. This framework, specifically adapted for analyzing cyclostationary signals using an elastic Riemannian metric, was introduced recently by Kurtek et al. [2]. It relies on a special representation of curves called the square-root velocity function to pose the alignment problem as an optimization over the re-parametrization space. The cost function for alignment is a proper metric and is used to separate phase and amplitude components of juggling cycles. We present results of segmenting juggling trials into cycles, separating phase and amplitude components of cycles, and developing principal component analysis (PCA) based statistical models for these individual components.},
	language = {EN},
	number = {2},
	urldate = {2020-11-18},
	journal = {Electronic Journal of Statistics},
	author = {Kurtek, Sebastian and Xie, Qian and Srivastava, Anuj},
	year = {2014},
	mrnumber = {MR3273606},
	zmnumber = {1305.62331},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Cyclostationary processes, cycle extraction, elastic functional data analysis, phase-amplitude separation},
	pages = {1865--1873},
}

@article{ramsay_description_2014,
	title = {Description and processing of functional data arising from juggling trajectories},
	volume = {8},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1414588167},
	doi = {10.1214/14-EJS937},
	abstract = {In this data introduction paper we discuss different aspects of a juggling dataset collected in 1998 at the motor control laboratory in the McGill University Department of Psychology. The juggler was asked to juggle three balls and the x, y, z position of his index finger was recorded. This data consists of ten juggling trials, each lasting 10 seconds, with 11–13 cycles per trial. We also describe a set of processing steps applied to this dataset. In particular, the raw data was smoothed and a new coordinate system was defined. Finally, we provide a few initial observations from examining the raw data.},
	language = {EN},
	number = {2},
	urldate = {2020-11-16},
	journal = {Electronic Journal of Statistics},
	author = {Ramsay, James O. and Gribble, Paul and Kurtek, Sebastian},
	year = {2014},
	mrnumber = {MR3273599},
	zmnumber = {1305.62018},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Functional data analysis, data processing, juggling trajectories and cycles},
	pages = {1811--1816},
}

@article{marron_statistics_2014,
	title = {Statistics of time warpings and phase variations},
	volume = {8},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1414588152},
	doi = {10.1214/14-EJS901},
	abstract = {Many methods exist for one dimensional curve registration, and how methods compare has not been made clear in the literature. This special section is a summary of a detailed comparison of a number of major methods, done during a recent workshop. The basis of the comparison was simultaneous analysis of a set of four real data sets, which engendered a high level of informative discussion. Most research groups in this area were represented, and many insights were gained, which are discussed here. The format of this special section is four papers introducing the data, each accompanied by a number of analyses by different groups, plus a discussion summary of the lessons learned.},
	language = {EN},
	number = {2},
	urldate = {2020-11-16},
	journal = {Electronic Journal of Statistics},
	author = {Marron, J. S. and Ramsay, James O. and Sangalli, Laura M. and Srivastava, Anuj},
	year = {2014},
	mrnumber = {MR3273584},
	zmnumber = {1305.62015},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Functional data analysis, phase and amplitude variation, registration, warping},
	pages = {1697--1702},
}

@misc{noauthor_ctw_2012,
	title = {{CTW}: {Statistics} of {Time} {Warpings} and {Phase} {Variations}},
	url = {https://archive.mbi.ohio-state.edu/event/?id=162#description},
	urldate = {2020-11-16},
	year = {2012},
}

@article{ramsay_functional_2014,
	title = {Functional data analysis of juggling trajectories: {Rejoinder}},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Functional data analysis of juggling trajectories},
	url = {https://projecteuclid.org/euclid.ejs/1414588175},
	doi = {10.1214/14-EJS937REJ},
	abstract = {Project Euclid - mathematics and statistics online},
	language = {EN},
	number = {2},
	urldate = {2020-11-12},
	journal = {Electronic Journal of Statistics},
	author = {Ramsay, James O.},
	year = {2014},
	mrnumber = {MR3273607},
	zmnumber = {1305.62017},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	pages = {1874--1878},
}

@article{bernardi_analysis_2014,
	title = {Analysis of proteomics data: {Block} \$k\$-mean alignment},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of proteomics data},
	url = {https://projecteuclid.org/euclid.ejs/1414588154},
	doi = {10.1214/14-EJS900A},
	abstract = {We analyze the proteomics data introducing a block kkk-mean alignment procedure. This technique is able to jointly align and cluster the data, accounting appropriately for the block structure of these data, that includes measurement repetitions for each patient. An analysis of area-under-peaks, following the alignment, separates patients who respond and those who do not respond to treatment.},
	language = {EN},
	number = {2},
	urldate = {2020-11-12},
	journal = {Electronic Journal of Statistics},
	author = {Bernardi, Mara and Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone},
	year = {2014},
	mrnumber = {MR3273586},
	zmnumber = {1305.62365},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Block \$k\$-mean alignment, functional clustering, proteomics data, registration},
	pages = {1714--1723},
}

@article{sangalli_analysis_2014,
	title = {Analysis of {AneuRisk65} data: \$k\$-mean alignment},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of {AneuRisk65} data},
	url = {https://projecteuclid.org/euclid.ejs/1414588177},
	doi = {10.1214/14-EJS938A},
	abstract = {We describe the kkk-mean alignment procedure, for the joint alignment and clustering of functional data and we apply it to the analysis of the AneuRisk65 data. Thanks to the efficient separation of the variability in phase variability and within/between clusters amplitude variability, we are able to discriminate subjects having aneurysms in different cerebral districts and identifying different morphological shapes of Inner Carotid Arteries, unveiling a strong association between arteries morphologies and the aneurysmal pathology.},
	language = {EN},
	number = {2},
	urldate = {2020-11-12},
	journal = {Electronic Journal of Statistics},
	author = {Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone},
	year = {2014},
	mrnumber = {MR3273609},
	zmnumber = {1305.62377},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {\$k\$-mean alignment, AneuRisk65 data, functional clustering, registration},
	pages = {1891--1904},
}

@article{bernardi_analysis_2014-1,
	title = {Analysis of juggling data: {An} application of \$k\$-mean alignment},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588168},
	doi = {10.1214/14-EJS937A},
	abstract = {We analyze the juggling data by means of the kkk-mean alignment algorithm using cycles as the experimental units of the analysis. Allowing for affine warping, we detect two clusters distinguishing between mainly-planar trajectories and trajectories tilted toward the body of the juggler in the lower part of the cycle. In particular we detect an anomalous presence of tilted trajectories among the trial third cycles. We also find warping functions to be clustered according to trials suggesting that each trial is performed at a different pace and thus associated to a different typical cycle-duration.},
	language = {EN},
	number = {2},
	urldate = {2020-11-12},
	journal = {Electronic Journal of Statistics},
	author = {Bernardi, Mara and Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone},
	year = {2014},
	mrnumber = {MR3273600},
	zmnumber = {1305.62012},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {\$k\$-mean alignment, functional clustering, juggling data, registration},
	pages = {1817--1824},
}

@article{sangalli_k-mean_2010,
	title = {k-mean alignment for curve clustering},
	volume = {54},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947309004605},
	doi = {10.1016/j.csda.2009.12.008},
	abstract = {The problem of curve clustering when curves are misaligned is considered. A novel algorithm is described, which jointly clusters and aligns curves. The proposed procedure efficiently decouples amplitude and phase variability; in particular, it is able to detect amplitude clusters while simultaneously disclosing clustering structures in the phase, pointing out features that can neither be captured by simple curve clustering nor by simple curve alignment. The procedure is illustrated via simulation studies and applications to real data.},
	language = {en},
	number = {5},
	urldate = {2020-11-12},
	journal = {Computational Statistics \& Data Analysis},
	author = {Sangalli, Laura M. and Secchi, Piercesare and Vantini, Simone and Vitelli, Valeria},
	month = may,
	year = {2010},
	keywords = {-mean algorithm, Curve alignment, Curve clustering, Functional data analysis},
	pages = {1219--1233},
}

@article{ramsay_analysis_2014,
	title = {Analysis of juggling data: {Landmark} and continuous registration of juggling trajectories},
	volume = {8},
	issn = {1935-7524},
	shorttitle = {Analysis of juggling data},
	url = {https://projecteuclid.org/euclid.ejs/1414588170},
	doi = {10.1214/14-EJS937C},
	abstract = {This paper focuses on the two one-dimensional summaries of the three-dimensional juggling data: tangential velocity and tangential acceleration. These are used jointly to define the beginnings and endings of the 123 cycles in the data divided unevenly over ten trials. Two levels of registration were used. The first was a landmark registration of each trial to a periodic image of itself with the period fixed at 712 milliseconds. The 123 tangential velocity cycles were then subjected to a continuous registration over this fixed cycle length. The amounts of across-trial and within-cycle phase variation, respectively, were surprisingly small, indicating tight neural control over the behavior. Within-cycle phase variation was primarily due to variation in the trajectories of the ball between throw and catch.},
	language = {EN},
	number = {2},
	urldate = {2020-11-08},
	journal = {Electronic Journal of Statistics},
	author = {Ramsay, James O. and Gribble, Paul and Kurtek, Sebastian},
	year = {2014},
	mrnumber = {MR3273602},
	zmnumber = {1305.62019},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Functional data analysis, continuous registration, juggling trajectories, landmark registration, phase variation},
	pages = {1835--1841},
}

@article{kipp_bivariate_2020,
	title = {Bivariate functional principal component analysis of barbell trajectories during the snatch},
	volume = {0},
	issn = {1476-3141},
	url = {https://doi.org/10.1080/14763141.2020.1820074},
	doi = {10.1080/14763141.2020.1820074},
	abstract = {The purpose of this study was to use bivariate functional principal components analysis (bfPCA) to quantify patterns in barbell trajectories during the snatch and to investigate whether these patterns correlate with weightlifting performance and biomechanical characteristics that characterise weightlifting technique. A motion capture system was used to record three-dimensional barbell trajectories as six weightlifters performed three snatch lifts during a weightlifting competition. Horizontal and vertical barbell positions of all lifts were used as input to a bfPCA. Weightlifting performance was quantified through the ratio of barbell mass/body-mass, whereas biomechanical variables were quantified through peak vertical barbell velocity and acceleration. The bfPCA extracted barbell trajectory patterns related to variations in general forward/backward motion (pattern 1), peak height (pattern 2), and crossing of the vertical reference line during the first pull (pattern 3). Spearman rank correlations showed that pattern 1 correlated positively with weightlifting performance and negatively with peak barbell velocity and acceleration. The opposite results were found for pattern 3. Interpretation of the extracted barbell trajectory patterns and statistical results suggest that better weightlifting performances were characterised by snatch lifts that exhibited general backward shifts and limited forward motions during the first and second pull, regardless of peak heights.},
	number = {0},
	urldate = {2020-11-05},
	journal = {Sports Biomechanics},
	author = {Kipp, Kristof and Cunanan, Aaron J. and Warmenhoven, John},
	month = oct,
	year = {2020},
	pmid = {33112700},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763141.2020.1820074},
	keywords = {Biomechanics, bar path, pattern classification, sports, weightlifting},
	pages = {1--11},
}

@article{abramovich_optimal_2004,
	title = {Optimal {Testing} in a {Fixed}-{Effects} {Functional} {Analysis} of {Variance} {Model}},
	doi = {10.1142/S0219691304000639},
	abstract = {We consider the testing problem in a fixed-effects functional analysis of variance model. We test the null hypotheses that the functional main effects and the functional interactions are zeros against the composite nonparametric alternative hypotheses that they are separated away from zero in L2-norm and also possess some smoothness properties. We adapt the optimal (minimax) hypothesis testing procedures for testing a zero signal in a Gaussian "signal plus noise" model to derive optimal (minimax) non-adaptive and adaptive hypothesis testing procedures for the functional main effects and the functional interactions. The corresponding tests are based on the empirical wavelet coefficients of the data. Wavelet decompositions allow one to characterize different types of smoothness conditions assumed on the response function by means of its wavelet coefficients for a wide range of function classes. In order to shed some light on the theoretical results obtained, we carry out a simulation study to examine the finite sample performance of the proposed functional hypothesis testing procedures. As an illustration, we also apply these tests to a real-life data example arising from physiology. Concluding remarks and hints for possible extensions of the proposed methodology are also given.},
	journal = {Int. J. Wavelets Multiresolution Inf. Process.},
	author = {Abramovich, Felix and Antoniadis, A. and Sapatinas, T. and Vidakovic, B.},
	year = {2004},
}

@article{antoniadis_estimation_2007,
	title = {Estimation and inference in functional mixed-effects models},
	volume = {51},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947306003628},
	doi = {10.1016/j.csda.2006.09.038},
	abstract = {Functional mixed-effects models are very useful in analyzing functional data. A general functional mixed-effects model that inherits the flexibility of linear mixed-effects models in handling complex designs and correlation structures is considered. A wavelet decomposition approach is used to model both fixed-effects and random-effects in the same functional space, meaning that the population-average curve and the subject-specific curves have the same smoothness property. A linear mixed-effects representation is then obtained that is used for estimation and inference in the general functional mixed-effects model. Adapting recent methodologies in linear mixed-effects and nonparametric regression models, hypothesis testing procedures for both fixed-effects and random-effects are provided. Using classical linear mixed-effects estimation techniques, the linear mixed-effects representation is also used to obtain wavelet-based estimates for both fixed-effects and random-effects in the general functional mixed-effects model. The usefulness of the proposed estimation and hypothesis testing procedures is illustrated by means of a small simulation study and a real-life dataset arising from physiology.},
	language = {en},
	number = {10},
	urldate = {2020-10-13},
	journal = {Computational Statistics \& Data Analysis},
	author = {Antoniadis, Anestis and Sapatinas, Theofanis},
	month = jun,
	year = {2007},
	keywords = {Functional data, Linear mixed-effects models, Nonparametric hypothesis testing, Smoothing spline estimation, Wavelet estimation},
	pages = {4793--4813},
}

@article{yao_functional_2005,
	title = {Functional {Data} {Analysis} for {Sparse} {Longitudinal} {Data}},
	volume = {100},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/27590579},
	abstract = {We propose a nonparametric method to perform functional principal components analysis for the case of sparse longitudinal data. The method aims at irregularly spaced longitudinal data, where the number of repeated measurements available per subject is small. In contrast, classical functional data analysis requires a large number of regularly spaced measurements per subject. We assume that the repeated measurements are located randomly with a random number of repetitions for each subject and are determined by an underlying smooth random (subject-specific) trajectory plus measurement errors. Basic elements of our approach are the parsimonious estimation of the covariance structure and mean function of the trajectories, and the estimation of the variance of the measurement errors. The eigenfunction basis is estimated from the data, and functional principal components score estimates are obtained by a conditioning step. This conditional estimation method is conceptually simple and straightforward to implement. A key step is the derivation of asymptotic consistency and distribution results under mild conditions, using tools from functional analysis. Functional data analysis for sparse longitudinal data enables prediction of individual smooth trajectories even if only one or few measurements are available for a subject. Asymptotic pointwise and simultaneous confidence bands are obtained for predicted individual trajectories, based on asymptotic distributions, for simultaneous bands under the assumption of a finite number of components. Model selection techniques, such as the Akaike information criterion, are used to choose the model dimension corresponding to the number of eigenfunctions in the model. The methods are illustrated with a simulation study, longitudinal CD4 data for a sample of AIDS patients, and time-course gene expression data for the yeast cell cycle.},
	number = {470},
	urldate = {2020-10-12},
	journal = {Journal of the American Statistical Association},
	author = {Yao, Fang and Müller, Hans-Georg and Wang, Jane-Ling},
	year = {2005},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {577--590},
}

@article{abramovich_testing_2006,
	title = {Testing in mixed-effects {FANOVA} models},
	volume = {136},
	issn = {0378-3758},
	url = {http://www.sciencedirect.com/science/article/pii/S0378375805001400},
	doi = {10.1016/j.jspi.2005.06.002},
	abstract = {We consider the testing problem in the mixed-effects functional analysis of variance models. We develop asymptotically optimal (minimax) testing procedures for testing the significance of functional global trend and the functional fixed effects based on the empirical wavelet coefficients of the data. Wavelet decompositions allow one to characterize various types of assumed smoothness conditions on the response function under the nonparametric alternatives. The distribution of the functional random-effects component is defined in the wavelet domain and captures the sparseness of wavelet representation for a wide variety of functions. The simulation study presented in the paper demonstrates the finite sample properties of the proposed testing procedures. We also applied them to the real data from the physiological experiments.},
	language = {en},
	number = {12},
	urldate = {2020-10-12},
	journal = {Journal of Statistical Planning and Inference},
	author = {Abramovich, Felix and Angelini, Claudia},
	month = dec,
	year = {2006},
	keywords = {Besov spaces, Functional analysis of variance, Functional hypothesis testing, Mixed effects, Wavelets},
	pages = {4326--4348},
}

@article{gorecki_fdanova_2018,
	title = {{fdANOVA}: an {R} software package for analysis of variance for univariate and multivariate functional data},
	shorttitle = {{fdANOVA}},
	doi = {10.1007/s00180-018-0842-7},
	abstract = {Functional data, i.e., observations represented by curves or functions, frequently arise in various fields. The theory and practice of statistical methods for such data is referred to as functional data analysis (FDA) which is one of major research fields in statistics. The practical use of FDA methods is made possible thanks to availability of specialized and usually free software. In particular, a number of R packages is devoted to these methods. In the paper, we introduce a new R package fdANOVA which provides an access to a broad range of global analysis of variance methods for univariate and multivariate functional data. The implemented testing procedures mainly for homoscedastic case are briefly overviewed and illustrated by examples on a well known functional data set. To reduce the computation time, parallel implementation is developed and its efficiency is empirically evaluated. Since some of the implemented tests have not been compared in terms of size control and power yet, appropriate simulations are also conducted. Their results can help in choosing proper testing procedures in practice.},
	journal = {Computational Statistics},
	author = {Górecki, Tomasz and Smaga, Łukasz},
	month = sep,
	year = {2018},
}

@book{penny_statistical_2011,
	title = {Statistical {Parametric} {Mapping}: {The} {Analysis} of {Functional} {Brain} {Images}},
	isbn = {978-0-08-046650-7},
	shorttitle = {Statistical {Parametric} {Mapping}},
	abstract = {In an age where the amount of data collected from brain imaging is increasing constantly, it is of critical importance to analyse those data within an accepted framework to ensure proper integration and comparison of the information collected. This book describes the ideas and procedures that underlie the analysis of signals produced by the brain. The aim is to understand how the brain works, in terms of its functional architecture and dynamics. This book provides the background and methodology for the analysis of all types of brain imaging data, from functional magnetic resonance imaging to magnetoencephalography. Critically, Statistical Parametric Mapping provides a widely accepted conceptual framework which allows treatment of all these different modalities. This rests on an understanding of the brain's functional anatomy and the way that measured signals are caused experimentally. The book takes the reader from the basic concepts underlying the analysis of neuroimaging data to cutting edge approaches that would be difficult to find in any other source. Critically, the material is presented in an incremental way so that the reader can understand the precedents for each new development. This book will be particularly useful to neuroscientists engaged in any form of brain mapping; who have to contend with the real-world problems of data analysis and understanding the techniques they are using. It is primarily a scientific treatment and a didactic introduction to the analysis of brain imaging data. It can be used as both a textbook for students and scientists starting to use the techniques, as well as a reference for practicing neuroscientists. The book also serves as a companion to the software packages that have been developed for brain imaging data analysis.An essential reference and companion for users of the SPM softwareProvides a complete description of the concepts and procedures entailed by the analysis of brain imagesOffers full didactic treatment of the basic mathematics behind the analysis of brain imaging dataStands as a compendium of all the advances in neuroimaging data analysis over the past decadeAdopts an easy to understand and incremental approach that takes the reader from basic statistics to state of the art approaches such as Variational BayesStructured treatment of data analysis issues that links different modalities and modelsIncludes a series of appendices and tutorial-style chapters that makes even the most sophisticated approaches accessible},
	language = {en},
	publisher = {Elsevier},
	author = {Penny, William D. and Friston, Karl J. and Ashburner, John T. and Kiebel, Stefan J. and Nichols, Thomas E.},
	month = apr,
	year = {2011},
	note = {Google-Books-ID: G\_qdEsDlkp0C},
	keywords = {Medical / Neurology, Medical / Neuroscience, Science / Life Sciences / Neuroscience},
}

@article{pataky_generalized_2010,
	title = {Generalized n-dimensional biomechanical field analysis using statistical parametric mapping},
	volume = {43},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929010001533},
	doi = {10.1016/j.jbiomech.2010.03.008},
	abstract = {A variety of biomechanical data are sampled from smooth n-dimensional spatiotemporal fields. These data are usually analyzed discretely, by extracting summary metrics from particular points or regions in the continuum. It has been shown that, in certain situations, such schemes can compromise the spatiotemporal integrity of the original fields. An alternative methodology called statistical parametric mapping (SPM), designed specifically for continuous field analysis, constructs statistical images that lie in the original, biomechanically meaningful sampling space. The current paper demonstrates how SPM can be used to analyze both experimental and simulated biomechanical field data of arbitrary spatiotemporal dimensionality. Firstly, 0-, 1-, 2-, and 3-dimensional spatiotemporal datasets derived from a pedobarographic experiment were analyzed using a common linear model to emphasize that SPM procedures are (practically) identical irrespective of the data's physical dimensionality. Secondly two probabilistic finite element simulation studies were conducted, examining heel pad stress and femoral strain fields, respectively, to demonstrate how SPM can be used to probe the significance of field-wide simulation results in the presence of uncontrollable or induced modeling uncertainty. Results were biomechanically intuitive and suggest that SPM may be suitable for a wide variety of mechanical field applications. SPM's main theoretical advantage is that it avoids problems associated with a priori assumptions regarding the spatiotemporal foci of field signals. SPM's main practical advantage is that a unified framework, encapsulated by a single linear equation, affords comprehensive statistical analyses of smooth scalar fields in arbitrarily bounded n-dimensional spaces.},
	language = {en},
	number = {10},
	urldate = {2020-10-08},
	journal = {Journal of Biomechanics},
	author = {Pataky, Todd C.},
	month = jul,
	year = {2010},
	keywords = {Mechanical deformation fields, Multivariate statistics, Pedobarography, Probabilistic finite element analysis, Random field theory},
	pages = {1976--1982},
}

@article{pataky_one-dimensional_2012,
	title = {One-dimensional statistical parametric mapping in {Python}},
	volume = {15},
	issn = {1025-5842},
	url = {https://doi.org/10.1080/10255842.2010.527837},
	doi = {10.1080/10255842.2010.527837},
	abstract = {Statistical parametric mapping (SPM) is a topological methodology for detecting field changes in smooth n-dimensional continua. Many classes of biomechanical data are smooth and contained within discrete bounds and as such are well suited to SPM analyses. The current paper accompanies release of ‘SPM1D’, a free and open-source Python package for conducting SPM analyses on a set of registered 1D curves. Three example applications are presented: (i) kinematics, (ii) ground reaction forces and (iii) contact pressure distribution in probabilistic finite element modelling. In addition to offering a high-level interface to a variety of common statistical tests like t tests, regression and ANOVA, SPM1D also emphasises fundamental concepts of SPM theory through stand-alone example scripts. Source code and documentation are available at: www.tpataky.net/spm1d/.},
	number = {3},
	urldate = {2020-10-08},
	journal = {Computer Methods in Biomechanics and Biomedical Engineering},
	author = {Pataky, Todd C.},
	month = mar,
	year = {2012},
	pmid = {21756121},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10255842.2010.527837},
	keywords = {ground reaction force, kinematic trajectory analysis, object-oriented programming, open-source software, probabilistic finite element modelling, topological statistics},
	pages = {295--301},
}

@article{shen_f_2004,
	title = {An {F} test for linear models with functional responses},
	volume = {14},
	issn = {1017-0405},
	url = {https://researchportal.bath.ac.uk/en/publications/an-f-test-for-linear-models-with-functional-responses},
	language = {English},
	number = {4},
	urldate = {2020-10-08},
	journal = {Statistica Sinica},
	author = {Shen, Q. and Faraway, J.},
	year = {2004},
	note = {Publisher: Institute of Statistical Science},
	pages = {1239--1257},
}

@article{chau_managing_2005,
	title = {Managing variability in the summary and comparison of gait data},
	volume = {2},
	issn = {1743-0003},
	url = {https://doi.org/10.1186/1743-0003-2-22},
	doi = {10.1186/1743-0003-2-22},
	abstract = {Variability in quantitative gait data arises from many potential sources, including natural temporal dynamics of neuromotor control, pathologies of the neurological or musculoskeletal systems, the effects of aging, as well as variations in the external environment, assistive devices, instrumentation or data collection methodologies. In light of this variability, unidimensional, cycle-based gait variables such as stride period should be viewed as random variables and prototypical single-cycle kinematic or kinetic curves ought to be considered as random functions of time. Within this framework, we exemplify some practical solutions to a number of commonly encountered analytical challenges in dealing with gait variability. On the topic of univariate gait variables, robust estimation is proposed as a means of coping with contaminated gait data, and the summary of non-normally distributed gait data is demonstrated by way of empirical examples. On the summary of gait curves, we discuss methods to manage undesirable phase variation and non-robust spread estimates. To overcome the limitations of conventional comparisons among curve landmarks or parameters, we propose as a viable alternative, the combination of curve registration, robust estimation, and formal statistical testing of curves as coherent units. On the basis of these discussions, we provide heuristic guidelines for the summary of gait variables and the comparison of gait curves.},
	number = {1},
	urldate = {2020-10-08},
	journal = {Journal of NeuroEngineering and Rehabilitation},
	author = {Chau, Tom and Young, Scott and Redekop, Sue},
	month = jul,
	year = {2005},
	pages = {22},
}

@article{fan_test_1998,
	title = {Test of {Significance} {When} {Data} {Are} {Curves}},
	volume = {93},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2669845},
	doi = {10.2307/2669845},
	abstract = {With modern technology, massive data can easily be collected in a form of multiple sets of curves. New statistical challenge includes testing whether there is any statistically significant difference among these sets of curves. In this article we propose some new tests for comparing two groups of curves based on the adaptive Neyman test and the wavelet thresholding techniques introduced earlier by Fan. We demonstrate that these tests inherit the properties outlined by Fan and that they are simple and powerful for detecting differences between two sets of curves. We then further generalize the idea to compare multiple sets of curves, resulting in an adaptive high-dimensional analysis of variance, called HANOVA. These newly developed techniques are illustrated by using a dataset on pizza commercials where observations are curves and an analysis of cornea topography in ophthalmology where images of individuals are observed. A simulation example is also presented to illustrate the power of the adaptive Neyman test.},
	number = {443},
	urldate = {2020-10-08},
	journal = {Journal of the American Statistical Association},
	author = {Fan, Jianqing and Lin, Sheng-Kuei},
	year = {1998},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1007--1021},
}

@article{pini_interval_2016,
	title = {The interval testing procedure: {A} general framework for inference in functional data analysis},
	volume = {72},
	copyright = {© 2016, The International Biometric Society},
	issn = {1541-0420},
	shorttitle = {The interval testing procedure},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12476},
	doi = {10.1111/biom.12476},
	abstract = {We introduce in this work the Interval Testing Procedure (ITP), a novel inferential technique for functional data. The procedure can be used to test different functional hypotheses, e.g., distributional equality between two or more functional populations, equality of mean function of a functional population to a reference. ITP involves three steps: (i) the representation of data on a (possibly high-dimensional) functional basis; (ii) the test of each possible set of consecutive basis coefficients; (iii) the computation of the adjusted p-values associated to each basis component, by means of a new strategy here proposed. We define a new type of error control, the interval-wise control of the family wise error rate, particularly suited for functional data. We show that ITP is provided with such a control. A simulation study comparing ITP with other testing procedures is reported. ITP is then applied to the analysis of hemodynamical features involved with cerebral aneurysm pathology. ITP is implemented in the fdatest R package.},
	language = {en},
	number = {3},
	urldate = {2020-10-07},
	journal = {Biometrics},
	author = {Pini, Alessia and Vantini, Simone},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12476},
	keywords = {Family wise error rate, Functional data analysis, Inference, Multiple comparison, Permutation method},
	pages = {835--845},
}

@article{tengman_anterior_2015,
	title = {Anterior cruciate ligament injury about 20 years post-treatment: {A} kinematic analysis of one-leg hop},
	volume = {25},
	issn = {1600-0838},
	shorttitle = {Anterior cruciate ligament injury about 20 years post-treatment},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.12434},
	doi = {10.1111/sms.12434},
	abstract = {Reduced dynamic knee stability, often evaluated with one-leg hops (OLHs), is reported after anterior cruciate ligament (ACL) injury. This may lead to long-standing altered movement patterns, which are less investigated. 3D kinematics during OLH were explored in 70 persons 23 ± 2 years after ACL injury; 33 were treated with physiotherapy in combination with ACL reconstruction (ACLR) and 37 with physiotherapy alone (ACLPT). Comparisons were made to 33 matched controls. We analyzed (a) maximal knee joint angles and range of motion (flexion, abduction, rotation); (b) medio-lateral position of the center of mass (COM) in relation to knee and ankle joint centers, during take-off and landing phases. Unlike controls, ACL-injured displayed leg asymmetries: less knee flexion and less internal rotation at take-off and landing and more lateral COM related to knee and ankle joint of the injured leg at landing. Compared to controls, ACLR had larger external rotation of the injured leg at landing. ACLPT showed less knee flexion and larger external rotation at take-off and landing, and larger knee abduction at Landing. COM was more medial in relation to the knee at take-off and less laterally placed relative to the ankle at landing. ACL injury results in long-term kinematic alterations during OLH, which are less evident for ACLR.},
	language = {en},
	number = {6},
	urldate = {2020-10-07},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Tengman, E. and Grip, H. and Stensdotter, Ak and Häger, C. K.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.12434},
	keywords = {Biomechanics, jump performance, knee, long-term perspective},
	pages = {818--827},
}

@article{pietrosimone_walking_2019,
	title = {Walking {Ground} {Reaction} {Force} {Post}-{ACL} {Reconstruction}: {Analysis} of {Time} and {Symptoms}},
	volume = {51},
	issn = {0195-9131},
	shorttitle = {Walking {Ground} {Reaction} {Force} {Post}-{ACL} {Reconstruction}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6335151/},
	doi = {10.1249/MSS.0000000000001776},
	abstract = {Purpose:
The association between lower-extremity loading and clinically-relevant knee symptoms at different time points following anterior cruciate ligament reconstruction (ACLR) is unclear. Vertical ground reaction force (vGRF) from walking was compared between individuals with and without clinically-relevant knee symptoms in three cohorts: {\textless}12 months post-ACLR, 12–24 months post-ACLR, and {\textgreater}24 months post-ACLR.

Methods:
128 individuals with unilateral ACLR were classified as symptomatic or asymptomatic, based on previously-defined cutoff values for the Knee Osteoarthritis and Injury Outcome Score ({\textless}12 months post-ACLR [symptomatic n=28, asymptomatic n=24]; 12–24 months post-ACLR [symptomatic n=15, asymptomatic n=15], and {\textgreater}24 months post-ACLR [symptomatic n=13, asymptomatic n=33]). vGRF exerted on the ACLR limb was collected during walking gait, and functional analyses of variance were used to evaluate the effects of symptoms and time post-ACLR on vGRF throughout stance phase (α=0.05).

Results:
Symptomatic individuals, {\textless}12 months post-ACLR, demonstrated less vGRF during both vGRF peaks (i.e. weight acceptance and propulsion) and greater vGRF during midstance, compared to asymptomatic individuals. vGRF characteristics were not different between symptomatic and asymptomatic individuals for most of stance in individuals between 12 and 24 months post-ACLR. Symptomatic individuals who were {\textgreater}24 months post-ACLR, exhibited greater vGRF during both peaks, but lesser vGRF during midstance, compared to asymptomatic individuals.

Conclusion:
Relative to asymptomatic individuals, symptomatic individuals are more likely to underload the ACLR limb early following ACLR (i.e., {\textless}12 months) during both vGRF peaks, but overload the ACLR limb, during both vGRF peaks, at later time points (i.e., {\textgreater}24 months). We propose these differences in lower extremity loading during walking might have implications for long-term knee health, and should be considered when designing therapeutic interventions for individuals with an ACLR.},
	number = {2},
	urldate = {2020-10-02},
	journal = {Medicine and science in sports and exercise},
	author = {Pietrosimone, Brian and Seeley, Matthew K. and Johnston, Christopher and Pfeiffer, Steven J. and Spang, Jeffery T. and Blackburn, J. Troy},
	month = feb,
	year = {2019},
	pmid = {30157111},
	pmcid = {PMC6335151},
	pages = {246--254},
}

@article{passmore_hip-_2018,
	title = {Hip- and patellofemoral-joint loading during gait are increased in children with idiopathic torsional deformities},
	volume = {63},
	issn = {0966-6362},
	url = {http://www.sciencedirect.com/science/article/pii/S0966636218305071},
	doi = {10.1016/j.gaitpost.2018.05.003},
	abstract = {Background
Torsional deformities of the femur and tibia are associated with gait impairments and joint pain. Several studies have investigated these gait deviations in children with cerebral palsy. However, relatively little is known about gait deviations in children with idiopathic torsion and debate ensues about the management of these patients.
Research question
What are the effects of idiopathic increased femoral neck anteversion and external tibial torsion on lower-limb kinematics, kinetics and joint loading during gait in children and adolescents.
Methods
Patient-specific musculoskeletal models were created for 12 children/adolescents (mean age of 14 years) with torsional deformities using low-dose biplane radiographic imaging and 3D gait analysis. Comparisons of joint motion and net joint torques during gait were made to an age-matched control group with no torsional deformities. The effects of torsional deformities on muscle and joint contact forces were investigated using two personalised musculoskeletal models: one with normal torsion and another with patient-specific torsion.
Results
Femoral neck anteversion and external tibial torsion for the patients were (mean ± SD) 38° ± 9° and 40° ± 10°, respectively. Patients had increased internal hip rotation and external knee rotation as well as increased pelvic tilt during gait. Additionally, the efficacy of the plantarflexor-knee extension mechanism was diminished. Hip joint contact force was higher in the model with patient-specific torsion. The mediolateral component of the patellofemoral joint contact force was also increased despite the magnitude of the resultant patellofemoral contact force being unchanged.
Significance
It has been previously established that idiopathic lower-limb torsional deformities alter gait kinematics. However, this study also showed that loading of the hip and patellofemoral joints are increased. This is an important insight for the clinical management of these patients and highlights that idiopathic lower-limb torsional deformities are not a purely cosmetic issue.},
	language = {en},
	urldate = {2020-10-02},
	journal = {Gait \& Posture},
	author = {Passmore, Elyse and Graham, H. Kerr and Pandy, Marcus G. and Sangeux, Morgan},
	month = jun,
	year = {2018},
	keywords = {3D gait analysis, Biplanar radiographs, External tibial torsion, Femoral neck anteversion, Patient-specific musculoskeletal modelling},
	pages = {228--235},
}

@article{sangeux_slipped_2014,
	title = {Slipped capital femoral epiphysis, fixation by single screw in situ: {A} kinematic and radiographic study},
	volume = {29},
	issn = {1879-1271},
	shorttitle = {Slipped capital femoral epiphysis, fixation by single screw in situ},
	doi = {10.1016/j.clinbiomech.2014.03.012},
	abstract = {BACKGROUND: Slipped capital femoral epiphysis is known to produce characteristic deformities in the proximal femur, which affect hip motion and may cause a limp. This paper assessed the 3D gait kinematics in adolescents after single screw fixation of moderate to severe, stable, unilateral slipped capital femoral epiphysis. Our goals were to characterize the 3D kinematic patterns and to investigate the correlation between the severity of radiological deformity and severity of gait disturbance.
METHODS: This was a retrospective study of patients seen at our institution between 2000 and 2009. Antero-posterior and frog lateral X-rays were reviewed to measure: Southwick's lateral slip angle, the alpha angle of Notzli and Klein's line offset. Quantitative 3D gait data was collected using a state of the art motion capture system. Kinematic waveforms were compared using a functional data analysis version of the t-test.
FINDINGS: There were 30 patients with an average age at pinning of 13y (10-17y). Mean gait profile scores were significantly abnormal for slipped side (10.8°) versus sound side (6.8°), slipped side versus normal (5.6°) and sound side versus normal. There was little statistically significant correlation between severity of radiographic deformity and degree of gait disturbance.
INTERPRETATION: Major kinematic pattern deviations could be associated with (a) morphology of the proximal femur and potential femoral acetabular impingement problems and (b) leg length discrepancy. Gait analysis was able to quantify the kinematic deviations due to the anatomical deformities.},
	language = {eng},
	number = {5},
	journal = {Clinical Biomechanics (Bristol, Avon)},
	author = {Sangeux, Morgan and Passmore, Elyse and Gomez, Glenn and Balakumar, Jitendra and Graham, H. Kerr},
	month = may,
	year = {2014},
	pmid = {24768225},
	keywords = {Adolescent, Biomechanical Phenomena, Bone Screws, Child, Female, Femur Head, Gait, Hip Joint, Humans, Leg Length Inequality, Male, Radiography, Retrospective Studies, Slipped Capital Femoral Epiphyses, Young Adult},
	pages = {523--530},
}

@article{roislien_simultaneous_2009,
	title = {Simultaneous estimation of effects of gender, age and walking speed on kinematic gait data},
	volume = {30},
	issn = {0966-6362},
	url = {http://www.sciencedirect.com/science/article/pii/S0966636209001957},
	doi = {10.1016/j.gaitpost.2009.07.002},
	abstract = {Analysis of variations in normal gait has received considerable attention over the last years. However, most such analyses are carried out on one explanatory variable at a time, and adjustments for other possibly influencing factors are often done using ad hoc methods. As a result, it can be difficult to know whether observed effects are actually a result of the variable under study. We wanted to simultaneously statistically test the effect of gender, age and walking speed on gait in a normal population, while also properly adjusting for the possibly confounding effects of body height and weight. Since point-by-point analysis does not take into account the time dependency in the data, we turned to functional data analysis (FDA). In FDA the whole gait curve is represented not by a set of points, but by a mathematical function spanning the whole gait cycle. We performed several multiple functional regression analyses, and the results indicate that walking speed is the main factor influencing gait in the reference material at our motion analysis laboratory. This effect is also largely unaffected by the presence of other variables in the model. A gender effect was also apparent in several planes and joints, but this effect was often more outspoken in the multiple than in the univariate regression analyses, highlighting the importance of adjusting for confounders like body height and weight.},
	language = {en},
	number = {4},
	urldate = {2020-10-02},
	journal = {Gait \& Posture},
	author = {Røislien, Jo and Skare, Øivind and Gustavsen, Marit and Broch, Nana L. and Rennie, Linda and Opheim, Arve},
	month = nov,
	year = {2009},
	keywords = {Functional data analysis, Kinematic gait data, Reference population, Simultaneous estimation},
	pages = {441--445},
}

@article{andrade_functional_2014,
	title = {Functional data analyses for the assessment of joint power profiles during gait of stroke subjects},
	volume = {30},
	issn = {1543-2688},
	doi = {10.1123/jab.2013-0147},
	abstract = {Lower extremity kinetic data during walking of 12 people with chronic poststroke were reanalyzed, using functional analysis of variance (FANOVA). To perform the FANOVA, the whole curve is represented by a mathematical function, which spans the whole gait cycle and avoids the need to identify isolated points, as required for traditional parametric analyses of variance (ANOVA). The power variables at the ankle, knee, and hip joints, in the sagittal plane, were compared between two conditions: With and without walking sticks at comfortable and fast speeds. For the ankle joint, FANOVA demonstrated increases in plantar flexion power generation during 60-80\% of the gait cycle between fast and comfortable speeds with the use of walking sticks. For the knee joint, the use of walking sticks resulted in increases in the knee extension power generation during 10-30\% of the gait cycle. During both speeds, the use of walking sticks resulted in increased power generation by the hip extensors and flexors during 10-30\% and 40-70\% of the gait cycle, respectively. These findings demonstrated the benefits of applying the FANOVA approach to improve the knowledge regarding the effects of walking sticks on gait biomechanics and encourage its use within other clinical contexts.},
	language = {eng},
	number = {2},
	journal = {Journal of Applied Biomechanics},
	author = {Andrade, André G. P. and Polese, Janaine C. and Paolucci, Leopoldo A. and Menzel, Hans-Joachim K. and Teixeira-Salmela, Luci F.},
	month = apr,
	year = {2014},
	pmid = {24145625},
	keywords = {Analysis of Variance, Ankle Joint, Biomechanical Phenomena, Canes, Female, Gait Disorders, Neurologic, Hip Joint, Humans, Knee Joint, Male, Middle Aged, Stroke},
	pages = {348--352},
}

@article{son_movement_2017,
	title = {Movement {Strategies} among {Groups} of {Chronic} {Ankle} {Instability}, {Coper}, and {Control}},
	volume = {49},
	issn = {1530-0315},
	doi = {10.1249/MSS.0000000000001255},
	abstract = {INTRODUCTION: Comprehensive evaluation of movement strategies during functional movement is a difficult undertaking. Because of this challenge, studied movements have been oversimplified. Furthermore, evaluating movement strategies at only a discrete time point(s) provide limited insight into how movement strategies may change or adapt in chronic ankle instability (CAI) patients. This study aimed to identify abnormal movement strategies in individuals with a history of ankle sprain injury during a sports maneuver compared with healthy controls.
METHODS: Sixty-six participants, consisting of 22 CAI patients, 22 ankle sprain copers, and 22 healthy controls, participated in this study. Functional profiles of lower extremity kinematics, kinetics, and EMG activation from initial contact (0\% of stance) to toe-off (100\% of stance) were collected and analyzed during a jump landing/cutting task using a functional data analysis approach.
RESULTS: Compared with copers, CAI patients displayed landing positions of less plantarflexion, less inversion, more knee flexion, more hip flexion, and less hip abduction during the first 25\% of stance. However, restricted dorsiflexion angle was observed in both CAI patients and copers relative to controls during the midlanding to mid-side-cutting phase when the ankle and knee reached its peak range of motion (e.g., dorsiflexion and knee flexion). Reduced EMG activation of tibialis anterior, peroneus longus, medial gastrocnemius, and gluteus medius may be due to altered kinematics that reduce muscular demands on the involved muscles.
CONCLUSIONS: CAI patients displayed altered movement strategies, perhaps in an attempt to avoid perceived positions of risk. Although sagittal joint positions seemed to increase the external torque on the knee and hip extensors, frontal joint positions appeared to reduce the muscular demands on evertor and hip abductor muscles.},
	language = {eng},
	number = {8},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Son, S. Jun and Kim, Hyunsoo and Seeley, Matthew K. and Hopkins, J. Ty},
	year = {2017},
	pmid = {28350716},
	keywords = {Adolescent, Adult, Ankle Injuries, Ankle Joint, Biomechanical Phenomena, Electromyography, Female, Humans, Joint Instability, Lower Extremity, Male, Movement, Muscle, Skeletal, Task Performance and Analysis, Young Adult},
	pages = {1649--1661},
}

@article{son_efficacy_2017,
	title = {Efficacy of {Sensory} {Transcutaneous} {Electrical} {Nerve} {Stimulation} on {Perceived} {Pain} and {Gait} {Patterns} in {Individuals} {With} {Experimental} {Knee} {Pain}},
	volume = {98},
	issn = {1532-821X},
	doi = {10.1016/j.apmr.2016.05.022},
	abstract = {OBJECTIVES: To examine the effect of experimental knee pain on perceived knee pain and gait patterns and to examine the efficacy of transcutaneous electrical nerve stimulation (TENS) on perceived knee pain and pain-induced knee gait mechanics.
DESIGN: Crossover trial.
SETTING: Biomechanics laboratory.
PARTICIPANTS: Recreationally active, individuals without musculoskeletal pain aged 18 to 35 years (N=30).
INTERVENTIONS: Thirty able-bodied individuals were assigned to either a TENS (n=15) or a placebo (n=15) group. All participants completed 3 experimental sessions in a counterbalanced order separated by 2 days: (1) hypertonic saline infusion (5\% NaCl); (2) isotonic saline infusion (0.9\% NaCl); and (3) control. Each group received sensory electrical stimulation or placebo treatment for 20 minutes, respectively.
MAIN OUTCOME MEASURES: Perceived pain was collected every 2 minutes using a 10-cm visual analog scale (VAS) for 50 minutes and analyzed using a mixed model analysis of covariance with repeated measures. Gait analyses were performed at baseline, infusion, and treatment. Sagittal and frontal knee angles and internal net joint torque across the entire stance were analyzed using a functional data analysis approach.
RESULTS: Hypertonic saline infusion increased perceived pain (4/10cm on a VAS; P{\textless}.05) and altered right knee angle (more flexion and less abduction; P{\textless}.05) and internal net joint torque (less extension and greater abduction; P{\textless}.05) across various stance phases. TENS treatment reduced perceived pain and improved right sagittal gait abnormalities as compared with placebo treatment (P{\textless}.05).
CONCLUSIONS: This pain model increases perceived pain and induces compensatory gait patterns in a way that indicates potential quadriceps weakness. However, TENS treatment effectively reduces perceived pain and restores pain-induced gait abnormalities in sagittal knee mechanics.},
	language = {eng},
	number = {1},
	journal = {Archives of Physical Medicine and Rehabilitation},
	author = {Son, S. Jun and Kim, Hyunsoo and Seeley, Matthew K. and Hopkins, J. Ty},
	year = {2017},
	pmid = {27343344},
	keywords = {Adult, Afferent Pathways, Arthralgia, Biomechanical Phenomena, Cartilage, Cross-Over Studies, Female, Gait, Humans, Knee Joint, Male, Osteoarthritis, Pain Measurement, Pain Perception, Patellofemoral pain syndrome, Physical therapy modalities, Quadriceps muscle, Rehabilitation, Saline Solution, Hypertonic, Torque, Transcutaneous Electric Nerve Stimulation, Young Adult},
	pages = {25--35},
}

@article{baumgart_phase-specific_2017,
	title = {Phase-{Specific} {Ground} {Reaction} {Force} {Analyses} of {Bilateral} and {Unilateral} {Jumps} in {Patients} {With} {ACL} {Reconstruction}},
	volume = {5},
	issn = {2325-9671},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5480638/},
	doi = {10.1177/2325967117710912},
	abstract = {Background:
In patients who have undergone anterior cruciate ligament (ACL) reconstruction, there is a weak correlation between subjective evaluation of knee function on questionnaires and clinical or biomechanical test results.

Hypothesis:
Patients with lower subjective knee function will demonstrate lower ground-reaction forces (GRFs) in the operated leg and greater GRF asymmetries in both phase-specific and functional data analysis (FDA) approaches compared with patients with higher subjective knee function.

Study Design:
Descriptive laboratory study.

Methods:
The GRFs of the operated and nonoperated legs of 40 patients who previously underwent ACL reconstruction (patellar tendon) were analyzed during unilateral and bilateral countermovement jumps at a mean 2.5 years after surgery. The patients were separated into 2 groups depending on their International Knee Documentation Committee (IKDC) Subjective Form score: low IKDC and high IKDC.

Results:
Both phase-specific and FDA approaches showed lower GRF values in the operated compared with the nonoperated leg within the low-IKDC group during bilateral jumps. Moreover, lower GRF values were also present in the operated and nonoperated legs in the low-IKDC group compared with those of the high-IKDC group. Differences in GRFs were predominantly observed during the eccentric deceleration phase of jumping.

Conclusion:
Patients with previous ACL reconstruction who have limited subjective knee function have lower GRF values and greater GRF asymmetries, suggesting the use of interlimb compensation strategies.

Clinical Relevance:
The study results lead to a better understanding of the motor control needed during the eccentric and concentric movement phases of unilateral and bilateral jumps in patients who have undergone ACL reconstruction.},
	number = {6},
	urldate = {2020-10-02},
	journal = {Orthopaedic Journal of Sports Medicine},
	author = {Baumgart, Christian and Hoppe, Matthias W. and Freiwald, Jürgen},
	month = jun,
	year = {2017},
	pmid = {28680890},
	pmcid = {PMC5480638},
}

@article{abramowicz_nonparametric_2018,
	title = {Nonparametric inference for functional-on-scalar linear models applied to knee kinematic hop data after injury of the anterior cruciate ligament},
	volume = {45},
	copyright = {© 2018 The Authors Scandinavian Journal of Statistics published by John Wiley \& Sons Ltd on behalf of The Board of the Foundation of the Scandinavian Journal of Statistics},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12333},
	doi = {10.1111/sjos.12333},
	abstract = {Motivated by the analysis of the dependence of knee movement patterns during functional tasks on subject-specific covariates, we introduce a distribution-free procedure for testing a functional-on-scalar linear model with fixed effects. The procedure does not only test the global hypothesis on the entire domain but also selects the intervals where statistically significant effects are detected. We prove that the proposed tests are provided with an asymptotic control of the intervalwise error rate, that is, the probability of falsely rejecting any interval of true null hypotheses. The procedure is applied to one-leg hop data from a study on anterior cruciate ligament injury. We compare knee kinematics of three groups of individuals (two injured groups with different treatments and one group of healthy controls), taking individual-specific covariates into account.},
	language = {en},
	number = {4},
	urldate = {2020-10-02},
	journal = {Scandinavian Journal of Statistics},
	author = {Abramowicz, Konrad and Häger, Charlotte K. and Pini, Alessia and Schelin, Lina and Luna, Sara Sjöstedt de and Vantini, Simone},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12333},
	keywords = {analysis of covariance, functional data, human movement, intervalwise testing, permutation test},
	pages = {1036--1061},
}

@article{warmenhoven_force_2018,
	title = {Force coordination strategies in on-water single sculling: {Are} asymmetries related to better rowing performance?},
	volume = {28},
	copyright = {© 2017 John Wiley \& Sons A/S. Published by John Wiley \& Sons Ltd},
	issn = {1600-0838},
	shorttitle = {Force coordination strategies in on-water single sculling},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.13031},
	doi = {10.1111/sms.13031},
	abstract = {Asymmetries of the rowing stroke cycle have been assessed with reference to kinematics and foot-force measures in laboratory testing environments. It remains unclear how asymmetries in propulsive kinetic measures are related to on-water rowing performance. A new approach for the evaluation of both global and local asymmetries across the entire movement was used to assess the continuous role of asymmetries and whether these change according to the level of competitive representation. Twenty-seven highly skilled female rowers (national and international competition level), rowing at 32 strokes per minute in a single scull boat, were evaluated. A symmetry index (SI) and functional data analysis (FDA) techniques were applied to a continuous difference time-series, which described fluctuating asymmetry in propulsive pin forces for each rower. Univariate ANOVAs revealed that differences in asymmetries were present as a factor of competition level for the SI and results of FDA. International athletes were more likely to utilize an asymmetry strategy with increased stroke-side (port-side) force early in the drive phase and increased bow-side (starboard) force through the second half of the drive. This was likely the result of international performers customizing their movement strategies relative to known boat mechanical offsets. The first half of the drive phase was also found to be an adaptive part of the rowing stroke cycle, suggesting asymmetries may have a functional role in successful execution of movements during the rowing stroke.},
	language = {en},
	number = {4},
	urldate = {2020-09-15},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Warmenhoven, John and Smith, Richard and Draper, Conny and Harrison, Andrew J. and Bargary, Norma and Cobley, Stephen},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.13031},
	keywords = {Biomechanics, rowing, sport expertise, symmetry},
	pages = {1379--1388},
}

@article{warmenhoven_assessment_2017,
	title = {Assessment of propulsive pin force and oar angle time-series using functional data analysis in on-water rowing},
	volume = {27},
	copyright = {© 2017 John Wiley \& Sons A/S. Published by John Wiley \& Sons Ltd},
	issn = {1600-0838},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.12871},
	doi = {10.1111/sms.12871},
	abstract = {The graphical presentation of the propulsive force applied at the pin plotted relative to the horizontal angle of the oar has been used practically in on-water rowing for the qualitative assessment of skill. How the pattern is related to performance variables has not been well identified, particularly for highly trained sculling athletes. Bivariate functional principal components analysis (bfPCA) was used on force-angle data to identify the main modes of variance in curves representing twenty-seven female rowers of different competition levels (national level and international level), rowing at 32 strokes per minute in a single scull boat. Discriminant function analysis showed moderate classification of rowers using force-angle graphs across both sides of the boat, with rate of force development identified as a potentially important characteristic for international rowers. Additionally for the bow-side, spending less time in the first half of the drive phase was also identified as an important feature for international rowers. Multiple linear regression of scores from the bfPCAs showed that a more pronounced front-peaked profile was associated with a higher average boat velocity. The results of this demonstrate that different characteristics of the force-angle graph may be associated with different metrics of performance.},
	language = {en},
	number = {12},
	urldate = {2020-09-15},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Warmenhoven, John and Cobley, Stephen and Draper, Conny and Harrison, Andrew J. and Bargary, Norma and Smith, Richard},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.12871},
	keywords = {biomechanics, bivariate functional principal components analysis, rowing, sport expertise},
	pages = {1688--1696},
}

@misc{noauthor_how_nodate,
	title = {How gender and boat-side affect shape characteristics of force–angle profiles in single sculling: {Insights} from functional data analysis {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {How gender and boat-side affect shape characteristics of force–angle profiles in single sculling},
	url = {https://reader.elsevier.com/reader/sd/pii/S1440244017309982?token=FAAA20906F14E8B3F4B46E3678AE39839B91658AECF06E6D2473DAA8A94690975AA689BEE7DC1E0A39747125BF11445E},
	language = {en},
	urldate = {2020-09-29},
	doi = {10.1016/j.jsams.2017.08.010},
}

@article{james_clustering_2003,
	title = {Clustering for {Sparsely} {Sampled} {Functional} {Data}},
	volume = {98},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/30045249},
	abstract = {We develop a flexible model-based procedure for clustering functional data. The technique can be applied to all types of curve data but is particularly useful when individuals are observed at a sparse set of time points. In addition to producing final cluster assignments, the procedure generates predictions and confidence intervals for missing portions of curves. Our approach also provides many useful tools for evaluating the resulting models. Clustering can be assessed visually via low-dimensional representations of the curves, and the regions of greatest separation between clusters can be determined using a discriminant function. Finally, we extend the model to handle multiple functional and finite-dimensional covariates and show how it can be applied to standard finite-dimensional clustering problems involving missing data.},
	number = {462},
	urldate = {2020-09-28},
	journal = {Journal of the American Statistical Association},
	author = {James, Gareth M. and Sugar, Catherine A.},
	year = {2003},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {397--408},
}

@misc{noauthor_shmueli_nodate,
	title = {Shmueli : {To} {Explain} or to {Predict}?},
	url = {https://projecteuclid.org/euclid.ss/1294167961},
	urldate = {2020-09-25},
}

@article{epifanio_analysis_2008,
	title = {Analysis of multiple waveforms by means of functional principal component analysis: normal versus pathological patterns in sit-to-stand movement},
	volume = {46},
	issn = {0140-0118},
	shorttitle = {Analysis of multiple waveforms by means of functional principal component analysis},
	doi = {10.1007/s11517-008-0339-6},
	abstract = {This paper presents an application of functional principal component analysis (FPCA) to describe the inter-subject variability of multiple waveforms. This technique was applied to the study of sit-to-stand movement in two groups of people, osteoarthritic patients and healthy subjects. Although STS movement has not been extensively applied to the study of knee osteoarthritis, it can provide relevant information about the effect of osteoarthritis on knee joint function. Two waveforms, knee flexion angle and flexion moment, were analysed simultaneously. Instead of using the common multivariate approach we used the functional one, which allows working with continuous functions with neither discretization nor time-scale normalization. The results show that time-scale normalization can alter the FPCA solution. Furthermore, FPCA presents better discriminatory power compared with the classical multivariate approach. This technique can, therefore, be applied as a functional assessment tool, allowing the identification of relevant variables to discriminate heterogeneous groups such as healthy and pathological subjects.},
	language = {eng},
	number = {6},
	journal = {Medical \& Biological Engineering \& Computing},
	author = {Epifanio, Irene and Avila, Carolina and Page, Alvaro and Atienza, Carlos},
	month = jun,
	year = {2008},
	pmid = {18392871},
	keywords = {Aged, Aged, 80 and over, Case-Control Studies, Female, Humans, Knee Joint, Male, Middle Aged, Movement, Osteoarthritis, Knee, Posture, Principal Component Analysis, Range of Motion, Articular, Video Recording},
	pages = {551--561},
}

@article{fisher_use_1936,
	title = {The {Use} of {Multiple} {Measurements} in {Taxonomic} {Problems}},
	volume = {7},
	copyright = {1936 Blackwell Publishing Ltd/University College London},
	issn = {2050-1439},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
	language = {en},
	number = {2},
	urldate = {2020-09-24},
	journal = {Annals of Eugenics},
	author = {Fisher, R. A.},
	year = {1936},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
	pages = {179--188},
}

@article{coffey_clustering_2014,
	title = {Clustering longitudinal profiles using {P}-splines and mixed effects models applied to time-course gene expression data},
	volume = {71},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S016794731300131X},
	doi = {10.1016/j.csda.2013.04.001},
	abstract = {Longitudinal data is becoming increasingly common and various methods have been developed to analyze this type of data. Profiles from time-course gene…},
	language = {en},
	urldate = {2020-09-22},
	journal = {Computational Statistics \& Data Analysis},
	author = {Coffey, Norma and Hinde, John and Holian, Emma},
	month = mar,
	year = {2014},
	note = {Publisher: North-Holland},
	pages = {14--29},
}

@article{deluzio_principal_1997,
	title = {Principal component models of knee kinematics and kinetics: {Normal} vs. pathological gait patterns},
	volume = {16},
	issn = {0167-9457},
	shorttitle = {Principal component models of knee kinematics and kinetics},
	url = {https://mdanderson.elsevierpure.com/en/publications/principal-component-models-of-knee-kinematics-and-kinetics-normal},
	doi = {10.1016/S0167-9457(96)00051-6},
	language = {English (US)},
	number = {2-3},
	urldate = {2020-09-24},
	journal = {Human Movement Science},
	author = {Deluzio, Kevin J. and Wyss, Urs P. and Zee, Benny Chung-ying and Costigan, Patrick A. and Sorbie, Charles},
	month = jan,
	year = {1997},
	note = {Publisher: Elsevier},
	pages = {201--217},
}

@article{deluzio_biomechanical_2007,
	title = {Biomechanical features of gait waveform data associated with knee osteoarthritis: {An} application of principal component analysis},
	volume = {25},
	issn = {0966-6362},
	shorttitle = {Biomechanical features of gait waveform data associated with knee osteoarthritis},
	url = {http://www.sciencedirect.com/science/article/pii/S0966636206000300},
	doi = {10.1016/j.gaitpost.2006.01.007},
	abstract = {This study compared the gait of 50 patients with end-stage knee osteoarthritis to a group of 63 age-matched asymptomatic control subjects. The analysis focused on three gait waveform measures that were selected based on previous literature demonstrating their relevance to knee osteoarthritis (OA): the knee flexion angle, flexion moment, and adduction moment. The objective was to determine the biomechanical features of these gait measures related to knee osteoarthritis. Principal component analysis was used as a data reduction tool, as well as a preliminary step for further analysis to determine gait pattern differences between the OA and the control groups. These further analyses included statistical hypothesis testing to detect group differences, and discriminant analysis to quantify overall group separation and to establish a hierarchy of discriminatory ability among the gait waveform features. The two groups were separated with a misclassification rate (estimated by cross-validation) of 8\%. The discriminatory features of the gait waveforms were, in order of their discriminatory ability: the amplitude of the flexion moment, the range of motion of the flexion angle, the magnitude of the flexion moment during early stance, and the magnitude of the adduction moment during stance.},
	language = {en},
	number = {1},
	urldate = {2020-09-24},
	journal = {Gait \& Posture},
	author = {Deluzio, K. J. and Astephen, J. L.},
	month = jan,
	year = {2007},
	keywords = {Gait analysis, Knee kinematics, Knee kinetics, Knee osteoarthritis, Principal component analysis},
	pages = {86--93},
}

@article{menz_two_2004,
	title = {Two feet, or one person? {Problems} associated with statistical analysis of paired data in foot and ankle medicine},
	volume = {14},
	shorttitle = {Two feet, or one person?},
	url = {https://app.dimensions.ai/details/publication/pub.1029708007},
	doi = {10.1016/s0958-2592(03)00047-6},
	abstract = {Re-imagining discovery and access to research: grants, datasets, publications, citations, clinical trials, patents and policy documents in one place.},
	language = {en},
	number = {1},
	urldate = {2020-09-24},
	author = {Menz, Hylton B},
	month = mar,
	year = {2004},
	pages = {2--5},
}

@article{sutton_two_1997,
	title = {Two knees or one person: data analysis strategies for paired joints or organs},
	volume = {56},
	issn = {0003-4967},
	shorttitle = {Two knees or one person},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1752405/},
	number = {7},
	urldate = {2020-09-24},
	journal = {Annals of the Rheumatic Diseases},
	author = {SUTTON, A. and MUIR, K. and JONES, A.},
	month = jul,
	year = {1997},
	pmid = {9485999},
	pmcid = {PMC1752405},
	pages = {401--402},
}

@article{shou_structured_2015,
	title = {Structured functional principal component analysis},
	volume = {71},
	copyright = {© 2014, The International Biometric Society},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12236},
	doi = {10.1111/biom.12236},
	abstract = {Motivated by modern observational studies, we introduce a class of functional models that expand nested and crossed designs. These models account for the natural inheritance of the correlation structures from sampling designs in studies where the fundamental unit is a function or image. Inference is based on functional quadratics and their relationship with the underlying covariance structure of the latent processes. A computationally fast and scalable estimation procedure is developed for high-dimensional data. Methods are used in applications including high-frequency accelerometer data for daily activity, pitch linguistic data for phonetic analysis, and EEG data for studying electrical brain activity during sleep.},
	language = {en},
	number = {1},
	urldate = {2020-09-24},
	journal = {Biometrics},
	author = {Shou, Haochang and Zipunnikov, Vadim and Crainiceanu, Ciprian M. and Greven, Sonja},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12236},
	keywords = {Functional linear mixed model, Functional principal component analysis, Latent process, Multilevel correlation structure, Variance component},
	pages = {247--257},
}

@book{mcelreath_statistical_2016,
	address = {Boca Raton},
	title = {Statistical {Rethinking}: {A} {Bayesian} {Course} with {Examples} in {R} and {Stan}},
	isbn = {978-1-4822-5344-3},
	shorttitle = {Statistical {Rethinking}},
	abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers’ knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today’s model-based statistics, the book pushes readers to perform step-by-step calculations that are usually automated. This unique computational approach ensures that readers understand enough of the details to make reasonable choices and interpretations in their own modeling work.  The text presents generalized linear multilevel models from a Bayesian perspective, relying on a simple logical interpretation of Bayesian probability and maximum entropy. It covers from the basics of regression to multilevel models. The author also discusses measurement error, missing data, and Gaussian process models for spatial and network autocorrelation.  By using complete R code examples throughout, this book provides a practical foundation for performing statistical inference. Designed for both PhD students and seasoned professionals in the natural and social sciences, it prepares them for more advanced or specialized statistical modeling.  Web ResourceThe book is accompanied by an R package (rethinking) that is available on the author’s website and GitHub. The two core functions (map and map2stan) of this package allow a variety of statistical models to be constructed from standard model formulas.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {McElreath, Richard},
	month = jan,
	year = {2016},
}

@inproceedings{escabias_functional_2017,
	address = {Cham},
	series = {Contributions to {Statistics}},
	title = {Functional data analysis in kinematics of children going to school},
	isbn = {978-3-319-55846-2},
	doi = {10.1007/978-3-319-55846-2_13},
	abstract = {Traditionally gait analysis has examined discrete measures as descriptors of gait to compare different experimental situations. Functional data analysis (FDA) uses information from the entire curves and trajectories, thus revealing the nature of the movement. The aim of our study is to develop some repeated measures FDA methodologies to analyze kinematics of children’s trunks while transporting a backpack and a trolley with different loads.},
	language = {en},
	booktitle = {Functional {Statistics} and {Related} {Fields}},
	publisher = {Springer International Publishing},
	author = {Escabias, Manuel and Aguilera, Ana M. and Heredia-Jiménez, Jose M. and Orantes-González, Eva},
	editor = {Aneiros, Germán and G. Bongiorno, Enea and Cao, Ricardo and Vieu, Philippe},
	year = {2017},
	keywords = {Functional Data Analysis, Functional Principal Component Analysis, Gait Analysis, Gait Cycle, Single Support Phase},
	pages = {95--103},
}

@article{flury_common_1984,
	title = {Common {Principal} {Components} in {K} {Groups}},
	volume = {79},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2288721},
	doi = {10.2307/2288721},
	abstract = {This article generalizes the method of principal components to so-called "common principal components" as follows: Consider the hypothesis that the covariance matrices Σi for k populations are simultaneously diagonalizable. That is, there is an orthogonal matrix β such that β'Σi β is diagonal for i = 1,..., k. I derive the normal-theory maximum likelihood estimates of the common component Σi matrices and the log-likelihood-ratio statistics for testing this hypothesis. The solution has some favorable properties that do not depend on normality assumptions. Numerical examples illustrate the method. Applications to data reduction, multiple regression, and nonlinear discriminant analysis are sketched.},
	number = {388},
	urldate = {2020-09-23},
	journal = {Journal of the American Statistical Association},
	author = {Flury, Bernhard N.},
	year = {1984},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {892--898},
}

@techreport{benko_common_2006,
	title = {Common {Functional} {Principal} {Components}},
	url = {https://ideas.repec.org/p/hum/wpaper/sfb649dp2006-010.html},
	abstract = {Functional principal component analysis (FPCA) based on the Karhunen-Lo`eve decomposition has been successfully applied in many applications, mainly for one sample problems. In this paper we consider common functional principal components for two sample problems. Our research is motivated not only by the theoretical challenge of this data situation but also by the actual question of dynamics of implied volatility (IV) functions. For different maturities the logreturns of IVs are samples of (smooth) random functions and the methods proposed here study the similarities of their stochastic behavior. Firstly we present a new method for estimation of functional principal components from discrete noisy data. Next we present the two sample inference for FPCA and develop two sample theory. We propose bootstrap tests for testing the equality of eigenvalues, eigenfunctions, and mean functions of two functional samples, illustrate the test-properties by simulation study and apply the method to the IV analysis.},
	language = {en},
	number = {SFB649DP2006-010},
	urldate = {2020-09-23},
	institution = {Sonderforschungsbereich 649, Humboldt University, Berlin, Germany},
	author = {Benko, Michal and Härdle, Wolfgang and Kneip, Alois},
	month = jan,
	year = {2006},
	note = {Publication Title: SFB 649 Discussion Papers},
	keywords = {Bootstrap, Functional Principal Components, Nonparametric Regression, Two Sample Problem},
}

@article{thompson_stepwise_2016,
	title = {Stepwise {Regression} and {Stepwise} {Discriminant} {Analysis} {Need} {Not} {Apply} here: {A} {Guidelines} {Editorial}:},
	shorttitle = {Stepwise {Regression} and {Stepwise} {Discriminant} {Analysis} {Need} {Not} {Apply} here},
	url = {https://journals.sagepub.com/doi/10.1177/0013164495055004001},
	doi = {10.1177/0013164495055004001},
	abstract = {Stepwise methods are frequently employed in educational and psychological research, both to select useful subsets of variables and to evaluate the order of impo...},
	language = {en},
	urldate = {2020-09-23},
	journal = {Educational and Psychological Measurement},
	author = {Thompson, Bruce},
	month = jul,
	year = {2016},
	note = {Publisher: Sage PublicationsSage CA: Thousand Oaks, CA},
}

@article{coffey_common_2011,
	title = {Common functional principal components analysis: {A} new approach to analyzing human movement data},
	volume = {30},
	issn = {0167-9457},
	shorttitle = {Common functional principal components analysis},
	url = {http://www.sciencedirect.com/science/article/pii/S0167945710001867},
	doi = {10.1016/j.humov.2010.11.005},
	abstract = {In many human movement studies angle-time series data on several groups of individuals are measured. Current methods to compare groups include comparisons of the mean value in each group or use multivariate techniques such as principal components analysis and perform tests on the principal component scores. Such methods have been useful, though discard a large amount of information. Functional data analysis (FDA) is an emerging statistical analysis technique in human movement research which treats the angle-time series data as a function rather than a series of discrete measurements. This approach retains all of the information in the data. Functional principal components analysis (FPCA) is an extension of multivariate principal components analysis which examines the variability of a sample of curves and has been used to examine differences in movement patterns of several groups of individuals. Currently the functional principal components (FPCs) for each group are either determined separately (yielding components that are group-specific), or by combining the data for all groups and determining the FPCs of the combined data (yielding components that summarize the entire data set). The group-specific FPCs contain both within and between group variation and issues arise when comparing FPCs across groups when the order of the FPCs alter in each group. The FPCs of the combined data may not adequately describe all groups of individuals and comparisons between groups typically use t-tests of the mean FPC scores in each group. When these differences are statistically non-significant it can be difficult to determine how a particular intervention is affecting movement patterns or how injured subjects differ from controls. In this paper we aim to perform FPCA in a manner allowing sensible comparisons between groups of curves. A statistical technique called common functional principal components analysis (CFPCA) is implemented. CFPCA identifies the common sources of variation evident across groups but allows the order of each component to change for a particular group. This allows for the direct comparison of components across groups. We use our method to analyze a biomechanical data set examining the mechanisms of chronic Achilles tendon injury and the functional effects of orthoses.},
	language = {en},
	number = {6},
	urldate = {2020-09-23},
	journal = {Human Movement Science},
	author = {Coffey, N. and Harrison, A. J. and Donoghue, O. A. and Hayes, K.},
	month = dec,
	year = {2011},
	keywords = {Common principal component analysis, Functional data analysis, Gait, Orthoses, Variability},
	pages = {1144--1166},
}

@article{coffey_common_2011-1,
	title = {Common functional principal components analysis: {A} new approach to analyzing human movement data},
	volume = {30},
	issn = {0167-9457},
	shorttitle = {Common functional principal components analysis},
	url = {http://www.sciencedirect.com/science/article/pii/S0167945710001867},
	doi = {10.1016/j.humov.2010.11.005},
	abstract = {In many human movement studies angle-time series data on several groups of individuals are measured. Current methods to compare groups include comparisons of the mean value in each group or use multivariate techniques such as principal components analysis and perform tests on the principal component scores. Such methods have been useful, though discard a large amount of information. Functional data analysis (FDA) is an emerging statistical analysis technique in human movement research which treats the angle-time series data as a function rather than a series of discrete measurements. This approach retains all of the information in the data. Functional principal components analysis (FPCA) is an extension of multivariate principal components analysis which examines the variability of a sample of curves and has been used to examine differences in movement patterns of several groups of individuals. Currently the functional principal components (FPCs) for each group are either determined separately (yielding components that are group-specific), or by combining the data for all groups and determining the FPCs of the combined data (yielding components that summarize the entire data set). The group-specific FPCs contain both within and between group variation and issues arise when comparing FPCs across groups when the order of the FPCs alter in each group. The FPCs of the combined data may not adequately describe all groups of individuals and comparisons between groups typically use t-tests of the mean FPC scores in each group. When these differences are statistically non-significant it can be difficult to determine how a particular intervention is affecting movement patterns or how injured subjects differ from controls. In this paper we aim to perform FPCA in a manner allowing sensible comparisons between groups of curves. A statistical technique called common functional principal components analysis (CFPCA) is implemented. CFPCA identifies the common sources of variation evident across groups but allows the order of each component to change for a particular group. This allows for the direct comparison of components across groups. We use our method to analyze a biomechanical data set examining the mechanisms of chronic Achilles tendon injury and the functional effects of orthoses.},
	language = {en},
	number = {6},
	urldate = {2020-09-23},
	journal = {Human Movement Science},
	author = {Coffey, N. and Harrison, A. J. and Donoghue, O. A. and Hayes, K.},
	month = dec,
	year = {2011},
	keywords = {Common principal component analysis, Functional data analysis, Gait, Orthoses, Variability},
	pages = {1144--1166},
}

@article{jacques_model-based_2014,
	title = {Model-based clustering for multivariate functional data},
	volume = {71},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947312004380},
	doi = {10.1016/j.csda.2012.12.004},
	abstract = {The first model-based clustering algorithm for multivariate functional data is proposed. After introducing multivariate functional principal components analysis (MFPCA), a parametric mixture model, based on the assumption of normality of the principal component scores, is defined and estimated by an EM-like algorithm. The main advantage of the proposed model is its ability to take into account the dependence among curves. Results on simulated and real datasets show the efficiency of the proposed method.},
	language = {en},
	urldate = {2020-09-22},
	journal = {Computational Statistics \& Data Analysis},
	author = {Jacques, Julien and Preda, Cristian},
	month = mar,
	year = {2014},
	keywords = {Density approximation, EM-algorithm, Model-based clustering, Multivariate functional data, Multivariate functional principal component analysis},
	pages = {92--106},
}

@article{sacilotto_investigation_2015,
	title = {{INVESTIGATION} {OF} {ATM} {PROPULSION} {FORCE}-{TIME} {PROFILES} {USING} {FUNCTIONAL} {DATA} {ANALYSIS} {ON} {FRONT} {CRAWL} {SPRINT} {SWIMMERS}},
	copyright = {Copyright (c) 2016 ISBS - Conference Proceedings Archive},
	issn = {1999-4168},
	url = {https://ojs.ub.uni-konstanz.de/cpa/article/view/6493},
	abstract = {The purpose of this investigation was to assess whether characteristics of the Assisted Towing Method (ATM) propulsive force-time profiles can discriminate between elite and sub-elite male sprint swimmers. Eleven elite and seven sub-elite sprint front crawl swimmers completed the ATM protocol to capture propulsion force-time profiles. The second full stroke cycle taken from the median propulsion trial on both the right and left arms were selected and functional data analysis was used to process the trials. Functional principal components analysis (fPCA) results revealed a statistical difference between the elite and sub-elite groups (p {\textgreater} 0.000). Further, within the elite group profiles, a distinctive double peak was found. The double peak profile could suggest a more efficient and effective stroking ratio of active drag and propulsion within the elite group.},
	language = {en},
	urldate = {2020-09-22},
	journal = {ISBS - Conference Proceedings Archive},
	author = {Sacilotto, Gina B. D. and Warmenhoven, John S. and Mason, Bruce R. and Ball, Nick and Clothier, Peter J.},
	year = {2015},
	keywords = {Swimming, functional principal component analysis},
}

@article{dona_application_2009,
	title = {Application of functional principal component analysis in race walking: {An} emerging methodology},
	volume = {8},
	issn = {1476-3141},
	shorttitle = {Application of functional principal component analysis in race walking},
	url = {https://doi.org/10.1080/14763140903414425},
	doi = {10.1080/14763140903414425},
	abstract = {This study considered the problem of identifying and evaluating the factors of individual performance during race walking. In particular, the study explored the use of functional principal component analysis (f-PCA), a multivariate data analysis, for assessing and classifying the kinematics and kinetics of the knee joint in competitive race walkers. Seven race walkers of international and national level participated to the study. An optoelectronic system and a force platform were used to capture three-dimensional kinematics and kinetics of lower limbs during the race walking cycle. Functional principal component analysis was applied bilaterally to the sagittal knee angle and net moment data, because knee joint motion is fundamental to race walking technique. Scatterplots of principal component scores provided evidence of athletes' technical differences and asymmetries even when traditional analysis (mean ± s curves) was not effective. Principal components provided indications for race walkers' classification and identified potentially important technical differences between higher and lower skilled athletes. Therefore, f-PCA might represent a future aid for the fine analysis of sports movements, if consistently applied to performance monitoring.},
	number = {4},
	urldate = {2020-09-21},
	journal = {Sports Biomechanics},
	author = {Donà, Giulia and Preatoni, Ezio and Cobelli, Claudio and Rodano, Renato and Harrison, Andrew J.},
	month = nov,
	year = {2009},
	pmid = {20169759},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14763140903414425},
	keywords = {Functional, analysis, component, kinematics, kinetics, movement, principal, sports skills, variability},
	pages = {284--301},
}

@article{jones_displaying_1992,
	title = {Displaying the {Important} {Features} of {Large} {Collections} of {Similar} {Curves}},
	volume = {46},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2684184},
	doi = {10.2307/2684184},
	abstract = {Naively displaying a large collection of curves by superimposing them one on another all on the same graph is largely uninformative and aesthetically unappealing. We propose that a simple principal component analysis be used to identify important modes of variation among the curves and that principal component scores be used to identify particular curves which clearly demonstrate the form and extent of that variation. As a result, we obtain a small number of figures on which are plotted a very few "representative" curves from the original collection; these successfully convey the major information present in sets of "similar" curves in a clear and attractive manner. Useful adjunct displays, including the plotting of principal component scores against covariates, are also described. Two examples-one concerning a data-based bandwidth selection procedure for kernel density estimation, the other involving ozone level curve data-illustrate the ideas.},
	number = {2},
	urldate = {2020-09-21},
	journal = {The American Statistician},
	author = {Jones, M. C. and Rice, John A.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {140--145},
}

@article{jones_displaying_1992-1,
	title = {Displaying the {Important} {Features} of {Large} {Collections} of {Similar} {Curves}},
	volume = {46},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2684184},
	doi = {10.2307/2684184},
	abstract = {Naively displaying a large collection of curves by superimposing them one on another all on the same graph is largely uninformative and aesthetically unappealing. We propose that a simple principal component analysis be used to identify important modes of variation among the curves and that principal component scores be used to identify particular curves which clearly demonstrate the form and extent of that variation. As a result, we obtain a small number of figures on which are plotted a very few "representative" curves from the original collection; these successfully convey the major information present in sets of "similar" curves in a clear and attractive manner. Useful adjunct displays, including the plotting of principal component scores against covariates, are also described. Two examples-one concerning a data-based bandwidth selection procedure for kernel density estimation, the other involving ozone level curve data-illustrate the ideas.},
	number = {2},
	urldate = {2020-09-21},
	journal = {The American Statistician},
	author = {Jones, M. C. and Rice, John A.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {140--145},
}

@article{jones_displaying_1992-2,
	title = {Displaying the {Important} {Features} of {Large} {Collections} of {Similar} {Curves}},
	volume = {46},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2684184},
	doi = {10.2307/2684184},
	abstract = {Naively displaying a large collection of curves by superimposing them one on another all on the same graph is largely uninformative and aesthetically unappealing. We propose that a simple principal component analysis be used to identify important modes of variation among the curves and that principal component scores be used to identify particular curves which clearly demonstrate the form and extent of that variation. As a result, we obtain a small number of figures on which are plotted a very few "representative" curves from the original collection; these successfully convey the major information present in sets of "similar" curves in a clear and attractive manner. Useful adjunct displays, including the plotting of principal component scores against covariates, are also described. Two examples-one concerning a data-based bandwidth selection procedure for kernel density estimation, the other involving ozone level curve data-illustrate the ideas.},
	number = {2},
	urldate = {2020-09-21},
	journal = {The American Statistician},
	author = {Jones, M. C. and Rice, John A.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {140--145},
}

@article{harrison_functional_2007,
	title = {Functional data analysis of joint coordination in the development of vertical jump performance},
	volume = {6},
	issn = {1476-3141},
	doi = {10.1080/14763140701323042},
	abstract = {Mastery of complex motor skills requires effective development of inter-segment coordination patterns. These coordination patterns can be described and quantified using various methods, including descriptive angle-angle diagrams, conjugate cross-correlations, vector coding, normalized root mean squared error techniques and, as in this study, functional data analysis procedures. Lower limb kinematic data were obtained for 49 children performing the vertical jump. Participants were assigned to developmental stages using the criteria of Gallahue and Ozmun . Inter-segment joint coordination data consisting of pairs of joint angle-time data were smoothed using B-splines and the resulting bivariate functions were analysed using functional principal component analysis and stepwise discriminant analysis. The results of the analysis showed that the knee-hip joint coordination pattern was most effective at discriminating between developmental stages. The results provide support for the application of functional data analysis techniques in the analysis of joint coordination or time series type data.},
	language = {eng},
	number = {2},
	journal = {Sports Biomechanics},
	author = {Harrison, A. J. and Ryan, W. and Hayes, K.},
	month = may,
	year = {2007},
	pmid = {17892096},
	keywords = {Biomechanical Phenomena, Child, Child, Preschool, Female, Hip Joint, Humans, Knee Joint, Male, Models, Biological, Motion, Motor Skills, Principal Component Analysis},
	pages = {199--214},
}

@misc{aj_functional_2007,
	title = {Functional data analysis of joint coordination in the development of vertical jump performance},
	url = {https://pubmed.ncbi.nlm.nih.gov/17892096/},
	abstract = {Mastery of complex motor skills requires effective development of inter-segment coordination patterns. These coordination patterns can be described and quantified using various methods, including descriptive angle-angle diagrams, conjugate cross-correlations, vector coding, normalized root mean squa …},
	language = {en},
	urldate = {2020-09-21},
	journal = {Sports biomechanics},
	author = {Aj, Harrison and W, Ryan and K, Hayes},
	month = may,
	year = {2007},
	pmid = {17892096},
	doi = {10.1080/14763140701323042},
	note = {ISSN: 1476-3141
Issue: 2
Publisher: Sports Biomech
Volume: 6},
}

@article{jones_displaying_1992-3,
	title = {Displaying the {Important} {Features} of {Large} {Collections} of {Similar} {Curves}},
	volume = {46},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2684184},
	doi = {10.2307/2684184},
	abstract = {Naively displaying a large collection of curves by superimposing them one on another all on the same graph is largely uninformative and aesthetically unappealing. We propose that a simple principal component analysis be used to identify important modes of variation among the curves and that principal component scores be used to identify particular curves which clearly demonstrate the form and extent of that variation. As a result, we obtain a small number of figures on which are plotted a very few "representative" curves from the original collection; these successfully convey the major information present in sets of "similar" curves in a clear and attractive manner. Useful adjunct displays, including the plotting of principal component scores against covariates, are also described. Two examples-one concerning a data-based bandwidth selection procedure for kernel density estimation, the other involving ozone level curve data-illustrate the ideas.},
	number = {2},
	urldate = {2020-09-21},
	journal = {The American Statistician},
	author = {Jones, M. C. and Rice, John A.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {140--145},
}

@article{wrobel_interactive_2016,
	title = {Interactive graphics for functional data analyses},
	volume = {5},
	issn = {2049-1573},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4864857/},
	doi = {10.1002/sta4.109},
	abstract = {Although there are established graphics that accompany the most common functional data analyses, generating these graphics for each dataset and analysis can be cumbersome and time consuming. Often, the barriers to visualization inhibit useful exploratory data analyses and prevent the development of intuition for a method and its application to a particular dataset. The 
refund.shiny package was developed to address these issues for several of the most common functional data analyses. After conducting an analysis, the 
plot shiny() function is used to generate an interactive visualization environment that contains several distinct graphics, many of which are updated in response to user input. These visualizations reduce the burden of exploratory analyses and can serve as a useful tool for the communication of results to non-statisticians.},
	number = {1},
	urldate = {2020-09-21},
	journal = {Stat (International Statistical Institute)},
	author = {Wrobel, Julia and Park, So Young and Staicu, Ana Maria and Goldsmith, Jeff},
	year = {2016},
	pmid = {27182437},
	pmcid = {PMC4864857},
	pages = {108--118},
}

@article{kipp_kinematic_2012,
	title = {Kinematic and kinetic synergies of the lower extremities during the pull in olympic weightlifting},
	volume = {28},
	issn = {1543-2688},
	doi = {10.1123/jab.28.3.271},
	abstract = {The purpose of this study was to identify multijoint lower extremity kinematic and kinetic synergies in weightlifting and compare these synergies between joints and across different external loads. Subjects completed sets of the clean exercise at loads equal to 65, 75, and 85\% of their estimated 1-RM. Functional data analysis was used to extract principal component functions (PCF's) for hip, knee, and ankle joint angles and moments of force during the pull phase of the clean at all loads. The PCF scores were then compared between joints and across loads to determine how much of each PCF was present at each joint and how it differed across loads. The analyses extracted two kinematic and four kinetic PCF's. The statistical comparisons indicated that all kinematic and two of the four kinetic PCF's did not differ across load, but scaled according to joint function. The PCF's captured a set of joint- and load-specific synergies that quantified biomechanical function of the lower extremity during Olympic weightlifting and revealed important technical characteristics that should be considered in sports training and future research.},
	language = {eng},
	number = {3},
	journal = {Journal of Applied Biomechanics},
	author = {Kipp, Kristof and Redden, Josh and Sabick, Michelle and Harris, Chad},
	month = jul,
	year = {2012},
	pmid = {21975459},
	keywords = {Ankle Joint, Computer Simulation, Female, Hip Joint, Humans, Kinetics, Knee Joint, Male, Models, Biological, Torque, Weight Lifting, Young Adult},
	pages = {271--278},
}

@article{kipp_patterns_2015,
	title = {Patterns of barbell acceleration during the snatch in weightlifting competition},
	volume = {33},
	issn = {0264-0414},
	url = {https://doi.org/10.1080/02640414.2014.992035},
	doi = {10.1080/02640414.2014.992035},
	abstract = {The purpose of this study was to determine the association between weightlifting performance and vertical barbell acceleration patterns. Barbell kinematic time-series data were tracked from 18 snatches from six weightlifters during a regional weightlifting competition. These data were used to calculate vertical barbell accelerations. Time-series data were normalised to 100\% of lift phase, defined as the time interval between barbell lift-off and maximum height of the barbell during each snatch lift. The time-series data were then entered into a pattern recognition algorithm that extracted principal patterns and calculated principal pattern scores. Body mass-normalised lift weight, which was used to quantify weightlifting performance, was significantly correlated (r = 0.673; P = 0.033) with a pattern that captured a difference in peak vertical barbell acceleration between the transition and the second pull phase. This correlation indicated that barbell acceleration profiles of higher weight snatch lifts were characterised by smaller decreases in acceleration during the second knee bend and smaller peak acceleration during the second pull phase. Weightlifting coaches and sports scientist should monitor and track vertical acceleration of the barbell, with focus on acceleration profiles that limit (1) deceleration during the transition phase between the first and second pull and (2) peak acceleration during the second pull phase of the snatch.},
	number = {14},
	urldate = {2020-09-18},
	journal = {Journal of Sports Sciences},
	author = {Kipp, Kristof and Harris, Chad},
	month = aug,
	year = {2015},
	pmid = {25530037},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02640414.2014.992035},
	keywords = {biomechanics, functional data analysis, principal component analysis},
	pages = {1467--1471},
}

@article{wakim_functional_2014,
	title = {Functional {Data} {Analysis} of {Aging} {Curves} in {Sports}},
	abstract = {It is well known that athletic and physical condition is affected by age. Plotting an individual athlete's performance against age creates a graph commonly called the player's aging curve. Despite the obvious interest to coaches and managers, the analysis of aging curves so far has used fairly rudimentary techniques. In this paper, we introduce functional data analysis (FDA) to the study of aging curves in sports and argue that it is both more general and more flexible compared to the methods that have previously been used. We also illustrate the rich analysis that is possible by analyzing data for NBA and MLB players. In the analysis of MLB data, we use functional principal components analysis (fPCA) to perform functional hypothesis testing and show differences in aging curves between potential power hitters and potential non-power hitters. The analysis of aging curves in NBA players illustrates the use of the PACE method. We show that there are three distinct aging patterns among NBA players and that player scoring ability differs across the patterns. We also show that aging pattern is independent of position.},
	author = {Wakim, Alexander F. and Jin, Jimmy},
	year = {2014},
}

@article{page_normalizing_2006,
	title = {Normalizing temporal patterns to analyze sit-to-stand movements by using registration of functional data},
	volume = {39},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929005003556},
	doi = {10.1016/j.jbiomech.2005.07.032},
	abstract = {Functional data analysis techniques provide an alternative way of representing movement and movement variability as a function of time. In particular, the registration of functional data provides a local normalization of time functions. This normalization transforms a set of curves, records of repeated trials, yielding a new set of curves that only vary in terms of amplitude. Therefore, main events occur at the “same time” for all transformed curves and interesting features of individual recordings remain after averaging processes. This paper presents an application of the registration process to the analysis of the vertical forces exerted on the ground by both feet during the sit-to-stand movement. This movement is particularly interesting in functional evaluations related to balance control, lower extremity dysfunction or low-back pain.},
	language = {en},
	number = {13},
	urldate = {2020-09-16},
	journal = {Journal of Biomechanics},
	author = {Page, A. and Ayala, G. and León, M. T. and Peydro, M. F. and Prat, J. M.},
	month = jan,
	year = {2006},
	keywords = {Registration, sit-to-stand, vgrf},
	pages = {2526--2534},
}

@inproceedings{yao_functional_2005,
	title = {Functional data analysis for sparse longitudinal data.},
	url = {http://citeseerx.ist.psu.edu/viewdoc/citations;jsessionid=B08787B949BDC92F008C30F99CCDB716?doi=10.1.1.1068.3969},
	abstract = {CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): We propose a nonparametric method to perform functional principal components analysis for the case of sparse longitudinal data. The method aims at irregularly spaced longitudinal data, where the number of repeated measurements available per subject is small. In contrast, classical functional data analysis requires a large number of regularly spaced measurements per subject. We assume that the repeated measurements are located randomly with a random number of repetitions for each subject and are determined by an underlying smooth random (subject-specific) trajectory plus measurement errors. Basic elements of our approach are the parsimonious estimation of the covariance structure and mean function of the trajectories, and the estimation of the variance of the measurement errors. The eigenfunction basis is estimated from the data, and functional principal components score estimates are obtained by a conditioning step. This conditional estimation method is conceptually simple and straightforward to implement. A key step is the derivation of asymptotic consistency and distribution results under mild conditions, using tools from functional analysis. Functional data analysis for sparse longitudinal data enables prediction of individual smooth trajectories even if only one or few measurements are available for a subject. Asymptotic pointwise and simultaneous confidence bands are obtained for predicted individual trajectories, based on asymptotic distributions, for simultaneous bands under the assumption of a finite number of components. Model selection techniques, such as the Akaike information criterion, are used to choose the model dimension corresponding to the number of eigenfunctions in the model. The methods are illustrated with a simulation study, longitudinal CD4 data for a sample of AIDS patients, and time-course gene expression data for the yeast cell cycle.},
	language = {en},
	urldate = {2020-09-18},
	author = {Yao, Fang and Müller, Hans-Georg and Wang, Jane-Ling},
	year = {2005},
}

@misc{carroll_fdapace_2020,
	title = {fdapace: {Functional} {Data} {Analysis} and {Empirical} {Dynamics}},
	copyright = {BSD\_3\_clause + file LICENSE},
	shorttitle = {fdapace},
	url = {https://CRAN.R-project.org/package=fdapace},
	abstract = {A versatile package that provides implementation of various methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this package is Functional Principal Component Analysis (FPCA), a key technique for functional data analysis, for sparsely or densely sampled random trajectories and time courses, via the Principal Analysis by Conditional Estimation (PACE) algorithm. This core algorithm yields covariance and mean functions, eigenfunctions and principal component (scores), for both functional data and derivatives, for both dense (functional) and sparse (longitudinal) sampling designs. For sparse designs, it provides fitted continuous trajectories with confidence bands, even for subjects with very few longitudinal observations. PACE is a viable and flexible alternative to random effects modeling of longitudinal data. There is also a Matlab version (PACE) that contains some methods not available on fdapace and vice versa. Updates to fdapace were supported by grants from NIH Echo and NSF DMS-1712864 and DMS-2014626. Please cite our package if you use it (You may run the command citation("fdapace") to get the citation format and bibtex entry). References: Wang, J.L., Chiou, J., Müller, H.G. (2016) {\textless}doi:10.1146/annurev-statistics-041715-033624{\textgreater}; Chen, K., Zhang, X., Petersen, A., Müller, H.G. (2017) {\textless}doi:10.1007/s12561-015-9137-5{\textgreater}.},
	urldate = {2020-09-18},
	author = {Carroll, Cody and Gajardo, Alvaro and Chen, Yaqing and Dai, Xiongtao and Fan, Jianing and Hadjipantelis, Pantelis Z. and Han, Kyunghee and Ji, Hao and Lin, Shu-Chin and Dubey, Paromita and Mueller, Hans-Georg and Wang, Jane-Ling},
	month = jul,
	year = {2020},
	keywords = {FunctionalData},
}

@article{james_principal_2000,
	title = {Principal {Component} {Models} for {Sparse} {Functional} {Data}},
	volume = {87},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2673632},
	abstract = {The elements of a multivariate dataset are often curves rather than single points. Functional principal components can be used to describe the modes of variation of such curves. If one has complete measurements for each individual curve or, as is more common, one has measurements on a fine grid taken at the same time points for all curves, then many standard techniques may be applied. However, curves are often measured at an irregular and sparse set of time points which can differ widely across individuals. We present a technique for handling this more difficult case using a reduced rank mixed effects framework.},
	number = {3},
	urldate = {2020-09-17},
	journal = {Biometrika},
	author = {James, Gareth M. and Hastie, Trevor J. and Sugar, Catherine A.},
	year = {2000},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {587--602},
}

@article{baumgart_phase-specific_2017-1,
	title = {Phase-{Specific} {Ground} {Reaction} {Force} {Analyses} of {Bilateral} and {Unilateral} {Jumps} in {Patients} {With} {ACL} {Reconstruction}},
	volume = {5},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5480638/},
	doi = {10.1177/2325967117710912},
	abstract = {In patients who have undergone anterior cruciate ligament (ACL) reconstruction, there is a weak correlation between subjective evaluation of knee function on questionnaires and clinical or biomechanical test results.Patients with lower subjective knee ...},
	language = {en},
	number = {6},
	urldate = {2020-09-16},
	journal = {Orthopaedic Journal of Sports Medicine},
	author = {Baumgart, Christian and Hoppe, Matthias W. and Freiwald, Jürgen},
	month = jun,
	year = {2017},
	pmid = {28680890},
	note = {Publisher: SAGE Publications},
}

@article{park_functional_2017,
	title = {Functional vs. {Traditional} {Analysis} in {Biomechanical} {Gait} {Data}: {An} {Alternative} {Statistical} {Approach}},
	volume = {60},
	issn = {1640-5544},
	shorttitle = {Functional vs. {Traditional} {Analysis} in {Biomechanical} {Gait} {Data}},
	doi = {10.1515/hukin-2017-0114},
	abstract = {In human motion studies, discrete points such as peak or average kinematic values are commonly selected to test hypotheses. The purpose of this study was to describe a functional data analysis and describe the advantages of using functional data analyses when compared with a traditional analysis of variance (ANOVA) approach. Nineteen healthy participants (age: 22 ± 2 yrs, body height: 1.7 ± 0.1 m, body mass: 73 ± 16 kg) walked under two different conditions: control and pain+effusion. Pain+effusion was induced by injection of sterile saline into the joint capsule and hypertonic saline into the infrapatellar fat pad. Sagittal-plane ankle, knee, and hip joint kinematics were recorded and compared following injections using 2×2 mixed model ANOVAs and FANOVAs. The results of ANOVAs detected a condition × time interaction for the peak ankle (F1,18 = 8.56, p = 0.01) and hip joint angle (F1,18 = 5.77, p = 0.03), but did not for the knee joint angle (F1,18 = 0.36, p = 0.56). The functional data analysis, however, found several differences at initial contact (ankle and knee joint), in the mid-stance (each joint) and at toe off (ankle). Although a traditional ANOVA is often appropriate for discrete or summary data, in biomechanical applications, the functional data analysis could be a beneficial alternative. When using the functional data analysis approach, a researcher can (1) evaluate the entire data as a function, and (2) detect the location and magnitude of differences within the evaluated function.},
	language = {eng},
	journal = {Journal of Human Kinetics},
	author = {Park, Jihong and Seeley, Matthew K. and Francom, Devin and Reese, C. Shane and Hopkins, J. Ty},
	month = dec,
	year = {2017},
	pmid = {29339984},
	pmcid = {PMC5765784},
	keywords = {functional data analysis, joint kinematics, statistics},
	pages = {39--49},
}

@misc{noauthor_stata_nodate,
	title = {Stata {\textbar} {FAQ}: {Problems} with stepwise regression},
	shorttitle = {Stata {\textbar} {FAQ}},
	url = {https://www.stata.com/support/faqs/statistics/stepwise-regression-problems/},
	abstract = {What are some of the problems with stepwise regression?},
	urldate = {2020-09-16},
}

@article{white_force-time_2020,
	title = {{FORCE}-{TIME} {CURVE} {ALIGNMENT} {FOR} {FUNCTIONAL} {PRINCIPAL} {COMPONENT} {ANALYSIS} {IN} {VERTICAL} {JUMPING}},
	volume = {38},
	url = {https://commons.nmu.edu/isbs/vol38/iss1/82},
	number = {1},
	journal = {ISBS Proceedings Archive},
	author = {White, Mark and Bezodis, Neil and Neville, Jono and Summers, Huw},
	month = jul,
	year = {2020},
	pages = {320},
}

@misc{noauthor_force-time_nodate,
	title = {"{FORCE}-{TIME} {CURVE} {ALIGNMENT} {FOR} {FUNCTIONAL} {PRINCIPAL} {COMPONENT} {ANALYSIS}" by {Mark} {White}, {Neil} {Bezodis} et al.},
	url = {https://commons.nmu.edu/isbs/vol38/iss1/82/},
	urldate = {2020-09-16},
}

@article{moudy_landmark_2018,
	title = {Landmark registering waveform data improves the ability to predict performance measures},
	volume = {78},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929018306055},
	doi = {10.1016/j.jbiomech.2018.07.027},
	abstract = {The purpose of this study was to investigate the benefit of landmark registration when applied to waveform data. We compared the ability of data reduced from time-normalised and landmark registered vertical ground reaction force (vGRF) waveforms captured during maximal countermovement jumps (CMJ) of 53 active male subjects to predict jump height. vGRF waveforms were landmark registered using different landmarks resulting in four registration conditions: (i) end of the eccentric phase, (ii) adding maximum centre of mass (CoM) power, (iii) adding minimum CoM power, (iv) adding minimum vGRF. In addition to the four registration conditions, the non-registered vGRF and concentric phase only were time-normalised and used in subsequent analysis. Analysis of characterising phases was performed to reduce the vGRF data to features that captured the behaviour of each waveform. These features were extracted from each condition’s vGRF waveform, time-domain (time taken to complete the movement), and warping functions (generated from landmark registration). The identified features were used as predictor features to fit a step-wise multilinear regression to jump height. Features generated from the best performing registration condition were able to predict jump height to a similar extent as the concentric phase (86–87\%), while all registration conditions could explain jump height to a greater extent than time-normalisation alone (65\%). This suggests waveform variability was reduced as phases of the CMJ were aligned. However, findings suggest that over-registration can occur when applying landmark registration. Overall, landmark registration can improve prediction power to performance measures as waveform data can be reduced to more appropriate performance related features.},
	language = {en},
	urldate = {2020-09-16},
	journal = {Journal of Biomechanics},
	author = {Moudy, Sarah and Richter, Chris and Strike, Siobhán},
	month = sep,
	year = {2018},
	keywords = {Countermovement jump, Data reduction, Dynamic time warping, Landmark registration},
	pages = {109--117},
}

@article{allison_hip_2018,
	title = {Hip abductor muscle activity during walking in individuals with gluteal tendinopathy},
	volume = {28},
	issn = {1600-0838},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sms.12942},
	doi = {10.1111/sms.12942},
	abstract = {The external hip adduction moment during walking is greater in individuals with gluteal tendinopathy (GT) than pain-free controls. Although this likely represents a greater demand on the hip abductor muscles implicated in GT, no study has investigated activation of these muscles in GT. For this purpose, fine wire electrodes were inserted into the segments of the gluteus minimus and medius muscles, and surface electrodes placed on the tensor fascia lata, upper gluteus maximus, and vastus lateralis muscles of eight individuals with, and eight without, GT. Participants underwent six walking trials. Individual muscle patterns were compared between groups using a wavelet-based linear effects model and muscle synergy analysis performed using non-negative matrix factorization to evaluate muscle activation patterns, within- and between-participant variability. Compared to controls, individuals with GT exhibited a more sustained initial burst of the posterior gluteus minimus and middle gluteus medius muscle segments. Two muscle synergies were identified; Synergy-1 activated in early-mid stance and Synergy-2 in early stance. In GT participants, posterior gluteus minimus and posterior gluteus medius and tensor fascia lata contributed more to Synergy-1 active during the period of single leg support. Participants with GT exhibited reduced within-participant variability of posterior gluteus medius and reduced between-participant variability of anterior gluteus minimus and medius and upper gluteus maximus. In conclusion, individuals with GT exhibit modified muscle activation patterns of the hip abductor muscles during walking, with potential relevance for gluteal tendon loading.},
	language = {en},
	number = {2},
	urldate = {2020-09-16},
	journal = {Scandinavian Journal of Medicine \& Science in Sports},
	author = {Allison, K. and Salomoni, S. E. and Bennell, K. L. and Wrigley, T. V. and Hug, F. and Vicenzino, B. and Grimaldi, A. and Hodges, P. W.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/sms.12942},
	keywords = {fine-wire electromyography, gait, greater trochanteric pain syndrome, hip abductor muscle},
	pages = {686--695},
}

@article{liebl_ankle_2014,
	title = {Ankle plantarflexion strength in rearfoot and forefoot runners: {A} novel clusteranalytic approach},
	volume = {35},
	issn = {0167-9457},
	shorttitle = {Ankle plantarflexion strength in rearfoot and forefoot runners},
	url = {http://www.sciencedirect.com/science/article/pii/S0167945714000402},
	doi = {10.1016/j.humov.2014.03.008},
	abstract = {The purpose of the present study was to test for differences in ankle plantarflexion strengths of habitually rearfoot and forefoot runners. In order to approach this issue, we revisit the problem of classifying different footfall patterns in human runners. A dataset of 119 subjects running shod and barefoot (speed 3.5m/s) was analyzed. The footfall patterns were clustered by a novel statistical approach, which is motivated by advances in the statistical literature on functional data analysis. We explain the novel statistical approach in detail and compare it to the classically used strike index of Cavanagh and Lafortune (1980). The two groups found by the new cluster approach are well interpretable as a forefoot and a rearfoot footfall groups. The subsequent comparison study of the clustered subjects reveals that runners with a forefoot footfall pattern are capable of producing significantly higher joint moments in a maximum voluntary contraction (MVC) of their ankle plantarflexor muscles tendon units; difference in means: 0.28Nm/kg. This effect remains significant after controlling for an additional gender effect and for differences in training levels. Our analysis confirms the hypothesis that forefoot runners have a higher mean MVC plantarflexion strength than rearfoot runners. Furthermore, we demonstrate that our proposed stochastic cluster analysis provides a robust and useful framework for clustering foot strikes.},
	language = {en},
	urldate = {2020-09-16},
	journal = {Human Movement Science},
	author = {Liebl, Dominik and Willwacher, Steffen and Hamill, Joseph and Brüggemann, Gert-Peter},
	month = jun,
	year = {2014},
	keywords = {Barefoot, Biomechanics, Cluster analysis, Foot strike, Functional data analysis, Running, Shod},
	pages = {104--120},
}

@article{hebert-losier_curve_2018,
	title = {Curve analyses reveal altered knee, hip, and trunk kinematics during drop–jumps long after anterior cruciate ligament rupture},
	volume = {25},
	issn = {0968-0160},
	url = {http://www.sciencedirect.com/science/article/pii/S0968016017303356},
	doi = {10.1016/j.knee.2017.12.005},
	abstract = {Background
Anterior cruciate ligament (ACL) ruptures may lead to knee dysfunctions later in life. Single-leg tasks are often evaluated, but bilateral movements may also be compromised. Our aim was to use curve analyses to examine double-leg drop–jump kinematics in ACL-reconstructed, ACL-deficient, and healthy-knee cohorts.
Methods
Subjects with unilateral ACL ruptures treated more than two decades ago (17–28years) conservatively with physiotherapy (ACLPT, n=26) or in combination with reconstructive surgery (ACLR, n=28) and healthy-knee controls (n=25) performed 40-cm drop–jumps. Three-dimensional knee, hip, and trunk kinematics were analyzed during Rebound, Flight, and Landing phases. Curves were time-normalized and compared between groups (injured and non-injured legs of ACLPT and ACLR vs. non-dominant and dominant legs of controls) and within groups (between legs) using functional analysis of variance methods.
Results
Compared to controls, ACL groups exhibited less knee and hip flexion on both legs during Rebound and greater knee external rotation on their injured leg at the start of Rebound and Landing. ACLR also showed less trunk flexion during Rebound. Between-leg differences were observed in ACLR only, with the injured leg more internally rotated at the hip. Overall, kinematic curves were similar between ACLR and ACLPT. However, compared to controls, deviations spanned a greater proportion of the drop–jump movement at the hip in ACLR and at the knee in ACLPT.
Conclusions
Trunk and bilateral leg kinematics during double-leg drop–jumps are still compromised long after ACL-rupture care, independent of treatment. Curve analyses indicate the presence of distinct compensatory mechanisms in ACLPT and ACLR compared to controls.},
	language = {en},
	number = {2},
	urldate = {2020-09-16},
	journal = {The Knee},
	author = {Hébert-Losier, Kim and Schelin, Lina and Tengman, Eva and Strong, Andrew and Häger, Charlotte K.},
	month = mar,
	year = {2018},
	keywords = {ACL, Biomechanics, Functional data analysis, Interval testing procedure, Lower extremity, Rehabilitation},
	pages = {226--239},
}

@inproceedings{escabias_functional_2017-1,
	address = {Cham},
	series = {Contributions to {Statistics}},
	title = {Functional data analysis in kinematics of children going to school},
	isbn = {978-3-319-55846-2},
	doi = {10.1007/978-3-319-55846-2_13},
	abstract = {Traditionally gait analysis has examined discrete measures as descriptors of gait to compare different experimental situations. Functional data analysis (FDA) uses information from the entire curves and trajectories, thus revealing the nature of the movement. The aim of our study is to develop some repeated measures FDA methodologies to analyze kinematics of children’s trunks while transporting a backpack and a trolley with different loads.},
	language = {en},
	booktitle = {Functional {Statistics} and {Related} {Fields}},
	publisher = {Springer International Publishing},
	author = {Escabias, Manuel and Aguilera, Ana M. and Heredia-Jiménez, Jose M. and Orantes-González, Eva},
	editor = {Aneiros, Germán and G. Bongiorno, Enea and Cao, Ricardo and Vieu, Philippe},
	year = {2017},
	keywords = {Functional Data Analysis, Functional Principal Component Analysis, Gait Analysis, Gait Cycle, Single Support Phase},
	pages = {95--103},
}

@article{dannenmaier_application_2020,
	title = {Application of functional data analysis to explore movements: walking, running and jumping - {A} systematic review},
	volume = {77},
	issn = {1879-2219},
	shorttitle = {Application of functional data analysis to explore movements},
	doi = {10.1016/j.gaitpost.2020.02.002},
	abstract = {Background Signals are continuously captured during the recording of motion data. Statistical analysis, however, usually uses only a few aspects of the recorded data. Functional data analysis offers the possibility to analyze the entire signal over time. Research question The review is based on the question of how functional data analysis is used in the study of lower limb movements. Methods The literature search was based on the databases EMBASE, PUBMED and OVID MEDLINE. All articles on the application of functional data analysis to motion-associated variables trajectories, ground reaction force,electromyography were included. The references were assessed independently by two reviewers. Results In total 1448 articles were found in the search. Finally, 13 articles were included in the review. All were of moderate methodological quality. The publication year of the studies ranges from 2009 to 2019. Healthy volunteers and persons with cruciate ligament injuries, knee osteoarthritis, gluteal tendinopathy, idiopathic torsional deformities, slipped capital femoral epiphysis and chronic ankle instability were examined in the studies. Movements were analyzed on basis of kinematics (3D motion analysis), ground reaction forces and electromyography. Functional Data Analysis was used in terms of landmark registration, functional principal component analysis, functional t-test and functional ANOVA. Significance Functional data analysis provides the possibility to gain detailed and in-depth insights into the analysis of motion patterns. As a result of the increase in references over the past year, the FDA is becoming more important in the analysis of continuous signals and the explorative analysis of movement data.},
	language = {eng},
	journal = {Gait \& Posture},
	author = {Dannenmaier, Julia and Kaltenbach, Christina and Kölle, Theresa and Krischak, Gert},
	year = {2020},
	pmid = {32058281},
	keywords = {Functional data analysis, Motion analysis, Systematic review},
	pages = {182--189},
}

@article{spitzner_mixed-model_2003,
	title = {Mixed-{Model} {Functional} {ANOVA} for {Studying} {Human} {Tactile} {Perception}},
	volume = {98},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214503000035},
	doi = {10.1198/016214503000035},
	abstract = {Human tactile perception is studied through digitized images of hand-drawn curves generated by subjects treated with various facial preparations. The drawings represent their subjective assessment of a small brush moving across the face. In this study, exploratory data analysis is carried out through a functional data analog of principal components analysis and curve decomposition based on Fourier representations. In addition, high-dimensional analysis of variance is adapted for mixed-model functional data and applied to test whether preparation effects are significant.},
	number = {462},
	urldate = {2020-09-15},
	journal = {Journal of the American Statistical Association},
	author = {Spitzner, Dan J. and Marron, J. S. and Essick, G. K.},
	month = jun,
	year = {2003},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214503000035},
	keywords = {Fourier representation, Functional data analysis, High-dimensional ANOVA, Principal components analysis},
	pages = {263--272},
}

@article{ormoneit_representing_2005,
	title = {Representing cyclic human motion using functional analysis},
	volume = {23},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885605001526},
	doi = {10.1016/j.imavis.2005.09.004},
	abstract = {We present a robust automatic method for modeling cyclic 3D human motion such as walking using motion-capture data. The pose of the body is represented by a time-series of joint angles which are automatically segmented into a sequence of motion cycles. The mean and the principal components of these cycles are computed using a new algorithm that enforces smooth transitions between the cycles by operating in the Fourier domain. Key to this method is its ability to automatically deal with noise and missing data. A learned walking model is then exploited for Bayesian tracking of 3D human motion.},
	language = {en},
	number = {14},
	urldate = {2020-09-15},
	journal = {Image and Vision Computing},
	author = {Ormoneit, Dirk and Black, Michael J. and Hastie, Trevor and Kjellström, Hedvig},
	month = dec,
	year = {2005},
	keywords = {Functional data analysis, Human motion, Missing data, Motion capture, Principal component analysis, Singular value decomposition, Tracking},
	pages = {1264--1276},
}

@misc{noauthor_ios_nodate,
	title = {{IOS} {Press} {Ebooks} - {Functional} data analysis for gait curves study in {Parkinson}'s disease},
	url = {http://ebooks.iospress.nl/publication/9746},
	urldate = {2020-09-15},
}

@article{duhamel_functional_2006,
	title = {Functional data analysis for gait curves study in {Parkinson}'s disease},
	volume = {124},
	issn = {0926-9630},
	abstract = {In Parkinson's disease, precise analysis of gait disorders remains essential for the diagnostic or the evaluation of treatments. During a gait analysis session, a series of successive dynamic gait trials are recorded and data involves a set of continuous curves for each patient. An important aspect of such data is the infinite dimension of the space data belong. Therefore, classical multivariate statistical analysis are inadequate. Recent methods known as functional data analysis allow to deal with this kind of data. In this paper, we present a functional data analysis approach for solving two problems encountered in clinical practice: (1) for a given patient, assessing the reliability of the gait curves corresponding to the different trials (2) performing intra individual curves comparisons for assessing the effect of a therapy. In a first step, each discretized curve was interpolated using cubic B-splines bases in order to ensure the continuous character of data. A cluster analysis was performed on the smoothed curves to assess the reliability and to identify a subset of representative curves for a given patient. Intra individual curves comparisons were carried out in the following way: (1) functional principal component analysis was performed to describe the temporal structure of data and to derive a finite number of reliable principal components. (2) These principal components were used in a linear discriminant analysis to point out the differences between the curves. This procedure was applied to compare the gait curves of 12 parkinsonian patients under 4 therapeutic conditions. This study allowed us to develop objective criteria for measuring the improvements in a subject's gait and comparing the effect of different treatments. The methods presented in this paper could be used in other medical domains when data consist in continuous curves.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Duhamel, Alain and Devos, Patrick and Bourriez, Jean Louis and Preda, C. and Defebvre, L. and Beuscart, Regis},
	year = {2006},
	pmid = {17108578},
	keywords = {France, Gait, Humans, Parkinson Disease, Statistics as Topic},
	pages = {569--574},
}

@article{ryan_functional_2006,
	title = {Functional data analysis of knee joint kinematics in the vertical jump},
	volume = {5},
	issn = {1476-3141},
	doi = {10.1080/14763141.2006.9628228},
	abstract = {Understanding of the motor development process is usually based on descriptive studies using either cross-sectional or longitudinal designs. These data typically consist of sets of measurements on groups of individuals gathered during the performance of a single task. A natural approach is to represent the set of measurements for an individual as a single entity, a function. In practice, however, this approach is seldom applied. Typically, the analysis proceeds by reducing what are intrinsically functional responses to a single summary measurement and then using this to draw conclusions. As a result, many potentially informative data are ignored. Functional data analysis (FDA) is an emerging field in statistics that focuses on treating an entire sequence of measurements for an experimental unit as a single function. Therefore, functional data analysis appears to be inherently suitable for analysing kinematic data. In this paper, the key concepts and procedures of functional data analysis are introduced and illustrated using data obtained from a cross-sectional study on the development of the vertical jump.},
	language = {eng},
	number = {1},
	journal = {Sports Biomechanics},
	author = {Ryan, Willie and Harrison, Andrew and Hayes, Kevin},
	month = jan,
	year = {2006},
	pmid = {16521626},
	keywords = {Biomechanical Phenomena, Child, Child, Preschool, Female, Humans, Knee Joint, Locomotion, Male, Principal Component Analysis},
	pages = {121--138},
}

@article{page_normalizing_2006-1,
	title = {Normalizing temporal patterns to analyze sit-to-stand movements by using registration of functional data},
	volume = {39},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929005003556},
	doi = {10.1016/j.jbiomech.2005.07.032},
	abstract = {Functional data analysis techniques provide an alternative way of representing movement and movement variability as a function of time. In particular, the registration of functional data provides a local normalization of time functions. This normalization transforms a set of curves, records of repeated trials, yielding a new set of curves that only vary in terms of amplitude. Therefore, main events occur at the “same time” for all transformed curves and interesting features of individual recordings remain after averaging processes. This paper presents an application of the registration process to the analysis of the vertical forces exerted on the ground by both feet during the sit-to-stand movement. This movement is particularly interesting in functional evaluations related to balance control, lower extremity dysfunction or low-back pain.},
	language = {en},
	number = {13},
	urldate = {2020-09-15},
	journal = {Journal of Biomechanics},
	author = {Page, A. and Ayala, G. and León, M. T. and Peydro, M. F. and Prat, J. M.},
	month = jan,
	year = {2006},
	keywords = {Functional assessment, Functional data, Low-back pain, Nonlinear time normalization, Registration, Sit-to-stand movement, Warping function},
	pages = {2526--2534},
}

@article{donoghue_functional_2008,
	title = {Functional data analysis of running kinematics in chronic {Achilles} tendon injury},
	volume = {40},
	issn = {0195-9131},
	doi = {10.1249/MSS.0b013e31816c4807},
	abstract = {PURPOSE: Chronic Achilles tendon (AT) injuries are common, but kinematic studies confirming the exact mechanisms of injury and how orthoses are effective are lacking. Existing analysis often relies on discrete measures and provides an incomplete analysis because many of the data are discarded. Functional data analysis (FDA) views the entire dataset as a function, thus retaining the main features of the curve. This study uses FDA to examine the mechanisms of chronic AT injury and the functional effects of orthoses.
METHODS: Twelve subjects with a history of chronic AT injury and 12 controls ran on a treadmill with and without customized orthoses. Three-dimensional kinematic data were obtained using Qualisys motion capture systems operating at 200 Hz. Ankle dorsiflexion (ADF), knee flexion (KF), eversion (EV), calcaneal, and leg abduction angles were calculated across stance. These angle data were represented as functions, and functional principal components were extracted to describe the factors accounting for variation in the data. These components were compared in AT versus control groups and orthoses versus no-orthoses conditions.
RESULTS: Kinematic differences were observed, with the AT group showing greater EV, ADF, and KF during stance, whereas orthoses reduced ADF but increased EV. Different patterns of frontal plane variation distinguished between groups and conditions.
CONCLUSION: Results provided additional information about movement patterns compared to traditional approaches and identified the first half of stance as the most relevant period in injury occurrence. The study showed evidence that variability is related to the presence of injury in this clinical population. Further FDA focusing on within-subject variation is recommended to gain greater insight into the role of variability in injury occurrence.},
	language = {eng},
	number = {7},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Donoghue, Orna A. and Harrison, Andrew J. and Coffey, Norma and Hayes, Kevin},
	month = jul,
	year = {2008},
	pmid = {18580414},
	keywords = {Achilles Tendon, Adult, Biomechanical Phenomena, Case-Control Studies, Chronic Disease, Data Interpretation, Statistical, Exercise Test, Female, Gait, Humans, Male, Models, Theoretical, Risk Factors, Running, Tendon Injuries},
	pages = {1323--1335},
}

@article{roislien_simultaneous_2009,
	title = {Simultaneous estimation of effects of gender, age and walking speed on kinematic gait data},
	volume = {30},
	issn = {1879-2219},
	doi = {10.1016/j.gaitpost.2009.07.002},
	abstract = {Analysis of variations in normal gait has received considerable attention over the last years. However, most such analyses are carried out on one explanatory variable at a time, and adjustments for other possibly influencing factors are often done using ad hoc methods. As a result, it can be difficult to know whether observed effects are actually a result of the variable under study. We wanted to simultaneously statistically test the effect of gender, age and walking speed on gait in a normal population, while also properly adjusting for the possibly confounding effects of body height and weight. Since point-by-point analysis does not take into account the time dependency in the data, we turned to functional data analysis (FDA). In FDA the whole gait curve is represented not by a set of points, but by a mathematical function spanning the whole gait cycle. We performed several multiple functional regression analyses, and the results indicate that walking speed is the main factor influencing gait in the reference material at our motion analysis laboratory. This effect is also largely unaffected by the presence of other variables in the model. A gender effect was also apparent in several planes and joints, but this effect was often more outspoken in the multiple than in the univariate regression analyses, highlighting the importance of adjusting for confounders like body height and weight.},
	language = {eng},
	number = {4},
	journal = {Gait \& Posture},
	author = {Røislien, Jo and Skare, Øivind and Gustavsen, Marit and Broch, Nana L. and Rennie, Linda and Opheim, Arve},
	month = nov,
	year = {2009},
	pmid = {19665379},
	keywords = {Adult, Age Factors, Aging, Biomechanical Phenomena, Body Height, Body Weight, Female, Gait, Humans, Male, Middle Aged, Reference Values, Regression Analysis, Sex Factors, Walking},
	pages = {441--445},
}

@article{crane_effect_2010,
	title = {Effect of registration on cyclical kinematic data},
	volume = {43},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929010002368},
	doi = {10.1016/j.jbiomech.2010.04.024},
	abstract = {Given growing interest in functional data analysis (FDA) as a useful method for analyzing human movement data, it is critical to understand the effects of standard FDA procedures, including registration, on biomechanical analyses. Registration is used to reduce phase variability between curves while preserving the individual curve's shape and amplitude. The application of three methods available to assess registration could benefit those in the biomechanics community using FDA techniques: comparison of mean curves, comparison of average RMS values, and assessment of time-warping functions. Therefore, the present study has two purposes. First, the necessity of registration applied to cyclical data after time normalization is assessed. Second, we illustrate the three methods for evaluating registration effects. Masticatory jaw movements of 22 healthy adults (2 males, 21 females) were tracked while subjects chewed a gum-based pellet for 20s. Motion data were captured at 60Hz with two gen-locked video cameras. Individual chewing cycles were time normalized and then transformed into functional observations. Registration did not affect mean curves and warping functions were linear. Although registration decreased the RMS, indicating a decrease in inter-subject variability, the difference was not statistically significant. Together these results indicate that registration may not always be necessary for cyclical chewing data. An important contribution of this paper is the illustration of three methods for evaluating registration that are easy to apply and useful for judging whether the extra data manipulation is necessary.},
	language = {en},
	number = {12},
	urldate = {2020-09-15},
	journal = {Journal of Biomechanics},
	author = {Crane, Elizabeth A. and Cassidy, Ruth B. and Rothman, Edward D. and Gerstner, Geoffrey E.},
	month = aug,
	year = {2010},
	keywords = {Cyclical data, Functional data analysis, Mastication, Registration},
	pages = {2444--2447},
}

@article{dura_comparison_2010,
	title = {Comparison of {Functional} {Regression} and {Nonfunctional} {Regression} {Approaches} to the {Study} of the {Walking} {Velocity} {Effect} in {Force} {Platform} {Measures}},
	volume = {26},
	issn = {1065-8483, 1543-2688},
	url = {https://journals.humankinetics.com/view/journals/jab/26/2/article-p234.xml},
	doi = {10.1123/jab.26.2.234},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}p{\textgreater}The effect of walking velocity on force platform measures is examined by means of functional regression and nonfunctional regression analyses. The two techniques are compared using a data set of ground reaction forces. Functional data analysis avoids the need to identify significant points, and provides more information along the waveform.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en\_US},
	number = {2},
	urldate = {2020-09-15},
	journal = {Journal of Applied Biomechanics},
	author = {Durá, Juan V. and Belda, Juan M. and Poveda, Rakel and Page, Álvaro and Laparra, José and Das, José and Prat, Jaime and García, Ana C.},
	month = may,
	year = {2010},
	note = {Publisher: Human Kinetics, Inc.
Section: Journal of Applied Biomechanics},
	pages = {234--239},
}

@article{ullah_applications_2013,
	title = {Applications of functional data analysis: {A} systematic review},
	volume = {13},
	issn = {1471-2288},
	shorttitle = {Applications of functional data analysis},
	url = {https://doi.org/10.1186/1471-2288-13-43},
	doi = {10.1186/1471-2288-13-43},
	abstract = {Functional data analysis (FDA) is increasingly being used to better analyze, model and predict time series data. Key aspects of FDA include the choice of smoothing technique, data reduction, adjustment for clustering, functional linear modeling and forecasting methods.},
	number = {1},
	urldate = {2020-09-15},
	journal = {BMC Medical Research Methodology},
	author = {Ullah, Shahid and Finch, Caroline F.},
	month = mar,
	year = {2013},
	pages = {43},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {Applications} of functional data analysis: {A} systematic review},
	shorttitle = {({PDF}) {Applications} of functional data analysis},
	url = {https://www.researchgate.net/publication/236062832_Applications_of_functional_data_analysis_A_systematic_review},
	abstract = {PDF {\textbar} Background Functional data analysis (FDA) is increasingly being used to better analyze, model and predict time series data. Key aspects of FDA... {\textbar} Find, read and cite all the research you need on ResearchGate},
	language = {en},
	urldate = {2020-09-15},
	journal = {ResearchGate},
	doi = {10.1186/1471-2288-13-43},
}

@article{silverman_aspects_1985,
	title = {Some {Aspects} of the {Spline} {Smoothing} {Approach} to {Non}-{Parametric} {Regression} {Curve} {Fitting}},
	volume = {47},
	copyright = {© 1985 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1985.tb01327.x},
	doi = {10.1111/j.2517-6161.1985.tb01327.x},
	abstract = {Non-parametric regression using cubic splines is an attractive, flexible and widely-applicable approach to curve estimation. Although the basic idea was formulated many years ago, the method is not as widely known or adopted as perhaps it should be. The topics and examples discussed in this paper are intended to promote the understanding and extend the practicability of the spline smoothing methodology. Particular subjects covered include the basic principles of the method; the relation with moving average and other smoothing methods; the automatic choice of the amount of smoothing; and the use of residuals for diagnostic checking and model adaptation. The question of providing inference regions for curves – and for relevant properties of curves – is approached via a finite-dimensional Bayesian formulation.},
	language = {en},
	number = {1},
	urldate = {2020-09-15},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Silverman, B. W.},
	year = {1985},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1985.tb01327.x},
	keywords = {automatic smoothing, b-splines, bayesian inference, change point, cross-validation, empirical bayes, functionals of curves, generalized smoothing, growth curves, local reweighting, model choice, regression diagnostics, residuals, robust smoothing, roughness penalty, smoothing, surface estimation, variable kernel, weight function},
	pages = {1--21},
}

@article{silverman_aspects_1985-1,
	title = {Some {Aspects} of the {Spline} {Smoothing} {Approach} to {Non}-{Parametric} {Regression} {Curve} {Fitting}},
	volume = {47},
	copyright = {© 1985 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1985.tb01327.x},
	doi = {10.1111/j.2517-6161.1985.tb01327.x},
	abstract = {Non-parametric regression using cubic splines is an attractive, flexible and widely-applicable approach to curve estimation. Although the basic idea was formulated many years ago, the method is not as widely known or adopted as perhaps it should be. The topics and examples discussed in this paper are intended to promote the understanding and extend the practicability of the spline smoothing methodology. Particular subjects covered include the basic principles of the method; the relation with moving average and other smoothing methods; the automatic choice of the amount of smoothing; and the use of residuals for diagnostic checking and model adaptation. The question of providing inference regions for curves – and for relevant properties of curves – is approached via a finite-dimensional Bayesian formulation.},
	language = {en},
	number = {1},
	urldate = {2020-09-15},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Silverman, B. W.},
	year = {1985},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1985.tb01327.x},
	keywords = {automatic smoothing, b-splines, bayesian inference, change point, cross-validation, empirical bayes, functionals of curves, generalized smoothing, growth curves, local reweighting, model choice, regression diagnostics, residuals, robust smoothing, roughness penalty, smoothing, surface estimation, variable kernel, weight function},
	pages = {1--21},
}

@article{corain_new_2014,
	title = {New insights on permutation approach for hypothesis testing on functional data},
	doi = {10.1007/s11634-013-0162-2},
	abstract = {The permutation approach for testing the equality of distributions and thereby comparing two populations of functional data has recently received increasing attention thanks to the flexibility of permutation tests to handle complex testing problems. The purpose of this work is to present some new insights in the context of nonparametric inference on functional data using the permutation approach, more specifically we formally show the equivalence of some permutation procedures proposed in the literature and we suggest the use of the permutation and combination-based approach within the basis function approximation layout. Validation of theoretical results is shown by simulation studies.},
	journal = {Adv. Data Anal. Classif.},
	author = {Corain, L. and Melas, V. and Pepelyshev, A. and Salmaso, L.},
	year = {2014},
}

@article{staicu_likelihood_2014,
	title = {Likelihood {Ratio} {Tests} for {Dependent} {Data} with {Applications} to {Longitudinal} and {Functional} {Data} {Analysis}},
	doi = {10.1111/SJOS.12075},
	abstract = {type="main" xml:id="sjos12075-abs-0001"{\textgreater} This paper introduces a general framework for testing hypotheses about the structure of the mean function of complex functional processes. Important particular cases of the proposed framework are as follows: (1) testing the null hypothesis that the mean of a functional process is parametric against a general alternative modelled by penalized splines; and (2) testing the null hypothesis that the means of two possibly correlated functional processes are equal or differ by only a simple parametric function. A global pseudo-likelihood ratio test is proposed, and its asymptotic distribution is derived. The size and power properties of the test are confirmed in realistic simulation scenarios. Finite-sample power results indicate that the proposed test is much more powerful than competing alternatives. Methods are applied to testing the equality between the means of normalized δ-power of sleep electroencephalograms of subjects with sleep-disordered breathing and matched controls.},
	author = {Staicu, A. and Li, Yingxing and Crainiceanu, C. and Ruppert, D.},
	year = {2014},
}

@article{olshen_gait_1989,
	title = {Gait {Analysis} and the {Bootstrap}},
	volume = {17},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2241642},
	abstract = {This paper is about random coefficient trigonometric regression models and their use in gait analysis. Here gait analysis means free-speed walking on a level surface. Our study focuses on bootstrap-based prediction regions for the angular rotation curves of test children, when the relevant training data are gathered from normal children of comparable ages. Considerations that led to our choice of model and use of the bootstrap are given. Prediction regions and empirical bootstrap distributions are displayed, as is their application to several test cases. Also included is a study of the almost sure asymptotic behavior of the theoretical bootstrap probability of the prediction regions.},
	number = {4},
	urldate = {2020-09-15},
	journal = {The Annals of Statistics},
	author = {Olshen, Richard A. and Biden, Edmund N. and Wyatt, Marilynn P. and Sutherland, David H.},
	year = {1989},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1419--1440},
}

@article{leurgans_canonical_1993,
	title = {Canonical {Correlation} {Analysis} when the {Data} are {Curves}},
	volume = {55},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345883},
	abstract = {It is not immediately straightforward to extend canonical correlation analysis to the context of functional data analysis, where the data are themselves curves or functions. The obvious approach breaks down, and it is necessary to use a method involving smoothing in some way. Such a method is introduced and discussed with reference to a data set on human gait. The breakdown of the unsmoothed method is illustrated in a practical context and is demonstrated theoretically. A consistency theorem for the smoothed method is proved.},
	number = {3},
	urldate = {2020-09-15},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Leurgans, S. E. and Moyeed, R. A. and Silverman, B. W.},
	year = {1993},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {725--740},
}

@article{silverman_smoothed_1996,
	title = {Smoothed functional principal components analysis by choice of norm},
	volume = {24},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1033066196},
	doi = {10.1214/aos/1033066196},
	abstract = {The principal components analysis of functional data is often enhanced by the use of smoothing. It is shown that an attractive method of incorporating smoothing is to replace the usual L2L2L{\textasciicircum}2-orthonormality constraint on the principal components by orthonormality with respect to an inner product that takes account of the roughness of the functions. The method is easily implemented in practice by making use of appropriate function transforms (Fourier transforms for periodic data) and standard principal components analysis programs. Several alternative possible interpretations of the smoothed principal components as obtained by the method are presented. Some theoretical properties of the method are discussed: the estimates are shown to be consistent under appropriate conditions, and asymptotic expansion techniques are used to investigate their bias and variance properties. These indicate that the form of smoothing proposed is advantageous under mild conditions, indeed milder than those for existing methods of smoothed functional principal components analysis. The choice of smoothing parameter by cross-validation is discussed. The methodology of the paper is illustrated by an application to a biomechanical data set obtained in the study of the behaviour of the human thumb-forefinger system.},
	language = {en},
	number = {1},
	urldate = {2020-09-09},
	journal = {Annals of Statistics},
	author = {Silverman, Bernard W.},
	month = feb,
	year = {1996},
	mrnumber = {MR1389877},
	zmnumber = {0853.62044},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Biomechanics, PCA, consistency, cross-validation, functional data analysis, mean integrated square error, roughness penalty, smoothing},
	pages = {1--24},
}

@article{rice_estimating_1991,
	title = {Estimating the {Mean} and {Covariance} {Structure} {Nonparametrically} {When} the {Data} are {Curves}},
	volume = {53},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345738},
	abstract = {We develop methods for the analysis of a collection of curves which are stochastically modelled as independent realizations of a random function with an unknown mean and covariance structure. We propose a method of estimating the mean function non-parametrically under the assumption that it is smooth. We suggest a variant on the usual form of cross-validation for choosing the degree of smoothing to be employed. This method of cross-validation, which consists of deleting entire sample curves, has the advantage that it does not require that the covariance structure be known or estimated. In the estimation of the covariance structure, we are primarily concerned with models in which the first few eigenfunctions are smooth and the eigenvalues decay rapidly, so that the variability is predominantly of large scale. We propose smooth nonparametric estimates of the eigen-functions and a suitable method of cross-validation to determine the amount of smoothing. Our methods are applied to data on the gaits of a group of 5-year-old children.},
	number = {1},
	urldate = {2020-09-09},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Rice, John A. and Silverman, B. W.},
	year = {1991},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {233--243},
}

@article{rice_estimating_1991-1,
	title = {Estimating the {Mean} and {Covariance} {Structure} {Nonparametrically} {When} the {Data} are {Curves}},
	volume = {53},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345738},
	abstract = {We develop methods for the analysis of a collection of curves which are stochastically modelled as independent realizations of a random function with an unknown mean and covariance structure. We propose a method of estimating the mean function non-parametrically under the assumption that it is smooth. We suggest a variant on the usual form of cross-validation for choosing the degree of smoothing to be employed. This method of cross-validation, which consists of deleting entire sample curves, has the advantage that it does not require that the covariance structure be known or estimated. In the estimation of the covariance structure, we are primarily concerned with models in which the first few eigenfunctions are smooth and the eigenvalues decay rapidly, so that the variability is predominantly of large scale. We propose smooth nonparametric estimates of the eigen-functions and a suitable method of cross-validation to determine the amount of smoothing. Our methods are applied to data on the gaits of a group of 5-year-old children.},
	number = {1},
	urldate = {2020-09-09},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Rice, John A. and Silverman, B. W.},
	year = {1991},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {233--243},
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2020-09-08},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Computer software, Control systems, Data management, Metadata, Programming languages, Reproducibility, Software tools, Source code},
	pages = {e1005510},
}

@article{kostic_exploring_2013,
	title = {Exploring host–microbiota interactions in animal models and humans},
	volume = {27},
	issn = {0890-9369, 1549-5477},
	url = {http://genesdev.cshlp.org/content/27/7/701},
	doi = {10.1101/gad.212522.112},
	abstract = {The animal and bacterial kingdoms have coevolved and coadapted in response to environmental selective pressures over hundreds of millions of years. The meta'omics revolution in both sequencing and its analytic pipelines is fostering an explosion of interest in how the gut microbiome impacts physiology and propensity to disease. Gut microbiome studies are inherently interdisciplinary, drawing on approaches and technical skill sets from the biomedical sciences, ecology, and computational biology. Central to unraveling the complex biology of environment, genetics, and microbiome interaction in human health and disease is a deeper understanding of the symbiosis between animals and bacteria. Experimental model systems, including mice, fish, insects, and the Hawaiian bobtail squid, continue to provide critical insight into how host–microbiota homeostasis is constructed and maintained. Here we consider how model systems are influencing current understanding of host–microbiota interactions and explore recent human microbiome studies.},
	language = {en},
	number = {7},
	urldate = {2020-09-07},
	journal = {Genes \& Development},
	author = {Kostic, Aleksandar D. and Howitt, Michael R. and Garrett, Wendy S.},
	month = apr,
	year = {2013},
	pmid = {23592793},
	note = {Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Institution: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Publisher: Cold Spring Harbor Lab},
	keywords = {microbiome, microbiota, model organisms, symbiosis},
	pages = {701--718},
}

@article{melancon_best_2017,
	title = {Best practices for germ-free derivation and gnotobiotic zebrafish husbandry},
	volume = {138},
	issn = {0091-679X},
	doi = {10.1016/bs.mcb.2016.11.005},
	abstract = {All animals are ecosystems with resident microbial communities, referred to as microbiota, which play profound roles in host development, physiology, and evolution. Enabled by new DNA sequencing technologies, there is a burgeoning interest in animal-microbiota interactions, but dissecting the specific impacts of microbes on their hosts is experimentally challenging. Gnotobiology, the study of biological systems in which all members are known, enables precise experimental analysis of the necessity and sufficiency of microbes in animal biology by deriving animals germ-free (GF) and inoculating them with defined microbial lineages. Mammalian host models have long dominated gnotobiology, but we have recently adapted gnotobiotic approaches to the zebrafish (Danio rerio), an important aquatic model. Zebrafish offer several experimental attributes that enable rapid, large-scale gnotobiotic experimentation with high replication rates and exquisite optical resolution. Here we describe detailed protocols for three procedures that form the foundation of zebrafish gnotobiology: derivation of GF embryos, microbial association of GF animals, and long-term, GF husbandry. Our aim is to provide sufficient guidance in zebrafish gnotobiotic methodology to expand and enrich this exciting field of research.},
	language = {eng},
	journal = {Methods in Cell Biology},
	author = {Melancon, E. and Gomez De La Torre Canny, S. and Sichel, S. and Kelly, M. and Wiles, T. J. and Rawls, J. F. and Eisen, J. S. and Guillemin, K.},
	year = {2017},
	pmid = {28129860},
	pmcid = {PMC5568843},
	keywords = {Animals, Axenic, Bacterial colonization, Biological Evolution, Germ-Free Life, Germ-free, Gnotobiotic, Husbandry, Mammals, Microbiome, Microbiota, Sterile, Zebrafish},
	pages = {61--100},
}

@article{richardson_zebrafish_2017,
	title = {The zebrafish eye—a paradigm for investigating human ocular genetics},
	volume = {31},
	issn = {0950-222X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5233929/},
	doi = {10.1038/eye.2016.198},
	abstract = {Although human epidemiological and genetic studies are essential to elucidate the aetiology of normal and aberrant ocular development, animal models have provided us with an understanding of the pathogenesis of multiple developmental ocular malformations. Zebrafish eye development displays in depth molecular complexity and stringent spatiotemporal regulation that incorporates developmental contributions of the surface ectoderm, neuroectoderm and head mesenchyme, similar to that seen in humans. For this reason, and due to its genetic tractability, external fertilisation, and early optical clarity, the zebrafish has become an invaluable vertebrate system to investigate human ocular development and disease. Recently, zebrafish have been at the leading edge of preclinical therapy development, with their amenability to genetic manipulation facilitating the generation of robust ocular disease models required for large-scale genetic and drug screening programmes. This review presents an overview of human and zebrafish ocular development, genetic methodologies employed for zebrafish mutagenesis, relevant models of ocular disease, and finally therapeutic approaches, which may have translational leads in the future.},
	number = {1},
	urldate = {2020-09-07},
	journal = {Eye},
	author = {Richardson, R and Tracey-White, D and Webster, A and Moosajee, M},
	month = jan,
	year = {2017},
	pmid = {27612182},
	pmcid = {PMC5233929},
	pages = {68--86},
}

@article{melancon_best_2017-1,
	title = {Best practices for germ-free derivation and gnotobiotic zebrafish husbandry},
	volume = {138},
	issn = {0091-679X},
	doi = {10.1016/bs.mcb.2016.11.005},
	abstract = {All animals are ecosystems with resident microbial communities, referred to as microbiota, which play profound roles in host development, physiology, and evolution. Enabled by new DNA sequencing technologies, there is a burgeoning interest in animal-microbiota interactions, but dissecting the specific impacts of microbes on their hosts is experimentally challenging. Gnotobiology, the study of biological systems in which all members are known, enables precise experimental analysis of the necessity and sufficiency of microbes in animal biology by deriving animals germ-free (GF) and inoculating them with defined microbial lineages. Mammalian host models have long dominated gnotobiology, but we have recently adapted gnotobiotic approaches to the zebrafish (Danio rerio), an important aquatic model. Zebrafish offer several experimental attributes that enable rapid, large-scale gnotobiotic experimentation with high replication rates and exquisite optical resolution. Here we describe detailed protocols for three procedures that form the foundation of zebrafish gnotobiology: derivation of GF embryos, microbial association of GF animals, and long-term, GF husbandry. Our aim is to provide sufficient guidance in zebrafish gnotobiotic methodology to expand and enrich this exciting field of research.},
	language = {eng},
	journal = {Methods in Cell Biology},
	author = {Melancon, E. and Gomez De La Torre Canny, S. and Sichel, S. and Kelly, M. and Wiles, T. J. and Rawls, J. F. and Eisen, J. S. and Guillemin, K.},
	year = {2017},
	pmid = {28129860},
	pmcid = {PMC5568843},
	keywords = {Animals, Axenic, Bacterial colonization, Biological Evolution, Germ-Free Life, Germ-free, Gnotobiotic, Husbandry, Mammals, Microbiome, Microbiota, Sterile, Zebrafish},
	pages = {61--100},
}

@article{kostic_exploring_2013-1,
	title = {Exploring host–microbiota interactions in animal models and humans},
	volume = {27},
	issn = {0890-9369, 1549-5477},
	url = {http://genesdev.cshlp.org/content/27/7/701},
	doi = {10.1101/gad.212522.112},
	abstract = {The animal and bacterial kingdoms have coevolved and coadapted in response to environmental selective pressures over hundreds of millions of years. The meta'omics revolution in both sequencing and its analytic pipelines is fostering an explosion of interest in how the gut microbiome impacts physiology and propensity to disease. Gut microbiome studies are inherently interdisciplinary, drawing on approaches and technical skill sets from the biomedical sciences, ecology, and computational biology. Central to unraveling the complex biology of environment, genetics, and microbiome interaction in human health and disease is a deeper understanding of the symbiosis between animals and bacteria. Experimental model systems, including mice, fish, insects, and the Hawaiian bobtail squid, continue to provide critical insight into how host–microbiota homeostasis is constructed and maintained. Here we consider how model systems are influencing current understanding of host–microbiota interactions and explore recent human microbiome studies.},
	language = {en},
	number = {7},
	urldate = {2020-09-07},
	journal = {Genes \& Development},
	author = {Kostic, Aleksandar D. and Howitt, Michael R. and Garrett, Wendy S.},
	month = apr,
	year = {2013},
	pmid = {23592793},
	note = {Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Institution: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Publisher: Cold Spring Harbor Lab},
	keywords = {microbiome, microbiota, model organisms, symbiosis},
	pages = {701--718},
}

@article{rana_wearable_2020,
	title = {Wearable {Sensors} for {Real}-{Time} {Kinematics} {Analysis} in sports: {A} {Review}},
	issn = {1558-1748},
	shorttitle = {Wearable {Sensors} for {Real}-{Time} {Kinematics} {Analysis} in sports},
	doi = {10.1109/JSEN.2020.3019016},
	abstract = {Wearable Inertial sensors have revolutionised the way kinematics analysis is performed in sports. This paper aims to present a comprehensive review of the literature related to the use of wearable inertial sensors for performance analysis in various games. Kinematics analysis using wearable sensors can provide real-time feedback to the players about their adopted techniques in their respective sports and thus help them to perform efficiently. This paper reviews the key technologies (IMU sensors, communication technology, data fusion and data analysis techniques) that enable the implementation of wearable sensors for performance analysis in sports. The review focuses on research papers, commercial sports sensors and 3D motion tracking products to provide a holistic and systematic categorisation \& analysis of the wearable sensors in sports. The review identifies the importance of sensors classification, applications and performance parameters in sports for structured analysis. The survey also reviews the technology concerning sensor architecture, network and communication protocols, covers various data fusion algorithms and their accuracy while throwing light on essential performance matrices for an athlete. This review paper will assist both end-users and the researchers to have a comprehensive glimpse of the wearable technology pertaining to designing sensors and solutions for athletes in different sports.},
	journal = {IEEE Sensors Journal},
	author = {Rana, Manju and Mittal, Vikas},
	year = {2020},
	note = {Conference Name: IEEE Sensors Journal},
	keywords = {3D Motion Tracking, Gyroscopes, IMU sensors, Magnetic sensors, Sensor fusion, Sensor systems, Wearable inertial sensors, Wearable sensors, accelerometer, data analytics, gyroscope, kinematics analysis, magnetometer, performance analysis},
	pages = {1--1},
}

@misc{noauthor_evaluation_nodate,
	title = {Evaluation of {Validity} and {Reliability} of {Inertial} {Measurement} {Unit}-{Based} {Gait} {Analysis} {Systems}},
	url = {https://www.e-arm.org/journal/view.php?doi=10.5535/arm.2018.42.6.872},
	urldate = {2020-08-21},
}

@article{dai_derivative_2017,
	title = {Derivative {Principal} {Component} {Analysis} for {Representing} the {Time} {Dynamics} of {Longitudinal} and {Functional} {Data}},
	url = {http://arxiv.org/abs/1707.04360},
	abstract = {We propose a nonparametric method to explicitly model and represent the derivatives of smooth underlying trajectories for longitudinal data. This representation is based on a direct Karhunen--Lo{\textbackslash}`eve expansion of the unobserved derivatives and leads to the notion of derivative principal component analysis, which complements functional principal component analysis, one of the most popular tools of functional data analysis. The proposed derivative principal component scores can be obtained for irregularly spaced and sparsely observed longitudinal data, as typically encountered in biomedical studies, as well as for functional data which are densely measured. Novel consistency results and asymptotic convergence rates for the proposed estimates of the derivative principal component scores and other components of the model are derived under a unified scheme for sparse or dense observations and mild conditions. We compare the proposed representations for derivatives with alternative approaches in simulation settings and also in a wallaby growth curve application. It emerges that representations using the proposed derivative principal component analysis recover the underlying derivatives more accurately compared to principal component analysis-based approaches especially in settings where the functional data are represented with only a very small number of components or are densely sampled. In a second wheat spectra classification example, derivative principal component scores were found to be more predictive for the protein content of wheat than the conventional functional principal component scores.},
	urldate = {2020-08-18},
	journal = {arXiv:1707.04360 [math, stat]},
	author = {Dai, Xiongtao and Müller, Hans-Georg and Tao, Wenwen},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.04360},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
}

@article{rao_statistical_1958,
	title = {Some statistical methods for comparison of growth curves},
	volume = {14},
	issn = {1541-0420(Electronic),0006-341X(Print)},
	doi = {10.2307/2527726},
	abstract = {The problem of comparing the characteristics of growth under different conditions is approached by replacing the observations by summary figures. Reducing the data to a minimum number of dimensions and developing tests of significance are the purposes of this paper. Tests are developed to examine whether, by a common transformation, the curves of different groups can be made linear and to test whether the slopes are the same. A factor-analysis model is examined, and a general solution for continuous curves is discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Biometrics},
	author = {Rao, C. Radhakrishma},
	year = {1958},
	pages = {1--17},
}

@article{noauthor_notitle_nodate,
}

@article{goldsmith_corrected_2013,
	title = {Corrected {Confidence} {Bands} for {Functional} {Data} {Using} {Principal} {Components}},
	volume = {69},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2012.01808.x},
	doi = {10.1111/j.1541-0420.2012.01808.x},
	abstract = {Functional principal components (FPC) analysis is widely used to decompose and express functional observations. Curve estimates implicitly condition on basis functions and other quantities derived from FPC decompositions; however these objects are unknown in practice. In this article, we propose a method for obtaining correct curve estimates by accounting for uncertainty in FPC decompositions. Additionally, pointwise and simultaneous confidence intervals that account for both model- and decomposition-based variability are constructed. Standard mixed model representations of functional expansions are used to construct curve estimates and variances conditional on a specific decomposition. Iterated expectation and variance formulas combine model-based conditional estimates across the distribution of decompositions. A bootstrap procedure is implemented to understand the uncertainty in principal component decomposition quantities. Our method compares favorably to competing approaches in simulation studies that include both densely and sparsely observed functions. We apply our method to sparse observations of CD4 cell counts and to dense white-matter tract profiles. Code for the analyses and simulations is publicly available, and our method is implemented in the R package refund on CRAN.},
	language = {en},
	number = {1},
	urldate = {2020-08-15},
	journal = {Biometrics},
	author = {Goldsmith, J. and Greven, S. and Crainiceanu, C.},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2012.01808.x},
	keywords = {Bootstrap, Functional principal components analysis, Iterated expectation and variance, Simultaneous bands},
	pages = {41--51},
}

@article{ford_reliability_2007,
	title = {Reliability of landing {3D} motion analysis: implications for longitudinal analyses},
	volume = {39},
	issn = {0195-9131},
	shorttitle = {Reliability of landing {3D} motion analysis},
	doi = {10.1249/mss.0b013e318149332d},
	abstract = {PURPOSE: Biomechanical measures quantified during dynamic tasks with coupled epidemiological data in longitudinal experimental designs may be useful to determine which mechanisms underlie injury risk in young athletes. A key component is the ability to reliably measure biomechanical variables between testing sessions. The purpose was to determine the reliability of three-dimensional (3D) lower-extremity kinematic and kinetic variables during landing in young athletes measured within a session and between two sessions 7 wk apart.
METHODS: Lower-extremity kinetics and kinematics were quantified during a drop vertical jump. Coefficient of multiple correlations (CMC), intraclass correlation coefficients (ICC (3, k), ICC (3, 1)), and typical error (TE) analyses were used to examine within- and between-session reliability.
RESULTS: There were no differences in within-session reliability for peak angular rotations between planes with all discrete variables combined (sagittal ICC {\textgreater} or = 0.933, frontal ICC {\textgreater} or = 0.955, transverse ICC {\textgreater} or = 0.934). Similarly, the between-session reliability of kinematic measures were not different between the three planes of motion but were lower than the within-session ICC. The within- and between-session reliability of discrete joint moment variables were excellent for all sagittal (within ICC {\textgreater} or = 0.925, between ICC {\textgreater} or = 0.800) and frontal plane moment measures (within ICC {\textgreater} or = 0.778, between ICC {\textgreater} or = 0.748). CMC analysis revealed similar averaged within-session (CMC = 0.830 +/- 0.119) and between-session (CMC = 0.823 +/- 0.124) waveform comparisons.
CONCLUSION: The majority of the kinematic and kinetic variables in young athletes during landing have excellent to good reliability. The ability to reliably quantify lower-extremity biomechanical variables of young athletes during dynamic tasks over extended intervals may aid in identifying potential mechanisms related to injury risk factors.},
	language = {eng},
	number = {11},
	journal = {Medicine and Science in Sports and Exercise},
	author = {Ford, Kevin R. and Myer, Gregory D. and Hewett, Timothy E.},
	month = nov,
	year = {2007},
	pmid = {17986911},
	keywords = {Adolescent, Athletic Injuries, Biomechanical Phenomena, Cohort Studies, Female, Humans, Longitudinal Studies, Male, Motion, Reproducibility of Results, United States},
	pages = {2021--2028},
}

@article{ramsay_tools_1991,
	title = {Some {Tools} for {Functional} {Data} {Analysis}},
	volume = {53},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2345586},
	abstract = {Multivariate data analysis permits the study of observations which are finite sets of numbers, but modern data collection situations can involve data, or the processes giving rise to them, which are functions. Functional data analysis involves infinite dimensional processes and/or data. The paper shows how the theory of L-splines can support generalizations of linear modelling and principal components analysis to samples drawn from random functions. Spline smoothing rests on a partition of a function space into two orthogonal subspaces, one of which contains the obvious or structural components of variation among a set of observed functions, and the other of which contains residual components. This partitioning is achieved through the use of a linear differential operator, and we show how the theory of polynomial splines can be applied more generally with an arbitrary operator and associated boundary constraints. These data analysis tools are illustrated by a study of variation in temperature-precipitation patterns among some Canadian weather-stations.},
	number = {3},
	urldate = {2020-08-12},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Ramsay, J. O. and Dalzell, C. J.},
	year = {1991},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {539--572},
}

@article{tian_functional_2010,
	title = {Functional {Data} {Analysis} in {Brain} {Imaging} {Studies}},
	volume = {1},
	issn = {1664-1078},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3153754/},
	doi = {10.3389/fpsyg.2010.00035},
	abstract = {Functional data analysis (FDA) considers the continuity of the curves or functions, and is a topic of increasing interest in the statistics community. FDA is commonly applied to time-series and spatial-series studies. The development of functional brain imaging techniques in recent years made it possible to study the relationship between brain and mind over time. Consequently, an enormous amount of functional data is collected and needs to be analyzed. Functional techniques designed for these data are in strong demand. This paper discusses three statistically challenging problems utilizing FDA techniques in functional brain imaging analysis. These problems are dimension reduction (or feature extraction), spatial classification in functional magnetic resonance imaging studies, and the inverse problem in magneto-encephalography studies. The application of FDA to these issues is relatively new but has been shown to be considerably effective. Future efforts can further explore the potential of FDA in functional brain imaging studies.},
	urldate = {2020-08-12},
	journal = {Frontiers in Psychology},
	author = {Tian, Tian Siva},
	month = oct,
	year = {2010},
	pmid = {21833205},
	pmcid = {PMC3153754},
}

@book{ramsay_functional_2009,
	address = {New York},
	series = {Use {R}!},
	title = {Functional {Data} {Analysis} with {R} and {MATLAB}},
	isbn = {978-0-387-98184-0},
	url = {https://www.springer.com/gp/book/9780387981840},
	abstract = {Scientists often collect samples of curves and other functional observations, and develop models where parameters are also functions. This volume in the UseR! Series is aimed at a wide range of readers, and especially those who would like apply these techniques to their research problems. It complements Functional Data Analysis, Second Edition and Applied Functional Data Analysis: Methods and Case Studies by providing computer code in both the R and Matlab languages for a set of data analyses that showcase functional data analysis techniques. The authors make it easy to get up and running in new applications by adapting the code for the examples, and by being able to access the details of key functions within these pages. This book is accompanied by additional web-based support at http://www.functionaldata.org for applying existing functions and developing new ones in either language. The companion 'fda' package for R includes script files to reproduce nearly all the examples in the book including all but one of the 76 figures. Jim Ramsay is Professor Emeritus at McGill University and is an international authority on many aspects of multivariate analysis. He was President of the Statistical Society of Canada in 2002-3 and holds the Society’s Gold Medal for his work in functional data analysis. His statistical work draws on his collaboration with researchers in biomechanics, chemical engineering, climatology, ecology, economics, human biology, medicine and psychology. Giles Hooker is Assistant Professor of Biological Statistics and Computational Biology at Cornell University. His research interests include statistical inference in nonlinear dynamics, machine learning and computational statistics. Spencer Graves is an engineer with a PhD in Statistics and over 15 years experience using S-Plus and R to analyze data in a broad range of applications. He has made substantive contributions to several CRAN packages including ‘fda’ and ‘DierckxSpline.’},
	language = {en},
	urldate = {2020-08-12},
	publisher = {Springer-Verlag},
	author = {Ramsay, James O. and Hooker, Giles and Graves, Spencer},
	year = {2009},
	doi = {10.1007/978-0-387-98185-7},
}

@article{wang_review_2015,
	title = {Review of {Functional} {Data} {Analysis}},
	url = {http://arxiv.org/abs/1507.05135},
	abstract = {With the advance of modern technology, more and more data are being recorded continuously during a time interval or intermittently at several discrete time points. They are both examples of "functional data", which have become a prevailing type of data. Functional Data Analysis (FDA) encompasses the statistical methodology for such data. Broadly interpreted, FDA deals with the analysis and theory of data that are in the form of functions. This paper provides an overview of FDA, starting with simple statistical notions such as mean and covariance functions, then covering some core techniques, the most popular of which is Functional Principal Component Analysis (FPCA). FPCA is an important dimension reduction tool and in sparse data situations can be used to impute functional data that are sparsely observed. Other dimension reduction approaches are also discussed. In addition, we review another core technique, functional linear regression, as well as clustering and classification of functional data. Beyond linear and single or multiple index methods we touch upon a few nonlinear approaches that are promising for certain applications. They include additive and other nonlinear functional regression models, such as time warping, manifold learning, and dynamic modeling with empirical differential equations. The paper concludes with a brief discussion of future directions.},
	urldate = {2020-08-12},
	journal = {arXiv:1507.05135 [stat]},
	author = {Wang, Jane-Ling and Chiou, Jeng-Min and Mueller, Hans-Georg},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.05135},
	keywords = {62, Statistics - Methodology},
}
